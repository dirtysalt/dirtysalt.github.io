<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Spark SQL: Relational Data Processing in Spark</title>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content">
<h1 class="title">Spark SQL: Relational Data Processing in Spark</h1>
<p>
这个东西在Spark的生态中特别有用，尤其是在ML领域。读下来的感觉就是，这个东西的亮点主要是在接口设计上，计算实现则完全依赖于Spark计算引擎：
</p>
<ol class="org-ol">
<li>不像常见的OLAP提供的SQL界面，Spark SQL的界面是DataFrame API，这个东西在ML领域非常常见。
</li>
<li>SQL/Query优化引擎叫做Catalyst，它的特点就是非常地Extensible，允许用户编写带来来扩展数据源(data sources)，优化规则(optimizations)，以及数据类型(data types)
</li>
</ol>

<p>
下面4点是Spark SQL的设计目标：
</p>
<ol class="org-ol">
<li>Support relational processing both within Spark programs (on native RDDs) and on external data sources using a programmer- friendly API.
</li>
<li>Provide high performance using established DBMS techniques.
</li>
<li>Easily support new data sources, including semi-structured data and external databases amenable to query federation.
</li>
<li>Enable extension with advanced analytics algorithms such as graph processing and machine learning.
</li>
</ol>

<p>
Spark SQL 在 Spark ecosystem中占据的位置：强化Spark作为底层执行引擎，而Spark SQL作为用户界面
</p>


<div class="figure">
<p><img src="images/spark-sql-interfaces.png" alt="spark-sql-interfaces.png" />
</p>
</div>

<p>
下图是Spark SQL的的执行过程，catalyst optimizers是里面所有圆形边角的长方形区域：
</p>
<ol class="org-ol">
<li>logical optimization 主要靠pattern matching 对tree进行rule-based rewrite
</li>
<li>physical planning 将logical plan使用spark operator改写成为physical plan
</li>
<li>phyiscal optimization 则包含将projection以及filter尽可能地push down以及pipeline, 这是rule-based optimization. 而在选择join算法上使用cost-based optimization.
</li>
<li>因为这个东西是JVM编写的，所以使用了一个叫做 `quasiquotes` 的库动态生成JVM code，就是code generation部分
</li>
<li>现阶段用户的扩展点主要是在data source以及user-defined types上。扩展data source告诉catalyst如何scan, PrunedScan(选择特定columns), 以及PrunedFilteredScan(选择特定columns以及filter objects).
</li>
</ol>


<div class="figure">
<p><img src="images/spark-sql-query-planning.png" alt="spark-sql-query-planning.png" />
</p>
</div>
</div>
</body>
</html>
