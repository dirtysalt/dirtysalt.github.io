<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Computer Architecture Readings - Princeton - Review/Superscalar/VLIW</title>
<meta name="author" content="dirtysalt" />
<meta name="generator" content="Org Mode" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content" class="content">
<h1 class="title">Computer Architecture Readings - Princeton - Review/Superscalar/VLIW</h1>
<p>
<b>ELE/COS 475 Computer Architecture</b>
</p>

<hr />

<p>
计算机架构在不断变化，有同时来自门电路技术改进以及软件需求。计算机体系结构主要研究中间三层：ISA，微架构，RTL。下面开始的门电路/逻辑电路属于更底层的硬件层，而上面则属于软件层。
</p>


<div id="org5d9513a" class="figure">
<p><img src="../images/Pasted-Image-20231225103940.png" alt="Pasted-Image-20231225103940.png" />
</p>
</div>

<p>
ISA和Microarch之间的差别，对于软件开发者只需要关注到ISA这层就行，而MA层则是由芯片设计者来决定如何高效地实现ISA这层语义。
</p>

<p>
Architecture vs. Microarchitecture “Architecture”/Instruction Set Architecture:
</p>
<ul class="org-ul">
<li>Programmer visible state (Memory &amp; Register)</li>
<li>Operations (Instructions and how they work)</li>
<li>Execution Semantics (interrupts)</li>
<li>Input/Output</li>
<li>Data Types/Sizes</li>
</ul>

<p>
Microarchitecture/Organization:
</p>
<ul class="org-ul">
<li>Tradeoffs on how to implement ISA for some metric (Speed, Energy, Cost)</li>
<li>Examples: Pipeline depth, number of pipelines, cache size, silicon area, peak power, execution ordering, bus widths, ALU widths</li>
</ul>

<p>
ISA差异很大的原因有下面这些
</p>

<p>
Technology Influenced ISA
</p>
<ul class="org-ul">
<li>Storage is expensive, tight encoding important</li>
<li>Reduced Instruction Set Computer</li>
<li>Remove instructions until whole computer fits on die</li>
<li>Multicore/Manycore
– Transistors not turning into sequential performance</li>
</ul>

<p>
Application Influenced ISA
</p>
<ul class="org-ul">
<li>Instructions for Applications
<ul class="org-ul">
<li>DSP instructions</li>
</ul></li>
<li>Compiler Technology has improved
<ul class="org-ul">
<li>SPARC Register Windows no longer needed – Compiler can register allocate effectively</li>
</ul></li>
</ul>

<hr />

<p>
顺序处理器的性能变化，RISC出现在1986年，2006年开始放弃在单核上做改进转向多核。
</p>


<div id="org67486fa" class="figure">
<p><img src="../images/Pasted-Image-20231225103933.png" alt="Pasted-Image-20231225103933.png" />
</p>
</div>


<p>
现代处理器需要考虑的事情非常多：指令/数据/线程级别并行，超长流水，内存和缓存技术
</p>


<div id="orgf0659e8" class="figure">
<p><img src="../images/Pasted-Image-20231225104046.png" alt="Pasted-Image-20231225104046.png" />
</p>
</div>

<p>
指令中几种阻碍深流水线的因素：
</p>

<ul class="org-ul">
<li>Structural Hazard: An instruction in the pipeline needs a resource being used by another instruction in the pipeline (使用到相同的运算/控制单元，解决办法如下)
<ul class="org-ul">
<li>Schedule: Programmer explicitly avoids scheduling instructions that would create structural hazards 调整指令熟顺序</li>
<li>Stall: Hardware includes control logic that stalls until earlier instruction is no longer using contended resource 暂停流水</li>
<li>Duplicate: Add more hardware to design so that each instruction can access independent resources at the same time 冗余的运算/控制单元</li>
</ul></li>

<li>Data Hazard: An instruction depends on a data value produced by an earlier instruction（多条指令之间存在数据依赖，解决办法如下）
<ul class="org-ul">
<li>Schedule: Programmer explicitly avoids scheduling instructions that would create data hazards 调整指令顺序</li>
<li>Stall: Hardware includes control logic that freezes earlier stages until preceding instruction has finished producing data value 暂停流水</li>
<li>Bypass: Hardware datapath allows values to be sent to an earlier stage before preceding instruction has left the pipeline 调整流水线结构，可以提前得到数据</li>
<li>Speculate: Guess that there is not a problem, if incorrect kill speculative instruction and restart 推测执行</li>
</ul></li>

<li>Control Hazard: Whether or not an instruction should be executed depends on a control decision made by an earlier instruction（控制结构比jb/jbe/jmp这些，使用分支预测解决）</li>
</ul>

<hr />

<p>
几种常见/可预测的内存访问模式，可以看到都是满足时间/空间局部性的：获取指令，堆栈访问，向量/标量化数据的访问。
</p>


<div id="org991950c" class="figure">
<p><img src="../images/Pasted-Image-20231225104051.png" alt="Pasted-Image-20231225104051.png" />
</p>
</div>

<p>
可视化地观察时间/空间局部性
</p>


<div id="orgd50642c" class="figure">
<p><img src="../images/Pasted-Image-20231225103816.png" alt="Pasted-Image-20231225103816.png" />
</p>
</div>

<p>
Cache几种Missing分类：3C, Compulsory(第一次访问), Capacity(容量不够造成的淘汰), Conflict(冲突造成的淘汰， 实际上容量是足够的)
</p>


<div id="org869d796" class="figure">
<p><img src="../images/Pasted-Image-20231225103817.png" alt="Pasted-Image-20231225103817.png" />
</p>
</div>

<p>
Cache设计上的权衡：N-way, Block Cache, Cache Size. Block Cache在64, N-way上越大越好，Cache Size越大越好。
</p>

<p>
N-way上, 1-way的访问时间是最短的，但是2/4/8时间其实差别不大很大，但是1-way的miss rate却非常高，所以理论上选择8-way是应该是更好的选择。
</p>


<div id="org525c7e5" class="figure">
<p><img src="../images/Pasted-Image-20231225103711.png" alt="Pasted-Image-20231225103711.png" />
</p>
</div>


<div id="orgab25960" class="figure">
<p><img src="../images/Pasted-Image-20231225103708.png" alt="Pasted-Image-20231225103708.png" />
</p>
</div>

<p>
Cache Block Size Pros &amp; Cons: 好处就是一次获取数据更多带宽更大，而坏处就是如果数据没有完全访问的话那么就相当于浪费带宽，而且更大的Block Size会导致更少的cache items, 冲突率更大。从下图可以看到几乎Block Size = 64 是个最优值，不过也不好说是不是软件在优化上就使用了block size = 64这个事实。
</p>


<div id="orgea3ca9c" class="figure">
<p><img src="../images/Pasted-Image-20231225104356.png" alt="Pasted-Image-20231225104356.png" />
</p>
</div>

<p>
Cache Size有个法则就是：Cache Size翻倍， miss rate降低30%. (1-1/(2^0.5))
</p>


<div id="org69e3e91" class="figure">
<p><img src="../images/Pasted-Image-20231225104403.png" alt="Pasted-Image-20231225104403.png" />
</p>
</div>

<hr />

<p>
VLIW要求将多条操作打包在一个指令里面，并且操作之间是相互独立的：使用不同的计算/控制单元，不存在数据之间的依赖。从PPT里面来看，每个slot里面还有具体的cycle latency要求，看起来这个对于编译器的要求非常高。
</p>


<div id="org6f0d45b" class="figure">
<p><img src="../images/Pasted-Image-20231225103339.png" alt="Pasted-Image-20231225103339.png" />
</p>
</div>

<p>
实际上VLIW问题是比较多的（一些点没有看懂）：
</p>

<p>
VLIW Compiler Responsibilities
</p>
<ul class="org-ul">
<li>Schedule operations to maximize parallel execution</li>
<li>Guarantees intra-instruction parallelism</li>
<li>Schedule to avoid data hazards (no interlocks)
<ul class="org-ul">
<li>Typically separates operations with explicit NOPs</li>
</ul></li>
</ul>

<p>
Problems with “Classic” VLIW
</p>
<ul class="org-ul">
<li>Object-code compatibility (二进制兼容性)
<ul class="org-ul">
<li>have to recompile all code for every machine, even for two machines in same generation</li>
</ul></li>
<li>Object code size (二进制大小)
<ul class="org-ul">
<li>instruction padding wastes instruction memory/cache</li>
<li>loop unrolling/software pipelining replicates code</li>
</ul></li>
<li>Scheduling variable latency memory operations
<ul class="org-ul">
<li>caches and/or memory bank conflicts impose statically unpredictable variability</li>
</ul></li>
<li>Knowing branch probabilities
<ul class="org-ul">
<li>Profiling requires an significant extra step in build process</li>
</ul></li>
<li>Scheduling for statically unpredictable branches
<ul class="org-ul">
<li>optimal schedule varies with branch path</li>
</ul></li>
<li>Precise Interrupts can be challenging
– Does fault in one portion of bundle fault whole bundle?
– EQ Model has problem with single step, etc.</li>
</ul>
</div>
</body>
</html>
