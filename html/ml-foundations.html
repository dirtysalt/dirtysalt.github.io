<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>机器学习基石 on Coursera</title>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content">
<h1 class="title">机器学习基石 on Coursera</h1>
<p>
<a href="https://class.coursera.org/ntumlone-002">https://class.coursera.org/ntumlone-002</a>
</p>

<ul class="org-ul">
<li>UPDATE@2018-01 在Coursera上面好像拆分成为了两门课程，《机器学习技法》这么课程下架了。
<ul class="org-ul">
<li><a href="https://www.coursera.org/learn/ntumlone-mathematicalfoundations/home/welcome">https://www.coursera.org/learn/ntumlone-mathematicalfoundations/home/welcome</a>
</li>
<li><a href="https://www.coursera.org/learn/ntumlone-algorithmicfoundations/home/welcome">https://www.coursera.org/learn/ntumlone-algorithmicfoundations/home/welcome</a>
</li>
</ul>
</li>
<li>在林老师的 <a href="https://www.csie.ntu.edu.tw/~htlin/mooc/">主页</a> 上这两门课程的所有材料和视频
</li>
</ul>

<hr  />
<p>
L1 机器学习介绍
</p>

<p>
和其他三个领域之间的差别和关系
</p>


<div class="figure">
<p><img src="images/ntuml-ml-related-fields.png" alt="ntuml-ml-related-fields.png" />
</p>
</div>

<hr  />
<p>
L2 PLA(Perceptron Learning Algorithm)
</p>

<hr  />
<p>
L3 机器学习分类
</p>
<ul class="org-ul">
<li>输出类型分类：classification/regression/structured(结构化)
</li>
<li>数据标签分类：supervised/unsupervised/semi-supervised(获得标签代价非常高)/reinforcement(强化，返回反馈满意度)
</li>
<li>输入方式分类：batch/online/active. 其中online和active都是顺序处理数据，但是active能够主动提问
</li>
<li>输入特征分类：concrete/raw/abstract. abstract相比raw特征更加隐蔽. 转换为concrete特征需要domain-knowledge来做辅助.
</li>
</ul>

<hr  />
<p>
L4-L7 学习可行性分析
</p>
<ul class="org-ul">
<li>通常一个模型model会对应很多参数，给定一个参数就对应一个hypothesis. 因此model实际上给出的是一个假设集合hypothesis-set, 我们记为H.
</li>
<li>从Hoeffding不等式，到H即hypothesis-set的effective-number/break-point，到更加正式的定义vc-dimension.
</li>
<li>vc-dimension只和H有关，或者说只和model有关。vc物理意义是：H处理二分类问题有多少自由度。vc越大说明H选择更多，能力越强，也说明越复杂。
</li>
<li>model/H进行训练效果满足不等式 P(|u-v| &gt; e) &lt;= 2 * (2N)^vc * exp(-2 * e^2 * N). 其中vc是H的vc-dimension.
</li>
<li>从上面不等式可以看到，vc和N(数据集合大小)之间存在trade-off. vc越大H选择越多，但是需要更多的数据才能找到更好的假设。
</li>
</ul>


<div class="figure">
<p><img src="images/ntuml-theoretical-bounds.png" alt="ntuml-theoretical-bounds.png" />
</p>
</div>

<hr  />
<p>
L8 噪音和误差
</p>
<ul class="org-ul">
<li>引入噪音并不会改变H的vc-dimension. 因此即使训练数据里面包含噪音，我们依然能够进行训练和学习。
</li>
<li>衡量误差的时候，我们可能会针对false-positive/false-negative给出不同的penalty或者是weight. 这种效果等价于我们对dataset这些错误输入进行virtual-copy.
</li>
</ul>

<hr  />
<p>
L9-L11 线性回归，逻辑回归，线性模型
</p>
<ul class="org-ul">
<li>线性回归中，使用最小二乘法作为代价函数的话，那么可以使用分析方法计算出w = ((x' * x) ^ -1 * x') * y. 前半部分我们可以称之为pseudo-inverse, 记为x*.
</li>
<li>线性回归中，如果将w作用在x上的话就可以求解出预测向量y' = x * x* * y = (x * x*) * y. 我们将(x * x*)称为hat-matrix/H.
</li>
<li>逻辑回归的损失函数，通过合适的缩放，可以看做是err0/1分类损失函数的上限。因此逻辑回归函数可以用来做二分分类。
</li>
<li>OVA(one-versus-all)来求解K多分类问题：1. 需要跑K个二分类问题，每个二分类问题处理N条记录 2. 如果K太大容易造成数据倾斜.
</li>
<li>OVO(one-versus-one)来求解K多分类问题：1. 可以避免OVA出现的数据倾斜问题 2. 需要跑K*(K-1)*0.5个二分类问题，每个二分类问题只处理2*N/K个记录.
</li>
</ul>

<hr  />
<p>
L12 非线性变换
</p>

<hr  />
<p>
L13-L15 过拟合，正则化，验证
</p>
<ul class="org-ul">
<li>泛化能力不好表现loww Ein, high Eout. 过拟合表现是lower Ein, higher Eout.
</li>
<li>出现过拟合的原因有这些： 1. vc过大 2. 夹杂噪音 3. 数据量不够
</li>
<li>即使target-function是10th多项式，那么2th多项式H2给出的结果不一定会比10th多项式H10差。虽然可能Ein(H2) &gt; Ein(H2), 但是更有可能是Eout(H2) &lt; Eout(H10).
<ul class="org-ul">
<li>可以看出部分原因我们还没有学习足够多的数据集合
</li>
<li>而且对于vc越大的H需要学习数据量越大才能获得较好效果
</li>
</ul>
</li>
</ul>


<div class="figure">
<p><img src="images/ntuml-overfitting-learning-curve.png" alt="ntuml-overfitting-learning-curve.png" />
</p>
</div>

<ul class="org-ul">
<li>噪音可以分为两类：stochastic noise(随机噪音)表示数据集合本身偏差引入的，deterministic noise(确定噪音)表示target-function自身复杂性引入的。
<ul class="org-ul">
<li>比如伪随机数(噪音多)就是使用复杂的(高阶)函数来模拟产生的.
</li>
</ul>
</li>
</ul>

<div class="figure">
<p><img src="images/ntuml-overfitting-noise-and-data-size.png" alt="ntuml-overfitting-noise-and-data-size.png" />
</p>
</div>

<ul class="org-ul">
<li>解决过拟合问题有下面几个手段 1. 先从简单模型入手 2. data cleaning/pruning 3. data hinting 4.regularization 5. validation
</li>
<li>引入regularization非常有启发性：通过限制w'w &lt;= C，使用Lagrange Multiplier(拉格朗日乘子法), 推导出weight-decay regularization也就是ridge regression
</li>
<li>如果需要使用多项式变换的话，应该选用Legendre多项式，可以认为这些多项式之间是相互"正交"的。
<ul class="org-ul">
<li>因为如果我们只是用x^n来做多项式的话，那么高次方的x^n值通常很小，因此要求对应项的w很大。
</li>
<li>而这与regularization相悖，因为正规化项要求w应该尽可能小。
</li>
</ul>
</li>
<li>通常使用5~10-Fold来做CV. 训练像是初赛，CV则像是复赛，只有最终测试才是决赛。所以我们要关注应该是测试效果，而不是验证效果。
</li>
</ul>

<hr  />
<p>
L16 学习三原则
</p>

<p>
Sampling Bias（采样偏差）表明我们需要仔细了解数据收集产生的过程。如果收集产生过程本身就有偏差的话，那么我们在训练和验证阶段就需要将偏差考虑进去。
</p>

<p>
Data Snooping（数据窥视）表明我们不能将测试数据加入训练/CV集合，否则会影响训练效果。机器会学习到这些测试数据的特性，影响到泛化能力。
</p>

<p>
不要过早地去查看数据来做出假设和模型，但是有时候确实也需要通过观察数据来选择features和模型，因此我们必须在验证的时候严格把关。按照作者的话说应该就是 "careful balance between data-driven modeling(snooping) and validation(no-snooping)."
</p>

<hr  />
<p>
机器学习和数据挖掘，机器学习和人工智能，机器学习和统计学
</p>

<p>
<img src="images/ntuml-ml-vs-dm.png" alt="ntuml-ml-vs-dm.png" /> <img src="images/ntuml-ml-vs-ai.png" alt="ntuml-ml-vs-ai.png" /> <img src="images/ntuml-ml-vs-st.png" alt="ntuml-ml-vs-st.png" />
</p>
</div>
</body>
</html>
