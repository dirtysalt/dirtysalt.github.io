<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Albis: High-Performance File Format for Big Data Systems</title>
<meta name="author" content="dirtysalt" />
<meta name="generator" content="Org Mode" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content" class="content">
<h1 class="title">Albis: High-Performance File Format for Big Data Systems</h1>
<p>
文章有个假设就是现阶段CPU/IO之间的差距出现了变化，随着100Gbps网卡以及NVMe存储设备的出现，IO速度越来越高，反而CPU处理上出现瓶颈。所以文章认为在文件格式设计上，应该尽可能地减少CPU的处理时间（解压缩以及解码的时间），不使用复杂的编码/压缩方法，另外就是直接使用二进制存储，减少反序列化的时间。最终设计出来的文件格式好像没有什么意思，按照列进行切分，本质上还是row-based format. 每行上所有的column都是使用类似内存的二进制方式紧凑存储的。我觉得文章对我启发最大的点，在于如何说明CPU而非IO开始成为瓶颈。
</p>

<p>
下图是当前情况下大部分大数据系统的架构图，可以看到网卡变为100Gbps, 存储设备换成为NVMe
</p>


<div id="org11db97b" class="figure">
<p><img src="../images/Pasted-Image-20231225103559.png" alt="Pasted-Image-20231225103559.png" />
</p>
</div>


<p>
网卡的带宽提升了一个量级，NVMe的IOPS增大，随机访问速度和顺序访问速度相当（类似SSD），并且允许small access. 底层IO设备的变化，使得原来某些假设变得不再成立。
</p>


<div id="orga0d3c8d" class="figure">
<p><img src="../images/Pasted-Image-20231225103223.png" alt="Pasted-Image-20231225103223.png" />
</p>
</div>

<p>
IOPS的变化可以通过cycle/io unit的比例来观察，假设cpu 1 cycle 可以处理1个network packet(1500byte)，可以处理1个disk sector(512 byte). CPU是3Ghz的话，那么cycles/unit可以看下图。作为参考，memory access的cycles/unit大约是100. 我觉得这个比较方式可以很显然地说明，我们几乎可以把remote disk file当做memory来使用了，虽然还不及cpu cache速度快。
</p>


<div id="org0dcc413" class="figure">
<p><img src="../images/Pasted-Image-20231225104622.png" alt="Pasted-Image-20231225104622.png" />
</p>
</div>

<p>
另外一个关于IO误区就是，我们应该尽可能地读取大的block(128/256MB)，来减disk IO的时间。当然这个误区是基于disk的，到了SSD就不是这么回事了，到了NVMe时代就更是错了。我们还是不能一味地加大read block, 因为这会对内存分配带来很大的压力，对于cache来说也不太友好。
</p>

<p>
Albis File format 设计的几个点是：
</p>
<ol class="org-ol">
<li>no compression or encoding. 降低对CPU的压力</li>
<li>remove object ser/deser by providing binary API. 直接二进制读写</li>
<li>keep metadata/data management simple. 数据管理更加简单，简化IO path.</li>
</ol>

<p>
最终出来的文件格式也比较简单，就是下面这个样子。每个RG上也会存在stats信息，然后也提供了谓词过滤。CG表示column group，有点类似hbase column family. RG表示row group, 数据写到一定量就会切分。不过我在想，如果CG0和CG1的column 大小相差很大的话，岂不是几个RG大小差别也很大。
</p>


<div id="orgbd75154" class="figure">
<p><img src="../images/Pasted-Image-20231225104209.png" alt="Pasted-Image-20231225104209.png" />
</p>
</div>
</div>
</body>
</html>
