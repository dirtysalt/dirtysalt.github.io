<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Hadoop</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="dirtysalt" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content">
<h1 class="title">Hadoop</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org9248be5">1. CDH3u3搭建单节点集群</a></li>
<li><a href="#orgcc82cdb">2. CDH4.2.0搭建单节点集群</a></li>
<li><a href="#org9883c1e">3. CDH4.3.0搭建单节点集群</a></li>
<li><a href="#org791bf78">4. Configuration Files</a>
<ul>
<li><a href="#org194df0b">4.1. core-site.xml</a></li>
<li><a href="#orga13c74b">4.2. hdfs-site.xml</a></li>
<li><a href="#org228942e">4.3. mapred-site.xml</a></li>
<li><a href="#orgf4bedea">4.4. hadoop-env.sh</a></li>
<li><a href="#org4b10bad">4.5. hbase-site.xml</a></li>
<li><a href="#orgc96bf0b">4.6. hbase-env.sh</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org9248be5" class="outline-2">
<h2 id="org9248be5"><span class="section-number-2">1</span> CDH3u3搭建单节点集群</h2>
<div class="outline-text-2" id="text-1">
<p>
搭建单节点集群允许我们在单机做一些模拟或者是测试，还是非常有意义的。如何操作的话可以参考链接 <a href="http://localhost/utils/hadoop-0.20.2-cdh3u3/docs/single_node_setup.html">http://localhost/utils/hadoop-0.20.2-cdh3u3/docs/single_node_setup.html</a>
</p>

<p>
这里稍微总结一下：
</p>
<ul class="org-ul">
<li>首先安装ssh和rsync # sudo apt-get install ssh &amp;&amp;  sudo apt-get install rsync</li>
<li>本机建立好信任关系 # cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</li>
<li>将{hadoop-package}/conf配置文件修改如下：</li>
<li>conf/core-site.xml</li>
</ul>
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;fs.default.name&lt;/name&gt;
         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>
<ul class="org-ul">
<li>conf/hdfs-site.xml</li>
</ul>
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.replication&lt;/name&gt;
         &lt;value&gt;1&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<ul class="org-ul">
<li>conf/mapred-site.xml</li>
</ul>
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;mapred.job.tracker&lt;/name&gt;
         &lt;value&gt;localhost:9001&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>
<ul class="org-ul">
<li>格式化namenode # bin/hadoop namenode -format</li>
<li>启动hadoop集群 # bin/start-all.sh</li>
<li>停止hadoop集群 # bin/stop-all.sh</li>
<li>webconsole
<ul class="org-ul">
<li>NameNode - <a href="http://localhost:50070/">http://localhost:50070/</a></li>
<li>JobTracker - <a href="http://localhost:50030/">http://localhost:50030/</a></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgcc82cdb" class="outline-2">
<h2 id="orgcc82cdb"><span class="section-number-2">2</span> CDH4.2.0搭建单节点集群</h2>
<div class="outline-text-2" id="text-2">
<p>
基本流程和CDH3u3是相同的，但是有一些差异我记录下来。
</p>
<ul class="org-ul">
<li>配置文件
<ul class="org-ul">
<li>配置文件在etc/hadoop，包括环境配置脚本比如hadoop-env.sh</li>
<li>bin/sbin目录下面有hadoop集群启动停止工具 #note: 不要使用它们</li>
<li>libexec目录下面是公用的配置脚本</li>
<li>mapred-site.xml中jobtracker地址配置key修改为 mapred.jobtracker.address #note: for yarn.如果是mr1那么不用修改,依然是mapred.job.tracker</li>
<li><del>hadoop-daemons.sh会使用/sbin/slaves.sh来在各个节点启动，但是 <b>不知道什么原因，很多环境变量没有设置</b> ，所以在slaves.sh执行ssh命令部分最开始增加了 source ~/.shrc; 来强制设置我的环境变量</del></li>
<li>#note: 不要使用shell脚本来启动，而是直接使用类似hadoop namenode这种方式来启动单个机器上的实例</li>
</ul></li>
<li>公共组件
<ul class="org-ul">
<li>CDH4.2.0 native-library都放在了目录lib/native下面，而不是CDH3u3的lib/native/Linux-amd64-64下面，这点需要注意。</li>
<li>CDH4.2.0 没有自带libhadoop.so, 所以启动的时候都会出现 ”Unable to load native-hadoop library for your platform&#x2026; using builtin-java classes where applicable“ 这个警告。需要自己编译放到lib/native目录下面。</li>
<li>CDH4.2.0 lib下面没有任何文件，所有的lib都在share/hadoop/*/lib下面，比如share/hadoop/common/lib. 这点和CDH3有差别，CDH3所有的jar都放在lib目录下面。使用 hadoop classpath 命令可以察看</li>
</ul></li>
<li>环境变量
<ul class="org-ul">
<li>JAVA_LIBRARY_PATH用来设置native library path</li>
<li>HADOOP_CLASSPATH可以用来设置hadoop相关的classpath（比如使用hadoop-lzo等）</li>
</ul></li>
<li>准备工作
<ul class="org-ul">
<li>使用hdfs namenode -format来做格式化 <b>注意如果使用sudo apt-get来安装的话，是其他用户比如hdfs,impala,mapred,yarn来启动的，所以必须确保目录对于这些用户是可写的</b></li>
<li>使用命令 hadoop org/apache/hadoop/examples/QuasiMonteCarlo 1 1 确定集群是否可以正常运行。</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org9883c1e" class="outline-2">
<h2 id="org9883c1e"><span class="section-number-2">3</span> CDH4.3.0搭建单节点集群</h2>
<div class="outline-text-2" id="text-3">
<p>
基本流程和CDH4.2.0是相同的，但是存在一些差异我记录下来的。从4.3.0开始将mr1和mr2分开存放，还是一个比较大的区别的。这里我以使用mr1为例。
</p>
<ul class="org-ul">
<li><del>在libexec/hadoop-config.sh添加source ~/.shrc 来强制设置环境变量。</del></li>
<li>mr1和mr2分开存放主要有
<ul class="org-ul">
<li>etc目录，hadoop and hadoop-mapreduce1</li>
<li>bin目录，bin and bin-mapreduce1</li>
<li>lib目录。如果需要使用mr1的话，那么cp -r share/hadoop/mapreduce1/ . #note: 不要用软链接
<ul class="org-ul">
<li>#note：似乎只需要最顶层的一些jar文件即可</li>
<li>#note: 似乎只需要hadoop-core-.jar文件即可</li>
</ul></li>
<li>webapps目录。如果需要使用mr1的话，那么cp -r share/hadoop/mapreduce1/webapps . 不然不能够访问JobTracker WebUI</li>
</ul></li>
<li><del>在bin/hadoop-config.sh添加source ~/.shrc 来强制设置环境变量。</del></li>
<li>#note: 不要使用start-dfs.sh这些脚本启动，似乎这些脚本会去读取master,slaves这些文件然后逐个上去ssh启动。直接使用hadoop namenode这种方式可以只启动单个机器上的实例</li>
</ul>
</div>
</div>

<div id="outline-container-org791bf78" class="outline-2">
<h2 id="org791bf78"><span class="section-number-2">4</span> Configuration Files</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org194df0b" class="outline-3">
<h3 id="org194df0b"><span class="section-number-3">4.1</span> core-site.xml</h3>
<div class="outline-text-3" id="text-4-1">
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.default.name&lt;/name&gt;
    &lt;value&gt;hdfs://umengds1.mob.cm3:8020&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.trash.interval&lt;/name&gt;
    &lt;value&gt;1440&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;

</pre>
</div>
</div>
</div>

<div id="outline-container-orga13c74b" class="outline-3">
<h3 id="orga13c74b"><span class="section-number-3">4.2</span> hdfs-site.xml</h3>
<div class="outline-text-3" id="text-4-2">
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.name.dir&lt;/name&gt;
    &lt;value&gt;/home/dirlt/hadoop/dfs/nn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;/home/dirlt/hadoop/dfs/dn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.checkpoint.dir&lt;/name&gt;
    &lt;value&gt;/home/dirlt/hadoop/dfs/snn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<hr />

<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.name.dir&lt;/name&gt;
    &lt;value&gt;/disk1/data/dfs/nn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;/disk1/data/dfs/dn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.checkpoint.dir&lt;/name&gt;
    &lt;value&gt;/disk1/data/dfs/snn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.block.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;
    &lt;value&gt;8192&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.datanode.du.reserved&lt;/name&gt;
    &lt;value&gt;21474836480&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;
    &lt;value&gt;64&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt;
    &lt;value&gt;32&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;

</pre>
</div>
</div>
</div>

<div id="outline-container-org228942e" class="outline-3">
<h3 id="org228942e"><span class="section-number-3">4.3</span> mapred-site.xml</h3>
<div class="outline-text-3" id="text-4-3">
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.job.tracker&lt;/name&gt;
    &lt;value&gt;localhost:8021&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<hr />

<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.job.tracker&lt;/name&gt;
    &lt;value&gt;umengds2.mob.cm3:8021&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapred.system.dir&lt;/name&gt;
    &lt;value&gt;/tmp/mapred/system&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;
    &lt;value&gt;/user&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapred.local.dir&lt;/name&gt;
    &lt;value&gt;/disk1/data/mapred/local&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapred.submit.replication&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
    &lt;final&gt;true&lt;/final&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapred.tasktracker.map.tasks.maximum&lt;/name&gt;
    &lt;value&gt;6&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.tasktracker.reduce.tasks.maximum&lt;/name&gt;
    &lt;value&gt;8&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapred.child.java.opts&lt;/name&gt;
    &lt;value&gt; -Xmx2048M -XX:-UseGCOverheadLimit&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapred.job.tracker.handler.count&lt;/name&gt;
    &lt;value&gt;64&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;io.sort.mb&lt;/name&gt;
    &lt;value&gt;256&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;io.sort.factor&lt;/name&gt;
    &lt;value&gt;64&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;

</pre>
</div>
</div>
</div>

<div id="outline-container-orgf4bedea" class="outline-3">
<h3 id="orgf4bedea"><span class="section-number-3">4.4</span> hadoop-env.sh</h3>
<div class="outline-text-3" id="text-4-4">
<div class="org-src-container">
<pre class="src src-Shell"># The maximum amount of heap to use, in MB. Default is 1000.
export HADOOP_HEAPSIZE=6000

# Extra Java runtime options. Empty by default.
# if [ "$HADOOP_OPTS" == "" ]; then export HADOOP_OPTS=-server; else HADOOP_OPTS+=" -server"; fi

# Command specific options appended to HADOOP_OPTS when specified
export HADOOP_NAMENODE_OPTS="-Xmx12000m $HADOOP_NAMENODE_OPTS"
export HADOOP_SECONDARYNAMENODE_OPTS="-Xmx12000m $HADOOP_SECONDARYNAMENODE_OPTS"
export HADOOP_DATANODE_OPTS="-Xmx6000m $HADOOP_DATANODE_OPTS"
export HADOOP_BALANCER_OPTS="-Xmx3000m $HADOOP_BALANCER_OPTS"
export HADOOP_JOBTRACKER_OPTS="-Xmx12000m $HADOOP_JOBTRACKER_OPTS"
</pre>
</div>
</div>
</div>

<div id="outline-container-org4b10bad" class="outline-3">
<h3 id="org4b10bad"><span class="section-number-3">4.5</span> hbase-site.xml</h3>
<div class="outline-text-3" id="text-4-5">
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://umengds1.mob.cm3:8020/hbase&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;umengds1.mob.cm3,umengds2.mob.cm3&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.mslab.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt;
    &lt;value&gt;128&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.client.write.buffer&lt;/name&gt;
    &lt;value&gt;4194304&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.block.multiplier&lt;/name&gt;
    &lt;value&gt;8&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.server.thread.wakefrequency&lt;/name&gt;
    &lt;value&gt;1000&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.lease.period&lt;/name&gt;
    &lt;value&gt;600000&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.hstore.blockingStoreFiles&lt;/name&gt;
    &lt;value&gt;15&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt;
    &lt;value&gt;2147483648&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.ipc.client.tcpnodelay&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;ipc.ping.interval&lt;/name&gt;
    &lt;value&gt;10000&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.hregion.majorcompaction&lt;/name&gt;
    &lt;value&gt;0&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.checksum.verify&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;

</pre>
</div>
</div>
</div>

<div id="outline-container-orgc96bf0b" class="outline-3">
<h3 id="orgc96bf0b"><span class="section-number-3">4.6</span> hbase-env.sh</h3>
<div class="outline-text-3" id="text-4-6">
<div class="org-src-container">
<pre class="src src-Shell"># The maximum amount of heap to use, in MB. Default is 1000.
export HBASE_HEAPSIZE=14000

# Extra Java runtime options.
# Below are what we set by default. May only work with SUN JVM.
# For more on why as well as other possible settings,
# see http://wiki.apache.org/hadoop/PerformanceTuning
# export HBASE_OPTS="-ea -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode"
export HBASE_OPTS="-ea -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSInitiatingOccupancyFraction=90"

</pre>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
