<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Voltnisky字符串搜索算法</title>
<meta name="author" content="dirtysalt" />
<meta name="generator" content="Org Mode" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content" class="content">
<h1 class="title">Voltnisky字符串搜索算法</h1>
<p>
<a href="https://clickhouse.tech/codebrowser/html_report/ClickHouse/src/Common/Volnitsky.h.html">https://clickhouse.tech/codebrowser/html_report/ClickHouse/src/Common/Volnitsky.h.html</a>
</p>

<p>
感觉这个算法并不是特别难理解，但是一些数值选择上很有讲究：
</p>
<ol class="org-ol">
<li>hashtable 大小设置成为了64K, 这个和l2 cache大小相同</li>
<li>如果是ascii字符的话，那么选择2-gram做快速检查，2-gram就是uint16_t. 范围是64K.</li>
<li>将needle大小上限设置为255，偏移就是[0,254]，可以使用1个字节表示。为了表示hashtable中没有使用的状态(0), 所以needle大小故意减少1</li>
<li>如果偏移使用1个字节表示，那么hashtable可以有64K个buckets.</li>
<li>needle有了长度上限之后，2-gram的上限就是255个</li>
<li>所以理想状态下这个load factor就会是 255/64K ~= 0.3%</li>
</ol>

<p>
本质上这个算法就是快速过滤不合理的搜索区间。这样的话，我们能否把这个gram大小增加，比如4-gram? 这样是不是更容易减少false positive？。不过这样的后果是，hash collision也会更大，又会提高false positive。感觉4-gram还是2-gram的选择可以具体分析pattern string.
</p>
</div>
</body>
</html>
