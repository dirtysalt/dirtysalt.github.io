<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>storm</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="dirtysalt" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content">
<h1 class="title">storm</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgcb697e9">1. overview</a></li>
<li><a href="#org26bc84f">2. grouping</a></li>
<li><a href="#orga3bdf3c">3. distributed-RPC</a></li>
<li><a href="#org0bba097">4. parallelism</a></li>
<li><a href="#orga8e3327">5. reliability</a></li>
</ul>
</div>
</div>
<ul class="org-ul">
<li>Documentation · nathanmarz/storm Wiki <a href="https://github.com/nathanmarz/storm/wiki/Documentation">https://github.com/nathanmarz/storm/wiki/Documentation</a></li>
<li>Storm, distributed and fault-tolerant realtime computation : <a href="http://storm-project.net/">http://storm-project.net/</a></li>
<li><a href="http://www.slideshare.net/nathanmarz/storm-distributed-and-faulttolerant-realtime-computation">http://www.slideshare.net/nathanmarz/storm-distributed-and-faulttolerant-realtime-computation</a></li>
<li><a href="http://ifeve.com/wp-content/uploads/2014/03/Getting-Started-With-Storm-Jonathan-Leibiusky-Gabriel-E_1276.pdf">Getting Started With Storm</a></li>
<li>通常storm都是和kafka对接的，<a href="https://github.com/miguno/kafka-storm-starter">这个项目</a> 可以作为参考</li>
<li>另外storm还支持multilang, 我这里也做了一个 <a href="https://github.com/dirtysalt/codes/tree/master/scala/kafka-streaming">demo</a></li>
</ul>

<div id="outline-container-orgcb697e9" class="outline-2">
<h2 id="orgcb697e9"><span class="section-number-2">1</span> overview</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li><a href="http://storm.apache.org/documentation/Tutorial.html">http://storm.apache.org/documentation/Tutorial.html</a></li>
<li><a href="http://storm.apache.org/documentation/Concepts.html">http://storm.apache.org/documentation/Concepts.html</a></li>
</ul>

<p>
因为storm是流式处理系统, 应用逻辑可以是长久运行的, 所以在上面运行的应用不称为Jobs而称为Topologies.
</p>

<p>
storm集群由三个部分组成: 1) master(nimbus) 2) coordinator(zookeeper) 3 ) worker(supervisor). 如果和MapReduce框架对应起来的话, 那么nimbus &lt;-&gt; jobtracker, supervisor &lt;-&gt; tasktracker.
</p>


<div class="figure">
<p><img src="images/storm-cluster.png" alt="storm-cluster.png" />
</p>
</div>

<p>
一个topology分为spout和bolt两大类组件. 其中spout负责从外部源读入数据注射入系统, 而bolt则负责逻辑业务本身. 这里bolt仅仅是逻辑单元, 在物理层面执行的时候可以通过设置parallelism相关参数增加tasks数量来提高吞吐. spout/bolt以及bolt/bolt之间相互传递数据都是由storm framework来管理的, 用户只需要编写处理数据逻辑即可.
</p>


<div class="figure">
<p><img src="images/storm-topology.png" alt="storm-topology.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org26bc84f" class="outline-2">
<h2 id="org26bc84f"><span class="section-number-2">2</span> grouping</h2>
<div class="outline-text-2" id="text-2">
<p>
输入输出数据模型是key-value model. 其中key可以用来进行grouping. 所以grouping就是决定数据如何向下面一层分发. storm提供下面几种grouping方式
</p>
<ul class="org-ul">
<li>shuffle grouping. 随机分布</li>
<li>fields grouping. 按照k分布</li>
<li>all grouping. 人手一份</li>
<li>global grouping. 只传给某一个task. 通常来说是编号最小的那个.</li>
<li>direct grouping. producer指定传给某个task. #note: 破坏透明性</li>
</ul>
</div>
</div>

<div id="outline-container-orga3bdf3c" class="outline-2">
<h2 id="orga3bdf3c"><span class="section-number-2">3</span> distributed-RPC</h2>
<div class="outline-text-2" id="text-3">
<p>
用storm可以很容易实现DRPC. 似乎这个功能非常有用, 但是我现在还没有想到一个比较合适的场景.
</p>


<div class="figure">
<p><img src="images/storm-drpc-workflow.png" alt="storm-drpc-workflow.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0bba097" class="outline-2">
<h2 id="org0bba097"><span class="section-number-2">4</span> parallelism</h2>
<div class="outline-text-2" id="text-4">
<p>
storm parallelism有三个概念 1) worker process 2) executor 3) task. 下面这张图解释了三者之间的关系
</p>


<div class="figure">
<p><img src="images/storm-parallelism.png" alt="storm-parallelism.png" />
</p>
</div>

<ul class="org-ul">
<li>worker process 只属于某个topology. 在一个node上可能存在多个work processes. (对应进程)</li>
<li>executor 属于某个work process. 一个executor只运行某一个spout/bolt. (对应线程)</li>
<li>task 属于某个executor. storm里面最小的执行单元. (#executor &lt;= #task. 但是通常两者相等)</li>
</ul>
</div>
</div>

<div id="outline-container-orga8e3327" class="outline-2">
<h2 id="orga8e3327"><span class="section-number-2">5</span> reliability</h2>
<div class="outline-text-2" id="text-5">
<p>
如何保证每条消息能够都被处理? 我们需要先来定义"消息被完全处理". 在流式系统中一个input tuple到最后结束可能会产生许多tuples并且中途也会有很多tuples生成. 如果我们将这些生成关系画成树的话
</p>


<div class="figure">
<p><img src="images/storm-tuple-tree.png" alt="storm-tuple-tree.png" />
</p>
</div>

<p>
一个input-tuple产生许多中间tuples. bolts只有对input-tuple以及每个中间输入消息给予确认的话, 才能认为这个input-tuple被完全处理. 当然某些应用只要求第一个bolt处理了input-tuple就OK了. 如果input-tuple在某段时间内没有被确认的话, 那么这个input-tuple会重发. #note: out-of-order
</p>

<p>
如何将中间消息和input-tuple关联起来? storm API提供了 <b>anchoring</b> 接口. anchoring就是将某个output-input和input-tuple关联起来. 这样output-tuple里面其实带上了input-tuple id. 如果我们ack output-tuple时, storm会从output-tuple里面抽取input-tuple id并且ack这个input-tuple. storm API来提供了 <b>multiple-anchoring</b> 接口允许某个output-tuple和多个input-tuple关联起来.
</p>

<hr />

<p>
storm如何实现消息确认? storm会为每个output-tuple分配一个random 64bit id. storm会启动acker服务来接收spout/bolt返回的ack消息并且通过维护一个hashmap对tuple进行追踪. 整个过程是
</p>
<ul class="org-ul">
<li>当spout从某个输入源读取tuple的时候, 会为这个tuple生成一个tuple-id. 这个tuple-id要求能够回放. 也就是如果spout拿到这个tuple-id的话, 还可以从输入源读取这个tuple.</li>
<li>当spout/bolt处理tuple的时候, spout/bolt会向acker发送(tuple-id, input-tuple-id, output-tuple-id) #note: tuple-id是spout分配的id, input-tuple-id是上一层过来的tuple id.</li>
<li>acker处理逻辑是:（个人推断）
<ul class="org-ul">
<li>初始化  hashmap[tuple-id] = (spout-task-id, val[default = 0]) # 这里spout-task-id追踪是为了知道要那个spout-task重发tuple.</li>
<li>处理ack hashmap[tuple-id].val xor = (input-tuple-id xor output-tuple-id)</li>
<li>如果某个tuple-id, hashmap[tuple-id].val在一段时间(超时时间)内没有变为0的话, 那么就需要重发这个tuple-id对应的tuple.</li>
<li>反之如果变成0的话, 那么就可以认为这个tuple被正确处理掉了.</li>
</ul></li>
</ul>
<p>
理论上如果消息没有被完全处理的话在中途过程也有可能出现0x0, 但是概率非常小. 并且在真实情况下只有tuple没有被正确处理的时候才会丢数据. 综合考虑概率非常小.
</p>

<p>
我们这里举个例子, 假设topology T如下:
</p>
<pre class="example">
A -&gt; B -&gt; D
  -&gt; C
</pre>
<p>
其中spout A从输入源读取tuple-id(=123). 发出两个tuples(t1 = 0x12345678, t2 = 0x23456781)被两个bolt B,C处理分别产生tuples(t3 = 0x34567812, t4 = 0x45678123), 然后t2,t3被D处理.
</p>
<ul class="org-ul">
<li>初始化 hash(123) = 0x0</li>
<li>A发出两个t1 hash(123) = 0 xor (t1) 0x12345678 xor (t2) 0x23456781 = 0x317131f9</li>
<li>B处理t1 hash(123) = 0x317131f9 xor (t1) 0x12345678 xor (t3) 0x34567812 = 0x17131f93</li>
<li>C处理t2 hash(123) = 0x17131f93 xor (t2) 0x23456781 xor (t4) 0x45678123 = 0x7131f931</li>
<li>D处理t3,t4 hash(123) = 0x7131f931 xor (t3) 0x34567812 xor (t4) 0x45678123 = 0x0</li>
</ul>

<p>
默认storm是启动1个acker服务来进行追踪. 但是如果消息量非常大的话那么可以启动多个acker服务来进行追踪. 一旦acker服务发现某个tuple需要重传的话, 会根据hashmap里面的spout-task-id来通知对应的spout.
</p>
</div>
</div>
</div>
</body>
</html>
