<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Apache HBase Configuration</title>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content">
<h1 class="title">Apache HBase Configuration</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. core</a></li>
<li><a href="#sec-2">2. master</a></li>
<li><a href="#sec-3">3. regionserver</a></li>
<li><a href="#sec-4">4. client</a></li>
<li><a href="#sec-5">5. zookeeper</a></li>
</ul>
</div>
</div>
<ul class="org-ul">
<li><a href="http://hbase.apache.org/book/book.html">http://hbase.apache.org/book/book.html</a>
</li>
<li><a href="http://hbase.apache.org/book/configuration.html">http://hbase.apache.org/book/configuration.html</a>
</li>
</ul>

<p>
配置文件分布在三个地方：
</p>
<ul class="org-ul">
<li>for HBase, site specific customizations go into the file <b>conf/hbase-site.xml.</b>
</li>
<li><b>hbase-default.xml</b> source file in the HBase source code at <b>src/main/resources.</b>
</li>
<li>Not all configuration options make it out to hbase-default.xml. <b>Configuration that it is thought rare anyone would change can exist only in code;</b> the only way to turn up such configurations is via a reading of the source code itself.
</li>
</ul>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> core</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>hbase.rootdir
<ul class="org-ul">
<li>The directory shared by region servers and into which HBase persists. The URL should be 'fully-qualified' to include the filesystem scheme.
</li>
<li>Default: <a href="file:///tmp/hbase-${user.name}/hbase">file:///tmp/hbase-${user.name}/hbase</a>
</li>
</ul>
</li>
<li>hbase.cluster.distributed
<ul class="org-ul">
<li>standalone(hbase and zk in one JVM) or distributed mode.
</li>
<li>Default: false
</li>
</ul>
</li>
<li>hbase.tmp.dir
<ul class="org-ul">
<li>Temporary directory on the local filesystem.
</li>
<li>#todo: hbase为什么需要local filesystem?
</li>
<li>Default: ${java.io.tmpdir}/hbase-${user.name}
</li>
</ul>
</li>
<li>hbase.local.dir
<ul class="org-ul">
<li>Directory on the local filesystem to be used as a local storage.
</li>
<li>Default: ${hbase.tmp.dir}/local/
</li>
</ul>
</li>
<li>dfs.support.append
<ul class="org-ul">
<li>hdfs是否支持append. #todo: 如果支持append是否有更好的实现？
</li>
<li>Default: true
</li>
</ul>
</li>
<li>hbase.offheapcache.percentage
<ul class="org-ul">
<li>使用heap cache的百分比（好像这个cache是会放在disk上的）
</li>
<li>The amount of off heap space to be allocated towards the experimental off heap cache.
</li>
<li>If you desire the cache to be disabled, simply set this value to 0.
</li>
<li>Default: 0
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> master</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li>hbase.master.port
<ul class="org-ul">
<li>Default: 60000
</li>
</ul>
</li>
<li>hbase.master.info.port
<ul class="org-ul">
<li>Default: 60010
</li>
</ul>
</li>
<li>hbase.master.info.bindAddress
<ul class="org-ul">
<li>Default: 0.0.0.0
</li>
</ul>
</li>
<li>hbase.master.dns.interface
<ul class="org-ul">
<li>The name of the Network Interface from which a master should report its IP address.
</li>
<li>Default: default
</li>
</ul>
</li>
<li>hbase.master.dns.nameserver
<ul class="org-ul">
<li>The host name or IP address of the name server (DNS) which a master should use to determine the host name used for communication and display purposes.
</li>
<li>Default: default
</li>
</ul>
</li>
<li><b>hbase.balancer.period</b>
<ul class="org-ul">
<li>多长时间进行balance
</li>
<li>Period at which the region balancer runs in the Master.
</li>
<li>Default: 300000(ms)=5min
</li>
</ul>
</li>
<li><b>hbase.regions.slop</b>
<ul class="org-ul">
<li>触发balance的倾斜度
</li>
<li>Rebalance if any regionserver has average + (average * slop) regions. Default is 20% slop.
</li>
<li>Default: 0.2
</li>
</ul>
</li>
<li>hbase.master.logcleaner.ttl
<ul class="org-ul">
<li>Maximum time a HLog can stay in the .oldlogdir directory, after which it will be cleaned by a Master thread.
</li>
<li>Default: 600000
</li>
</ul>
</li>
<li>hbase.master.cleaner.interval
<ul class="org-ul">
<li>master每隔一段时间都会检查log是否需要删除，默认是1分钟
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> regionserver</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>hbase.regionserver.port
<ul class="org-ul">
<li>Default: 60020
</li>
</ul>
</li>
<li>hbase.regionserver.info.port
<ul class="org-ul">
<li>Default: 60030
</li>
</ul>
</li>
<li>hbase.regionserver.info.port.auto
<ul class="org-ul">
<li>Enables automatic port search if hbase.regionserver.info.port is already in use.
</li>
<li>Default: false
</li>
</ul>
</li>
<li>hbase.regionserver.info.bindAddress
<ul class="org-ul">
<li>Default: 0.0.0.0
</li>
</ul>
</li>
<li><b>hbase.regionserver.handler.count</b>
<ul class="org-ul">
<li>rs和master的RPC线程数目
<ul class="org-ul">
<li>The default of 10 is rather low in order to prevent users from killing their region servers when using large write buffers with a high number of concurrent clients.
</li>
<li>The rule of thumb is to keep this number low when the payload per request approaches the MB (big puts, scans using a large cache) and high when the payload is small (gets, small puts, ICVs, deletes).
</li>
<li>It is safe to set that number to the maximum number of incoming clients if their payload is small, the typical example being a cluster that serves a website since puts aren't typically buffered and most of the operations are gets. （对于gets等website操作的话比较适合调高，因为每次payload都比较小）
</li>
<li>The reason why it is dangerous to keep this setting high is that the aggregate size of all the puts that are currently happening in a region server may impose too much pressure on its memory, or even trigger an OutOfMemoryError. （而对于大量put以及scan这样操作的话比较适合调低，以防止对内存造成巨大压力）
</li>
<li>A region server running on low memory will trigger its JVM's garbage collector to run more frequently up to a point where GC pauses become noticeable (the reason being that all the memory used to keep all the requests' payloads cannot be trashed, no matter how hard the garbage collector tries).
</li>
<li>After some time, the overall cluster throughput is affected since every request that hits that region server will take longer, which exacerbates the problem even more.
</li>
<li>可以通过做RPC-level logging来判断线程数目是多是少。
</li>
</ul>
</li>
<li>Count of RPC Listener instances spun up on RegionServers. Same property is used by the Master for count of master handlers.
</li>
<li>Default: 10
</li>
</ul>
</li>
<li>hbase.bulkload.retries.number
<ul class="org-ul">
<li>#todo: bulk load?
</li>
<li>This is maximum number of iterations to atomic bulk loads are attempted in the face of splitting operations 0 means never give up.
</li>
<li>Default: 0.
</li>
</ul>
</li>
<li><b>hbase.regionserver.msginterval</b>
<ul class="org-ul">
<li>#todo: heartbeat?
</li>
<li>Interval between messages from the RegionServer to Master in milliseconds.
</li>
<li>Default: 3000
</li>
</ul>
</li>
<li><b>hbase.regionserver.optionallogflushinterval</b>
<ul class="org-ul">
<li>sync hlog到hdfs时间间隔，如果在这段时间内没有足够的entry来做sync的话 #todo: 这里的entry是不是edit?
</li>
<li>Sync the HLog to the HDFS after this interval if it has not accumulated enough entries to trigger a sync.
</li>
<li>Default: 1000(ms)
</li>
</ul>
</li>
<li><b>hbase.regionserver.regionSplitLimit</b>
<ul class="org-ul">
<li>region splitting上限，超过这个上限之后就不做splitting
</li>
<li>Limit for the number of regions after which no more region splitting should take place.
</li>
<li>Default is set to MAX_INT; i.e. do not block splitting.
</li>
<li>Default: 2147483647
</li>
</ul>
</li>
<li><b>hbase.regionserver.logroll.period</b>
<ul class="org-ul">
<li>Period at which we will roll the commit log regardless of how many edits it has.
</li>
<li>Default: 3600000(ms)
</li>
</ul>
</li>
<li><b>hbase.regionserver.logroll.errors.tolerated</b>
<ul class="org-ul">
<li>WAL close时候出现error最多容忍多少次
</li>
<li>The number of consecutive WAL close errors we will allow before triggering a server abort.
</li>
<li>A setting of 0 will cause the region server to abort if closing the current WAL writer fails during log rolling.
</li>
<li>Even a small value (2 or 3) will allow a region server to ride over transient HDFS errors.
</li>
<li>Default: 2
</li>
</ul>
</li>
<li>hbase.regionserver.hlog.reader.impl
<ul class="org-ul">
<li>The HLog file reader implementation.
</li>
<li>Default: org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader
</li>
</ul>
</li>
<li>hbase.regionserver.hlog.writer.impl
<ul class="org-ul">
<li>The HLog file writer implementation.
</li>
<li>Default: org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter
</li>
</ul>
</li>
<li>hbase.regionserver.nbreservationblocks
<ul class="org-ul">
<li>保留的内存块以便出现OOME的时候还可以做cleanup
</li>
<li>The number of resevoir blocks of memory release on OOME so we can cleanup properly before server shutdown.
</li>
<li>Default: 4
</li>
</ul>
</li>
<li>hbase.regionserver.dns.interface
<ul class="org-ul">
<li>The name of the Network Interface from which a region server should report its IP address.
</li>
<li>Default: default
</li>
</ul>
</li>
<li>hbase.regionserver.dns.nameserver
<ul class="org-ul">
<li>The host name or IP address of the name server (DNS) which a region server should use to determine the host name used by the master for communication and display purposes.
</li>
<li>Default: default
</li>
</ul>
</li>
<li><b>hbase.regionserver.global.memstore.upperLimit</b>
<ul class="org-ul">
<li>所有memstore内存占用比率超过这个值的话就会block update并且强制进行flush
</li>
<li>Maximum size of all memstores in a region server before new updates are blocked and flushes are forced. Defaults to 40% of heap.
</li>
<li>Default: 0.4
</li>
</ul>
</li>
<li><b>hbase.regionserver.global.memstore.lowerLimit</b>
<ul class="org-ul">
<li>所有memstore内存占用比率超过这个值的话就会强制做flush
</li>
<li>Maximum size of all memstores in a region server before flushes are forced. Defaults to 35% of heap.
</li>
<li>Default: 0.35
</li>
</ul>
</li>
<li><b>hbase.server.thread.wakefrequency</b>
<ul class="org-ul">
<li>每隔一段时间去检查有什么例行任务需要完成，或者是做major compaction等。
</li>
<li>Time to sleep in between searches for work (in milliseconds). Used as sleep interval by service threads such as log roller.
</li>
<li>Default: 10000
</li>
</ul>
</li>
<li>hbase.server.versionfile.writeattempts
<ul class="org-ul">
<li>写version file的尝试次数，并且每隔一段时间会尝试写 #todo: what‘s version file？
</li>
<li>How many time to retry attempting to write a version file before just aborting.
</li>
<li>Each attempt is seperated by the hbase.server.thread.wakefrequency milliseconds.
</li>
<li>Default: 3
</li>
</ul>
</li>
<li><b>hbase.regionserver.optionalcacheflushinterval</b>
<ul class="org-ul">
<li>#todo: edit不是都要写到file的吗？
</li>
<li>Maximum amount of time an edit lives in memory before being automatically flushed.
</li>
<li>Set it to 0 to disable automatic flushing.
</li>
<li>Default: 3600000(ms)
</li>
</ul>
</li>
<li><b>hbase.hregion.memstore.flush.size</b>
<ul class="org-ul">
<li>memstore超过多少内存会刷新到disk，并且每隔一段时间会检查. #todo: 这个不是每次进行write memstore就可以检查的吗？只要超过内存大小应该立刻就可以感知到的
</li>
<li>Memstore will be flushed to disk if size of the memstore exceeds this number of bytes.
</li>
<li>Value is checked by a thread that runs every hbase.server.thread.wakefrequency.
</li>
<li>Default: 134217728
</li>
</ul>
</li>
<li><b>hbase.hregion.preclose.flush.size</b>
<ul class="org-ul">
<li>preclose可能是预先将一部分的数据刷到磁盘上面，这样在close memstore过程中就非常快
</li>
<li>If the memstores in a region are this size or larger when we go to close, run a "pre-flush" to clear out memstores before we put up the region closed flag and take the region offline.
</li>
<li>The preflush is meant to clean out the bulk of the memstore before putting up the close flag and taking the region offline so the flush that runs under the close flag has little to do.
</li>
<li>Default: 5242880
</li>
</ul>
</li>
<li><b>hbase.hregion.memstore.block.multiplier</b>
<ul class="org-ul">
<li>超过大小的话那么会阻塞update #todo: 为什么会出现这种情况？
</li>
<li>Block updates if memstore has hbase.hregion.block.memstore.multiplier time hbase.hregion.flush.size bytes.
</li>
<li>Default: 2
</li>
</ul>
</li>
<li><b>hbase.hregion.memstore.mslab.enabled</b>
<ul class="org-ul">
<li>#todo: what's mslab?
</li>
<li>Enables the MemStore-Local Allocation Buffer, a feature which works to prevent heap fragmentation under heavy write loads.
</li>
<li>This can reduce the frequency of stop-the-world GC pauses on large heaps.
</li>
<li>Default: true
</li>
</ul>
</li>
<li><b>hbase.hregion.max.filesize</b>
<ul class="org-ul">
<li>如果一个regionserver上面column family的hstorefiles大小总和过大的话，那么就会进行splitting
</li>
<li>For the 0.90.x codebase, the upper-bound of regionsize is about 4Gb, with a default of 256Mb. For 0.92.x codebase, due to the HFile v2 change much larger regionsizes can be supported (e.g., 20Gb). 对于0.90.x来说regionsize上界就是4GB，高版本更大的regionsize被支持。
</li>
<li>Maximum HStoreFile size. If any one of a column families' HStoreFiles has grown to exceed this value, the hosting HRegion is split in two.
</li>
<li>Default: 10737418240(10G)
</li>
</ul>
</li>
<li><b>hbase.hstore.compactionThreshold</b>
<ul class="org-ul">
<li>在一个HStore下面过多的hstorefile就会进行compaction合并成为1个文件。如果这个值过大的话，那么做compaction的时间就会更长。注意这里也说了一个hstorefile是一个memstore flush的结果。
</li>
<li>If more than this number of HStoreFiles in any one HStore (one HStoreFile is written per flush of memstore) then a compaction is run to rewrite all HStoreFiles files as one.      - Larger numbers put off compaction but when it runs, it takes longer to complete.
</li>
<li>Default: 3
</li>
</ul>
</li>
<li><b>hbase.hstore.blockingStoreFiles</b>
<ul class="org-ul">
<li>如果超过hstorefile没有合并完成的话，那么就会阻塞，直到compaction完成，或者是超过一定时间
</li>
<li>If more than this number of StoreFiles in any one Store (one StoreFile is written per flush of MemStore) then updates are blocked for this HRegion until a compaction is completed, or until hbase.hstore.blockingWaitTime has been exceeded.
</li>
<li>Default: 7
</li>
</ul>
</li>
<li><b>hbase.hstore.blockingWaitTime</b>
<ul class="org-ul">
<li>如果超过这些时间之后，那么HRegion将不会阻塞update.
</li>
<li>The time an HRegion will block updates for after hitting the StoreFile limit defined by hbase.hstore.blockingStoreFiles.
</li>
<li>After this time has elapsed, the HRegion will stop blocking updates even if a compaction has not been completed. Default: 90 seconds.
</li>
<li>Default: 90000(s)
</li>
</ul>
</li>
<li><b>hbase.hstore.compaction.max</b>
<ul class="org-ul">
<li>一次minor compaction的文件数目
</li>
<li>Max number of HStoreFiles to compact per 'minor' compaction.
</li>
<li>Default: 10
</li>
</ul>
</li>
<li><b>hbase.hregion.majorcompaction</b>
<ul class="org-ul">
<li>两次做major compaction的间隔
</li>
<li>The time (in miliseconds) between 'major' compactions of all HStoreFiles in a region.
</li>
<li>Set to 0 to disable automated major compactions.
</li>
<li>Default: 86400000(ms) = 1day
</li>
</ul>
</li>
<li>hbase.storescanner.parallel.seek.enable
<ul class="org-ul">
<li>Enables StoreFileScanner parallel-seeking in StoreScanner, a feature which can reduce response latency under special conditions.
</li>
<li>Default: false
</li>
</ul>
</li>
<li>hbase.storescanner.parallel.seek.threads
<ul class="org-ul">
<li>The default thread pool size if parallel-seeking feature enabled.
</li>
<li>Default: 10
</li>
</ul>
</li>
<li><b>hfile.block.cache.size</b>
<ul class="org-ul">
<li>HFile/StoreFile分配多少内存作为block cache.
</li>
<li>Percentage of maximum heap (-Xmx setting) to allocate to block cache used by HFile/StoreFile.
</li>
<li>Set to 0 to disable but it's not recommended.
</li>
<li>Default: 0.25
</li>
</ul>
</li>
<li><b>hbase.hash.type</b>
<ul class="org-ul">
<li>用于bloom filter的hash算法
</li>
<li>The hashing algorithm for use in HashFunction.
</li>
<li>Two values are supported now: murmur (MurmurHash) and jenkins (JenkinsHash). Used by bloom filters.
</li>
<li>Default: murmur
</li>
</ul>
</li>
<li>hfile.format.version
<ul class="org-ul">
<li>HFile的格式版本号，用于处理兼容性问题。
</li>
<li>The HFile format version to use for new files. Set this to 1 to test backwards-compatibility. The default value of this option should be consistent with FixedFileTrailer.MAX_VERSION.
</li>
<li>Default: 2
</li>
</ul>
</li>
<li><b>io.storefile.bloom.block.size</b>
<ul class="org-ul">
<li>HFile block大小，这个大小包括data + bloom filter.
</li>
<li>The size in bytes of a single block ("chunk") of a compound Bloom filter.
</li>
<li>Default: 131072
</li>
</ul>
</li>
<li>hbase.rpc.server.engine
<ul class="org-ul">
<li>Implementation of org.apache.hadoop.hbase.ipc.RpcServerEngine to be used for server RPC call marshalling.
</li>
<li>Default: org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine
</li>
</ul>
</li>
<li><b>hbase.ipc.client.tcpnodelay</b>
<ul class="org-ul">
<li>Set no delay on rpc socket connections.
</li>
<li>Default: true
</li>
</ul>
</li>
<li>hbase.data.umask.enable
<ul class="org-ul">
<li>regionserver是否使用umask来决定文件权限
</li>
<li>Enable, if true, that file permissions should be assigned to the files written by the regionserver
</li>
<li>Default: false
</li>
</ul>
</li>
<li>hbase.data.umask
<ul class="org-ul">
<li>File permissions that should be used to write data files when hbase.data.umask.enable is true
</li>
<li>Default: 000
</li>
</ul>
</li>
<li><b>hbase.rpc.timeout</b>
<ul class="org-ul">
<li>用来估计client rpc timeout时间
</li>
<li>This is for the RPC layer to define how long HBase client applications take for a remote call to time out.
</li>
<li>It uses pings to check connections but will eventually throw a TimeoutException. The default value is 60000ms(60s).
</li>
<li>Default: 60000
</li>
</ul>
</li>
<li><b>hbase.server.compactchecker.interval.multiplier</b>
<ul class="org-ul">
<li>多长时间检查一次是否需要做compaction.(major compaction)
</li>
<li>The number that determines how often we scan to see if compaction is necessary.
</li>
<li>Normally, compactions are done after some events (such as memstore flush), but if region didn't receive a lot of writes for some time, or due to different compaction policies, it may be necessary to check it periodically.
</li>
<li>The interval between checks is hbase.server.compactchecker.interval.multiplier multiplied by hbase.server.thread.wakefrequency.
</li>
<li>Default: 1000
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> client</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>hbase.client.write.buffer
<ul class="org-ul">
<li>HTable client writer buffer in bytes.
</li>
<li>Default: 2097152 = 2M
</li>
<li>A bigger buffer takes more memory &#x2013; on both the client and server side since server instantiates the passed write buffer to process it &#x2013; but a larger buffer size reduces the number of RPCs made.
</li>
<li>For an estimate of server-side memory-used, evaluate hbase.client.write.buffer * hbase.regionserver.handler.count <b>用来估计handler.count以及server memory used</b>
</li>
</ul>
</li>
<li>hbase.client.pause
<ul class="org-ul">
<li>General client pause value. Used mostly as value to wait before running a retry of a failed get, region lookup, etc.  <b>client retry之间的pause时间</b>
</li>
<li>Default: 1000
</li>
</ul>
</li>
<li>hbase.client.retries.number
<ul class="org-ul">
<li>Default: 10
</li>
</ul>
</li>
<li>hbase.client.scanner.caching
<ul class="org-ul">
<li>Number of rows that will be fetched when calling next on a scanner <b>每次scanner取出的row number</b>
</li>
<li>Default: 100
</li>
<li>Do not set this value such that the time between invocations is greater than the scanner timeout; i.e. hbase.client.scanner.timeout.period  <b>但是需要注意两次操作之间不要超时</b>
</li>
</ul>
</li>
<li>hbase.client.keyvalue.maxsize
<ul class="org-ul">
<li>Specifies the combined maximum allowed size of a KeyValue instance. Setting it to zero or less disables the check.
</li>
<li>Default: 10485760 = 10MB
</li>
</ul>
</li>
<li>hbase.client.scanner.timeout.period
<ul class="org-ul">
<li>Client scanner lease period in milliseconds. <b>scanner两次操作之间的lease时长</b>
</li>
<li>Default: 60000(ms)
</li>
</ul>
</li>
<li>hbase.mapreduce.hfileoutputformat.blocksize
<ul class="org-ul">
<li>HFileOutputFormat直接输出HBase文件的blocksize.
</li>
<li>Default: 65536(64KB?)
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> zookeeper</h2>
<div class="outline-text-2" id="text-5">
<ul class="org-ul">
<li>hbase.zookeeper.dns.interface
<ul class="org-ul">
<li>The name of the Network Interface from which a ZooKeeper server should report its IP address.
</li>
<li>Default: default
</li>
</ul>
</li>
<li>hbase.zookeeper.dns.nameserver
<ul class="org-ul">
<li>The host name or IP address of the name server (DNS) which a ZooKeeper server should use to determine the host name used by the master for communication and display purposes.
</li>
<li>Default: default
</li>
</ul>
</li>
<li><b>zookeeper.session.timeout</b>
<ul class="org-ul">
<li>zookeeper的session超时时间. 这个参数一方面涉及到hmaster多久发现regionserver挂掉，另外一方面也设计到regionserver本身做GC会和zookeeper比较长时间没有通信。
</li>
<li>ZooKeeper session timeout. HBase passes this to the zk quorum as suggested maximum time for a session
</li>
<li>"The client sends a requested timeout, the server responds with the timeout that it can give the client. " In milliseconds.
</li>
<li>Default: 180000(3min)
</li>
</ul>
</li>
<li><b>zookeeper.znode.parent</b>
<ul class="org-ul">
<li>Root ZNode for HBase in ZooKeeper. All of HBase's ZooKeeper files that are configured with a relative path will go under this node.
</li>
<li>By default, all of HBase's ZooKeeper file path are configured with a relative path, so they will all go under this directory unless changed.
</li>
<li>Default: /hbase
</li>
</ul>
</li>
<li><b>zookeeper.znode.rootserver</b>
<ul class="org-ul">
<li>Path to ZNode holding root region location. This is written by the master and read by clients and region servers.
</li>
<li>Default: root-region-server
</li>
</ul>
</li>
<li><b>hbase.zookeeper.quorum</b>
<ul class="org-ul">
<li>Comma separated list of servers in the ZooKeeper Quorum.
</li>
<li>"host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".
</li>
<li>Default: localhost
</li>
</ul>
</li>
<li><b>hbase.zookeeper.peerport</b>
<ul class="org-ul">
<li>Port used by ZooKeeper peers to talk to each other.
</li>
<li>Default: 2888
</li>
</ul>
</li>
<li><b>hbase.zookeeper.leaderport</b>
<ul class="org-ul">
<li>Port used by ZooKeeper for leader election.
</li>
<li>Default:
</li>
</ul>
</li>
<li>hbase.zookeeper.property.initLimit
<ul class="org-ul">
<li>Property from ZooKeeper's config zoo.cfg. The number of ticks that the initial synchronization phase can take.
</li>
<li>Default: 10
</li>
</ul>
</li>
<li>hbase.zookeeper.property.syncLimit
<ul class="org-ul">
<li>Property from ZooKeeper's config zoo.cfg. The number of ticks that can pass between sending a request and getting an acknowledgment.
</li>
<li>Default: 5
</li>
</ul>
</li>
<li>hbase.zookeeper.property.dataDir
<ul class="org-ul">
<li>Property from ZooKeeper's config zoo.cfg. The directory where the snapshot is stored.
</li>
<li>Default: ${hbase.tmp.dir}/zookeeper
</li>
</ul>
</li>
<li><b>hbase.zookeeper.property.clientPort</b>
<ul class="org-ul">
<li>client链接zookeeper的port
</li>
<li>Property from ZooKeeper's config zoo.cfg. The port at which the clients will connect.
</li>
<li>Default: 2181
</li>
</ul>
</li>
<li><b>hbase.zookeeper.property.maxClientCnxns</b>
<ul class="org-ul">
<li>Property from ZooKeeper's config zoo.cfg. Limit on number of concurrent connections
</li>
<li>Default: 300
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</body>
</html>
