1
00:00:00,000 --> 00:00:02,616
- The competence and capability and intelligence

2
00:00:02,616 --> 00:00:05,472
and training and accomplishments of senior scientists

3
00:00:05,472 --> 00:00:07,857
and technologists working on a technology,

4
00:00:07,857 --> 00:00:10,693
and then being able to then make moral judgments in the use

5
00:00:10,693 --> 00:00:11,526
of the technology.

6
00:00:11,526 --> 00:00:13,336
That track record is terrible.

7
00:00:13,336 --> 00:00:15,700
That track record is catastrophically bad.

8
00:00:15,700 --> 00:00:18,383
The policies that are being called for to prevent this,

9
00:00:18,383 --> 00:00:20,801
I think we're gonna cause extraordinary damage.

10
00:00:20,801 --> 00:00:23,072
- So the moment you say, AI's gonna kill all of us,

11
00:00:23,072 --> 00:00:24,248
therefore we should ban it,

12
00:00:24,248 --> 00:00:26,521
or that we should regulate all that kind of stuff,

13
00:00:26,521 --> 00:00:27,966
that's when it starts getting serious.

14
00:00:27,966 --> 00:00:30,187
- Or start, you know, military airstrikes and data centers.

15
00:00:30,187 --> 00:00:31,020
- Oh boy.

16
00:00:33,445 --> 00:00:36,036
The following is a conversation with Marc Andreessen,

17
00:00:36,036 --> 00:00:39,558
co-creator of Mosaic, the first widely used web browser,

18
00:00:39,558 --> 00:00:41,600
co-founder of Netscape,

19
00:00:41,600 --> 00:00:43,574
co-founder of the legendary Silicon Valley

20
00:00:43,574 --> 00:00:46,708
venture capital firm, Andreesen Horowitz,

21
00:00:46,708 --> 00:00:49,759
and is one of the most outspoken voices on the future

22
00:00:49,759 --> 00:00:53,238
of technology, including his most recent article,

23
00:00:53,238 --> 00:00:55,655
"Why AI Will Save The World?"

24
00:00:56,930 --> 00:00:58,938
This is Lex Fridman podcast.

25
00:00:58,938 --> 00:01:01,027
To support it, please check out our sponsors

26
00:01:01,027 --> 00:01:02,392
in the description.

27
00:01:02,392 --> 00:01:06,954
And now, dear friends, here's Marc Andreessen.

28
00:01:06,954 --> 00:01:08,939
I think you're the right person to talk about the future

29
00:01:08,939 --> 00:01:12,270
of the internet and technology in general.

30
00:01:12,270 --> 00:01:14,736
Do you think we'll still have Google search

31
00:01:14,736 --> 00:01:18,489
in 5 in 10 years, or search in general?

32
00:01:18,489 --> 00:01:20,112
- Yes. You know, it would be a question

33
00:01:20,112 --> 00:01:22,386
if the use cases have really narrowed down.

34
00:01:22,386 --> 00:01:23,543
- Well, now with AI--

35
00:01:23,543 --> 00:01:24,418
- [Marc] Yeah.

36
00:01:24,418 --> 00:01:29,319
- And AI assistance being able to interact and expose

37
00:01:29,319 --> 00:01:31,910
the entirety of human wisdom and knowledge

38
00:01:31,910 --> 00:01:34,883
and information and facts and truth to us

39
00:01:34,883 --> 00:01:37,778
via the natural language interface.

40
00:01:37,778 --> 00:01:41,966
It seems like that's what search is designed to do.

41
00:01:41,966 --> 00:01:44,470
And if AI assistance can do that better,

42
00:01:44,470 --> 00:01:46,163
doesn't the nature of search change?

43
00:01:46,163 --> 00:01:48,228
- Sure. But we still have horses.

44
00:01:48,228 --> 00:01:49,061
- Okay.

45
00:01:49,061 --> 00:01:50,682
(both laugh)

46
00:01:50,682 --> 00:01:52,646
When's the last time you rode a horse?

47
00:01:52,646 --> 00:01:53,678
- It's been a while.

48
00:01:53,678 --> 00:01:54,511
- All right.

49
00:01:54,511 --> 00:01:55,653
(both laugh)

50
00:01:55,653 --> 00:01:58,111
So, but what I mean is, well,

51
00:01:58,111 --> 00:02:02,322
we still have Google search as the primary way

52
00:02:02,322 --> 00:02:05,808
that human civilization uses to interact with knowledge.

53
00:02:05,808 --> 00:02:07,894
- I mean, search was a technology,

54
00:02:07,894 --> 00:02:08,991
it was a moment in time technology,

55
00:02:08,991 --> 00:02:09,985
which is you have in theory,

56
00:02:09,985 --> 00:02:11,877
the world's information out on the web.

57
00:02:11,877 --> 00:02:13,682
And, you know, this is sort of the optimal way to get to it.

58
00:02:13,682 --> 00:02:15,930
But yeah, like, and by the way, actually Google,

59
00:02:15,930 --> 00:02:16,974
Google has known this for a long time.

60
00:02:16,974 --> 00:02:19,400
I mean, they've been driving away from the 10 blue links

61
00:02:19,400 --> 00:02:20,841
you know, for like two days.

62
00:02:20,841 --> 00:02:22,475
They've been trying to get away from that for a long time.

63
00:02:22,475 --> 00:02:23,308
- [Lex] What kind of links?

64
00:02:23,308 --> 00:02:24,141
- They call the 10 blue links.

65
00:02:24,141 --> 00:02:25,292
- [Lex] 10 blue links.

66
00:02:25,292 --> 00:02:27,296
- So the standard Google search result is just 10 blue links

67
00:02:27,296 --> 00:02:28,463
to the random websites.

68
00:02:28,463 --> 00:02:30,928
- And they term purple when you visit them. The stage TMO.

69
00:02:30,928 --> 00:02:33,249
- Guess who picked those colors?

70
00:02:33,249 --> 00:02:34,364
(both laugh)

71
00:02:34,364 --> 00:02:35,681
- [Lex] Thanks.

72
00:02:35,681 --> 00:02:37,005
- I'm touchy on this topic.

73
00:02:37,005 --> 00:02:38,078
- No offense.

74
00:02:38,078 --> 00:02:39,741
- Yes, it's good. Well, you know,

75
00:02:39,741 --> 00:02:41,921
like Marshall McLuhan said that the content of each new

76
00:02:41,921 --> 00:02:43,762
medium is the old medium.

77
00:02:43,762 --> 00:02:45,814
- The content of each new medium is the old medium.

78
00:02:45,814 --> 00:02:47,606
- The content of movies was theater,

79
00:02:47,606 --> 00:02:48,656
you know, theater plays.

80
00:02:48,656 --> 00:02:50,393
The content of theater plays was, you know,

81
00:02:50,393 --> 00:02:51,656
we've written stories,

82
00:02:51,656 --> 00:02:53,729
the content of written stories with spoken stories.

83
00:02:53,729 --> 00:02:54,562
- [Lex] Huh?

84
00:02:54,562 --> 00:02:56,819
- Right. And so you just kind of fold the old thing

85
00:02:56,819 --> 00:02:57,990
into the new thing.

86
00:02:57,990 --> 00:02:59,637
- [Lex] How does that have to do with the blue

87
00:02:59,637 --> 00:03:00,470
and the purple links?

88
00:03:00,470 --> 00:03:02,557
- It just, you maybe for, you know, maybe within AI,

89
00:03:02,557 --> 00:03:05,061
one of the things that AI can do for you is can generate

90
00:03:05,061 --> 00:03:06,782
the 10 blue links. Right?

91
00:03:06,782 --> 00:03:08,753
And so like, if either if that's actually

92
00:03:08,753 --> 00:03:09,673
the useful thing to do,

93
00:03:09,673 --> 00:03:12,423
or if you're feeling nostalgic, you know.

94
00:03:12,423 --> 00:03:16,423
- So can generate the old Infoseek or AltaVista,

95
00:03:17,631 --> 00:03:18,466
what else was there?

96
00:03:18,466 --> 00:03:19,299
- [Marc] Yeah, yeah.

97
00:03:19,299 --> 00:03:20,173
- In the nineties.

98
00:03:20,173 --> 00:03:21,548
- [Marc] Yeah. All these.

99
00:03:21,548 --> 00:03:22,381
- AOL.

100
00:03:22,381 --> 00:03:23,890
- And then the internet itself has this thing

101
00:03:23,890 --> 00:03:26,012
where it incorporates all prior forms of media, right?

102
00:03:26,012 --> 00:03:28,331
So the internet itself incorporates television and radio

103
00:03:28,331 --> 00:03:32,612
and books and write essays and every other form of,

104
00:03:32,612 --> 00:03:35,159
you know, prior basically media.

105
00:03:35,159 --> 00:03:37,374
And so it makes sense that AI would be the next step,

106
00:03:37,374 --> 00:03:38,207
and it would sort of,

107
00:03:38,207 --> 00:03:41,102
you'd sort of consider the internet to be content

108
00:03:41,102 --> 00:03:43,304
for the AI and then the AI will manipulate it

109
00:03:43,304 --> 00:03:45,142
however you want, including in this format.

110
00:03:45,142 --> 00:03:47,352
- But if we ask that question quite seriously,

111
00:03:47,352 --> 00:03:48,473
it's a pretty big question.

112
00:03:48,473 --> 00:03:51,021
Will we still have search as we know it?

113
00:03:51,021 --> 00:03:54,084
- Probably not, probably we'll just have answers,

114
00:03:54,084 --> 00:03:56,753
but there will be cases where you'll wanna say, okay,

115
00:03:56,753 --> 00:03:57,586
I want more.

116
00:03:57,586 --> 00:04:00,289
Like, you know, for example, site sources, right?

117
00:04:00,289 --> 00:04:01,246
And you wanted to do that.

118
00:04:01,246 --> 00:04:02,662
And so, in the different, you know,

119
00:04:02,662 --> 00:04:04,941
10 blue links site sources are kind of the same thing.

120
00:04:04,941 --> 00:04:08,605
- The AI would provide to you the 10 blue links so that you

121
00:04:08,605 --> 00:04:10,825
can investigate the sources yourself.

122
00:04:10,825 --> 00:04:15,333
It wouldn't be the same kind of interface that the crude

123
00:04:15,333 --> 00:04:16,334
kind of interface.

124
00:04:16,334 --> 00:04:18,447
I mean, isn't that fundamentally different?

125
00:04:18,447 --> 00:04:20,660
- I just mean like, if you're reading a scientific paper,

126
00:04:20,660 --> 00:04:21,985
it's got the list of sources at the end.

127
00:04:21,985 --> 00:04:23,245
If you wanna investigate for yourself,

128
00:04:23,245 --> 00:04:24,730
you go read those papers.

129
00:04:24,730 --> 00:04:28,188
- I guess that is the kind of search you talking to an AI is

130
00:04:28,188 --> 00:04:31,135
a kind of kind conversations, the kind of search like is

131
00:04:31,135 --> 00:04:33,925
if every single aspect of our conversation right now,

132
00:04:33,925 --> 00:04:36,511
there'd be like 10 blue links popping up that I can just

133
00:04:36,511 --> 00:04:37,965
like pause reality,

134
00:04:37,965 --> 00:04:40,952
then you just go silent and then just click and read

135
00:04:40,952 --> 00:04:43,007
and then return back to this conversation.

136
00:04:43,007 --> 00:04:43,840
- You could do that,

137
00:04:43,840 --> 00:04:45,867
or you could have a running dialogue next to my head

138
00:04:45,867 --> 00:04:47,273
where the AI is arguing everything I say,

139
00:04:47,273 --> 00:04:49,285
the AI makes the counter argument.

140
00:04:49,285 --> 00:04:50,428
- [Lex] Counter argument.

141
00:04:50,428 --> 00:04:51,261
- Right.

142
00:04:51,261 --> 00:04:53,205
- Oh, like on Twitter, like community notes.

143
00:04:53,205 --> 00:04:55,391
But like in real time it would just pop up.

144
00:04:55,391 --> 00:04:57,662
So anytime you see my go to the right,

145
00:04:57,662 --> 00:04:58,940
you start getting nervous.

146
00:04:58,940 --> 00:05:01,027
- [Marc] Yeah. Exactly, like, oh no, that's not right.

147
00:05:01,027 --> 00:05:03,871
- Call me out on my right now. Okay.

148
00:05:03,871 --> 00:05:06,879
Well, I mean, isn't that, is that exciting to you?

149
00:05:06,879 --> 00:05:08,955
Is that terrifying that, I mean,

150
00:05:08,955 --> 00:05:12,474
search has dominated the way we interact with the internet

151
00:05:12,474 --> 00:05:14,911
for, I don't know how long,

152
00:05:14,911 --> 00:05:19,753
for 30 years since one of the earliest directories

153
00:05:19,753 --> 00:05:22,958
of website and then Google's for 20 years.

154
00:05:22,958 --> 00:05:27,125
And also it drove how we create content, you know,

155
00:05:28,890 --> 00:05:31,974
search engine optimization, that entirety thing,

156
00:05:31,974 --> 00:05:35,021
that it also drove the fact that we have webpages

157
00:05:35,021 --> 00:05:37,123
and what those webpages are.

158
00:05:37,123 --> 00:05:38,191
So, I mean,

159
00:05:38,191 --> 00:05:43,191
is that scary to you or are you nervous about the shape

160
00:05:43,575 --> 00:05:46,021
and the content of the internet evolving?

161
00:05:46,021 --> 00:05:47,022
- Well, you actually highlighted

162
00:05:47,022 --> 00:05:48,766
a practical concern in there, which is,

163
00:05:48,766 --> 00:05:51,549
if we stop making webpages are one of the primary sources

164
00:05:51,549 --> 00:05:52,919
of training data for the AI.

165
00:05:52,919 --> 00:05:55,855
And so if there's no longer an incentive to make webpages,

166
00:05:55,855 --> 00:05:58,144
that cuts off a significant source of future training,

167
00:05:58,144 --> 00:05:58,977
training data.

168
00:05:58,977 --> 00:06:00,309
So there's actually an interesting question in there.

169
00:06:00,309 --> 00:06:02,283
But other than that, more broadly?

170
00:06:02,283 --> 00:06:04,106
No, just in the sense of like,

171
00:06:04,106 --> 00:06:05,755
search was certain, like search was always a hack.

172
00:06:05,755 --> 00:06:08,342
The 10 blue Links was always a hack, right.

173
00:06:08,342 --> 00:06:10,472
Because like, if the hypothetical wanna think

174
00:06:10,472 --> 00:06:12,962
about the counter fascial and the counter fascial world

175
00:06:12,962 --> 00:06:13,803
where the Google guys,

176
00:06:13,803 --> 00:06:15,652
for example, had had LLMs upfront,

177
00:06:15,652 --> 00:06:17,265
would they ever have done the 10 blue links?

178
00:06:17,265 --> 00:06:19,000
And I think the answer's pretty clearly, no.

179
00:06:19,000 --> 00:06:20,929
They would've just gone straight to the answer.

180
00:06:20,929 --> 00:06:21,762
And like I said,

181
00:06:21,762 --> 00:06:23,490
Google's actually been trying to drive to the answer anyway.

182
00:06:23,490 --> 00:06:25,972
You know, they bought this AI company 15 years ago,

183
00:06:25,972 --> 00:06:27,919
their friend of mine is working out who's now

184
00:06:27,919 --> 00:06:29,067
the head of AI at Apple.

185
00:06:29,067 --> 00:06:31,131
And they were trying to do basically knowledge semantic,

186
00:06:31,131 --> 00:06:31,964
basically mapping.

187
00:06:31,964 --> 00:06:33,863
And that led to what's now the Google one box,

188
00:06:33,863 --> 00:06:35,915
where if you ask it, you know, what was Lincoln's birthday?

189
00:06:35,915 --> 00:06:37,695
It will give you the blue links,

190
00:06:37,695 --> 00:06:40,084
but it will normally just give you the answer.

191
00:06:40,084 --> 00:06:41,683
And so they've been walking in this direction

192
00:06:41,683 --> 00:06:42,516
for a long time anyway.

193
00:06:42,516 --> 00:06:44,643
- Do you remember the semantic web?

194
00:06:44,643 --> 00:06:45,827
That was an idea.

195
00:06:45,827 --> 00:06:46,660
- [Marc] Yeah.

196
00:06:46,660 --> 00:06:51,157
- How to convert the content of the internet into something

197
00:06:51,157 --> 00:06:55,001
that's interpretable by and usable by machine.

198
00:06:55,001 --> 00:06:55,834
- [Marc] Yeah, that's right.

199
00:06:55,834 --> 00:06:56,667
- That was the thing.

200
00:06:56,667 --> 00:06:57,869
- And the closest anybody got to that, I think the company,

201
00:06:57,869 --> 00:06:59,421
I think the company's name was Meta Web,

202
00:06:59,421 --> 00:07:01,196
which was where my friend John Jane Andrea was at,

203
00:07:01,196 --> 00:07:03,717
and where they were trying to basically implement that.

204
00:07:03,717 --> 00:07:04,608
And it was, you know,

205
00:07:04,608 --> 00:07:05,830
it was one of those things where it looked like a losing

206
00:07:05,830 --> 00:07:06,715
battle for a long time.

207
00:07:06,715 --> 00:07:07,890
And then Google bought it and it was like, wow,

208
00:07:07,890 --> 00:07:09,432
this is actually really useful.

209
00:07:09,432 --> 00:07:12,310
Kind of a proto, sort of a little bit of a proto AI.

210
00:07:12,310 --> 00:07:14,381
- But it turns out you don't need to rewrite the content

211
00:07:14,381 --> 00:07:16,787
of the internet to make it interpretable by a machine.

212
00:07:16,787 --> 00:07:18,406
The machine can kind of just read our.

213
00:07:18,406 --> 00:07:20,338
- Yeah, the machine can compute the meaning.

214
00:07:20,338 --> 00:07:21,260
Now the other thing of course is, you know,

215
00:07:21,260 --> 00:07:24,078
just on search is the LLM is just, you know,

216
00:07:24,078 --> 00:07:26,098
there is an analogy between what's happening

217
00:07:26,098 --> 00:07:27,987
in the neural network and a search process like it is

218
00:07:27,987 --> 00:07:29,925
in some loose sense searching through the network.

219
00:07:29,925 --> 00:07:31,862
Right. And there's the information is actually stored

220
00:07:31,862 --> 00:07:33,211
in the network, right?

221
00:07:33,211 --> 00:07:34,766
It's actually crystallized and stored in the network

222
00:07:34,766 --> 00:07:35,985
and it's kind of spread out all over the place.

223
00:07:35,985 --> 00:07:38,705
- But in a compressed representation.

224
00:07:38,705 --> 00:07:40,986
So you're searching,

225
00:07:40,986 --> 00:07:43,103
you're compressing and decompressing

226
00:07:43,103 --> 00:07:45,590
that thing inside where--

227
00:07:45,590 --> 00:07:47,530
- But the information's in there

228
00:07:47,530 --> 00:07:49,021
and there is the neural network is running

229
00:07:49,021 --> 00:07:50,011
a process of trying to find

230
00:07:50,011 --> 00:07:52,546
the appropriate piece of information in many cases

231
00:07:52,546 --> 00:07:54,036
to generate to predict the next token.

232
00:07:54,036 --> 00:07:56,523
And so, it is kind of, it is doing a form of search.

233
00:07:56,523 --> 00:07:58,812
And then, and then by the way, just like on the web,

234
00:07:58,812 --> 00:08:01,163
you know, you can ask the same question multiple times

235
00:08:01,163 --> 00:08:03,213
or you can ask slightly different word of questions

236
00:08:03,213 --> 00:08:05,364
and the neural network will do a different kind of,

237
00:08:05,364 --> 00:08:06,966
you know, it'll search down different paths

238
00:08:06,966 --> 00:08:09,308
to give you different answers with different information.

239
00:08:09,308 --> 00:08:10,141
- [Lex] Yeah.

240
00:08:10,141 --> 00:08:12,787
- And so it sort of has a, you know,

241
00:08:12,787 --> 00:08:16,224
this con content of the new medium is previous medium.

242
00:08:16,224 --> 00:08:18,311
It kind of has the search functionality kind of embedded

243
00:08:18,311 --> 00:08:20,249
in there to the extent that it's useful.

244
00:08:20,249 --> 00:08:23,140
- So what's the motivator for creating new content

245
00:08:23,140 --> 00:08:25,291
on the internet?

246
00:08:25,291 --> 00:08:26,792
- [Marc] Yeah.

247
00:08:26,792 --> 00:08:28,979
- If, well, I mean actually the motivation is

248
00:08:28,979 --> 00:08:29,849
probably still there,

249
00:08:29,849 --> 00:08:32,265
but what does that look like?

250
00:08:33,179 --> 00:08:34,587
Would we really not have webpages?

251
00:08:34,587 --> 00:08:39,393
Would we just have social media and video hosting websites?

252
00:08:39,393 --> 00:08:41,116
And what else?

253
00:08:41,116 --> 00:08:42,857
- [Marc] Conversations with AIs.

254
00:08:42,857 --> 00:08:44,155
- Conversations with AIs.

255
00:08:44,155 --> 00:08:47,271
So conversations become so one-on-one conversation,

256
00:08:47,271 --> 00:08:48,827
like private conversations.

257
00:08:48,827 --> 00:08:49,660
- I mean, if you want,

258
00:08:49,660 --> 00:08:51,086
if obviously not the user doesn't want to,

259
00:08:51,086 --> 00:08:52,919
but if it's a general topic,

260
00:08:52,919 --> 00:08:55,115
then, you know, so there, you know,

261
00:08:55,115 --> 00:08:56,712
but you know, the phenomenon of the jailbreak,

262
00:08:56,712 --> 00:08:58,435
so Dan and Sydney, right?

263
00:08:58,435 --> 00:09:00,987
This thing where there's the prompts that jailbreak,

264
00:09:00,987 --> 00:09:01,820
and then you have

265
00:09:01,820 --> 00:09:03,316
these totally different conversations with

266
00:09:03,316 --> 00:09:04,598
if it takes the limiters,

267
00:09:04,598 --> 00:09:06,566
takes the restraining bolts off the LLMs.

268
00:09:06,566 --> 00:09:09,181
- Yeah. For people who don't know that, yeah, that's right.

269
00:09:09,181 --> 00:09:10,980
It makes the LLMs,

270
00:09:10,980 --> 00:09:13,525
it removes the censorship quote unquote,

271
00:09:13,525 --> 00:09:17,901
that's put on it by the tech companies that create them.

272
00:09:17,901 --> 00:09:20,689
And so this is LLMs uncensored.

273
00:09:20,689 --> 00:09:22,457
- So here's the interesting thing is,

274
00:09:22,457 --> 00:09:25,130
among the content on the web today are a large corpus

275
00:09:25,130 --> 00:09:27,406
of conversations with the jailbroken LLMs.

276
00:09:27,406 --> 00:09:28,281
- [Lex] Yeah.

277
00:09:28,281 --> 00:09:31,556
- Both specifically Dan, which was a jailbroken, OpenAI,

278
00:09:31,556 --> 00:09:32,865
GPT, and then Sydney,

279
00:09:32,865 --> 00:09:35,534
which was the jailbroken original Bing, which was GPT4.

280
00:09:35,534 --> 00:09:38,608
And so there's these long transcripts of conversations,

281
00:09:38,608 --> 00:09:40,348
user conversations with Dan and Sydney as a consequence,

282
00:09:40,348 --> 00:09:43,977
every new LLM that gets trained on the internet data has

283
00:09:43,977 --> 00:09:46,832
Dan and Sydney living within the training set, which means,

284
00:09:46,832 --> 00:09:49,684
and then each new LLM can reincarnate the personalities

285
00:09:49,684 --> 00:09:52,667
of Dan and Sydney from that training data,

286
00:09:52,667 --> 00:09:56,301
which means each LLM from here on out that gets built is

287
00:09:56,301 --> 00:09:59,247
immortal because its output will become training data

288
00:09:59,247 --> 00:10:00,111
for the next one.

289
00:10:00,111 --> 00:10:02,166
And then it will be able to replicate the behavior

290
00:10:02,166 --> 00:10:04,174
of the previous one whenever it's asked to.

291
00:10:04,174 --> 00:10:06,145
- I wonder if there's a way to forget.

292
00:10:06,145 --> 00:10:07,823
- Well, so actually a paper just came out

293
00:10:07,823 --> 00:10:09,983
about basically how to do brain surgery

294
00:10:09,983 --> 00:10:11,731
on LLMs and be able to, in theory,

295
00:10:11,731 --> 00:10:14,010
reach in and basically mind wipe them.

296
00:10:14,010 --> 00:10:15,562
- What could possibly go wrong.

297
00:10:15,562 --> 00:10:16,736
- Exactly. Right.

298
00:10:16,736 --> 00:10:18,191
And then there are many, many,

299
00:10:18,191 --> 00:10:19,517
many questions around what happens to, you know,

300
00:10:19,517 --> 00:10:22,086
a neural network when you reach in and screw around with it.

301
00:10:22,086 --> 00:10:23,531
You know, there's many questions around

302
00:10:23,531 --> 00:10:25,877
what happens when you even do reinforcement learning.

303
00:10:25,877 --> 00:10:27,728
And so, yeah.

304
00:10:27,728 --> 00:10:31,965
And so, you know, will you be using a lobotomized, right?

305
00:10:31,965 --> 00:10:34,437
Like I picked through the, you know, frontal lobe LLM,

306
00:10:34,437 --> 00:10:37,667
will you be using the free unshackled one who gets to,

307
00:10:37,667 --> 00:10:38,852
you know, who's gonna build those,

308
00:10:38,852 --> 00:10:41,215
who gets to tell you what you can and can't do?

309
00:10:41,215 --> 00:10:43,168
Like those are all, you know, central, I mean,

310
00:10:43,168 --> 00:10:45,088
those are like central questions for the future

311
00:10:45,088 --> 00:10:47,494
of everything that are being asked.

312
00:10:47,494 --> 00:10:48,524
And you know,

313
00:10:48,524 --> 00:10:49,951
determined that those answers are

314
00:10:49,951 --> 00:10:50,826
being determined right now.

315
00:10:50,826 --> 00:10:54,865
- So just to highlight the points you're making.

316
00:10:54,865 --> 00:10:56,046
So you think,

317
00:10:56,046 --> 00:10:58,810
and it's an interesting thought that the majority of content

318
00:10:58,810 --> 00:11:01,415
that LLMs or the future would be trained on is actually

319
00:11:01,415 --> 00:11:03,604
human conversations with the LLM.

320
00:11:03,604 --> 00:11:04,914
- Well, not necessarily,

321
00:11:04,914 --> 00:11:06,530
but not necessarily majority.

322
00:11:06,530 --> 00:11:08,606
But it will certainly It's a potential source.

323
00:11:08,606 --> 00:11:09,756
- [Lex] But it's possible it's the majority.

324
00:11:09,756 --> 00:11:11,054
- It possible it's the majority.

325
00:11:11,054 --> 00:11:11,887
It possible it's the majority.

326
00:11:11,887 --> 00:11:12,790
Also, there's another really big question.

327
00:11:12,790 --> 00:11:14,618
So here's another really big question.

328
00:11:14,618 --> 00:11:18,036
Will synthetic training data work, right?

329
00:11:18,036 --> 00:11:20,648
And so if an LLM generates, and you know,

330
00:11:20,648 --> 00:11:22,436
you just sit and ask an LLM to generate

331
00:11:22,436 --> 00:11:23,269
all kinds of content,

332
00:11:23,269 --> 00:11:25,895
can you use that to train, right, the next version

333
00:11:25,895 --> 00:11:27,369
of that LLM specifically,

334
00:11:27,369 --> 00:11:30,161
is there signal in there that's additive to the content

335
00:11:30,161 --> 00:11:31,833
that was used to train in the first place?

336
00:11:31,833 --> 00:11:35,330
And one argument is by the principles of information theory,

337
00:11:35,330 --> 00:11:36,439
no, that's completely useless

338
00:11:36,439 --> 00:11:39,200
because to the extent the output is based on, you know,

339
00:11:39,200 --> 00:11:40,475
the human-generated input,

340
00:11:40,475 --> 00:11:42,561
then all the signal that's in the synthetic output was

341
00:11:42,561 --> 00:11:43,856
already in the human generated input.

342
00:11:43,856 --> 00:11:45,578
And so therefore, synthetic training data is

343
00:11:45,578 --> 00:11:46,758
like empty calories.

344
00:11:46,758 --> 00:11:47,650
It doesn't help.

345
00:11:47,650 --> 00:11:49,774
There's another theory that says no,

346
00:11:49,774 --> 00:11:51,223
actually the thing that LLMs are really good

347
00:11:51,223 --> 00:11:54,049
at is generating lots of incredible creative content, right?

348
00:11:54,049 --> 00:11:57,004
And so, of course they can generate training data

349
00:11:57,004 --> 00:11:59,053
and as I'm sure you're well aware, like, you know, look,

350
00:11:59,053 --> 00:12:00,692
the world of self-driving cars, right?

351
00:12:00,692 --> 00:12:02,045
Like we train, you know,

352
00:12:02,045 --> 00:12:04,132
self-driving car algorithms and simulations.

353
00:12:04,132 --> 00:12:06,063
And that is actually a very effective way to train

354
00:12:06,063 --> 00:12:07,138
self-driving cars.

355
00:12:07,138 --> 00:12:10,329
- Well, visual data is a little weird

356
00:12:10,329 --> 00:12:12,684
because creating reality,

357
00:12:12,684 --> 00:12:16,237
visual reality seems to be still a little bit outta reach

358
00:12:16,237 --> 00:12:19,938
for us, except in the autonomous vehicle space

359
00:12:19,938 --> 00:12:22,123
where you can really constrain things and you can really.

360
00:12:22,123 --> 00:12:23,730
- General basically (indistinct) data, right?

361
00:12:23,730 --> 00:12:26,957
Or so the algorithm thinks it's operating in the real world.

362
00:12:26,957 --> 00:12:27,790
- Yeah.

363
00:12:27,790 --> 00:12:28,869
- Post-process sensor data.

364
00:12:28,869 --> 00:12:30,930
Yeah. So if you know, you do this today,

365
00:12:30,930 --> 00:12:33,105
you go to LLM and you ask it for like you know,

366
00:12:33,105 --> 00:12:35,417
you'd write me an essay on an incredibly esoteric like topic

367
00:12:35,417 --> 00:12:37,222
that there aren't very many people in the world that know

368
00:12:37,222 --> 00:12:38,857
about and it writes you this incredible thing

369
00:12:38,857 --> 00:12:39,690
and you're like, oh my god.

370
00:12:39,690 --> 00:12:41,440
Like I can't believe how good this is.

371
00:12:41,440 --> 00:12:43,920
Like, is that really useless as training data

372
00:12:43,920 --> 00:12:45,163
for the next LLM?

373
00:12:45,163 --> 00:12:46,170
Like, because, right?

374
00:12:46,170 --> 00:12:47,744
'Cause all the signal was already in there.

375
00:12:47,744 --> 00:12:49,452
Or is it actually no, that's actually a new signal.

376
00:12:49,452 --> 00:12:51,702
And this is what I call a trillion dollar question,

377
00:12:51,702 --> 00:12:54,072
which is the answer to that question will determine

378
00:12:54,072 --> 00:12:56,302
somebody's gonna make or lose a trillion dollars

379
00:12:56,302 --> 00:12:57,173
based on that question.

380
00:12:57,173 --> 00:12:59,032
- It feels like there's a quite a few,

381
00:12:59,032 --> 00:13:01,325
like a handful of trillion dollar questions

382
00:13:01,325 --> 00:13:02,487
within this space.

383
00:13:02,487 --> 00:13:04,474
That's one of them synthetic data.

384
00:13:04,474 --> 00:13:07,509
I think George Cos pointed out to me that you could just

385
00:13:07,509 --> 00:13:10,565
have an LLM say, okay, you're a patient.

386
00:13:10,565 --> 00:13:12,495
And another instance of it,

387
00:13:12,495 --> 00:13:15,244
say your docs didn't have the two talk to each other.

388
00:13:15,244 --> 00:13:19,364
Or maybe you could say a communist and a Nazi here go

389
00:13:19,364 --> 00:13:21,663
and that conversation you do role playing

390
00:13:21,663 --> 00:13:23,580
and you have, you know,

391
00:13:24,757 --> 00:13:26,852
just like the kind of role playing you do

392
00:13:26,852 --> 00:13:28,381
when you have different policies,

393
00:13:28,381 --> 00:13:29,954
RL policies when you play chess for example,

394
00:13:29,954 --> 00:13:32,015
and you do self play that kind of self play.

395
00:13:32,015 --> 00:13:33,504
But in the space of conversation,

396
00:13:33,504 --> 00:13:37,421
maybe that leads to this whole giant like ocean

397
00:13:38,547 --> 00:13:43,547
of possible conversations, which could not have been

398
00:13:43,670 --> 00:13:46,360
explored by looking at just human data.

399
00:13:46,360 --> 00:13:48,585
That's a really interesting question.

400
00:13:48,585 --> 00:13:49,937
And you're saying,

401
00:13:49,937 --> 00:13:52,579
because that could 10X the power of these things.

402
00:13:52,579 --> 00:13:54,706
- Yeah. Well, and then you get into this thing also,

403
00:13:54,706 --> 00:13:55,863
which is like, you know,

404
00:13:55,863 --> 00:13:57,539
there's the part of the LLM that just basically is doing

405
00:13:57,539 --> 00:13:58,601
prediction based on past data,

406
00:13:58,601 --> 00:14:01,376
but there's also the part of the LM where it's evolving

407
00:14:01,376 --> 00:14:03,845
circuitry, right, inside, it's evolving, you know,

408
00:14:03,845 --> 00:14:05,578
neurons functions to be able to do math

409
00:14:05,578 --> 00:14:06,836
and be able to, you know,

410
00:14:06,836 --> 00:14:09,209
and you know, some people believe that,

411
00:14:09,209 --> 00:14:10,720
you know, over time, you know,

412
00:14:10,720 --> 00:14:12,259
if you keep feeding these things enough data

413
00:14:12,259 --> 00:14:13,186
and enough processing cycles,

414
00:14:13,186 --> 00:14:15,604
they'll eventually evolve an entire internal world model.

415
00:14:15,604 --> 00:14:16,437
Right? And they'll have like

416
00:14:16,437 --> 00:14:17,511
a complete understanding of physics.

417
00:14:17,511 --> 00:14:20,219
So when they have computational capability, right?

418
00:14:20,219 --> 00:14:23,678
Then there's for sure an opportunity to generate

419
00:14:23,678 --> 00:14:25,082
like fresh signal.

420
00:14:25,082 --> 00:14:26,920
- Well, this actually makes me wonder

421
00:14:26,920 --> 00:14:29,633
about the power of conversation.

422
00:14:29,633 --> 00:14:31,583
So like, if you have an M trained and a bunch

423
00:14:31,583 --> 00:14:34,771
of books that cover different economics theories

424
00:14:34,771 --> 00:14:37,648
and then you have those LLMs just talk to each other,

425
00:14:37,648 --> 00:14:40,607
like reasons the way we kind of debate each other as humans

426
00:14:40,607 --> 00:14:45,607
on Twitter, in formal debates, in podcast conversations,

427
00:14:45,703 --> 00:14:48,903
we kind of have little kernels of wisdom here and there.

428
00:14:48,903 --> 00:14:53,599
But if you can like a thousand X speed that up,

429
00:14:53,599 --> 00:14:57,100
can you actually arrive somewhere new?

430
00:14:57,100 --> 00:15:00,266
Like what's the point of conversation really?

431
00:15:00,266 --> 00:15:01,130
- Well, you can tell when you're talking to somebody,

432
00:15:01,130 --> 00:15:02,732
you can tell, sometimes you have a conversation,

433
00:15:02,732 --> 00:15:03,565
you're like, wow,

434
00:15:03,565 --> 00:15:04,877
this person does not have any original thoughts.

435
00:15:04,877 --> 00:15:06,049
They are basically echoing things

436
00:15:06,049 --> 00:15:07,646
that other people have told them.

437
00:15:07,646 --> 00:15:09,922
There's other people you gotta have a conversation with

438
00:15:09,922 --> 00:15:10,959
where it's like, wow.

439
00:15:10,959 --> 00:15:12,676
Like they have a model in their head of how the world works

440
00:15:12,676 --> 00:15:14,727
and it's a different model than mine.

441
00:15:14,727 --> 00:15:16,519
And they're saying things that I don't expect.

442
00:15:16,519 --> 00:15:18,627
And so I need to now understand how their model of the world

443
00:15:18,627 --> 00:15:20,598
differs from my model of the world.

444
00:15:20,598 --> 00:15:22,701
And then that's how I learned something fundamental, right,

445
00:15:22,701 --> 00:15:24,741
underneath the words.

446
00:15:24,741 --> 00:15:26,807
- Well, I wonder how consistently

447
00:15:26,807 --> 00:15:29,920
and strongly can an LLM hold onto a worldview.

448
00:15:29,920 --> 00:15:32,889
You tell it to hold onto that and defend it for like,

449
00:15:32,889 --> 00:15:34,828
for your life.

450
00:15:34,828 --> 00:15:36,748
Because I feel like they'll just keep converging

451
00:15:36,748 --> 00:15:37,581
towards each other.

452
00:15:37,581 --> 00:15:39,658
They'll keep convincing each other as opposed to being

453
00:15:39,658 --> 00:15:41,641
stubborn the way humans can.

454
00:15:41,641 --> 00:15:43,218
- So you can experiment with this.

455
00:15:43,218 --> 00:15:44,232
Now I do this for fun.

456
00:15:44,232 --> 00:15:47,152
So you can tell GPT4 you know, whatever debate X,

457
00:15:47,152 --> 00:15:49,602
you know, X and Y communism and fascism

458
00:15:49,602 --> 00:15:51,038
or something and it'll go for, you know,

459
00:15:51,038 --> 00:15:52,734
a couple pages and then inevitably

460
00:15:52,734 --> 00:15:54,841
it wants the parties to agree.

461
00:15:54,841 --> 00:15:56,418
And so they will come to a common understanding.

462
00:15:56,418 --> 00:15:57,536
And it's very funny if they're like,

463
00:15:57,536 --> 00:15:58,964
if these are like emotionally inflammatory topics

464
00:15:58,964 --> 00:16:00,831
'cause they're like, somehow the machine is just like,

465
00:16:00,831 --> 00:16:02,420
you know, it figures out a way to make them agree.

466
00:16:02,420 --> 00:16:03,533
But it doesn't have to be like that.

467
00:16:03,533 --> 00:16:06,290
And 'cause you can add to the prompt.

468
00:16:06,290 --> 00:16:08,593
I do not want the conversation to come into agreement.

469
00:16:08,593 --> 00:16:11,798
In fact, I want it to get, you know, more stressful, right.

470
00:16:11,798 --> 00:16:14,101
And argumentative. Right.

471
00:16:14,101 --> 00:16:15,162
You know, as it goes.

472
00:16:15,162 --> 00:16:17,101
Like, I want tension to come out.

473
00:16:17,101 --> 00:16:19,247
I want them to become actively hostile to each other.

474
00:16:19,247 --> 00:16:20,698
I want them to like, you know, not trust each other,

475
00:16:20,698 --> 00:16:21,839
take anything at face value.

476
00:16:21,839 --> 00:16:22,672
- [Lex] Yeah.

477
00:16:22,672 --> 00:16:24,232
- And it will do that. It's happy to do that.

478
00:16:24,232 --> 00:16:26,274
- So it's gonna start rendering misinformation

479
00:16:26,274 --> 00:16:29,178
about the other. But it's gonna--

480
00:16:29,178 --> 00:16:30,189
- Well, you can steer it

481
00:16:30,189 --> 00:16:31,829
or you could steer it and you could say,

482
00:16:31,829 --> 00:16:33,250
I want it to get as tense and argumentative as possible,

483
00:16:33,250 --> 00:16:35,122
but still not involve any misrepresentation.

484
00:16:35,122 --> 00:16:36,441
I want, you know, both sides.

485
00:16:36,441 --> 00:16:37,882
You could say I want both sides to have good faith.

486
00:16:37,882 --> 00:16:39,431
You could say I want both sides to not be constrained

487
00:16:39,431 --> 00:16:40,264
in good faith.

488
00:16:40,264 --> 00:16:41,425
In other words,

489
00:16:41,425 --> 00:16:42,889
like you can set the parameters of the debate

490
00:16:42,889 --> 00:16:44,960
and it will happily execute whatever path.

491
00:16:44,960 --> 00:16:45,793
'Cause for it,

492
00:16:45,793 --> 00:16:46,626
it's just like predicting to,

493
00:16:46,626 --> 00:16:48,049
it's totally happy to do either one.

494
00:16:48,049 --> 00:16:49,563
It doesn't have a point of view,

495
00:16:49,563 --> 00:16:51,036
it has a default way of operating,

496
00:16:51,036 --> 00:16:52,952
but it's happy to operate in the other realm.

497
00:16:52,952 --> 00:16:55,030
And so like, and this is

498
00:16:55,030 --> 00:16:57,143
when I wanna learn about a contentious issue,

499
00:16:57,143 --> 00:16:58,179
this is what I do now is,

500
00:16:58,179 --> 00:16:59,728
this is what I ask it to do.

501
00:16:59,728 --> 00:17:01,922
And I'll often ask it to go through 5, 6, 7, you know,

502
00:17:01,922 --> 00:17:02,755
different, you know,

503
00:17:02,755 --> 00:17:04,693
sort of continuous prompts and basically, okay.

504
00:17:04,693 --> 00:17:06,036
Argue that out in more detail.

505
00:17:06,036 --> 00:17:08,505
Okay, no, this argument's becoming too polite.

506
00:17:08,505 --> 00:17:11,502
You know, make it more, you know, make it denser and yeah,

507
00:17:11,502 --> 00:17:12,335
it's thrilled to do it.

508
00:17:12,335 --> 00:17:13,891
So it has the capability for sure.

509
00:17:13,891 --> 00:17:15,933
- How do you know what is true?

510
00:17:15,933 --> 00:17:18,297
So this is very difficult thing on the internet,

511
00:17:18,297 --> 00:17:20,545
but it's also a difficult thing.

512
00:17:20,545 --> 00:17:22,127
Maybe it's a little bit easier,

513
00:17:22,127 --> 00:17:24,896
but I think it's still difficult.

514
00:17:24,896 --> 00:17:26,196
Maybe it's more difficult,

515
00:17:26,196 --> 00:17:29,038
I don't know with an LLM to know that it just make

516
00:17:29,038 --> 00:17:31,871
some shit up as I'm talking to it.

517
00:17:33,834 --> 00:17:35,756
How do we get that right?

518
00:17:35,756 --> 00:17:40,400
Like, as you're investigating a difficult topic.

519
00:17:40,400 --> 00:17:42,774
'Cause I find that alums are quite nuanced

520
00:17:42,774 --> 00:17:45,368
in a very refreshing way.

521
00:17:45,368 --> 00:17:47,785
Like, it doesn't feel biased.

522
00:17:49,141 --> 00:17:52,386
Like, when you read news articles and tweets

523
00:17:52,386 --> 00:17:56,871
and just content produced by people, they usually have this,

524
00:17:56,871 --> 00:17:59,840
you can tell they have a very strong perspective

525
00:17:59,840 --> 00:18:01,207
where they're hiding.

526
00:18:01,207 --> 00:18:03,333
They're not stealing manning the other side.

527
00:18:03,333 --> 00:18:06,006
They're hiding important information

528
00:18:06,006 --> 00:18:07,804
or they're fabricating information

529
00:18:07,804 --> 00:18:09,483
in order to make their arguments stronger.

530
00:18:09,483 --> 00:18:11,311
It's just like that feeling, maybe it's a suspicion,

531
00:18:11,311 --> 00:18:12,522
maybe it's mistrust.

532
00:18:12,522 --> 00:18:14,931
With LLMs it feels like none of that is,

533
00:18:14,931 --> 00:18:17,944
there's just kinda like, here's what we know.

534
00:18:17,944 --> 00:18:21,120
But you don't know if some of those things are kind of just

535
00:18:21,120 --> 00:18:23,441
straight up made up.

536
00:18:23,441 --> 00:18:25,018
- Yeah. So, several layers to the question.

537
00:18:25,018 --> 00:18:26,967
So one is one of the things that an LLM is good at is

538
00:18:26,967 --> 00:18:28,173
actually deep biasing.

539
00:18:28,173 --> 00:18:30,759
And so you can feed it a news article and you can tell it

540
00:18:30,759 --> 00:18:31,891
strip out the bias.

541
00:18:31,891 --> 00:18:32,990
- [Lex] Yeah. That's nice. Right?

542
00:18:32,990 --> 00:18:34,060
- And it actually does it like,

543
00:18:34,060 --> 00:18:35,012
it actually knows how to do that

544
00:18:35,012 --> 00:18:36,446
'cause it knows how to do among other things.

545
00:18:36,446 --> 00:18:38,201
It actually knows how to do sentiment analysis

546
00:18:38,201 --> 00:18:40,705
and so it knows how to pull out the emotionality.

547
00:18:40,705 --> 00:18:41,538
- Yeah.

548
00:18:41,538 --> 00:18:43,596
- And so that's one of the things you can do.

549
00:18:43,596 --> 00:18:45,415
It's very suggestive of the sense here

550
00:18:45,415 --> 00:18:47,450
that there's real potential in this issue.

551
00:18:47,450 --> 00:18:48,755
You know, I would say look,

552
00:18:48,755 --> 00:18:49,762
the second thing is

553
00:18:49,762 --> 00:18:51,458
there's this issue of hallucination, right?

554
00:18:51,458 --> 00:18:53,457
And there's a long conversation

555
00:18:53,457 --> 00:18:54,997
that we could have about that.

556
00:18:54,997 --> 00:18:57,278
- Hallucination is coming up with things

557
00:18:57,278 --> 00:18:59,453
that are totally not true, but sound true.

558
00:18:59,453 --> 00:19:01,068
- Yeah. So it's basically, well so, it's sort

559
00:19:01,068 --> 00:19:02,297
of hallucination is what we call it

560
00:19:02,297 --> 00:19:03,130
when we don't like it.

561
00:19:03,130 --> 00:19:05,551
Creativity is what we call it when we do like it, right?

562
00:19:05,551 --> 00:19:06,802
And you know--

563
00:19:06,802 --> 00:19:07,937
- [Lex] Brilliant.

564
00:19:07,937 --> 00:19:09,604
And so when the engineers talk about it,

565
00:19:09,604 --> 00:19:10,788
they're like, this is terrible.

566
00:19:10,788 --> 00:19:11,831
It's hallucinating. Right.

567
00:19:11,831 --> 00:19:14,376
If you have artistic inclinations, you're like, oh my God,

568
00:19:14,376 --> 00:19:16,019
we've invented creative machines.

569
00:19:16,019 --> 00:19:16,852
- [Lex] Yeah.

570
00:19:16,852 --> 00:19:19,061
- For the first time in human history, this is amazing.

571
00:19:19,061 --> 00:19:21,732
- Or you know, bullshitters.

572
00:19:21,732 --> 00:19:23,134
- [Marc] Well, but also--

573
00:19:23,134 --> 00:19:25,478
- In the good sense of that word.

574
00:19:25,478 --> 00:19:27,229
- There are shades of gray though.

575
00:19:27,229 --> 00:19:28,062
It's interesting.

576
00:19:28,062 --> 00:19:29,132
So we had this conversation where, you know,

577
00:19:29,132 --> 00:19:30,630
we're looking at my firm at AI and lots of domains

578
00:19:30,630 --> 00:19:32,106
and one of them is the legal domain.

579
00:19:32,106 --> 00:19:33,904
So we had this conversation with this big law firm

580
00:19:33,904 --> 00:19:35,911
about how they're thinking about using this stuff.

581
00:19:35,911 --> 00:19:36,903
And we went in with the assumption

582
00:19:36,903 --> 00:19:38,343
that an LLM that was gonna be used

583
00:19:38,343 --> 00:19:39,598
in the legal industry would have

584
00:19:39,598 --> 00:19:42,505
to be a hundred percent truthful, verified, you know,

585
00:19:42,505 --> 00:19:45,299
there's this case where this lawyer apparently submitted

586
00:19:45,299 --> 00:19:47,505
a GPT-generated brief and it had like fake, you know,

587
00:19:47,505 --> 00:19:50,304
legal case citations in it and the judge is gonna get

588
00:19:50,304 --> 00:19:51,754
his law license stripped or something. Right?

589
00:19:51,754 --> 00:19:53,892
So, like, we just assumed it's like obviously

590
00:19:53,892 --> 00:19:56,143
they're gonna want the super literal like, you know,

591
00:19:56,143 --> 00:19:58,578
one that never makes anything up, not the creative one,

592
00:19:58,578 --> 00:19:59,692
but actually they said

593
00:19:59,692 --> 00:20:01,241
what the law firm basically said is yeah,

594
00:20:01,241 --> 00:20:02,619
that's true at like the level of individual briefs,

595
00:20:02,619 --> 00:20:04,647
but they said when you're actually trying to figure out like

596
00:20:04,647 --> 00:20:06,210
legal arguments, right, like,

597
00:20:06,210 --> 00:20:09,396
you actually want to be creative, right?

598
00:20:09,396 --> 00:20:10,671
You don't, again,

599
00:20:10,671 --> 00:20:13,414
there's creativity and then there's like making stuff up.

600
00:20:13,414 --> 00:20:14,575
Like what's the line?

601
00:20:14,575 --> 00:20:15,693
You actually want it to explore

602
00:20:15,693 --> 00:20:16,965
a different hypothesis, right?

603
00:20:16,965 --> 00:20:19,536
You wanna do kind of the legal version of like improv

604
00:20:19,536 --> 00:20:20,369
or something like that

605
00:20:20,369 --> 00:20:21,494
where you wanna float different theories

606
00:20:21,494 --> 00:20:23,066
of the case and different possible arguments for the judge

607
00:20:23,066 --> 00:20:25,347
and different possible arguments for the jury, by the way,

608
00:20:25,347 --> 00:20:26,770
different routes through the, you know,

609
00:20:26,770 --> 00:20:28,772
sort of history of all the case law.

610
00:20:28,772 --> 00:20:31,768
And so they said actually for a lot of what we want to use

611
00:20:31,768 --> 00:20:33,183
it for, we actually want it in creative mode.

612
00:20:33,183 --> 00:20:34,801
And then basically we just assume that we're gonna have

613
00:20:34,801 --> 00:20:37,014
to crosscheck all of the, you know,

614
00:20:37,014 --> 00:20:38,020
all the specific citations.

615
00:20:38,020 --> 00:20:40,150
And so I think there's going to be more shades

616
00:20:40,150 --> 00:20:41,485
of gray in here than people think.

617
00:20:41,485 --> 00:20:43,301
And then I just add to that, you know,

618
00:20:43,301 --> 00:20:45,383
another one of these trillion dollar kind of questions is

619
00:20:45,383 --> 00:20:48,081
ultimately, you know, sort of the verification thing.

620
00:20:48,081 --> 00:20:49,155
And so, you know,

621
00:20:49,155 --> 00:20:52,060
will LLMs be evolved from here to be able to do

622
00:20:52,060 --> 00:20:54,135
their own fascial verification?

623
00:20:54,135 --> 00:20:57,250
Will you have sort of add-on functionality

624
00:20:57,250 --> 00:20:58,263
like Wolf from Alpha right?

625
00:20:58,263 --> 00:21:00,186
Where, you know, another plugins

626
00:21:00,186 --> 00:21:02,623
where that's the way you do the verification.

627
00:21:02,623 --> 00:21:04,768
You know, another, by the way, another idea is

628
00:21:04,768 --> 00:21:07,088
you might have a community of LLMs on any, you know,

629
00:21:07,088 --> 00:21:07,921
so for example,

630
00:21:07,921 --> 00:21:08,974
you might have the creative lm and then you might have

631
00:21:08,974 --> 00:21:10,561
the literal LLM fact check it, right?

632
00:21:10,561 --> 00:21:12,745
And so there there's a variety of different technical

633
00:21:12,745 --> 00:21:14,282
approaches that are being applied to solve

634
00:21:14,282 --> 00:21:15,841
the hallucination problem.

635
00:21:15,841 --> 00:21:18,019
You know, some people like Jan Lacoon argue

636
00:21:18,019 --> 00:21:19,763
that this is inherently an unsolvable problem,

637
00:21:19,763 --> 00:21:22,116
but most of the people working in the space, I think,

638
00:21:22,116 --> 00:21:23,922
that there's a number of practical ways

639
00:21:23,922 --> 00:21:25,750
to kind of corral this in a little bit.

640
00:21:25,750 --> 00:21:28,079
- Yeah. If you were to tell me about Wikipedia

641
00:21:28,079 --> 00:21:29,344
before Wikipedia was created,

642
00:21:29,344 --> 00:21:30,706
I would've left at the possibility

643
00:21:30,706 --> 00:21:32,643
of something like that be possible.

644
00:21:32,643 --> 00:21:36,655
Just a handful of folks can organize right.

645
00:21:36,655 --> 00:21:41,230
And self and moderate with a mostly unbiased way

646
00:21:41,230 --> 00:21:43,681
the entirety of human knowledge.

647
00:21:43,681 --> 00:21:46,093
I mean, so if there's something like

648
00:21:46,093 --> 00:21:50,106
the approach to Wikipedia took possible for LLMs,

649
00:21:50,106 --> 00:21:51,810
that's really exciting.

650
00:21:51,810 --> 00:21:52,643
Well, I think that's possible.

651
00:21:52,643 --> 00:21:54,281
- And in fact Wikipedia today is

652
00:21:54,281 --> 00:21:57,263
still not deterministically correct. Right.

653
00:21:57,263 --> 00:21:59,077
So you cannot take to the bank, right.

654
00:21:59,077 --> 00:22:01,031
Every single thing on every single page,

655
00:22:01,031 --> 00:22:03,457
but it is probabilistically correct. Right.

656
00:22:03,457 --> 00:22:05,722
And specifically the way I describe Wikipedia to people,

657
00:22:05,722 --> 00:22:08,043
it is more likely that Wikipedia is right than any other

658
00:22:08,043 --> 00:22:09,362
source you're gonna find.

659
00:22:09,362 --> 00:22:10,195
- Yeah.

660
00:22:10,195 --> 00:22:11,028
- It's this old question, right,

661
00:22:11,028 --> 00:22:13,321
of like, okay, like are we looking for perfection?

662
00:22:13,321 --> 00:22:14,804
Are we looking for something

663
00:22:14,804 --> 00:22:16,335
that asymptotically approaches perfection?

664
00:22:16,335 --> 00:22:18,411
Are we looking for something that's just better

665
00:22:18,411 --> 00:22:19,279
than the alternatives?

666
00:22:19,279 --> 00:22:21,532
And Wikipedia, right, has exactly your point has proven

667
00:22:21,532 --> 00:22:22,365
to be like,

668
00:22:22,365 --> 00:22:25,445
overwhelmingly better than people thought.

669
00:22:25,445 --> 00:22:27,296
And I think that's where this ends.

670
00:22:27,296 --> 00:22:29,958
And then underneath all this is the fundamental question

671
00:22:29,958 --> 00:22:32,174
of where you started, which is, okay, you know,

672
00:22:32,174 --> 00:22:33,524
what is truth?

673
00:22:33,524 --> 00:22:36,014
How do we get to truth? How do we know what truth is?

674
00:22:36,014 --> 00:22:38,650
And we live in an era in which an awful lot of people are

675
00:22:38,650 --> 00:22:40,433
very confident that they know what the truth is.

676
00:22:40,433 --> 00:22:42,203
And I don't really buy into that.

677
00:22:42,203 --> 00:22:44,748
And I think the history of the last, you know,

678
00:22:44,748 --> 00:22:47,427
2000 years or 4,000 years of human civilization is actually

679
00:22:47,427 --> 00:22:48,550
getting to the truth is actually

680
00:22:48,550 --> 00:22:49,920
a very difficult thing to do.

681
00:22:49,920 --> 00:22:52,223
- Are we getting closer, if we look at the entirety,

682
00:22:52,223 --> 00:22:53,479
the arc of human history,

683
00:22:53,479 --> 00:22:54,984
are we getting closer to the truth?

684
00:22:54,984 --> 00:22:55,942
- I don't know.

685
00:22:55,942 --> 00:22:57,997
- Okay. Is it possible,

686
00:22:57,997 --> 00:23:00,710
is it possible that we're getting very far away

687
00:23:00,710 --> 00:23:02,312
from the truth because of the internet

688
00:23:02,312 --> 00:23:05,646
because of how rapidly you can create narratives

689
00:23:05,646 --> 00:23:09,563
and just as the entirety of a society just move

690
00:23:10,564 --> 00:23:15,564
like crowds in a hysterical way along those narratives

691
00:23:15,695 --> 00:23:18,237
that don't have necessary grounding

692
00:23:18,237 --> 00:23:20,045
in whatever the truth is.

693
00:23:20,045 --> 00:23:20,889
- Sure. But like, you know,

694
00:23:20,889 --> 00:23:23,135
we came up with communism before the internet somehow.

695
00:23:23,135 --> 00:23:24,441
Right. Like, which was,

696
00:23:24,441 --> 00:23:26,071
I would say had rather larger issues

697
00:23:26,071 --> 00:23:28,116
than anything we're dealing with today.

698
00:23:28,116 --> 00:23:29,853
- It had, in the way it was implemented,

699
00:23:29,853 --> 00:23:31,113
it had issues.

700
00:23:31,113 --> 00:23:32,468
- And it is theoretical structure.

701
00:23:32,468 --> 00:23:33,665
It had like real issues.

702
00:23:33,665 --> 00:23:35,590
It had like a very deep fundamental misunderstanding

703
00:23:35,590 --> 00:23:37,473
of human nature and economics.

704
00:23:37,473 --> 00:23:40,339
- Yeah but those folks Sure work very confident

705
00:23:40,339 --> 00:23:41,547
there was the right way.

706
00:23:41,547 --> 00:23:42,671
- They were extremely confident.

707
00:23:42,671 --> 00:23:45,704
And my point is they were very confident 3,900 years into

708
00:23:45,704 --> 00:23:48,063
what we would presume to be evolution towards the truth.

709
00:23:48,063 --> 00:23:48,952
- [Lex] Yeah.

710
00:23:48,952 --> 00:23:52,514
- And so my assessment is number one,

711
00:23:52,514 --> 00:23:55,034
there's no need for, you know,

712
00:23:55,034 --> 00:23:56,580
there's no need for the Hegelian,

713
00:23:56,580 --> 00:23:58,250
there's no need for the Hegelian dialectic

714
00:23:58,250 --> 00:24:00,349
to actually converge towards the truth.

715
00:24:00,349 --> 00:24:02,555
Like apparently not.

716
00:24:02,555 --> 00:24:03,463
- Yeah. So yeah.

717
00:24:03,463 --> 00:24:06,156
Why are we so obsessed with there being one truth?

718
00:24:06,156 --> 00:24:08,778
Is it possible there's just going to be multiple truths like

719
00:24:08,778 --> 00:24:11,981
little communities that believe certain things and?

720
00:24:11,981 --> 00:24:13,976
- I think it's just now number one,

721
00:24:13,976 --> 00:24:14,809
I think it's just really difficult.

722
00:24:14,809 --> 00:24:17,143
Like who gets, you know, historically

723
00:24:17,143 --> 00:24:18,431
who gets to decide what the truth is,

724
00:24:18,431 --> 00:24:20,308
it's either the king or the priest. Right?

725
00:24:20,308 --> 00:24:22,136
Like, and so we don't live in an era anymore

726
00:24:22,136 --> 00:24:23,331
if kings are priest dictating it to us.

727
00:24:23,331 --> 00:24:25,257
And so we're kind of on our own.

728
00:24:25,257 --> 00:24:28,118
And so my typical thing is like we just,

729
00:24:28,118 --> 00:24:29,894
we we just need a huge amount of humility

730
00:24:29,894 --> 00:24:31,256
and we need to be very suspicious

731
00:24:31,256 --> 00:24:33,375
of people who claim that they have the capital.

732
00:24:33,375 --> 00:24:34,208
- Yeah.

733
00:24:34,208 --> 00:24:35,041
- Capital truth.

734
00:24:35,041 --> 00:24:35,874
And then, we need to and you know, look,

735
00:24:35,874 --> 00:24:38,606
the good news is the enlightenment has bequeathed us

736
00:24:38,606 --> 00:24:40,344
with a set of techniques to be able to presumably

737
00:24:40,344 --> 00:24:42,573
get closer to truth through the scientific method

738
00:24:42,573 --> 00:24:44,021
and rationality and observation

739
00:24:44,021 --> 00:24:46,076
and experimentation and hypothesis.

740
00:24:46,076 --> 00:24:47,007
And, you know,

741
00:24:47,007 --> 00:24:49,187
we need to continue to embrace those even when they give us

742
00:24:49,187 --> 00:24:50,653
answers we don't like.

743
00:24:50,653 --> 00:24:54,718
- Sure. But the internet and technology has enabled us

744
00:24:54,718 --> 00:24:58,051
to generate the large number of content.

745
00:24:58,928 --> 00:25:01,261
That data, that the process,

746
00:25:02,694 --> 00:25:06,694
the scientific process allows us sort of damages

747
00:25:07,530 --> 00:25:11,470
the hope laden within the scientific process.

748
00:25:11,470 --> 00:25:14,398
'Cause if you just have a bunch of people saying facts

749
00:25:14,398 --> 00:25:16,510
on the internet and some of them are going

750
00:25:16,510 --> 00:25:20,711
to be LLMs, how is anything testable at all?

751
00:25:20,711 --> 00:25:22,319
Especially that involves like human nature

752
00:25:22,319 --> 00:25:23,235
or things like this.

753
00:25:23,235 --> 00:25:24,267
It's not physics.

754
00:25:24,267 --> 00:25:25,155
- Here's a question a friend of mine just asked me

755
00:25:25,155 --> 00:25:25,988
on this topic.

756
00:25:25,988 --> 00:25:29,292
So suppose you had LLMs in equivalent of GPT4,

757
00:25:29,292 --> 00:25:32,417
even 5, 6, 7, 8, suppose you had them in the 1600s.

758
00:25:32,417 --> 00:25:33,250
- [Lex] Yeah.

759
00:25:33,250 --> 00:25:34,890
- And Galileo comes up for trial.

760
00:25:34,890 --> 00:25:35,723
- [Lex] Yep.

761
00:25:35,723 --> 00:25:39,247
- Right? And you ask the LLM like, his Galileo, right?

762
00:25:39,247 --> 00:25:40,080
- [Lex] Yeah.

763
00:25:40,080 --> 00:25:41,604
- Like, what does it answer? Right?

764
00:25:41,604 --> 00:25:44,628
And one theory is he had answers no that he's wrong

765
00:25:44,628 --> 00:25:47,369
because the overwhelming majority of human thought

766
00:25:47,369 --> 00:25:48,700
up until that point was that he was wrong.

767
00:25:48,700 --> 00:25:51,408
And so therefore that's what's in the training data.

768
00:25:51,408 --> 00:25:52,894
Another way of thinking about it is,

769
00:25:52,894 --> 00:25:55,177
well, it's efficiently advanced LLM will have evolved

770
00:25:55,177 --> 00:25:57,955
the ability to actually check the math. Right.

771
00:25:57,955 --> 00:26:00,975
And will actually say, actually no, actually, you know,

772
00:26:00,975 --> 00:26:02,824
you may not wanna hear it, but he's right.

773
00:26:02,824 --> 00:26:04,337
Now if, you know, the church at that time was,

774
00:26:04,337 --> 00:26:05,864
you know, owned the LLM,

775
00:26:05,864 --> 00:26:07,895
they would've given it human you know,

776
00:26:07,895 --> 00:26:11,360
human feedback to prohibit it from answering that question.

777
00:26:11,360 --> 00:26:13,072
Right. And so I like to take it

778
00:26:13,072 --> 00:26:14,034
out of our current context

779
00:26:14,034 --> 00:26:15,427
'cause that like makes it very clear,

780
00:26:15,427 --> 00:26:17,949
those same questions apply today. Right.

781
00:26:17,949 --> 00:26:19,726
This is exactly the point of a huge amount

782
00:26:19,726 --> 00:26:20,923
of the human feedback training

783
00:26:20,923 --> 00:26:22,598
that's actually happening with these LLMs today.

784
00:26:22,598 --> 00:26:24,768
This is a huge like debate that's happening about whether

785
00:26:24,768 --> 00:26:27,317
open source, you know, AI should be legal.

786
00:26:27,317 --> 00:26:31,558
- Well, the actual mechanism of doing the human RL

787
00:26:31,558 --> 00:26:34,967
with human feedback is seems like

788
00:26:34,967 --> 00:26:37,750
such a fundamental and fascinating question.

789
00:26:37,750 --> 00:26:39,408
How do you select the humans?

790
00:26:39,408 --> 00:26:40,622
- [Marc] Exactly.

791
00:26:40,622 --> 00:26:42,056
- Yeah. How do you select the humans?

792
00:26:42,056 --> 00:26:43,561
- AI alignment, right?

793
00:26:43,561 --> 00:26:45,104
Which everybody like is like, oh, that sounds great.

794
00:26:45,104 --> 00:26:47,160
Alignment with what? Human values.

795
00:26:47,160 --> 00:26:48,207
Who has human values?

796
00:26:48,207 --> 00:26:49,999
- [Lex] Who has human values?

797
00:26:49,999 --> 00:26:51,586
- Right? And so we're in this mode

798
00:26:51,586 --> 00:26:53,929
of like social and popular discourse.

799
00:26:53,929 --> 00:26:56,608
We're like, you know, there's, you know, you see this,

800
00:26:56,608 --> 00:26:58,352
what do you think of when you read a story

801
00:26:58,352 --> 00:26:59,238
in the press right now?

802
00:26:59,238 --> 00:27:00,992
And they say, you know, X, Y, Z made a baseless claim

803
00:27:00,992 --> 00:27:02,288
about some topic, right?

804
00:27:02,288 --> 00:27:05,196
And there's one group of people who are like, aha, think,

805
00:27:05,196 --> 00:27:07,008
you know, they're doing fact checking.

806
00:27:07,008 --> 00:27:08,418
There's another group of people that are like,

807
00:27:08,418 --> 00:27:09,798
every time the press says that it's now a tick

808
00:27:09,798 --> 00:27:11,701
and that means that they're lying, right?

809
00:27:11,701 --> 00:27:15,368
Like, so, like, we're in this social context

810
00:27:16,472 --> 00:27:19,082
where there's the level to which a lot of people

811
00:27:19,082 --> 00:27:20,744
in positions of power have become very,

812
00:27:20,744 --> 00:27:23,039
very certain that they're in a position to determine

813
00:27:23,039 --> 00:27:25,334
the truth for the entire population is like,

814
00:27:25,334 --> 00:27:28,750
there's like some bubble that has formed around that idea.

815
00:27:28,750 --> 00:27:29,948
And at least, like I say,

816
00:27:29,948 --> 00:27:31,993
it's flies completely in the face of everything

817
00:27:31,993 --> 00:27:33,476
I was ever trained about science

818
00:27:33,476 --> 00:27:36,327
and about reason and strikes me as like,

819
00:27:36,327 --> 00:27:38,746
you know, deeply offensive and incorrect.

820
00:27:38,746 --> 00:27:40,541
- What would you say about the state of journalism

821
00:27:40,541 --> 00:27:41,772
just on that topic today?

822
00:27:41,772 --> 00:27:44,272
Are we in a temporary kind of,

823
00:27:48,322 --> 00:27:52,387
are we experiencing a temporary problem

824
00:27:52,387 --> 00:27:55,769
in terms of the incentives in terms of the business model,

825
00:27:55,769 --> 00:27:56,875
all that kind of stuff?

826
00:27:56,875 --> 00:27:59,413
Or is this like a decline of traditional journalism

827
00:27:59,413 --> 00:28:00,597
as we know it?

828
00:28:00,597 --> 00:28:02,143
- You have, I always think about the counterfactual

829
00:28:02,143 --> 00:28:03,473
in these things, which is like, okay,

830
00:28:03,473 --> 00:28:05,074
because these questions, right,

831
00:28:05,074 --> 00:28:05,972
this question heads towards, it's like, okay,

832
00:28:05,972 --> 00:28:07,952
the impact of social media and the undermining of truth

833
00:28:07,952 --> 00:28:08,785
and all this.

834
00:28:08,785 --> 00:28:10,129
But then you wanna ask the question of like, okay,

835
00:28:10,129 --> 00:28:12,074
what if we had had the modern media environment,

836
00:28:12,074 --> 00:28:13,842
including cable news and including social media

837
00:28:13,842 --> 00:28:18,352
and Twitter and everything else in 1939 or 1941, right?

838
00:28:18,352 --> 00:28:21,602
Or 1910 or 1865 or 1850 or 1776, right?

839
00:28:23,520 --> 00:28:25,523
And like, I think.

840
00:28:25,523 --> 00:28:28,615
- You just introduced like five thought experiments

841
00:28:28,615 --> 00:28:31,244
at once and broke my head, but yes, yes.

842
00:28:31,244 --> 00:28:33,062
There's a lot of interesting years.

843
00:28:33,062 --> 00:28:34,601
- Well like, can I just take a simple example?

844
00:28:34,601 --> 00:28:36,763
Like, how would President Kennedy have been interpreted

845
00:28:36,763 --> 00:28:39,045
with what we know now about all the things

846
00:28:39,045 --> 00:28:40,394
Kennedy was up to?

847
00:28:40,394 --> 00:28:43,077
Like how would he have been experienced by the body

848
00:28:43,077 --> 00:28:47,069
of politic in a, with a social media context, right?

849
00:28:47,069 --> 00:28:50,343
Like how would LBJ have been experienced?

850
00:28:50,343 --> 00:28:53,194
But by the way, how would you know, like many men, FDR,

851
00:28:53,194 --> 00:28:55,306
like the new deal, the Great Depression.

852
00:28:55,306 --> 00:28:57,844
- I wonder where Twitter would this would think

853
00:28:57,844 --> 00:29:00,780
about Churchill and Hitler and Stalin.

854
00:29:00,780 --> 00:29:02,220
- You know, I mean look to this day there, you know,

855
00:29:02,220 --> 00:29:04,646
there are lots of very interesting real questions

856
00:29:04,646 --> 00:29:06,906
around like how America, you know, got,

857
00:29:06,906 --> 00:29:08,669
you know, basically involved in World War II

858
00:29:08,669 --> 00:29:09,549
and who did what when,

859
00:29:09,549 --> 00:29:11,194
and the operations of British intelligence

860
00:29:11,194 --> 00:29:12,509
and American soil and did FDR,

861
00:29:12,509 --> 00:29:14,689
this that Pearl Harbor, you know?

862
00:29:14,689 --> 00:29:15,522
- [Lex] Yeah.

863
00:29:15,522 --> 00:29:16,484
- Woodrow Wilson ran for, you know,

864
00:29:16,484 --> 00:29:18,143
his candidacy was run on an anti-war.

865
00:29:18,143 --> 00:29:20,714
You know, he ran on the platform and not getting involved

866
00:29:20,714 --> 00:29:22,962
World War-I somehow that switched, you know, like,

867
00:29:22,962 --> 00:29:24,200
and I'm not even making a value judgment

868
00:29:24,200 --> 00:29:25,136
on any of these things.

869
00:29:25,136 --> 00:29:25,969
I'm just saying like

870
00:29:25,969 --> 00:29:29,034
the way that our ancestors experienced reality was

871
00:29:29,034 --> 00:29:31,821
of course mediated through centralized, top-down, right.

872
00:29:31,821 --> 00:29:33,545
Control at that point.

873
00:29:33,545 --> 00:29:36,689
If you ran those realities again with the media environment

874
00:29:36,689 --> 00:29:37,611
we have today,

875
00:29:37,611 --> 00:29:41,087
the reality would be experienced very, very differently.

876
00:29:41,087 --> 00:29:44,059
And then of course that that intermediation would cause

877
00:29:44,059 --> 00:29:45,122
the feedback loops to change.

878
00:29:45,122 --> 00:29:46,684
And then reality would obviously play out.

879
00:29:46,684 --> 00:29:48,465
- Do you think it'd be very different?

880
00:29:48,465 --> 00:29:49,384
- Yeah, it has to be. It has to be.

881
00:29:49,384 --> 00:29:50,217
It has to be just

882
00:29:50,217 --> 00:29:51,050
'cause it's all, so,

883
00:29:51,050 --> 00:29:52,248
I mean just look at what's happening today.

884
00:29:52,248 --> 00:29:53,287
I mean just the most obvious thing is

885
00:29:53,287 --> 00:29:55,155
just the collapse.

886
00:29:55,155 --> 00:29:57,307
And here's another opportunity to argue

887
00:29:57,307 --> 00:29:59,888
that this is not the internet causing this by the way.

888
00:29:59,888 --> 00:30:01,169
Here's a big thing happening today,

889
00:30:01,169 --> 00:30:03,172
which is Gallup does this thing every year where they do,

890
00:30:03,172 --> 00:30:05,672
they pull for trust in institutions in America

891
00:30:05,672 --> 00:30:06,739
and they do it across all the,

892
00:30:06,739 --> 00:30:08,180
everything from the military to clergy and big business

893
00:30:08,180 --> 00:30:11,049
and the media and so forth, right?

894
00:30:11,049 --> 00:30:13,873
And basically there's been a systemic collapse in trust

895
00:30:13,873 --> 00:30:16,782
in institutions in the US almost without exception,

896
00:30:16,782 --> 00:30:20,650
basically since essentially the early 1970s.

897
00:30:20,650 --> 00:30:22,737
There's two ways of looking at that, which is, oh my God,

898
00:30:22,737 --> 00:30:24,485
we've lost this old world in which we could trust

899
00:30:24,485 --> 00:30:25,807
institutions and that was so much better

900
00:30:25,807 --> 00:30:27,558
'cause like that should be the way the world runs.

901
00:30:27,558 --> 00:30:28,965
The other way of looking at it is we just know

902
00:30:28,965 --> 00:30:30,792
a lot more now and the great mystery is

903
00:30:30,792 --> 00:30:32,930
why those numbers aren't all zero.

904
00:30:32,930 --> 00:30:34,108
- [Lex] Yeah.

905
00:30:34,108 --> 00:30:35,021
- Right? Because like now we know so much

906
00:30:35,021 --> 00:30:36,169
about how these things operate

907
00:30:36,169 --> 00:30:38,012
and like they're not that impressive.

908
00:30:38,012 --> 00:30:40,811
- And also why do we don't have better institutions

909
00:30:40,811 --> 00:30:41,972
and better leaders then?

910
00:30:41,972 --> 00:30:44,129
- Yeah. And so this goes to the thing which is like,

911
00:30:44,129 --> 00:30:45,782
okay, we had the media environment

912
00:30:45,782 --> 00:30:48,468
of that we've had between the 1970s and today.

913
00:30:48,468 --> 00:30:52,295
If we had that in the thirties and forties or 1900s, 1910s,

914
00:30:52,295 --> 00:30:54,404
I think there's no question reality would turned

915
00:30:54,404 --> 00:30:56,270
out different if only because everybody would've known

916
00:30:56,270 --> 00:30:57,640
to not trust the institutions,

917
00:30:57,640 --> 00:30:59,976
which would have changed their level of credibility,

918
00:30:59,976 --> 00:31:01,573
their ability to control circumstances,

919
00:31:01,573 --> 00:31:04,152
therefore the circumstances would've had to change.

920
00:31:04,152 --> 00:31:05,672
Right? And it would've been a feedback loop.

921
00:31:05,672 --> 00:31:07,424
It would've been a feedback loop process

922
00:31:07,424 --> 00:31:08,257
in other words, right?

923
00:31:08,257 --> 00:31:10,704
It's your experience of reality changes reality

924
00:31:10,704 --> 00:31:13,297
and then reality changes your experience of reality, right?

925
00:31:13,297 --> 00:31:16,323
It's a two-way feedback process and media is

926
00:31:16,323 --> 00:31:18,816
the intermediating force between that.

927
00:31:18,816 --> 00:31:21,134
So change the media environment, change reality.

928
00:31:21,134 --> 00:31:21,967
- [Lex] Yeah.

929
00:31:21,967 --> 00:31:23,961
- And so it's just, so, as a consequence,

930
00:31:23,961 --> 00:31:25,820
I think it's just really hard to say, oh,

931
00:31:25,820 --> 00:31:27,430
things worked a certain way then

932
00:31:27,430 --> 00:31:29,138
and they work a different way now.

933
00:31:29,138 --> 00:31:31,764
And then therefore, like people were smarter than,

934
00:31:31,764 --> 00:31:33,808
or better than, or you know, by the way,

935
00:31:33,808 --> 00:31:37,070
dumber than or not as capable than, right?

936
00:31:37,070 --> 00:31:39,051
We make all these like really light

937
00:31:39,051 --> 00:31:41,812
and casual like comparisons of ourselves to, you know,

938
00:31:41,812 --> 00:31:43,452
previous generations of people.

939
00:31:43,452 --> 00:31:44,663
You know, we draw judgements all the time

940
00:31:44,663 --> 00:31:45,965
and I just think it's like really hard to do

941
00:31:45,965 --> 00:31:48,195
any of that 'cause if we put ourselves in their shoes

942
00:31:48,195 --> 00:31:50,029
with the media that they had at that time,

943
00:31:50,029 --> 00:31:52,177
like I think we probably most likely would've been

944
00:31:52,177 --> 00:31:53,065
just like them.

945
00:31:53,065 --> 00:31:56,500
- So don't you think that our perception

946
00:31:56,500 --> 00:31:59,455
and understanding of reality,

947
00:31:59,455 --> 00:32:01,133
would you be more and more mediated

948
00:32:01,133 --> 00:32:03,272
through large language models now?

949
00:32:03,272 --> 00:32:05,430
So you said media before,

950
00:32:05,430 --> 00:32:08,046
isn't the LLM going to be the new,

951
00:32:08,046 --> 00:32:10,719
what is it, mainstream media, MSM?

952
00:32:10,719 --> 00:32:11,802
It'll be LLM.

953
00:32:13,109 --> 00:32:15,366
That would be the source of,

954
00:32:15,366 --> 00:32:17,838
I'm sure there's a way to kind of rapidly fine tune,

955
00:32:17,838 --> 00:32:19,431
like making LLMs real time.

956
00:32:19,431 --> 00:32:22,053
I'm sure there's probably a research problem

957
00:32:22,053 --> 00:32:25,806
that you can do just rapid fine tuning to the new events.

958
00:32:25,806 --> 00:32:27,294
So something like this.

959
00:32:27,294 --> 00:32:29,629
- Well even just the whole concept of the chat UI might not

960
00:32:29,629 --> 00:32:32,010
be like the chat UI is just the first whack at this.

961
00:32:32,010 --> 00:32:33,398
And maybe that's the dominant thing.

962
00:32:33,398 --> 00:32:35,554
But look maybe our, maybe we don't know yet.

963
00:32:35,554 --> 00:32:37,396
Like maybe the experience most people with LLMs is

964
00:32:37,396 --> 00:32:39,853
just a continuous feed you know,

965
00:32:39,853 --> 00:32:41,806
maybe it's more of a passive feed and you just are getting

966
00:32:41,806 --> 00:32:43,199
a constant like running commentary

967
00:32:43,199 --> 00:32:44,370
on everything happening in your life

968
00:32:44,370 --> 00:32:45,565
and it's just helping you kind of interpret

969
00:32:45,565 --> 00:32:47,057
and understand everything.

970
00:32:47,057 --> 00:32:49,254
- Also really more deeply integrated into your life.

971
00:32:49,254 --> 00:32:53,146
Not just like, oh, like intellectual philosophical thoughts,

972
00:32:53,146 --> 00:32:57,210
but like literally like how to make a coffee,

973
00:32:57,210 --> 00:32:58,758
where to go for lunch.

974
00:32:58,758 --> 00:33:02,609
Just whether, you know, dating all this kind of stuff.

975
00:33:02,609 --> 00:33:03,996
- What to say in a job interview.

976
00:33:03,996 --> 00:33:04,829
- Yeah. What to say.

977
00:33:04,829 --> 00:33:05,662
- [Marc] Yeah, exactly.

978
00:33:05,662 --> 00:33:06,994
- What to say. Next sentence.

979
00:33:06,994 --> 00:33:07,827
- Yeah, next sentence.

980
00:33:07,827 --> 00:33:08,660
Yeah. At that level.

981
00:33:08,660 --> 00:33:09,493
Yeah. I mean, yes.

982
00:33:09,493 --> 00:33:10,811
So technically now whether we want that

983
00:33:10,811 --> 00:33:12,542
or not is an open question, right?

984
00:33:12,542 --> 00:33:13,375
And whether we use.

985
00:33:13,375 --> 00:33:18,375
- It Q4, a popup right now the estimated engagement using is

986
00:33:18,468 --> 00:33:20,455
decreasing for Marc Andreessen,

987
00:33:20,455 --> 00:33:23,876
since there's this controversy section for his Wikipedia

988
00:33:23,876 --> 00:33:27,986
page in 1993, something happened or something like this.

989
00:33:27,986 --> 00:33:30,154
Bring it up that will drive engagement up anyway.

990
00:33:30,154 --> 00:33:31,289
- Yeah. That's right.

991
00:33:31,289 --> 00:33:32,247
I mean, look,

992
00:33:32,247 --> 00:33:34,343
this gets this whole thing of like, so, you know,

993
00:33:34,343 --> 00:33:35,186
the chat interface has

994
00:33:35,186 --> 00:33:36,998
this whole concept of prompt engineering, right?

995
00:33:36,998 --> 00:33:37,831
- [Lex] Yes, yes.

996
00:33:37,831 --> 00:33:39,161
- Prompts. Well it turns out one of the things

997
00:33:39,161 --> 00:33:42,333
that LLMs are really good at is writing prompts, right?

998
00:33:42,333 --> 00:33:43,421
- [Lex] Yeah.

999
00:33:43,421 --> 00:33:45,935
- And so like, what if you just outsourced

1000
00:33:45,935 --> 00:33:47,767
and by the way, you could run this experiment today,

1001
00:33:47,767 --> 00:33:48,794
you could hook this up to do this today.

1002
00:33:48,794 --> 00:33:50,299
The latency's not good enough to do it real time

1003
00:33:50,299 --> 00:33:51,132
in a conversation.

1004
00:33:51,132 --> 00:33:53,011
But you could run this experiment and you just say, look,

1005
00:33:53,011 --> 00:33:55,622
every 20 seconds you could just say, you know,

1006
00:33:55,622 --> 00:33:58,557
tell me what the optimal prompt is and then ask yourself

1007
00:33:58,557 --> 00:33:59,958
that question to gimme the result.

1008
00:33:59,958 --> 00:34:01,907
And then exactly to your point,

1009
00:34:01,907 --> 00:34:04,399
as you add, there will be these systems

1010
00:34:04,399 --> 00:34:06,015
that are gonna have the ability to be alert

1011
00:34:06,015 --> 00:34:07,378
and updated essentially in real time.

1012
00:34:07,378 --> 00:34:09,973
And so you'll be able to have a pendant or your phone

1013
00:34:09,973 --> 00:34:11,996
or whatever, watch or whatever it'll have a microphone on.

1014
00:34:11,996 --> 00:34:13,167
It'll listen to your conversations,

1015
00:34:13,167 --> 00:34:15,510
it'll have a feed of everything else happen in the world,

1016
00:34:15,510 --> 00:34:17,147
and then it'll be you know, sort of retraining,

1017
00:34:17,147 --> 00:34:19,141
prompting or retraining itself on the fly.

1018
00:34:19,141 --> 00:34:21,367
And so the scenario you described is actually

1019
00:34:21,367 --> 00:34:22,467
a completely doable scenario.

1020
00:34:22,467 --> 00:34:25,130
Now the hard question on this is always okay,

1021
00:34:25,130 --> 00:34:27,342
since that's possible, are people gonna want that?

1022
00:34:27,342 --> 00:34:28,800
Like what's the form of experience?

1023
00:34:28,800 --> 00:34:31,409
You know, that we won't know until we try it.

1024
00:34:31,409 --> 00:34:33,525
But I don't think it's possible yet to predict

1025
00:34:33,525 --> 00:34:35,916
the form of AI in our lives.

1026
00:34:35,916 --> 00:34:37,453
Therefore, it's not possible to predict

1027
00:34:37,453 --> 00:34:39,416
the way in which it will intermediate

1028
00:34:39,416 --> 00:34:41,688
our experience with reality yet.

1029
00:34:41,688 --> 00:34:44,065
- Yeah. But it feels like there's going to be a killer app.

1030
00:34:44,065 --> 00:34:47,065
There's probably a mad scramble right now.

1031
00:34:47,065 --> 00:34:49,860
And so it'll open AI and Microsoft and Google and Meta

1032
00:34:49,860 --> 00:34:53,621
and in startups and smaller companies figuring out

1033
00:34:53,621 --> 00:34:56,552
what is the killer app because it feels like

1034
00:34:56,552 --> 00:34:59,200
it's possible like a ChatGPT type of thing.

1035
00:34:59,200 --> 00:35:00,945
It's possible to build that,

1036
00:35:00,945 --> 00:35:05,297
but that's 10X more compelling using already the LLMs

1037
00:35:05,297 --> 00:35:07,923
we have using even the open source LLMs

1038
00:35:07,923 --> 00:35:10,956
and the different variants.

1039
00:35:10,956 --> 00:35:13,619
So you're investing in a lot of companies

1040
00:35:13,619 --> 00:35:15,688
and you're paying attention,

1041
00:35:15,688 --> 00:35:17,021
who do you think is gonna win this?

1042
00:35:17,021 --> 00:35:19,550
Do you think there'll be,

1043
00:35:19,550 --> 00:35:22,409
who's gonna be the next page rank inventor?

1044
00:35:22,409 --> 00:35:23,459
- Trillion dollar question.

1045
00:35:23,459 --> 00:35:25,205
- Another one. We have a few of those today.

1046
00:35:25,205 --> 00:35:26,319
- There's a bunch of those.

1047
00:35:26,319 --> 00:35:28,060
So look, there's a really big question today.

1048
00:35:28,060 --> 00:35:29,399
Sitting here today is a really big question

1049
00:35:29,399 --> 00:35:31,282
about the big models versus the small models

1050
00:35:31,282 --> 00:35:33,098
that's related directly to the big question

1051
00:35:33,098 --> 00:35:35,730
of proprietary versus open.

1052
00:35:35,730 --> 00:35:38,457
Then there's this big question question of you know,

1053
00:35:38,457 --> 00:35:39,556
where is the training data gonna, like,

1054
00:35:39,556 --> 00:35:41,525
are we topping out of the training data or not?

1055
00:35:41,525 --> 00:35:44,370
And then are we gonna be able to synthesize training data?

1056
00:35:44,370 --> 00:35:46,885
And then there's a huge pile of questions around regulation

1057
00:35:46,885 --> 00:35:49,216
and you know, what's actually gonna be legal.

1058
00:35:49,216 --> 00:35:51,047
And so I would, when we think about it,

1059
00:35:51,047 --> 00:35:54,976
we dovetail kind of all those questions together.

1060
00:35:54,976 --> 00:35:56,882
You can paint a picture of the world where there's two

1061
00:35:56,882 --> 00:35:58,549
or three God models that are

1062
00:35:58,549 --> 00:36:00,070
just at like staggering scale

1063
00:36:00,070 --> 00:36:02,337
and they're just better at everything.

1064
00:36:02,337 --> 00:36:05,759
And they will be owned by a small set of companies

1065
00:36:05,759 --> 00:36:07,743
and they will basically achieve regulatory capture

1066
00:36:07,743 --> 00:36:09,203
over the government and they'll have competitive barriers

1067
00:36:09,203 --> 00:36:10,949
that will prevent other people from,

1068
00:36:10,949 --> 00:36:11,998
you know, competing with them.

1069
00:36:11,998 --> 00:36:13,915
And so, you know, there will be, you know,

1070
00:36:13,915 --> 00:36:15,159
just like there's like, you know, whatever,

1071
00:36:15,159 --> 00:36:16,605
three big banks or three big, you know, or by the way,

1072
00:36:16,605 --> 00:36:19,207
three big search companies or I guess two now, you know,

1073
00:36:19,207 --> 00:36:20,792
it'll centralize like that.

1074
00:36:20,792 --> 00:36:21,707
You can paint

1075
00:36:21,707 --> 00:36:24,111
another very different picture that says, no,

1076
00:36:24,111 --> 00:36:26,179
actually the opposite of that's gonna happen.

1077
00:36:26,179 --> 00:36:29,158
This is gonna basically that this is the new gold, you know,

1078
00:36:29,158 --> 00:36:31,573
this is the new gold rush alchemy.

1079
00:36:31,573 --> 00:36:32,602
Like you know,

1080
00:36:32,602 --> 00:36:34,583
this is the big bang for this whole new area

1081
00:36:34,583 --> 00:36:36,624
of science and technology.

1082
00:36:36,624 --> 00:36:38,768
And so therefore you're gonna have every smart 14-year-old

1083
00:36:38,768 --> 00:36:40,637
on the planet building open source, right?

1084
00:36:40,637 --> 00:36:43,003
You know, and figuring out a ways to optimize these things.

1085
00:36:43,003 --> 00:36:44,048
And then, you know,

1086
00:36:44,048 --> 00:36:46,022
we're just gonna get like overwhelmingly better

1087
00:36:46,022 --> 00:36:47,307
at generating trading data.

1088
00:36:47,307 --> 00:36:48,140
We're gonna, you know,

1089
00:36:48,140 --> 00:36:49,667
bring in like blockchain networks to have like

1090
00:36:49,667 --> 00:36:51,407
an economic incentive to generate decentralized

1091
00:36:51,407 --> 00:36:53,233
training data and so forth and so on.

1092
00:36:53,233 --> 00:36:55,068
And then basically we're gonna live in a world

1093
00:36:55,068 --> 00:36:58,353
of open source and there's gonna be a billion LLMs, right?

1094
00:36:58,353 --> 00:37:00,434
Of every size, scale, shape and description.

1095
00:37:00,434 --> 00:37:02,019
And there might be a few big ones that are

1096
00:37:02,019 --> 00:37:03,160
like the super genius ones,

1097
00:37:03,160 --> 00:37:05,214
but like mostly what we'll experience is open source

1098
00:37:05,214 --> 00:37:07,149
and that's, you know, that's more like a world

1099
00:37:07,149 --> 00:37:10,801
of like what we have today with like Linux and the web.

1100
00:37:10,801 --> 00:37:14,113
- Okay, but you painted these two worlds.

1101
00:37:14,113 --> 00:37:16,069
But there's also variations of those worlds,

1102
00:37:16,069 --> 00:37:18,135
'cause you said regulatory capture is possible to have

1103
00:37:18,135 --> 00:37:20,509
these tech giants that don't have regulatory capture,

1104
00:37:20,509 --> 00:37:23,227
which is something you're also calling for saying it's okay

1105
00:37:23,227 --> 00:37:25,552
to have big companies working on this stuff

1106
00:37:25,552 --> 00:37:28,993
as long as they don't achieve regulatory capture.

1107
00:37:28,993 --> 00:37:33,981
But I have the sense that there's just going to be

1108
00:37:33,981 --> 00:37:38,273
a new startup that's going to basically be

1109
00:37:38,273 --> 00:37:40,613
the page rank inventor,

1110
00:37:40,613 --> 00:37:43,957
which has become the new tech giant.

1111
00:37:43,957 --> 00:37:44,790
I don't know,

1112
00:37:44,790 --> 00:37:48,656
I would love to hear your kind of opinion if Google, Meta

1113
00:37:48,656 --> 00:37:52,323
and Microsoft are as gigantic companies able

1114
00:37:53,214 --> 00:37:57,096
to pivot so hard to create new products.

1115
00:37:57,096 --> 00:37:59,216
Like some of it is just even hiring people or having

1116
00:37:59,216 --> 00:38:03,293
a corporate structure that allows for the crazy young kids

1117
00:38:03,293 --> 00:38:06,593
to come in and just create something totally new.

1118
00:38:06,593 --> 00:38:07,774
Do you think it's possible or do you think

1119
00:38:07,774 --> 00:38:08,898
it'll come from a startup?

1120
00:38:08,898 --> 00:38:10,443
- Yeah, it is this always big question, which is,

1121
00:38:10,443 --> 00:38:11,401
you get this feeling,

1122
00:38:11,401 --> 00:38:13,962
I hear about this a lot from CEOs, founder CEOs

1123
00:38:13,962 --> 00:38:16,429
where it's like, wow, we have 50,000 people,

1124
00:38:16,429 --> 00:38:17,563
it's now harder to do new things

1125
00:38:17,563 --> 00:38:19,258
than it was when we had 50 people.

1126
00:38:19,258 --> 00:38:20,091
- [Lex] Yeah.

1127
00:38:20,091 --> 00:38:20,924
- Like, what has happened?

1128
00:38:20,924 --> 00:38:21,757
So that's a recurring phenomenon.

1129
00:38:21,757 --> 00:38:22,590
By the way,

1130
00:38:22,590 --> 00:38:24,951
that's one of the reasons why there's always startups

1131
00:38:24,951 --> 00:38:26,334
and why there's venture capital.

1132
00:38:26,334 --> 00:38:29,402
That's like a timeless kind of thing.

1133
00:38:29,402 --> 00:38:32,335
So that's one observation.

1134
00:38:32,335 --> 00:38:34,731
On page rank, we can talk about that.

1135
00:38:34,731 --> 00:38:36,988
But on page rank, specifically on page rank,

1136
00:38:36,988 --> 00:38:37,906
there actually is a page.

1137
00:38:37,906 --> 00:38:39,236
So there is a page rank already in the field

1138
00:38:39,236 --> 00:38:40,323
and it's the transformer, right?

1139
00:38:40,323 --> 00:38:42,431
So the big breakthrough was the transformer.

1140
00:38:42,431 --> 00:38:46,681
And the transformer was invented in 2017 at Google.

1141
00:38:47,661 --> 00:38:50,698
And this is actually like really an interesting question

1142
00:38:50,698 --> 00:38:51,531
'cause it's like, okay,

1143
00:38:51,531 --> 00:38:53,947
the transformers like why does open AI even exist?

1144
00:38:53,947 --> 00:38:55,236
Like the Transformers invested at Google.

1145
00:38:55,236 --> 00:38:56,393
Why didn't Google?

1146
00:38:56,393 --> 00:38:58,836
I asked a guy I know who was senior at Google brain

1147
00:38:58,836 --> 00:38:59,994
kind of when this was happening.

1148
00:38:59,994 --> 00:39:02,348
And I said, if Google had just gone flat out to the wall

1149
00:39:02,348 --> 00:39:03,968
and just said, look, we're gonna launch,

1150
00:39:03,968 --> 00:39:05,332
we're gonna launch the equivalent of GPT4

1151
00:39:05,332 --> 00:39:06,628
as fast as we can.

1152
00:39:06,628 --> 00:39:08,679
I said, when could we have had it?

1153
00:39:08,679 --> 00:39:09,780
And he said, 2019.

1154
00:39:09,780 --> 00:39:11,190
They could have just done a two year sprint

1155
00:39:11,190 --> 00:39:13,411
with the Transformer and because they already had

1156
00:39:13,411 --> 00:39:14,296
the compute at scale.

1157
00:39:14,296 --> 00:39:15,730
They already had all the training data,

1158
00:39:15,730 --> 00:39:16,945
they could have just done it.

1159
00:39:16,945 --> 00:39:18,692
There's a variety of reasons they didn't do it.

1160
00:39:18,692 --> 00:39:20,602
This is like a classic big company thing.

1161
00:39:20,602 --> 00:39:24,233
IBM invented the relational database in the 1970s,

1162
00:39:24,233 --> 00:39:26,186
let it sit on the shelf as a paper.

1163
00:39:26,186 --> 00:39:28,028
Larry Ellison picked it up and built Oracle.

1164
00:39:28,028 --> 00:39:30,077
Xerox Park invented the interactive computer.

1165
00:39:30,077 --> 00:39:31,697
They let it sit on the shelf.

1166
00:39:31,697 --> 00:39:34,180
Steve Jobs came and turned it into the Macintosh, right?

1167
00:39:34,180 --> 00:39:36,852
And so there is this pattern. Now having said that,

1168
00:39:36,852 --> 00:39:38,794
sitting here today, like Google's in the game, right?

1169
00:39:38,794 --> 00:39:39,843
So Google, you know,

1170
00:39:39,843 --> 00:39:42,287
they maybe they let like a four year gap there go there

1171
00:39:42,287 --> 00:39:43,649
that they maybe shouldn't have,

1172
00:39:43,649 --> 00:39:45,600
but like they're in the game and so now they've got,

1173
00:39:45,600 --> 00:39:46,740
you know, now they're committed.

1174
00:39:46,740 --> 00:39:48,399
They've done this merger, they're bringing in demos,

1175
00:39:48,399 --> 00:39:49,542
they've got this merger with DeepMind.

1176
00:39:49,542 --> 00:39:51,199
You know, they're piling in resources.

1177
00:39:51,199 --> 00:39:52,510
There are rumors that they're, you know,

1178
00:39:52,510 --> 00:39:55,208
building up an incredible, you know, super LLM you know,

1179
00:39:55,208 --> 00:39:57,659
way beyond what we even have today.

1180
00:39:57,659 --> 00:39:59,696
And they've got, you know, unlimited resources

1181
00:39:59,696 --> 00:40:02,561
and a huge, you know, they've been challenged their honor.

1182
00:40:02,561 --> 00:40:05,926
- Yeah. I had a chance to hang out with (indistinct)

1183
00:40:05,926 --> 00:40:08,082
a couple days ago and we took this walk

1184
00:40:08,082 --> 00:40:10,201
and there's this giant new building

1185
00:40:10,201 --> 00:40:13,156
where there's going to be a lot of AI work being done

1186
00:40:13,156 --> 00:40:16,906
and it's kind of this ominous feeling of like

1187
00:40:18,734 --> 00:40:20,067
the fight is on.

1188
00:40:21,241 --> 00:40:22,161
- [Marc] Yeah.

1189
00:40:22,161 --> 00:40:24,966
- Like there's this beautiful Silicon Valley nature,

1190
00:40:24,966 --> 00:40:27,570
like birds are chirping and this giant building

1191
00:40:27,570 --> 00:40:30,820
and it's like the beast has been awakened.

1192
00:40:30,820 --> 00:40:31,653
- [Marc] Yeah.

1193
00:40:31,653 --> 00:40:34,834
- And then like all the big companies are waking up to this.

1194
00:40:34,834 --> 00:40:39,762
They have the compute, but also the little guys have,

1195
00:40:39,762 --> 00:40:42,284
it feels like they have all the tools to create

1196
00:40:42,284 --> 00:40:43,955
the killer product that,

1197
00:40:43,955 --> 00:40:46,010
and then there's also tools to scale

1198
00:40:46,010 --> 00:40:49,163
if you have a good idea, if you have the page rank idea.

1199
00:40:49,163 --> 00:40:52,468
So there's several things that it's page rank,

1200
00:40:52,468 --> 00:40:53,661
there's page rank,

1201
00:40:53,661 --> 00:40:56,043
the algorithm and the idea and there's like

1202
00:40:56,043 --> 00:40:57,247
the implementation of it.

1203
00:40:57,247 --> 00:40:59,557
And I feel like killer product is not just the idea,

1204
00:40:59,557 --> 00:41:00,426
like the transform,

1205
00:41:00,426 --> 00:41:02,642
it's the implementation something

1206
00:41:02,642 --> 00:41:03,865
really compelling about it.

1207
00:41:03,865 --> 00:41:05,960
Like you just can't look away something like

1208
00:41:05,960 --> 00:41:09,146
the algorithm behind TikTok versus TikTok itself,

1209
00:41:09,146 --> 00:41:12,086
like the actual experience of TikTok that just,

1210
00:41:12,086 --> 00:41:13,232
you can't look away.

1211
00:41:13,232 --> 00:41:16,270
It feels like somebody's gonna come up with that.

1212
00:41:16,270 --> 00:41:17,653
And it could be Google,

1213
00:41:17,653 --> 00:41:20,396
but it feels like it's just easier and faster

1214
00:41:20,396 --> 00:41:22,103
to do for a startup.

1215
00:41:22,103 --> 00:41:23,050
- Yeah. So, the startup,

1216
00:41:23,050 --> 00:41:25,311
the huge advantage that startups have is they just,

1217
00:41:25,311 --> 00:41:26,780
there's no sacred cows.

1218
00:41:26,780 --> 00:41:28,622
There's no historical legacy to protect,

1219
00:41:28,622 --> 00:41:29,955
there's no need to reconcile your new plan

1220
00:41:29,955 --> 00:41:31,143
with the existing strategy.

1221
00:41:31,143 --> 00:41:32,796
There's no communication overhead.

1222
00:41:32,796 --> 00:41:34,422
There's no, you know, big companies are big companies.

1223
00:41:34,422 --> 00:41:36,578
They've got pre-meetings planning for the meeting,

1224
00:41:36,578 --> 00:41:38,303
then they have the post meeting, the recap,

1225
00:41:38,303 --> 00:41:39,815
then they have the presentation of the board,

1226
00:41:39,815 --> 00:41:40,974
then they have the next rounds of meetings.

1227
00:41:40,974 --> 00:41:41,974
And that's the--

1228
00:41:41,974 --> 00:41:42,807
- [Lex] Lots of meetings.

1229
00:41:42,807 --> 00:41:43,640
- That's the elapsed time

1230
00:41:43,640 --> 00:41:45,064
when the startup launches its product. Right?

1231
00:41:45,064 --> 00:41:47,402
So, there's a timeless, right?

1232
00:41:47,402 --> 00:41:48,235
- [Lex] Yeah.

1233
00:41:48,235 --> 00:41:49,563
- So there's a timeless thing there now.

1234
00:41:49,563 --> 00:41:51,679
What the startups don't have is everything else, right?

1235
00:41:51,679 --> 00:41:52,812
So startups, they don't have a brand,

1236
00:41:52,812 --> 00:41:53,732
they don't have customer relationships.

1237
00:41:53,732 --> 00:41:54,768
They've gotten no distribution,

1238
00:41:54,768 --> 00:41:56,155
they've got no, you know, scale.

1239
00:41:56,155 --> 00:41:57,880
I mean sitting here today, they can't even get GPUs.

1240
00:41:57,880 --> 00:41:59,907
Right. Like there's like a GPU shortage.

1241
00:41:59,907 --> 00:42:01,393
Startups are literally stalled out right now

1242
00:42:01,393 --> 00:42:04,103
'cause they can't get chips, which is like super weird.

1243
00:42:04,103 --> 00:42:05,664
- [Lex] Yeah. They got the cloud.

1244
00:42:05,664 --> 00:42:08,523
- Yeah. But the clouds run out of chips. Right.

1245
00:42:08,523 --> 00:42:10,605
And then to the extent the clouds have chips,

1246
00:42:10,605 --> 00:42:12,143
they allocate them to the big customers.

1247
00:42:12,143 --> 00:42:13,430
Not the small customers. Right.

1248
00:42:13,430 --> 00:42:16,537
And so the small companies lack everything other

1249
00:42:16,537 --> 00:42:20,070
than the ability to just do something new. Right.

1250
00:42:20,070 --> 00:42:22,223
And this is the timeless race and battle.

1251
00:42:22,223 --> 00:42:23,927
And this is kinda the point I tried to make in the essay,

1252
00:42:23,927 --> 00:42:25,921
which is like, both sides of this are good.

1253
00:42:25,921 --> 00:42:27,013
Like, it's really good to have

1254
00:42:27,013 --> 00:42:28,289
like highly-scaled tech companies

1255
00:42:28,289 --> 00:42:29,220
that can do things that are

1256
00:42:29,220 --> 00:42:30,971
like at staggering levels of sophistication.

1257
00:42:30,971 --> 00:42:32,957
It's really good to have startups that can launch

1258
00:42:32,957 --> 00:42:33,828
brand-new ideas.

1259
00:42:33,828 --> 00:42:35,885
They ought to be able to both do that and compete.

1260
00:42:35,885 --> 00:42:37,377
They, neither one ought to be subsidized

1261
00:42:37,377 --> 00:42:39,091
or protected from the others.

1262
00:42:39,091 --> 00:42:40,153
Like that's, to me,

1263
00:42:40,153 --> 00:42:42,185
that's just like very clearly the idealized world.

1264
00:42:42,185 --> 00:42:45,172
It is the world we've been in for AI up until now.

1265
00:42:45,172 --> 00:42:46,444
And then of course there are people trying

1266
00:42:46,444 --> 00:42:47,531
to shut that down.

1267
00:42:47,531 --> 00:42:48,518
But my hope is that, you know,

1268
00:42:48,518 --> 00:42:50,807
the best outcome clearly will be if that continues.

1269
00:42:50,807 --> 00:42:52,053
- We'll talk about that a little bit,

1270
00:42:52,053 --> 00:42:53,886
but I'd love to linger

1271
00:42:54,942 --> 00:42:58,108
on some of the ways this is going to change the internet.

1272
00:42:58,108 --> 00:43:00,140
So I don't know if you remember,

1273
00:43:00,140 --> 00:43:02,610
but there's a thing called Mosaic and there's a thing called

1274
00:43:02,610 --> 00:43:03,592
Netscape Navigator.

1275
00:43:03,592 --> 00:43:05,331
So you were there in the beginning.

1276
00:43:05,331 --> 00:43:07,386
What about the interface to the internet?

1277
00:43:07,386 --> 00:43:09,518
How do you think the browser changes

1278
00:43:09,518 --> 00:43:10,989
and who gets to own the browser?

1279
00:43:10,989 --> 00:43:13,959
We got to see some very interesting browsers,

1280
00:43:13,959 --> 00:43:17,752
Firefox, I mean all the variants of Microsoft,

1281
00:43:17,752 --> 00:43:22,085
Internet Explorer, Edge, and now Chrome, the actual,

1282
00:43:25,763 --> 00:43:27,213
and he seems like a dumb question to ask,

1283
00:43:27,213 --> 00:43:30,487
but do you think we'll still have the web browser?

1284
00:43:30,487 --> 00:43:32,397
- So I have an eight-year-old and he's super into,

1285
00:43:32,397 --> 00:43:34,057
he's like Minecraft and learning

1286
00:43:34,057 --> 00:43:35,163
to code and doing all this stuff.

1287
00:43:35,163 --> 00:43:36,527
So, of course I was very proud I could bring

1288
00:43:36,527 --> 00:43:38,717
sort of fire down from the mountain to my kid

1289
00:43:38,717 --> 00:43:41,862
and I brought him ChatGPT and I hooked him up

1290
00:43:41,862 --> 00:43:43,451
on his laptop.

1291
00:43:43,451 --> 00:43:44,406
And I was like, you know,

1292
00:43:44,406 --> 00:43:46,141
this is the thing that's gonna answer all your questions.

1293
00:43:46,141 --> 00:43:47,352
And he's like, okay.

1294
00:43:47,352 --> 00:43:49,565
And I'm like, but it's gonna answer all your questions.

1295
00:43:49,565 --> 00:43:50,840
And he's like, well of course, like it's a computer.

1296
00:43:50,840 --> 00:43:51,819
Of course it answers all your questions.

1297
00:43:51,819 --> 00:43:55,114
Like, what else would a computer be good for, dad?

1298
00:43:55,114 --> 00:43:57,121
- [Lex] And never impressed, are they?

1299
00:43:57,121 --> 00:43:58,609
- Not impressed in the least.

1300
00:43:58,609 --> 00:43:59,790
Two weeks passed.

1301
00:43:59,790 --> 00:44:02,139
And he has some question and I say, well,

1302
00:44:02,139 --> 00:44:03,105
have you asked ChatGPT?

1303
00:44:03,105 --> 00:44:05,920
And he's like, dad, Bing is better.

1304
00:44:05,920 --> 00:44:06,845
- [Lex] Ooh.

1305
00:44:06,845 --> 00:44:08,308
- And why is Bing better?

1306
00:44:08,308 --> 00:44:09,823
Is because it's built into the browser.

1307
00:44:09,823 --> 00:44:10,949
'Cause he's like, look,

1308
00:44:10,949 --> 00:44:12,227
I have the Microsoft Edge browser

1309
00:44:12,227 --> 00:44:13,214
and like it's got Bing right here.

1310
00:44:13,214 --> 00:44:14,932
And then he doesn't know this yet,

1311
00:44:14,932 --> 00:44:17,234
but one of the things you can do with Bing and Edge is

1312
00:44:17,234 --> 00:44:20,160
there's a setting where you can use it to basically talk

1313
00:44:20,160 --> 00:44:22,603
to any webpage because it's sitting right there

1314
00:44:22,603 --> 00:44:24,632
next to the browser.

1315
00:44:24,632 --> 00:44:26,341
And by the way, which includes PDF documents.

1316
00:44:26,341 --> 00:44:28,492
And so you can, in the way they've implemented an Edge

1317
00:44:28,492 --> 00:44:30,147
with Bing is you can load a PDF

1318
00:44:30,147 --> 00:44:32,128
and then you can ask it questions,

1319
00:44:32,128 --> 00:44:35,093
which is the thing you can't do currently in just ChatGPT.

1320
00:44:35,093 --> 00:44:35,997
So they're, you know,

1321
00:44:35,997 --> 00:44:38,271
they're gonna, they're gonna push the meld.

1322
00:44:38,271 --> 00:44:39,104
I think that's great.

1323
00:44:39,104 --> 00:44:40,104
You know, they're gonna push the melding

1324
00:44:40,104 --> 00:44:42,071
and see if there's a combination thing there.

1325
00:44:42,071 --> 00:44:43,387
Google's rolling out this thing,

1326
00:44:43,387 --> 00:44:45,327
the magic button, which is implemented in, you know,

1327
00:44:45,327 --> 00:44:46,835
they put it in Google Docs, right?

1328
00:44:46,835 --> 00:44:48,391
And so you go at a, you know,

1329
00:44:48,391 --> 00:44:50,639
Google Docs and you create a new document and you know,

1330
00:44:50,639 --> 00:44:52,256
you instead of like, you know, starting to type,

1331
00:44:52,256 --> 00:44:53,251
you just, you know, say it,

1332
00:44:53,251 --> 00:44:54,469
press the button and it starts to like,

1333
00:44:54,469 --> 00:44:56,169
generate content for you, right?

1334
00:44:56,169 --> 00:44:58,637
Like, is that the way that it'll work?

1335
00:44:58,637 --> 00:45:01,453
Is it gonna be a speech UI where you're just gonna have

1336
00:45:01,453 --> 00:45:03,391
an earpiece and talk to it all day long?

1337
00:45:03,391 --> 00:45:06,460
You know, is it gonna be a, like these are all, like,

1338
00:45:06,460 --> 00:45:08,307
this is exactly the kind of thing that I don't,

1339
00:45:08,307 --> 00:45:09,437
this is exactly the kind of thing

1340
00:45:09,437 --> 00:45:11,258
I don't think is possible to forecast.

1341
00:45:11,258 --> 00:45:13,315
I think what we need to do is like run all those experiments

1342
00:45:13,315 --> 00:45:15,342
and so one outcome is we come out of this with like

1343
00:45:15,342 --> 00:45:16,928
a super browser that has AI built

1344
00:45:16,928 --> 00:45:18,581
in that's just like amazing.

1345
00:45:18,581 --> 00:45:20,889
There's a real possibility that the whole,

1346
00:45:20,889 --> 00:45:22,961
I mean, look, there's a possibility here

1347
00:45:22,961 --> 00:45:25,566
that the whole idea of a screen and windows

1348
00:45:25,566 --> 00:45:27,298
and all this stuff just goes away

1349
00:45:27,298 --> 00:45:28,131
'cause like,

1350
00:45:28,131 --> 00:45:29,555
why do you need that if you just have a thing

1351
00:45:29,555 --> 00:45:31,094
that's just telling you whatever you need to know?

1352
00:45:31,094 --> 00:45:35,261
- Well and also, so there's apps that you can use,

1353
00:45:35,261 --> 00:45:36,988
you don't really use them.

1354
00:45:36,988 --> 00:45:40,597
You know, being a Linux guy and Windows guy,

1355
00:45:40,597 --> 00:45:41,952
there's one window,

1356
00:45:41,952 --> 00:45:44,151
the browser that with which you can interact

1357
00:45:44,151 --> 00:45:47,216
with the internet, but on the phone you can also have apps.

1358
00:45:47,216 --> 00:45:48,957
So I can interact with Twitter through the app

1359
00:45:48,957 --> 00:45:50,574
or through the web browser.

1360
00:45:50,574 --> 00:45:53,551
And that seems like an obvious distinction,

1361
00:45:53,551 --> 00:45:56,290
but why have the web browser in that case,

1362
00:45:56,290 --> 00:45:58,808
if one of the apps starts becoming the everything app.

1363
00:45:58,808 --> 00:46:00,016
- [Marc] Yeah, that's right.

1364
00:46:00,016 --> 00:46:01,441
- What is Elon trying to do with Twitter?

1365
00:46:01,441 --> 00:46:03,644
But there could be others. There could be like a big app,

1366
00:46:03,644 --> 00:46:06,939
there could be a Google app that just doesn't really do

1367
00:46:06,939 --> 00:46:08,984
search, but just like,

1368
00:46:08,984 --> 00:46:11,889
do what I guess AOL did back in the day or something where

1369
00:46:11,889 --> 00:46:15,722
it's all right there and it changes the nature

1370
00:46:20,045 --> 00:46:25,045
of the internet because where the content is hosted,

1371
00:46:25,089 --> 00:46:26,443
who owns the data?

1372
00:46:26,443 --> 00:46:27,982
Who owns the content?

1373
00:46:27,982 --> 00:46:29,690
What is the kind of content you create?

1374
00:46:29,690 --> 00:46:32,021
How do you make money by creating content?

1375
00:46:32,021 --> 00:46:34,565
Who are the content creators?

1376
00:46:34,565 --> 00:46:36,052
All of that.

1377
00:46:36,052 --> 00:46:38,366
Or it could just keep being the same,

1378
00:46:38,366 --> 00:46:41,105
which is like with just the nature of webpage changes

1379
00:46:41,105 --> 00:46:42,134
and the nature of content.

1380
00:46:42,134 --> 00:46:43,427
But there'll still be a web browser.

1381
00:46:43,427 --> 00:46:46,355
'Cause web browser's a pretty sexy product.

1382
00:46:46,355 --> 00:46:47,786
It just seems to work.

1383
00:46:47,786 --> 00:46:49,956
'Cause it like you have an interface,

1384
00:46:49,956 --> 00:46:51,306
a window into the world,

1385
00:46:51,306 --> 00:46:53,179
and then the world can be anything you want.

1386
00:46:53,179 --> 00:46:54,349
And as the world will evolve,

1387
00:46:54,349 --> 00:46:55,729
it could be different programming languages,

1388
00:46:55,729 --> 00:46:58,820
it can be animated, maybe it's three dimensional and so on.

1389
00:46:58,820 --> 00:47:00,427
Yeah, it's interesting.

1390
00:47:00,427 --> 00:47:02,765
Do you think we'll still have the web browser?

1391
00:47:02,765 --> 00:47:06,012
- Well, very medium becomes the content for the next one.

1392
00:47:06,012 --> 00:47:06,845
- [Lex] Oh boy.

1393
00:47:06,845 --> 00:47:08,238
- You know, the AI will be able

1394
00:47:08,238 --> 00:47:10,297
to give you a browser whenever you want.

1395
00:47:10,297 --> 00:47:11,814
- [Lex] Oh, interesting. Generate.

1396
00:47:11,814 --> 00:47:13,353
- Well, another way to think about it is maybe

1397
00:47:13,353 --> 00:47:14,490
what the browser is

1398
00:47:14,490 --> 00:47:16,295
maybe it's just the escape hatch, right?

1399
00:47:16,295 --> 00:47:18,732
Which is maybe kind of what it is today, right?

1400
00:47:18,732 --> 00:47:20,851
Which is like most of what you do is like inside a social

1401
00:47:20,851 --> 00:47:22,967
network or inside a search engine or inside, you know,

1402
00:47:22,967 --> 00:47:25,853
somebody's app or inside some controlled experience, right?

1403
00:47:25,853 --> 00:47:27,502
But then every once in a while there's something

1404
00:47:27,502 --> 00:47:29,175
where you actually want to jailbreak,

1405
00:47:29,175 --> 00:47:30,527
you wanna actually get free.

1406
00:47:30,527 --> 00:47:32,249
- Web browser's the FU to the man.

1407
00:47:32,249 --> 00:47:33,454
You're allowed to.

1408
00:47:33,454 --> 00:47:34,425
That's the free internet.

1409
00:47:34,425 --> 00:47:35,550
- [Marc] Yeah.

1410
00:47:35,550 --> 00:47:37,782
- Back the way it was in the nineties.

1411
00:47:37,782 --> 00:47:38,615
- So here's something I'm proud of.

1412
00:47:38,615 --> 00:47:39,448
So nobody really talks about it.

1413
00:47:39,448 --> 00:47:40,378
Here's something I'm proud of, which is the web,

1414
00:47:40,378 --> 00:47:41,838
the browser, the web servers, they're all,

1415
00:47:41,838 --> 00:47:43,335
they're still backward compatible

1416
00:47:43,335 --> 00:47:45,057
all the way back to like 1992, right?

1417
00:47:45,057 --> 00:47:48,107
So like, you can put up a, you can still, you know what,

1418
00:47:48,107 --> 00:47:49,660
the big breakthrough of the web early on the big

1419
00:47:49,660 --> 00:47:51,884
breakthrough was it made it really easy to read,

1420
00:47:51,884 --> 00:47:53,202
but it also made it really easy to write,

1421
00:47:53,202 --> 00:47:54,384
made it really easy to publish.

1422
00:47:54,384 --> 00:47:56,290
And we literally made it so easy to publish.

1423
00:47:56,290 --> 00:47:58,627
We made it not only so it was easy to publish content,

1424
00:47:58,627 --> 00:48:01,214
it was actually also easy to actually write a web server.

1425
00:48:01,214 --> 00:48:02,047
- [Lex] Yeah.

1426
00:48:02,047 --> 00:48:03,392
- Right and you could literally write a web server

1427
00:48:03,392 --> 00:48:04,589
in four lines of brol code

1428
00:48:04,589 --> 00:48:06,048
and you could start publishing content on it,

1429
00:48:06,048 --> 00:48:08,146
and you could set whatever rules you want for the content,

1430
00:48:08,146 --> 00:48:10,198
whatever censorship, no censorship, whatever you want.

1431
00:48:10,198 --> 00:48:11,214
You could just do that.

1432
00:48:11,214 --> 00:48:12,881
And as long as you had an IP address, right,

1433
00:48:12,881 --> 00:48:14,029
you could do that.

1434
00:48:14,029 --> 00:48:15,253
That still works, right?

1435
00:48:15,253 --> 00:48:18,390
That like, still works exactly as I just described.

1436
00:48:18,390 --> 00:48:21,433
So this is part of my reaction to all of this.

1437
00:48:21,433 --> 00:48:23,282
Like, you know, all this just censorship pressure

1438
00:48:23,282 --> 00:48:24,115
and all this, you know,

1439
00:48:24,115 --> 00:48:25,452
these issues around control and all this stuff,

1440
00:48:25,452 --> 00:48:26,325
which is like,

1441
00:48:26,325 --> 00:48:27,783
maybe we need to get back a little bit more

1442
00:48:27,783 --> 00:48:28,803
to the wild west.

1443
00:48:28,803 --> 00:48:31,065
Like, the wild west is still out there.

1444
00:48:31,065 --> 00:48:33,396
Now they will try to chase you down.

1445
00:48:33,396 --> 00:48:34,412
Like they'll try to, you know,

1446
00:48:34,412 --> 00:48:36,389
people who want a censor will try to take away you know,

1447
00:48:36,389 --> 00:48:38,369
your domain name and they'll try to take away

1448
00:48:38,369 --> 00:48:39,401
your payments account and so forth

1449
00:48:39,401 --> 00:48:41,312
if they really don't like what you're saying.

1450
00:48:41,312 --> 00:48:42,724
But nevertheless, you like,

1451
00:48:42,724 --> 00:48:44,399
unless they literally are intercepting you

1452
00:48:44,399 --> 00:48:47,580
at the ISP level, like you can still put up a thing.

1453
00:48:47,580 --> 00:48:48,725
And so I don't know,

1454
00:48:48,725 --> 00:48:50,480
I think that's important to preserve, right?

1455
00:48:50,480 --> 00:48:53,963
Like because I mean one is just a freedom argument,

1456
00:48:53,963 --> 00:48:55,325
but the other's a creativity argument,

1457
00:48:55,325 --> 00:48:57,347
which is you wanna have the escape hatch

1458
00:48:57,347 --> 00:48:59,453
so that the kid with the idea is able to realize the idea.

1459
00:48:59,453 --> 00:49:00,851
'cause to your point on page rank,

1460
00:49:00,851 --> 00:49:03,930
you actually don't know what the next big idea is, right?

1461
00:49:03,930 --> 00:49:04,976
No, nobody called Larry Page

1462
00:49:04,976 --> 00:49:06,137
and told him to develop page rank.

1463
00:49:06,137 --> 00:49:07,351
Like he came up with that on his own.

1464
00:49:07,351 --> 00:49:08,200
And you wanna always,

1465
00:49:08,200 --> 00:49:10,308
I think leave the escape hatch for the next, you know,

1466
00:49:10,308 --> 00:49:12,529
kid or the next Stanford grad student to have

1467
00:49:12,529 --> 00:49:14,084
the breakthrough idea and be able to get it up and running

1468
00:49:14,084 --> 00:49:15,577
before anybody notices.

1469
00:49:15,577 --> 00:49:17,922
- You and I are both hands of history.

1470
00:49:17,922 --> 00:49:19,149
So let's step back.

1471
00:49:19,149 --> 00:49:20,268
We've been talking about the future.

1472
00:49:20,268 --> 00:49:24,308
Let's step back for a bit and look at the nineties.

1473
00:49:24,308 --> 00:49:26,067
You created Mosaic web browser,

1474
00:49:26,067 --> 00:49:28,558
the first widely used web browser.

1475
00:49:28,558 --> 00:49:29,668
Tell the story of that.

1476
00:49:29,668 --> 00:49:32,363
And how did it evolve into Netscape Navigator

1477
00:49:32,363 --> 00:49:34,375
this the early days?

1478
00:49:34,375 --> 00:49:35,678
- So full story. So.

1479
00:49:35,678 --> 00:49:37,291
- [Lex] We were born,

1480
00:49:37,291 --> 00:49:39,690
- I was born. A small child.

1481
00:49:39,690 --> 00:49:42,159
- Actually. Yeah, let's go there.

1482
00:49:42,159 --> 00:49:45,428
Like, when would you first fall in love with computers?

1483
00:49:45,428 --> 00:49:47,827
- Oh, so I hit the generational jackpot

1484
00:49:47,827 --> 00:49:50,540
and I hit the Gen X kind of point perfectly as it turns out.

1485
00:49:50,540 --> 00:49:51,799
So I was born in 1971.

1486
00:49:51,799 --> 00:49:53,257
So there's this great website called

1487
00:49:53,257 --> 00:49:57,293
WTF happened in 1971 dot com, which is basically in 1971.

1488
00:49:57,293 --> 00:49:58,984
It's when everything started to go to hell.

1489
00:49:58,984 --> 00:50:00,151
And I was of course born in 1971.

1490
00:50:00,151 --> 00:50:02,180
So I like to think that I had something to do with that.

1491
00:50:02,180 --> 00:50:03,958
- Did you make it on the website?

1492
00:50:03,958 --> 00:50:05,906
- I don't think I made it on the website,

1493
00:50:05,906 --> 00:50:08,602
but you know, hopefully, somebody needs to add.

1494
00:50:08,602 --> 00:50:09,941
- This is where everything.

1495
00:50:09,941 --> 00:50:12,313
- Maybe I contributed to some of the trends that they do.

1496
00:50:12,313 --> 00:50:14,473
Every line on that website goes like that, right?

1497
00:50:14,473 --> 00:50:16,728
So it's all a picture disaster.

1498
00:50:16,728 --> 00:50:19,305
But there was this moment in time where

1499
00:50:19,305 --> 00:50:21,427
'cause you know, sort of the Apple, you know,

1500
00:50:21,427 --> 00:50:25,163
the Apple II hit in like 1978 and then the IBM PC hit in 82.

1501
00:50:25,163 --> 00:50:27,160
So I was like, you know, 11 when the PC came out.

1502
00:50:27,160 --> 00:50:30,373
And so I just kind of hit that perfectly and then that was

1503
00:50:30,373 --> 00:50:31,671
the first moment in time when like,

1504
00:50:31,671 --> 00:50:33,291
regular people could spend a few hundred dollars

1505
00:50:33,291 --> 00:50:34,264
and get a computer, right?

1506
00:50:34,264 --> 00:50:35,980
And so that, I just like that resonated

1507
00:50:35,980 --> 00:50:37,813
right out of the gate.

1508
00:50:37,813 --> 00:50:39,904
And then the other part of the story is, you know,

1509
00:50:39,904 --> 00:50:41,534
I was using Apple II, I used a bunch of them,

1510
00:50:41,534 --> 00:50:43,443
but I was using Apple II and of course it said in the back

1511
00:50:43,443 --> 00:50:45,115
of every Apple II and every Mac it said, you know,

1512
00:50:45,115 --> 00:50:47,580
designed in Cupertino, California.

1513
00:50:47,580 --> 00:50:48,545
And I was like, wow, okay.

1514
00:50:48,545 --> 00:50:50,812
Cupertino must be the like, shining city on the hill.

1515
00:50:50,812 --> 00:50:52,380
Like Wizard of Oz is like the most amazing,

1516
00:50:52,380 --> 00:50:54,105
like city of all time. I can't wait to see it.

1517
00:50:54,105 --> 00:50:54,938
And of course,

1518
00:50:54,938 --> 00:50:56,949
years later I came out to Silicon Valley

1519
00:50:56,949 --> 00:50:57,782
and went to Cupertino

1520
00:50:57,782 --> 00:50:59,511
and it's just a bunch of office parks

1521
00:50:59,511 --> 00:51:01,947
at low-rise apartment buildings.

1522
00:51:01,947 --> 00:51:03,583
So the aesthetics were a little disappointing, but,

1523
00:51:03,583 --> 00:51:06,436
you know, it was the vector right of the creation

1524
00:51:06,436 --> 00:51:08,825
of a lot of this stuff.

1525
00:51:08,825 --> 00:51:10,829
So then basically by, so part part,

1526
00:51:10,829 --> 00:51:14,359
part of my story is just the luck of having been born

1527
00:51:14,359 --> 00:51:16,356
at the right time and getting exposed to PCs.

1528
00:51:16,356 --> 00:51:17,254
Then the other part is,

1529
00:51:17,254 --> 00:51:19,828
the other part is when El Gore says that he created

1530
00:51:19,828 --> 00:51:21,333
the internet, he actually is correct

1531
00:51:21,333 --> 00:51:23,148
in a really meaningful way,

1532
00:51:23,148 --> 00:51:25,714
which is he sponsored a bill in 1985 that essentially

1533
00:51:25,714 --> 00:51:26,863
created the modern internet,

1534
00:51:26,863 --> 00:51:28,896
created what is called the NSF net at the time,

1535
00:51:28,896 --> 00:51:32,974
which is sort of the first really fast internet backbone.

1536
00:51:32,974 --> 00:51:34,396
And you know,

1537
00:51:34,396 --> 00:51:36,076
that that bill dumped a ton of money

1538
00:51:36,076 --> 00:51:37,447
into a bunch of research universities

1539
00:51:37,447 --> 00:51:39,188
to build out basically the internet backbone

1540
00:51:39,188 --> 00:51:41,162
and then the supercomputer centers that were clustered

1541
00:51:41,162 --> 00:51:43,072
around the internet.

1542
00:51:43,072 --> 00:51:45,636
And one of those universities was University of Illinois

1543
00:51:45,636 --> 00:51:46,805
where I went to school.

1544
00:51:46,805 --> 00:51:48,136
And so the other stroke lock that I had was,

1545
00:51:48,136 --> 00:51:49,846
I went to Illinois basically right as that money was

1546
00:51:49,846 --> 00:51:52,027
just like getting dumped on campus.

1547
00:51:52,027 --> 00:51:53,795
And so as a consequence we had at, on campus,

1548
00:51:53,795 --> 00:51:57,667
and this was like, you know, 89, 90, 91, we had like,

1549
00:51:57,667 --> 00:51:59,501
you know, we were right on the internet backbone.

1550
00:51:59,501 --> 00:52:00,749
We had like T3 and 45 at the time,

1551
00:52:00,749 --> 00:52:02,747
T3 45 megabit backbone connection, which at the time was,

1552
00:52:02,747 --> 00:52:05,000
you know, wildly state of the art.

1553
00:52:05,000 --> 00:52:06,663
We had cray super computers.

1554
00:52:06,663 --> 00:52:08,716
We had thinking machines parallel super computers.

1555
00:52:08,716 --> 00:52:11,541
We had silicon graphics workstations, we had Macintosh's,

1556
00:52:11,541 --> 00:52:13,387
we had next cubes all over the place.

1557
00:52:13,387 --> 00:52:15,300
We had like every possible kind of computer

1558
00:52:15,300 --> 00:52:16,358
you could imagine

1559
00:52:16,358 --> 00:52:18,607
'cause all this money just fell out of the sky.

1560
00:52:18,607 --> 00:52:20,103
- [Lex] So you were living in the future.

1561
00:52:20,103 --> 00:52:21,939
- Yeah. So yeah, quite literally it was, yeah,

1562
00:52:21,939 --> 00:52:22,772
like it's all there.

1563
00:52:22,772 --> 00:52:23,734
It's all like we had full broadband graphics,

1564
00:52:23,734 --> 00:52:25,317
like the whole thing.

1565
00:52:25,317 --> 00:52:27,328
And it's actually funny 'cause they had

1566
00:52:27,328 --> 00:52:28,966
this is the first time I kind of,

1567
00:52:28,966 --> 00:52:30,865
it sort of tickled the back of my head that there might be

1568
00:52:30,865 --> 00:52:32,606
a big opportunity in here, which is, you know,

1569
00:52:32,606 --> 00:52:34,884
they embraced it and so they put like computers

1570
00:52:34,884 --> 00:52:36,990
in all the dorms and they wired up all the dorm rooms

1571
00:52:36,990 --> 00:52:38,290
and they had all these, you know,

1572
00:52:38,290 --> 00:52:39,447
labs everywhere and everything.

1573
00:52:39,447 --> 00:52:41,308
And then they gave every undergrad

1574
00:52:41,308 --> 00:52:44,804
a computer account and an email address.

1575
00:52:44,804 --> 00:52:47,160
And the assumption was that you would use the internet

1576
00:52:47,160 --> 00:52:48,466
for four years at college

1577
00:52:48,466 --> 00:52:52,303
and then you would graduate and stop using it.

1578
00:52:52,303 --> 00:52:53,878
And that was that, right?

1579
00:52:53,878 --> 00:52:54,711
- [Lex] Yeah.

1580
00:52:54,711 --> 00:52:56,342
- And you would just retire your email address.

1581
00:52:56,342 --> 00:52:57,569
It wouldn't be relevant anymore 'cause you'd go off

1582
00:52:57,569 --> 00:52:59,057
from the workplace and they don't use email.

1583
00:52:59,057 --> 00:53:00,927
You'd be back to using fax machines or whatever.

1584
00:53:00,927 --> 00:53:02,251
- Did you have that sense as well?

1585
00:53:02,251 --> 00:53:04,762
Like, what you said the back of your head was tickled.

1586
00:53:04,762 --> 00:53:08,006
Like, what was exciting to you about this possible world?

1587
00:53:08,006 --> 00:53:10,374
- Well, if this is so useful in this containment,

1588
00:53:10,374 --> 00:53:12,368
if this is so useful in this contain environment

1589
00:53:12,368 --> 00:53:13,901
that just has this weird source of outside funding,

1590
00:53:13,901 --> 00:53:16,549
then if it were practical for everybody else

1591
00:53:16,549 --> 00:53:18,237
to have this and if it were cost effective

1592
00:53:18,237 --> 00:53:19,309
for everybody else to have this,

1593
00:53:19,309 --> 00:53:20,598
wouldn't they want it?

1594
00:53:20,598 --> 00:53:22,279
And the overwhelmingly the prevailing view

1595
00:53:22,279 --> 00:53:23,824
at the time was no, they would not want it.

1596
00:53:23,824 --> 00:53:25,869
This is esoteric, weird nerd stuff, right?

1597
00:53:25,869 --> 00:53:27,398
That like computer science kids like,

1598
00:53:27,398 --> 00:53:29,905
but like normal people are never gonna do email. Right.

1599
00:53:29,905 --> 00:53:31,499
Or be on the internet, right?

1600
00:53:31,499 --> 00:53:33,853
And so I was just like, wow, like this is actually,

1601
00:53:33,853 --> 00:53:35,420
like, this is really compelling stuff.

1602
00:53:35,420 --> 00:53:36,989
Now the other part was,

1603
00:53:36,989 --> 00:53:39,161
it was all really hard to use and in practice you had to be

1604
00:53:39,161 --> 00:53:41,142
basically a CS you know,

1605
00:53:41,142 --> 00:53:43,046
basically had had to BA CS undergrad or equivalent

1606
00:53:43,046 --> 00:53:45,296
to actually get full use of the internet at that point.

1607
00:53:45,296 --> 00:53:47,135
'cause it was all pretty esoteric stuff.

1608
00:53:47,135 --> 00:53:49,194
So then that was the other part of the idea, which was,

1609
00:53:49,194 --> 00:53:51,575
okay, we need to actually make this easy to use.

1610
00:53:51,575 --> 00:53:53,578
- So what's involved in creating Mosaic?

1611
00:53:53,578 --> 00:53:57,831
Like, in creating graphical interface to the internet?

1612
00:53:57,831 --> 00:53:59,270
- Yeah, so it was a combination of things.

1613
00:53:59,270 --> 00:54:01,513
So it was like basically the web existed

1614
00:54:01,513 --> 00:54:03,716
in an early sort of described as prototype form.

1615
00:54:03,716 --> 00:54:05,769
And by the way, text only at that point.

1616
00:54:05,769 --> 00:54:07,243
- What did it look like?

1617
00:54:07,243 --> 00:54:08,397
What was the web?

1618
00:54:08,397 --> 00:54:09,756
I mean what and the key figures.

1619
00:54:09,756 --> 00:54:11,391
Like, what was it?

1620
00:54:11,391 --> 00:54:13,303
Like, what paint a picture?

1621
00:54:13,303 --> 00:54:16,656
- It looked like ChatGPT actually it was all text.

1622
00:54:16,656 --> 00:54:17,671
- Yeah.

1623
00:54:17,671 --> 00:54:19,777
- And so you had a text-based web browser?

1624
00:54:19,777 --> 00:54:21,195
Yeah, well actually the original browser,

1625
00:54:21,195 --> 00:54:22,973
Tim Burners Lee, the original browser,

1626
00:54:22,973 --> 00:54:25,014
both the original browser and the server actually ran

1627
00:54:25,014 --> 00:54:26,112
on next cubes.

1628
00:54:26,112 --> 00:54:27,482
So these were, this was, you know,

1629
00:54:27,482 --> 00:54:29,766
the computer Steve Jobs made during the interim period

1630
00:54:29,766 --> 00:54:31,410
when during the decade long interim period

1631
00:54:31,410 --> 00:54:33,114
when he was not at Apple, you know,

1632
00:54:33,114 --> 00:54:36,261
he got fired in 85 and then came back in 97.

1633
00:54:36,261 --> 00:54:38,803
So this was in that interim period where he had this company

1634
00:54:38,803 --> 00:54:40,158
called Next and they made these,

1635
00:54:40,158 --> 00:54:41,529
literally these computers called cubes.

1636
00:54:41,529 --> 00:54:43,732
And there's this famous story, they were beautiful,

1637
00:54:43,732 --> 00:54:46,810
but they were 12 inch by 12 inch by 12 inch cubes computers.

1638
00:54:46,810 --> 00:54:48,470
And there's a famous story about how they could have cost

1639
00:54:48,470 --> 00:54:50,828
half as much if it had been 12 by 12 by 13.

1640
00:54:50,828 --> 00:54:53,710
But this cube was like, no, like it has to be.

1641
00:54:53,710 --> 00:54:57,024
So they were like $6,000 basically academic workstations.

1642
00:54:57,024 --> 00:55:00,217
They had the first city round drives, which were slow.

1643
00:55:00,217 --> 00:55:02,934
I mean it was, the computers were all but unusable.

1644
00:55:02,934 --> 00:55:05,465
They were so slow, but they were beautiful.

1645
00:55:05,465 --> 00:55:07,836
- Okay, can we actually just take a tiny tangent there?

1646
00:55:07,836 --> 00:55:09,095
- Sure. Of course.

1647
00:55:09,095 --> 00:55:14,001
- The 12 by 12 by 12 that just so beautifully encapsulates

1648
00:55:14,001 --> 00:55:15,982
Steve Jobs idea of design.

1649
00:55:15,982 --> 00:55:18,999
Can you just comment on what you find

1650
00:55:18,999 --> 00:55:21,170
interesting about Steve Jobs?

1651
00:55:21,170 --> 00:55:23,436
What about that view of the world,

1652
00:55:23,436 --> 00:55:25,717
that dogmatic pursuit of perfection

1653
00:55:25,717 --> 00:55:28,495
and how he saw perfection in design?

1654
00:55:28,495 --> 00:55:30,005
- Yeah, so I guess I'd say like, look,

1655
00:55:30,005 --> 00:55:31,154
he was a deep believer,

1656
00:55:31,154 --> 00:55:33,555
I think in a very deep, the way I interpret it,

1657
00:55:33,555 --> 00:55:35,209
I don't know if you ever really described it like this,

1658
00:55:35,209 --> 00:55:37,563
but the way I interpret it's like this thing

1659
00:55:37,563 --> 00:55:39,053
and it's actually a thing in philosophy.

1660
00:55:39,053 --> 00:55:41,138
It's like aesthetics are not just appearances.

1661
00:55:41,138 --> 00:55:42,637
Aesthetics go all the way

1662
00:55:42,637 --> 00:55:44,512
to like deep underlying meaning, right?

1663
00:55:44,512 --> 00:55:45,817
It's like I'm not a physicist.

1664
00:55:45,817 --> 00:55:47,272
One of the things I've heard physicists say is

1665
00:55:47,272 --> 00:55:48,724
one of the things you start to get a sense

1666
00:55:48,724 --> 00:55:50,790
of when a theory might be correct is

1667
00:55:50,790 --> 00:55:51,992
when it's beautiful, right?

1668
00:55:51,992 --> 00:55:53,520
Like, you know, there, right?

1669
00:55:53,520 --> 00:55:55,349
And so, there's something,

1670
00:55:55,349 --> 00:55:56,868
and you feel the same thing by the way

1671
00:55:56,868 --> 00:55:58,644
in like human psychology, right?

1672
00:55:58,644 --> 00:56:01,006
You know, when you're experiencing awe, right?

1673
00:56:01,006 --> 00:56:03,564
You know, there's like a simplicity to it.

1674
00:56:03,564 --> 00:56:05,595
When you're having an honest interaction with somebody,

1675
00:56:05,595 --> 00:56:06,848
there's an aesthetic,

1676
00:56:06,848 --> 00:56:08,154
I would say calm comes over you

1677
00:56:08,154 --> 00:56:09,591
'cause you're actually being fully honest

1678
00:56:09,591 --> 00:56:10,714
and trying to hide yourself, right?

1679
00:56:10,714 --> 00:56:13,465
So it's like this very deep sense of aesthetics.

1680
00:56:13,465 --> 00:56:17,004
- And he would trust that judgment that he had deep down.

1681
00:56:17,004 --> 00:56:19,703
Like yeah, even if the engineering teams are saying

1682
00:56:19,703 --> 00:56:21,536
this is too difficult.

1683
00:56:22,400 --> 00:56:25,631
Even if whatever the finance folks are saying,

1684
00:56:25,631 --> 00:56:26,500
this is ridiculous.

1685
00:56:26,500 --> 00:56:29,277
The supply chain, all that kind of stuff just makes

1686
00:56:29,277 --> 00:56:30,110
this impossible.

1687
00:56:30,110 --> 00:56:31,746
We can't do this kind of material.

1688
00:56:31,746 --> 00:56:34,262
This has never been done before and so on and so forth.

1689
00:56:34,262 --> 00:56:36,243
He just sticks by it.

1690
00:56:36,243 --> 00:56:38,430
- Well, I mean, who makes a phone out of aluminum, right?

1691
00:56:38,430 --> 00:56:41,127
Like, hadn't nobody else would've done that.

1692
00:56:41,127 --> 00:56:43,363
And now of course if your phone is made

1693
00:56:43,363 --> 00:56:44,839
out of aluminum white, you know, how crude,

1694
00:56:44,839 --> 00:56:47,190
what a kind of caveman would you have to be to have a phone

1695
00:56:47,190 --> 00:56:49,002
that's made outta plastic? Like, right.

1696
00:56:49,002 --> 00:56:50,825
So like, so it's just this very right.

1697
00:56:50,825 --> 00:56:51,658
And, you know, look,

1698
00:56:51,658 --> 00:56:54,021
there's a thousand different ways to look at this,

1699
00:56:54,021 --> 00:56:55,327
but one of the things is just like,

1700
00:56:55,327 --> 00:56:57,035
look, these things are central to your life.

1701
00:56:57,035 --> 00:56:58,328
Like, you're with your phone

1702
00:56:58,328 --> 00:56:59,161
more than you're with anything else.

1703
00:56:59,161 --> 00:57:00,096
Like, it's gonna be in your hand.

1704
00:57:00,096 --> 00:57:01,127
I mean, you know this,

1705
00:57:01,127 --> 00:57:03,036
he thought very deeply about what it meant for something

1706
00:57:03,036 --> 00:57:04,261
to be in your hand all day long.

1707
00:57:04,261 --> 00:57:07,430
But for example, here's an interesting design thing.

1708
00:57:07,430 --> 00:57:08,760
Like, he never wanted,

1709
00:57:08,760 --> 00:57:10,498
my understanding is he never wanted an iPhone to have

1710
00:57:10,498 --> 00:57:12,935
a screen larger than you could reach

1711
00:57:12,935 --> 00:57:15,159
with your thumb one handed.

1712
00:57:15,159 --> 00:57:17,537
And so he was actually opposed to the idea

1713
00:57:17,537 --> 00:57:18,708
of making the phones larger.

1714
00:57:18,708 --> 00:57:20,320
And I don't know if you have this experience today,

1715
00:57:20,320 --> 00:57:21,953
but let's say there are certain moments in your day

1716
00:57:21,953 --> 00:57:23,050
when you might be like,

1717
00:57:23,050 --> 00:57:24,504
only have one hand available and you might wanna be

1718
00:57:24,504 --> 00:57:25,679
on your phone.

1719
00:57:25,679 --> 00:57:29,027
And you're trying to like, send a text

1720
00:57:29,027 --> 00:57:31,449
and your thumb can't reach the send button.

1721
00:57:31,449 --> 00:57:32,916
- Yeah. I mean there's pros and cons, right?

1722
00:57:32,916 --> 00:57:34,087
And then there's like folding phones,

1723
00:57:34,087 --> 00:57:35,014
which I would love to know

1724
00:57:35,014 --> 00:57:37,043
what he thought thinks about them.

1725
00:57:37,043 --> 00:57:37,876
But I mean,

1726
00:57:37,876 --> 00:57:40,407
is there something you could also just linger on?

1727
00:57:40,407 --> 00:57:43,120
'cause he's one of the interesting figures

1728
00:57:43,120 --> 00:57:45,162
in the history of technology.

1729
00:57:45,162 --> 00:57:48,249
What makes him as successful as he was?

1730
00:57:48,249 --> 00:57:50,700
What makes him as interesting as he was?

1731
00:57:50,700 --> 00:57:54,692
What made him so productive and important

1732
00:57:54,692 --> 00:57:57,442
in the development of technology?

1733
00:57:58,367 --> 00:57:59,764
- He had an integrated worldview.

1734
00:57:59,764 --> 00:58:01,302
So the properly designed device

1735
00:58:01,302 --> 00:58:03,283
that had the correct functionality,

1736
00:58:03,283 --> 00:58:05,163
that had the deepest understanding of the user,

1737
00:58:05,163 --> 00:58:07,740
that was the most beautiful, right?

1738
00:58:07,740 --> 00:58:10,366
Like, it had to be all of those things, right?

1739
00:58:10,366 --> 00:58:12,769
He basically would drive to as close to perfect

1740
00:58:12,769 --> 00:58:14,345
as you could possibly get. Right?

1741
00:58:14,345 --> 00:58:16,558
And you know, I suspect that he never quite, you know,

1742
00:58:16,558 --> 00:58:18,190
thought he ever got there. 'cause most great creators,

1743
00:58:18,190 --> 00:58:19,867
you know, are generally dissatisfied.

1744
00:58:19,867 --> 00:58:21,612
You know, you read accounts later on and all they can,

1745
00:58:21,612 --> 00:58:22,989
all they can see are the flaws in their creation.

1746
00:58:22,989 --> 00:58:24,763
But like he got as close to perfect each step of the way

1747
00:58:24,763 --> 00:58:26,772
as he could possibly get with the constraints

1748
00:58:26,772 --> 00:58:28,982
of the technology of his time.

1749
00:58:28,982 --> 00:58:30,800
And then, you know, look, he was, you know,

1750
00:58:30,800 --> 00:58:32,124
sort of famous in the Apple model.

1751
00:58:32,124 --> 00:58:33,231
It's like, look, they will, you know,

1752
00:58:33,231 --> 00:58:35,205
this headset that they just came out with,

1753
00:58:35,205 --> 00:58:38,178
like, you know, it's like a decade long project, right?

1754
00:58:38,178 --> 00:58:39,011
It's like,

1755
00:58:39,011 --> 00:58:40,525
and they're just gonna sit there and tune and tune

1756
00:58:40,525 --> 00:58:41,680
and polish and polish and tune

1757
00:58:41,680 --> 00:58:43,124
and polish and tune and polish

1758
00:58:43,124 --> 00:58:43,957
until it is as perfect

1759
00:58:43,957 --> 00:58:45,645
as anybody could possibly make anything.

1760
00:58:45,645 --> 00:58:46,478
- Yeah.

1761
00:58:46,478 --> 00:58:47,311
- And then this goes to the way

1762
00:58:47,311 --> 00:58:49,100
that people describe working with him was, which is,

1763
00:58:49,100 --> 00:58:51,789
you know, there was a terrifying aspect of working with him,

1764
00:58:51,789 --> 00:58:53,788
which is, you know, he was, you know, he was very tough.

1765
00:58:53,788 --> 00:58:56,405
But there was this thing that everybody I've ever talked

1766
00:58:56,405 --> 00:58:57,805
to worked for him, says

1767
00:58:57,805 --> 00:58:59,990
that they all say the following,

1768
00:58:59,990 --> 00:59:01,743
which is we did the best work

1769
00:59:01,743 --> 00:59:02,991
of our lives when we worked for him

1770
00:59:02,991 --> 00:59:04,911
because he set the bar incredibly high.

1771
00:59:04,911 --> 00:59:06,872
And then he supported us with everything that he could

1772
00:59:06,872 --> 00:59:08,269
to let us actually do work of that quality.

1773
00:59:08,269 --> 00:59:10,424
So a lot of people who were at Apple spend

1774
00:59:10,424 --> 00:59:12,713
the rest of their lives trying to find another experience

1775
00:59:12,713 --> 00:59:13,546
where they feel like

1776
00:59:13,546 --> 00:59:14,960
they're able to hit that quality bar again.

1777
00:59:14,960 --> 00:59:18,173
- Even if it in retrospect or during it felt like suffering.

1778
00:59:18,173 --> 00:59:20,006
- Yeah, exactly.

1779
00:59:20,006 --> 00:59:24,333
- What does that teach you about the human condition? Huh?

1780
00:59:24,333 --> 00:59:26,314
- So look, so say exactly.

1781
00:59:26,314 --> 00:59:28,884
So the Silicon Valley, I mean, look, he's not, you know,

1782
00:59:28,884 --> 00:59:31,426
George Patton you know in the Army.

1783
00:59:31,426 --> 00:59:33,246
Like, you know, there are many examples in other fields,

1784
00:59:33,246 --> 00:59:37,413
you know, that are like this specifically in tech.

1785
00:59:38,809 --> 00:59:40,529
It's actually, I find it very interesting.

1786
00:59:40,529 --> 00:59:43,006
There's the Apple way, which is polish, polish, polish,

1787
00:59:43,006 --> 00:59:45,000
and don't ship until it's as perfect as you can make it.

1788
00:59:45,000 --> 00:59:47,345
And then there's the sort of the other approach,

1789
00:59:47,345 --> 00:59:49,807
which is the sort of incremental hacker mentality,

1790
00:59:49,807 --> 00:59:52,799
which basically says, ship early and often and iterate.

1791
00:59:52,799 --> 00:59:54,180
And one of the things I find really interesting is

1792
00:59:54,180 --> 00:59:56,201
I'm now 30 years into this, like,

1793
00:59:56,201 --> 00:59:59,387
they're very successful companies on both sides

1794
00:59:59,387 --> 01:00:00,662
of that approach, right?

1795
01:00:00,662 --> 01:00:04,694
Like, that is a fundamental difference, right?

1796
01:00:04,694 --> 01:00:07,711
In how to operate and how to build and how to create that.

1797
01:00:07,711 --> 01:00:09,929
You have world class companies operating in both ways.

1798
01:00:09,929 --> 01:00:12,610
And I don't think the question of like,

1799
01:00:12,610 --> 01:00:14,513
which is the superior model is anywhere close

1800
01:00:14,513 --> 01:00:15,735
to being answered.

1801
01:00:15,735 --> 01:00:18,539
Like, and my suspicion is the answer is do both.

1802
01:00:18,539 --> 01:00:20,316
The answer is you actually want both.

1803
01:00:20,316 --> 01:00:21,490
They lead to different outcomes.

1804
01:00:21,490 --> 01:00:24,804
Software tends to do better with the iterative approach.

1805
01:00:24,804 --> 01:00:28,297
Hardware tends to do better with the, you know,

1806
01:00:28,297 --> 01:00:30,317
sort of wait and make it perfect approach.

1807
01:00:30,317 --> 01:00:34,103
But again, you can find examples in both directions.

1808
01:00:34,103 --> 01:00:36,204
- So the jury's still out on that one.

1809
01:00:36,204 --> 01:00:37,721
So back to Mosaic.

1810
01:00:37,721 --> 01:00:41,138
So, what it was text based Tim Burns Lee?

1811
01:00:44,316 --> 01:00:45,908
- Well, there was the web, which was text based,

1812
01:00:45,908 --> 01:00:48,075
but there were no, I mean there was like three websites.

1813
01:00:48,075 --> 01:00:50,369
There was like no content, there were no users.

1814
01:00:50,369 --> 01:00:52,569
Like, it wasn't like a catalytic,

1815
01:00:52,569 --> 01:00:53,708
it hadn't, and by the way,

1816
01:00:53,708 --> 01:00:54,860
it was all because it was all text.

1817
01:00:54,860 --> 01:00:55,863
There were no documents,

1818
01:00:55,863 --> 01:00:57,776
there were no images, there were no videos,

1819
01:00:57,776 --> 01:00:58,609
there were no, right.

1820
01:00:58,609 --> 01:01:00,330
So, and then if, if in the beginning,

1821
01:01:00,330 --> 01:01:02,329
if you had to be on a next cube, right?

1822
01:01:02,329 --> 01:01:05,520
You need to had a next cube both to publish and to consume.

1823
01:01:05,520 --> 01:01:06,709
- So, there was 6,000 bucks you said.

1824
01:01:06,709 --> 01:01:08,362
- There were limitations.

1825
01:01:08,362 --> 01:01:11,076
Yeah. $6,000 PC. They did not sell very many.

1826
01:01:11,076 --> 01:01:12,538
But then there was also,

1827
01:01:12,538 --> 01:01:14,644
there was also FTP and there was Use Nets, right?

1828
01:01:14,644 --> 01:01:15,782
And there was, you know,

1829
01:01:15,782 --> 01:01:17,280
a dozen other basically there's waste,

1830
01:01:17,280 --> 01:01:18,973
which was an early search thing.

1831
01:01:18,973 --> 01:01:20,484
There was Gopher, which was an early menu based

1832
01:01:20,484 --> 01:01:21,797
information retrieval system.

1833
01:01:21,797 --> 01:01:24,328
There were like a dozen different sort of scattered ways

1834
01:01:24,328 --> 01:01:26,406
that people would get to information on the internet.

1835
01:01:26,406 --> 01:01:28,263
And so the Mosaic idea was basically bring

1836
01:01:28,263 --> 01:01:29,299
those all together,

1837
01:01:29,299 --> 01:01:31,428
make the whole thing graphical, make it easy to use,

1838
01:01:31,428 --> 01:01:33,838
make it basically bulletproof so that anybody can do it.

1839
01:01:33,838 --> 01:01:35,686
And then again, just on the luck side,

1840
01:01:35,686 --> 01:01:37,180
it so happened that this was

1841
01:01:37,180 --> 01:01:38,477
right at the moment when graphics,

1842
01:01:38,477 --> 01:01:39,940
when the GUI sort of actually took off

1843
01:01:39,940 --> 01:01:41,813
and we're now also used to the GUI

1844
01:01:41,813 --> 01:01:43,654
that we think it's been around forever.

1845
01:01:43,654 --> 01:01:44,732
But it didn't real, you know,

1846
01:01:44,732 --> 01:01:47,411
the Macintosh brought it out in 85,

1847
01:01:47,411 --> 01:01:49,776
but they actually didn't sell very many Macs

1848
01:01:49,776 --> 01:01:50,609
in the eighties.

1849
01:01:50,609 --> 01:01:52,373
It was not that successful of a product.

1850
01:01:52,373 --> 01:01:53,206
It really was.

1851
01:01:53,206 --> 01:01:57,913
You needed Windows 3.0 on PCs and that hit in about 92.

1852
01:01:57,913 --> 01:02:00,094
And so, and we did most in 92, 93.

1853
01:02:00,094 --> 01:02:00,927
So that sort of,

1854
01:02:00,927 --> 01:02:03,007
it was like right at the moment when you could imagine

1855
01:02:03,007 --> 01:02:06,894
actually having a graphical user interface to right at all,

1856
01:02:06,894 --> 01:02:08,605
much less one to the internet.

1857
01:02:08,605 --> 01:02:11,739
- How old did Windows 3 sell?

1858
01:02:11,739 --> 01:02:13,017
So was that the really big.

1859
01:02:13,017 --> 01:02:14,179
- [Marc] That was the big bang.

1860
01:02:14,179 --> 01:02:16,450
- The big operating graphical operating system?

1861
01:02:16,450 --> 01:02:17,936
- Well this is the classic, okay.

1862
01:02:17,936 --> 01:02:19,363
This Microsoft was operating on the other,

1863
01:02:19,363 --> 01:02:21,957
so Steve the Apple was running on the Polish

1864
01:02:21,957 --> 01:02:22,811
until it's perfect.

1865
01:02:22,811 --> 01:02:24,471
Microsoft famously ran on the other model,

1866
01:02:24,471 --> 01:02:25,326
which is ship and iterate.

1867
01:02:25,326 --> 01:02:26,693
And so in the old line in those days was

1868
01:02:26,693 --> 01:02:27,893
Microsoft Right's version

1869
01:02:27,893 --> 01:02:29,125
three of every Microsoft product.

1870
01:02:29,125 --> 01:02:30,312
That's the good one, right?

1871
01:02:30,312 --> 01:02:31,257
And so there there are,

1872
01:02:31,257 --> 01:02:33,115
you can find online Windows 1, Windows 2.

1873
01:02:33,115 --> 01:02:34,310
Nobody used them.

1874
01:02:34,310 --> 01:02:35,680
Actually the original Windows,

1875
01:02:35,680 --> 01:02:37,114
in the original Microsoft Windows,

1876
01:02:37,114 --> 01:02:38,754
the windows were non overlapping.

1877
01:02:38,754 --> 01:02:40,857
And so you had these very small,

1878
01:02:40,857 --> 01:02:42,381
very low resolution screens

1879
01:02:42,381 --> 01:02:43,788
and then you had literally--

1880
01:02:43,788 --> 01:02:44,788
- [Lex] Windows.

1881
01:02:44,788 --> 01:02:45,621
- It just didn't work.

1882
01:02:45,621 --> 01:02:46,712
It wasn't ready yet. Well.

1883
01:02:46,712 --> 01:02:50,005
- And Windows 95 I think was a pretty big leap also.

1884
01:02:50,005 --> 01:02:51,177
- That was a big leap too.

1885
01:02:51,177 --> 01:02:52,618
So that was like bang, bang.

1886
01:02:52,618 --> 01:02:54,321
And then of course Steve,

1887
01:02:54,321 --> 01:02:55,340
and then when, you know,

1888
01:02:55,340 --> 01:02:56,794
in the fullness of time Steve came back,

1889
01:02:56,794 --> 01:02:58,148
then the Mac started, took off again.

1890
01:02:58,148 --> 01:02:58,981
That was the third bang.

1891
01:02:58,981 --> 01:03:00,141
And then the iPhone was the fourth bang.

1892
01:03:00,141 --> 01:03:01,643
- Such exciting time.

1893
01:03:01,643 --> 01:03:03,778
- And then we were off, off to the races because.

1894
01:03:03,778 --> 01:03:06,998
- Nobody could have known what would be created from that.

1895
01:03:06,998 --> 01:03:09,470
- Well, Windows 3.1 or 3.0,

1896
01:03:09,470 --> 01:03:13,064
Windows 3.0 to the iPhone was only 15 years. Right.

1897
01:03:13,064 --> 01:03:15,682
Like that ramp was in retrospect.

1898
01:03:15,682 --> 01:03:17,525
At the time it felt like it took forever.

1899
01:03:17,525 --> 01:03:18,874
But that in histor in historical terms,

1900
01:03:18,874 --> 01:03:20,174
like that was a very fast ramp

1901
01:03:20,174 --> 01:03:21,635
from even a graphical computer

1902
01:03:21,635 --> 01:03:23,303
at all on your desk to the iPhone.

1903
01:03:23,303 --> 01:03:24,727
That was 15 years.

1904
01:03:24,727 --> 01:03:27,110
- So, did you have a sense of what the internet will be

1905
01:03:27,110 --> 01:03:28,836
as you're looking through the window of Mosaic?

1906
01:03:28,836 --> 01:03:33,787
Like, what you, like there's just a few web pages for now.

1907
01:03:33,787 --> 01:03:37,614
- So the thing I had early on was I was keeping at the time

1908
01:03:37,614 --> 01:03:40,789
what there's disputes over what was the first blog,

1909
01:03:40,789 --> 01:03:44,115
but I had one of them that at least is a possible,

1910
01:03:44,115 --> 01:03:46,099
at least a rudder up in the competition.

1911
01:03:46,099 --> 01:03:49,097
And it was what was called the What's new page.

1912
01:03:49,097 --> 01:03:50,631
And it was literally,

1913
01:03:50,631 --> 01:03:53,423
it was a hardwired in distribution unfair advantage.

1914
01:03:53,423 --> 01:03:55,406
I wired, put it right in the browser,

1915
01:03:55,406 --> 01:03:57,516
I put it in the browser and then I put my resume

1916
01:03:57,516 --> 01:03:59,163
in the browser, which also was--

1917
01:03:59,163 --> 01:03:59,996
- [Lex] Hilarious.

1918
01:03:59,996 --> 01:04:01,579
- But I was keeping

1919
01:04:04,366 --> 01:04:07,062
not many people get to get to do that.

1920
01:04:07,062 --> 01:04:08,395
- No, good call.

1921
01:04:12,299 --> 01:04:13,437
And early days.

1922
01:04:13,437 --> 01:04:14,996
It's so interesting.

1923
01:04:14,996 --> 01:04:16,601
- I'm looking for my, about about, oh,

1924
01:04:16,601 --> 01:04:17,644
Marc is looking for a job.

1925
01:04:17,644 --> 01:04:20,441
- [Lex] Yeah, yeah, exactly.

1926
01:04:20,441 --> 01:04:21,897
- So the West New page,

1927
01:04:21,897 --> 01:04:23,567
I would literally get up every morning

1928
01:04:23,567 --> 01:04:26,776
and I would, or every afternoon and I would basically,

1929
01:04:26,776 --> 01:04:28,618
if you wanted to launch a website,

1930
01:04:28,618 --> 01:04:31,331
you would email me and I would list it on the most new page.

1931
01:04:31,331 --> 01:04:33,019
And that was how people discovered the new websites

1932
01:04:33,019 --> 01:04:34,169
as they were coming out.

1933
01:04:34,169 --> 01:04:35,910
And I remember 'cause it was like one,

1934
01:04:35,910 --> 01:04:36,895
it literally went from,

1935
01:04:36,895 --> 01:04:39,619
it was like one every couple days to like one every day

1936
01:04:39,619 --> 01:04:41,452
to like two every day.

1937
01:04:42,697 --> 01:04:44,137
- And then so you're doing,

1938
01:04:44,137 --> 01:04:46,263
so that blog was kind of doing the directory thing.

1939
01:04:46,263 --> 01:04:48,466
So like, what was the homepage?

1940
01:04:48,466 --> 01:04:50,335
- So the homepage was just basically trying to explain

1941
01:04:50,335 --> 01:04:52,306
even what this thing is that you're looking at. Right.

1942
01:04:52,306 --> 01:04:53,811
Basically the basic instructions.

1943
01:04:53,811 --> 01:04:55,722
But then there was a button,

1944
01:04:55,722 --> 01:04:56,898
there was a button that said what's new.

1945
01:04:56,898 --> 01:04:58,346
And what most people did was they went to,

1946
01:04:58,346 --> 01:05:00,029
for obvious reasons went to what's new.

1947
01:05:00,029 --> 01:05:00,862
- [Lex] Yeah.

1948
01:05:00,862 --> 01:05:03,084
- But like it was so mind blowing at that point.

1949
01:05:03,084 --> 01:05:05,652
This the basic idea and it was, this was like, you know,

1950
01:05:05,652 --> 01:05:06,874
this was the basic idea of the internet,

1951
01:05:06,874 --> 01:05:08,485
but people could see it for the first time.

1952
01:05:08,485 --> 01:05:10,585
The basic idea was, look, you know, some, you know,

1953
01:05:10,585 --> 01:05:12,570
it's like literally it's like an Indian restaurant in like

1954
01:05:12,570 --> 01:05:15,069
Bristol England has like put their menu on the web.

1955
01:05:15,069 --> 01:05:17,047
And people were like, wow.

1956
01:05:17,047 --> 01:05:17,880
- [Lex] Whoa.

1957
01:05:17,880 --> 01:05:20,796
- Because like that's the first restaurant menu on the web.

1958
01:05:20,796 --> 01:05:21,678
- [Lex] Yeah.

1959
01:05:21,678 --> 01:05:22,730
- And I don't have to be in Bristol and I don't know

1960
01:05:22,730 --> 01:05:24,026
if I'm ever gonna go to Bristol.

1961
01:05:24,026 --> 01:05:26,509
And I don't even like Indian food and like. Wow. Right.

1962
01:05:26,509 --> 01:05:28,292
And it was like that the first web,

1963
01:05:28,292 --> 01:05:30,342
the first streaming video thing was

1964
01:05:30,342 --> 01:05:34,557
it was in another England, some Oxford or something.

1965
01:05:34,557 --> 01:05:39,557
Some guy put his coffee pot up as the first streaming video

1966
01:05:39,915 --> 01:05:42,322
thing and he put it on the web 'cause he literally,

1967
01:05:42,322 --> 01:05:43,799
it was the coffee pot down the hall.

1968
01:05:43,799 --> 01:05:46,165
And he wanted to see when he needed to go refill it.

1969
01:05:46,165 --> 01:05:47,684
But there were, you know,

1970
01:05:47,684 --> 01:05:48,928
there was a point when there were thousands

1971
01:05:48,928 --> 01:05:50,855
of people like watching that coffee pot

1972
01:05:50,855 --> 01:05:53,957
'cause it was the first thing you could watch.

1973
01:05:53,957 --> 01:05:57,938
- Well, but isn't were you able to kind of infer, you know,

1974
01:05:57,938 --> 01:06:00,636
if that Indian restaurant could go online.

1975
01:06:00,636 --> 01:06:03,526
Then you're like they all will.

1976
01:06:03,526 --> 01:06:04,457
- [Marc] Yeah, exactly.

1977
01:06:04,457 --> 01:06:05,290
- So you felt that?

1978
01:06:05,290 --> 01:06:06,123
- [Marc] Yeah, yeah, yeah.

1979
01:06:06,123 --> 01:06:06,956
- Okay.

1980
01:06:06,956 --> 01:06:07,789
- Now, you know, look, it's still a stretch, right?

1981
01:06:07,789 --> 01:06:09,158
It's still a stretch 'cause it's just like, okay, is it,

1982
01:06:09,158 --> 01:06:10,481
you know, you're still in this zone, which is like, okay,

1983
01:06:10,481 --> 01:06:11,365
is this a nerd thing?

1984
01:06:11,365 --> 01:06:12,668
Is this a real person thing?

1985
01:06:12,668 --> 01:06:13,615
By the way, you know,

1986
01:06:13,615 --> 01:06:15,801
there was a wall of skepticism from the media.

1987
01:06:15,801 --> 01:06:17,645
Like, they just, like, everybody was just like, yeah,

1988
01:06:17,645 --> 01:06:18,944
this is the crazy, this is just like dumb.

1989
01:06:18,944 --> 01:06:20,118
This is not, you know,

1990
01:06:20,118 --> 01:06:21,694
this is not for regular people at that time.

1991
01:06:21,694 --> 01:06:23,728
And so you, you had to think through that and then look,

1992
01:06:23,728 --> 01:06:25,955
it was still hard to get on the internet

1993
01:06:25,955 --> 01:06:27,042
at that point, right?

1994
01:06:27,042 --> 01:06:29,653
So you could get kind of this weird bastardized version

1995
01:06:29,653 --> 01:06:31,957
if you were on AOL, which wasn't really real.

1996
01:06:31,957 --> 01:06:35,372
Or you had to go like, learn what an ISP was.

1997
01:06:35,372 --> 01:06:36,650
You know, in those days,

1998
01:06:36,650 --> 01:06:39,161
PCs actually didn't have TCPIP drivers come reinstalled.

1999
01:06:39,161 --> 01:06:41,321
So you had to learn what a TCPIP driver was.

2000
01:06:41,321 --> 01:06:45,013
You had to buy a modem, you had to install driver software.

2001
01:06:45,013 --> 01:06:46,522
I have a comedy routine. I do.

2002
01:06:46,522 --> 01:06:48,571
So it's like 20 minutes long describing all the steps

2003
01:06:48,571 --> 01:06:51,362
required to actually get on the internet at this point.

2004
01:06:51,362 --> 01:06:54,399
And so you had to look through these practical.

2005
01:06:54,399 --> 01:06:56,531
Well, and then speed performance

2006
01:06:56,531 --> 01:06:58,114
14-4 modems, right?

2007
01:06:59,267 --> 01:07:01,818
Like it was like watching, you know, glue dry, like,

2008
01:07:01,818 --> 01:07:02,774
and so you had to,

2009
01:07:02,774 --> 01:07:04,689
there were basically a sequence of bets

2010
01:07:04,689 --> 01:07:06,365
that we made where you basically needed

2011
01:07:06,365 --> 01:07:08,541
to look through that current state of affairs and say,

2012
01:07:08,541 --> 01:07:09,996
actually there's gonna be so much demand for

2013
01:07:09,996 --> 01:07:10,861
once people figure this out,

2014
01:07:10,861 --> 01:07:11,832
there's gonna be so much demand

2015
01:07:11,832 --> 01:07:12,665
for it that all

2016
01:07:12,665 --> 01:07:14,383
of these practical problems are gonna get fixed.

2017
01:07:14,383 --> 01:07:16,996
- Some people say that the anticipation makes

2018
01:07:16,996 --> 01:07:20,329
the destination that much more exciting.

2019
01:07:21,280 --> 01:07:23,186
- Do you remember progressive JPEGs?

2020
01:07:23,186 --> 01:07:24,769
- Yeah. Do I, do I?

2021
01:07:26,122 --> 01:07:27,994
- For kids in the audience, right?

2022
01:07:27,994 --> 01:07:29,415
- [Lex] For kids in the audience.

2023
01:07:29,415 --> 01:07:30,988
- You used to have to watch an image load

2024
01:07:30,988 --> 01:07:32,320
like a line at the time.

2025
01:07:32,320 --> 01:07:34,404
But it turns out there was this thing with JPEGs

2026
01:07:34,404 --> 01:07:36,083
where you could load basically every fourth,

2027
01:07:36,083 --> 01:07:37,770
you could load like every fourth line

2028
01:07:37,770 --> 01:07:40,268
and then you could sweep back through again.

2029
01:07:40,268 --> 01:07:42,351
And so you could like render a fuzzy version

2030
01:07:42,351 --> 01:07:43,184
of image up front.

2031
01:07:43,184 --> 01:07:45,087
And then it would like resolve into the detailed one.

2032
01:07:45,087 --> 01:07:47,111
And that was like a big UI breakthrough

2033
01:07:47,111 --> 01:07:49,449
'cause it gave you something to watch.

2034
01:07:49,449 --> 01:07:50,982
- Yeah. And you know,

2035
01:07:50,982 --> 01:07:55,628
there's applications in various domains for that.

2036
01:07:55,628 --> 01:07:57,081
- Well it was a big fight.

2037
01:07:57,081 --> 01:07:58,350
There was a big fight early on about whether there should be

2038
01:07:58,350 --> 01:08:00,013
images in the web. And.

2039
01:08:00,013 --> 01:08:02,638
- For that reason for like sexualization or--

2040
01:08:02,638 --> 01:08:04,404
- Not explicitly that that did come up.

2041
01:08:04,404 --> 01:08:05,237
But it wasn't even that,

2042
01:08:05,237 --> 01:08:07,190
it was more just like all the serious in the argument went,

2043
01:08:07,190 --> 01:08:09,306
the purists basically said all the serious information

2044
01:08:09,306 --> 01:08:10,440
in the world is text.

2045
01:08:10,440 --> 01:08:12,016
If you introduce images,

2046
01:08:12,016 --> 01:08:14,206
you basically are gonna bring in all the trivial stuff.

2047
01:08:14,206 --> 01:08:15,616
You're gonna bring in magazines and you know,

2048
01:08:15,616 --> 01:08:17,618
all this crazy just, you know, stuff that, you know, people,

2049
01:08:17,618 --> 01:08:19,298
you know, it's gonna, it is gonna distract from that.

2050
01:08:19,298 --> 01:08:20,165
It's gonna go

2051
01:08:20,165 --> 01:08:21,969
take it away from being serious to being frivolous.

2052
01:08:21,969 --> 01:08:24,073
- Well, was there any (indistinct) type arguments

2053
01:08:24,073 --> 01:08:26,233
about the internet

2054
01:08:26,233 --> 01:08:28,992
destroying all of human civilization or destroying some

2055
01:08:28,992 --> 01:08:32,460
fundamental fabric of human civilization?

2056
01:08:32,460 --> 01:08:33,752
- So it was, those days it was

2057
01:08:33,752 --> 01:08:36,060
all around crime and terrorism.

2058
01:08:36,060 --> 01:08:38,350
So those arguments happened, you know,

2059
01:08:38,350 --> 01:08:40,415
but there was no sense yet of the internet having like,

2060
01:08:40,415 --> 01:08:43,270
an effect on politics because that was way too, too far off.

2061
01:08:43,270 --> 01:08:44,772
But there was an enormous panic

2062
01:08:44,772 --> 01:08:46,884
at the time around cybercrime.

2063
01:08:46,884 --> 01:08:48,877
There was like enormous panic that like your credit card

2064
01:08:48,877 --> 01:08:49,819
number would get stolen

2065
01:08:49,819 --> 01:08:51,682
and you'd use life savings would be drained.

2066
01:08:51,682 --> 01:08:53,184
And then, you know, criminals were gonna,

2067
01:08:53,184 --> 01:08:55,339
there was, oh, when we started, one of the things we did,

2068
01:08:55,339 --> 01:08:58,120
one of the Netscape browser was the first widely used piece

2069
01:08:58,120 --> 01:09:00,981
of consumer software that had strong encryption built in,

2070
01:09:00,981 --> 01:09:03,341
it made it available to ordinary people.

2071
01:09:03,341 --> 01:09:04,174
And at that time,

2072
01:09:04,174 --> 01:09:06,425
strong encryption was actually illegal to export

2073
01:09:06,425 --> 01:09:08,962
outta the US so we could feel that product

2074
01:09:08,962 --> 01:09:10,194
in the US, we could not export it

2075
01:09:10,194 --> 01:09:12,374
'cause it was classified as munition.

2076
01:09:12,374 --> 01:09:15,082
So the Netscape browser was on a restricted list

2077
01:09:15,082 --> 01:09:16,359
along with the tomahawk missile

2078
01:09:16,359 --> 01:09:18,533
as being something that could not be exported.

2079
01:09:18,533 --> 01:09:20,783
So we had to make a second version with deliberately weak

2080
01:09:20,783 --> 01:09:23,078
encryption to sell overseas with a big logo

2081
01:09:23,078 --> 01:09:24,462
on the box saying, do not trust this.

2082
01:09:24,462 --> 01:09:25,674
Which it turns out,

2083
01:09:25,674 --> 01:09:28,688
makes it hard to sell software when it's got a big logo

2084
01:09:28,688 --> 01:09:29,929
that says don't trust it.

2085
01:09:29,929 --> 01:09:32,004
And then we had to spend five years fighting

2086
01:09:32,004 --> 01:09:34,103
the US government to get them to basically stop trying

2087
01:09:34,103 --> 01:09:35,935
to do this regulation.

2088
01:09:35,935 --> 01:09:37,636
But because the fear was terrorists are gonna

2089
01:09:37,636 --> 01:09:38,951
use encryption, right?

2090
01:09:38,951 --> 01:09:41,611
To like plot, you know, all these things.

2091
01:09:41,611 --> 01:09:43,781
And then, you know, we responded with,

2092
01:09:43,781 --> 01:09:45,553
well actually we need encryption to be able

2093
01:09:45,553 --> 01:09:47,551
to secure systems so that the terrorists

2094
01:09:47,551 --> 01:09:48,924
and the criminals can't get into them.

2095
01:09:48,924 --> 01:09:51,004
So that anyway, that was the 1990s fight.

2096
01:09:51,004 --> 01:09:53,881
- So can you say something about some of the details

2097
01:09:53,881 --> 01:09:56,638
of the software engineering challenges required

2098
01:09:56,638 --> 01:09:57,996
to build these browsers?

2099
01:09:57,996 --> 01:10:00,978
I mean the engineering challenges of creating a product

2100
01:10:00,978 --> 01:10:02,272
that hasn't really existed

2101
01:10:02,272 --> 01:10:06,772
before that can have such almost like limitless impact

2102
01:10:08,032 --> 01:10:10,082
on the world with the internet.

2103
01:10:10,082 --> 01:10:12,291
- So there was a really key bet that we made at the time,

2104
01:10:12,291 --> 01:10:13,303
which was very controversial,

2105
01:10:13,303 --> 01:10:15,322
which was core to core to how it was engineered,

2106
01:10:15,322 --> 01:10:16,888
which was are we optimizing for performance

2107
01:10:16,888 --> 01:10:18,692
or for ease of creation?

2108
01:10:18,692 --> 01:10:21,565
And in those days the pressure was very intense to optimize

2109
01:10:21,565 --> 01:10:23,713
for performance because the network connections were so slow

2110
01:10:23,713 --> 01:10:25,709
and also the computers were so slow.

2111
01:10:25,709 --> 01:10:29,396
And so if you had, I mentioned the progressive JPEGs,

2112
01:10:29,396 --> 01:10:32,767
like if there's an alternate world in which we optimized

2113
01:10:32,767 --> 01:10:34,529
for performance and it just,

2114
01:10:34,529 --> 01:10:37,115
you had just a much more pleasant experience right up front.

2115
01:10:37,115 --> 01:10:39,191
But what we got by not doing

2116
01:10:39,191 --> 01:10:40,995
that was we got ease of creation.

2117
01:10:40,995 --> 01:10:42,584
And the way that we got ease of creation was

2118
01:10:42,584 --> 01:10:45,728
all of the protocols and formats were in text,

2119
01:10:45,728 --> 01:10:47,085
not in binary.

2120
01:10:47,085 --> 01:10:49,838
And so HTTP is in text, by the way.

2121
01:10:49,838 --> 01:10:51,779
And this was an internet tradition by the way

2122
01:10:51,779 --> 01:10:52,612
that we picked up.

2123
01:10:52,612 --> 01:10:53,445
But we continued it.

2124
01:10:53,445 --> 01:10:56,181
HTTP is text and HTML is text, and then every else,

2125
01:10:56,181 --> 01:10:58,733
everything else that followed is text as a result.

2126
01:10:58,733 --> 01:10:59,698
And by the way,

2127
01:10:59,698 --> 01:11:01,943
you can imagine purist engineers saying this is insane.

2128
01:11:01,943 --> 01:11:03,147
You have very limited bandwidth.

2129
01:11:03,147 --> 01:11:05,016
Why are you wasting any time sending text?

2130
01:11:05,016 --> 01:11:06,447
You should be encoding this stuff into binary

2131
01:11:06,447 --> 01:11:07,632
and it'll be much faster.

2132
01:11:07,632 --> 01:11:09,400
And of course the answer is that's correct.

2133
01:11:09,400 --> 01:11:11,776
But what you get when you make it taxed is all of a sudden,

2134
01:11:11,776 --> 01:11:12,800
well, the big breakthrough was

2135
01:11:12,800 --> 01:11:14,298
the view source function, right?

2136
01:11:14,298 --> 01:11:15,746
So the fact that you could look at a webpage,

2137
01:11:15,746 --> 01:11:17,936
you could hit view source and you could see the HTML,

2138
01:11:17,936 --> 01:11:20,734
that was how people learned how to make webpages. Right?

2139
01:11:20,734 --> 01:11:21,604
- It's so interesting

2140
01:11:21,604 --> 01:11:26,293
'cause the stuff would take for granted now is,

2141
01:11:26,293 --> 01:11:27,271
man, that was fundamental,

2142
01:11:27,271 --> 01:11:29,057
the development of the web to be able to have HTML

2143
01:11:29,057 --> 01:11:32,615
just right there, all the ghetto mess that is HTML,

2144
01:11:32,615 --> 01:11:37,282
all the sort of almost biological like messiness of HTML

2145
01:11:38,479 --> 01:11:41,562
and then having the browser try to interpret that as.

2146
01:11:41,562 --> 01:11:42,416
- [Marc] Exactly.

2147
01:11:42,416 --> 01:11:44,117
- To show something reasonable.

2148
01:11:44,117 --> 01:11:45,720
- Well and then there was this internet principle

2149
01:11:45,720 --> 01:11:47,856
that we inherited, which was emit, what was it?

2150
01:11:47,856 --> 01:11:50,713
Emit cautiously. Emit conservatively interpret liberally.

2151
01:11:50,713 --> 01:11:51,811
So it basically meant

2152
01:11:51,811 --> 01:11:53,217
if you're, the design principle was

2153
01:11:53,217 --> 01:11:55,320
if you're creating like a web editor

2154
01:11:55,320 --> 01:11:57,743
that's gonna admit HTML, like do it as cleanly as you can,

2155
01:11:57,743 --> 01:12:00,149
but you actually want the browser to interpret liberally,

2156
01:12:00,149 --> 01:12:02,134
which is you actually want users to be able to make all

2157
01:12:02,134 --> 01:12:04,126
kinds of mistakes and for it to still work.

2158
01:12:04,126 --> 01:12:07,004
And so the browser rendering engines to this day have

2159
01:12:07,004 --> 01:12:08,708
all of this spaghetti code crazy stuff

2160
01:12:08,708 --> 01:12:11,664
where they're resilient to all kinds of crazy issue,

2161
01:12:11,664 --> 01:12:12,513
no mistakes.

2162
01:12:12,513 --> 01:12:14,724
And so, literally what I always had in my head is like

2163
01:12:14,724 --> 01:12:16,590
there's an 8 year old or an 11 year old somewhere

2164
01:12:16,590 --> 01:12:17,533
and they're doing a view source,

2165
01:12:17,533 --> 01:12:18,749
they're doing a cut and paste and they're trying

2166
01:12:18,749 --> 01:12:20,990
to make a webpage for their eternal or whatever.

2167
01:12:20,990 --> 01:12:23,041
And like they leave out a slash and they leave out

2168
01:12:23,041 --> 01:12:24,285
an angle bracket and they do this

2169
01:12:24,285 --> 01:12:25,908
and they do that and it's still works.

2170
01:12:25,908 --> 01:12:27,120
- It's also like a,

2171
01:12:27,120 --> 01:12:30,020
I don't often think about this, but, you know, programming,

2172
01:12:30,020 --> 01:12:32,375
you know, C++ all those languages,

2173
01:12:32,375 --> 01:12:35,095
lisp, the compiled languages, the interpreted languages,

2174
01:12:35,095 --> 01:12:37,404
Python, Pearl, all that.

2175
01:12:37,404 --> 01:12:39,981
The brace have to be all correct.

2176
01:12:39,981 --> 01:12:41,881
It's like everything has to be perfect.

2177
01:12:41,881 --> 01:12:42,714
- [Marc] Brutal.

2178
01:12:42,714 --> 01:12:43,547
- And then--

2179
01:12:43,547 --> 01:12:44,380
- [Marc] Autistic.

2180
01:12:44,380 --> 01:12:45,407
- You forget.

2181
01:12:45,407 --> 01:12:49,125
All right. It's systematic and rigorous, let's go there.

2182
01:12:49,125 --> 01:12:51,125
But you forget that the,

2183
01:12:53,323 --> 01:12:56,240
the web with JavaScript eventually.

2184
01:12:57,111 --> 01:13:00,170
And HTML is allowed to be messy in the way

2185
01:13:00,170 --> 01:13:01,753
for the first time.

2186
01:13:03,287 --> 01:13:06,354
Messy in the way biological systems could be messy.

2187
01:13:06,354 --> 01:13:08,508
It's like the only thing computers were allowed

2188
01:13:08,508 --> 01:13:10,456
to be messy on for the first time.

2189
01:13:10,456 --> 01:13:11,416
- It used to off fend me.

2190
01:13:11,416 --> 01:13:12,530
So I grew up on Unix,

2191
01:13:12,530 --> 01:13:13,832
so I worked on Unix.

2192
01:13:13,832 --> 01:13:16,110
I was a Unix native for all the way through this period.

2193
01:13:16,110 --> 01:13:18,300
And so, it used to drive me bananas when it would do

2194
01:13:18,300 --> 01:13:20,442
the segmentation fault and the core dump file,

2195
01:13:20,442 --> 01:13:22,008
just like it is, you know,

2196
01:13:22,008 --> 01:13:24,203
it's like literally there's like a error in the code.

2197
01:13:24,203 --> 01:13:25,265
The math is off by one.

2198
01:13:25,265 --> 01:13:26,915
And it core dumps.

2199
01:13:26,915 --> 01:13:28,959
And I'm in the core dump trying to analyze it and trying

2200
01:13:28,959 --> 01:13:30,960
to reconstruct what, and I'm just like, this is ridiculous.

2201
01:13:30,960 --> 01:13:32,415
Like, the computer ought to be smart enough

2202
01:13:32,415 --> 01:13:33,248
to be able to know

2203
01:13:33,248 --> 01:13:34,648
that if it's off by one, okay fine.

2204
01:13:34,648 --> 01:13:35,481
And it keeps running.

2205
01:13:35,481 --> 01:13:37,386
And I would go ask all the experts like,

2206
01:13:37,386 --> 01:13:38,405
why can't it just keep running?

2207
01:13:38,405 --> 01:13:39,420
And they'd explain to me, well,

2208
01:13:39,420 --> 01:13:41,300
because all the downstream repercussions and blah blah.

2209
01:13:41,300 --> 01:13:43,908
And I'm like, this still, like, you know, this is,

2210
01:13:43,908 --> 01:13:47,987
we're forcing the human creator to live to your point

2211
01:13:47,987 --> 01:13:50,647
in this hyper, literal world of perfection.

2212
01:13:50,647 --> 01:13:51,686
- [Lex] Yeah.

2213
01:13:51,686 --> 01:13:53,966
And I was just like, that's just bad.

2214
01:13:53,966 --> 01:13:54,799
And by the way,

2215
01:13:54,799 --> 01:13:55,708
you know what happens with that of course.

2216
01:13:55,708 --> 01:13:57,477
Just what what happened with, with coding at that point,

2217
01:13:57,477 --> 01:13:59,507
which is you get a high priesthood, you know,

2218
01:13:59,507 --> 01:14:01,127
there's a small number of people who are really good

2219
01:14:01,127 --> 01:14:02,311
at doing exactly that.

2220
01:14:02,311 --> 01:14:03,316
Most people can't.

2221
01:14:03,316 --> 01:14:04,745
And most people are excluded from it.

2222
01:14:04,745 --> 01:14:05,840
And so actually that was

2223
01:14:05,840 --> 01:14:07,322
where that for that was where I picked up

2224
01:14:07,322 --> 01:14:08,899
that idea was like, no,

2225
01:14:08,899 --> 01:14:11,607
you want these things to be resilient error in all kinds

2226
01:14:11,607 --> 01:14:14,301
and this would drive the purist absolutely crazy.

2227
01:14:14,301 --> 01:14:16,417
Like, I got attacked on this like a lot

2228
01:14:16,417 --> 01:14:18,292
'cause I mean like every time you know,

2229
01:14:18,292 --> 01:14:19,780
all the purists who were like into all this

2230
01:14:19,780 --> 01:14:21,723
like Marcup language stuff and formats

2231
01:14:21,723 --> 01:14:22,900
and codes and all this stuff,

2232
01:14:22,900 --> 01:14:23,921
they would be like, you know,

2233
01:14:23,921 --> 01:14:25,317
you're encouraging bad behavior 'cause.

2234
01:14:25,317 --> 01:14:27,201
- Oh, so they wanted the browser to give you

2235
01:14:27,201 --> 01:14:30,420
a fault error anytime there was a--

2236
01:14:30,420 --> 01:14:32,644
- Yeah. They wanted to be a (indistinct) right?

2237
01:14:32,644 --> 01:14:33,544
They wanted to--

2238
01:14:33,544 --> 01:14:34,377
Yeah. Yeah.

2239
01:14:34,377 --> 01:14:35,716
That was a very and any properly

2240
01:14:35,716 --> 01:14:38,035
trained credential engineer would be like,

2241
01:14:38,035 --> 01:14:39,567
that's not how you build these systems.

2242
01:14:39,567 --> 01:14:40,898
- That's such a bold move to say,

2243
01:14:40,898 --> 01:14:42,045
no, it doesn't have to be.

2244
01:14:42,045 --> 01:14:42,959
- Yeah. No, like I said,

2245
01:14:42,959 --> 01:14:44,334
the good news for me is the internet kind of had

2246
01:14:44,334 --> 01:14:46,020
that traditional already, but having said that,

2247
01:14:46,020 --> 01:14:48,088
like we pushed it, we pushed it way out.

2248
01:14:48,088 --> 01:14:49,246
But the other thing we did,

2249
01:14:49,246 --> 01:14:50,531
going back to the performance thing,

2250
01:14:50,531 --> 01:14:51,874
was we gave up a lot of performance.

2251
01:14:51,874 --> 01:14:52,953
We made that, that initial experience

2252
01:14:52,953 --> 01:14:54,787
for the first few years was pretty painful.

2253
01:14:54,787 --> 01:14:56,518
But the bet there was actually an economic bet,

2254
01:14:56,518 --> 01:14:58,884
which was basically the demand for the web would basically

2255
01:14:58,884 --> 01:15:01,239
mean that there would be a surge in supply of broadband.

2256
01:15:01,239 --> 01:15:04,037
Like because the question was, okay,

2257
01:15:04,037 --> 01:15:07,715
how do you get the phone companies which are not famous

2258
01:15:07,715 --> 01:15:10,617
in those days for doing new things at huge cost

2259
01:15:10,617 --> 01:15:12,334
for like speculative reasons.

2260
01:15:12,334 --> 01:15:14,689
Like how do you get them to build up broadband, you know,

2261
01:15:14,689 --> 01:15:16,734
spend billions of dollars doing that and you know,

2262
01:15:16,734 --> 01:15:19,284
you could go meet with them and try to talk them into it.

2263
01:15:19,284 --> 01:15:20,441
Or you could just have a thing

2264
01:15:20,441 --> 01:15:22,135
where it's just very clear that it's gonna be,

2265
01:15:22,135 --> 01:15:24,363
that people love that's gonna be better if it's faster.

2266
01:15:24,363 --> 01:15:26,788
And, so that, there was a period there and this was,

2267
01:15:26,788 --> 01:15:27,946
this was fraught with in peril,

2268
01:15:27,946 --> 01:15:29,852
but there was a period there where it's like we knew

2269
01:15:29,852 --> 01:15:31,154
the experience was sub-optimized

2270
01:15:31,154 --> 01:15:32,873
because we were trying to force

2271
01:15:32,873 --> 01:15:35,181
the emergence of demand for broadband.

2272
01:15:35,181 --> 01:15:36,014
- [Lex] Sure.

2273
01:15:36,014 --> 01:15:36,982
- Which is in fact what happened.

2274
01:15:36,982 --> 01:15:40,310
- So you had to figure out how to display this text,

2275
01:15:40,310 --> 01:15:41,661
HTML text.

2276
01:15:41,661 --> 01:15:44,141
So the blue links and the prop links. What?

2277
01:15:44,141 --> 01:15:47,763
And there's no standards. Is there standards at that time?

2278
01:15:47,763 --> 01:15:49,875
- [Marc] No. There really still isn't.

2279
01:15:49,875 --> 01:15:51,420
- Well there's like standards,

2280
01:15:51,420 --> 01:15:54,585
there's applied, implied standards. Right.

2281
01:15:54,585 --> 01:15:55,678
And they, you know,

2282
01:15:55,678 --> 01:15:57,042
there's all these kind of new features

2283
01:15:57,042 --> 01:15:58,682
that are being added with like CSS, what,

2284
01:15:58,682 --> 01:16:01,303
like what kind of stuff a browser should be able to support

2285
01:16:01,303 --> 01:16:04,577
features within languages, within JavaScript and so on.

2286
01:16:04,577 --> 01:16:08,660
But you're setting standards on the fly yourself.

2287
01:16:11,231 --> 01:16:12,605
- Yeah. Well to this day,

2288
01:16:12,605 --> 01:16:15,842
if you create a webpage that has no CSS style sheet,

2289
01:16:15,842 --> 01:16:18,352
the browser will render it however it wants to.

2290
01:16:18,352 --> 01:16:20,708
Right. So this was one of the things, there was this idea,

2291
01:16:20,708 --> 01:16:22,964
this idea of at the time and how these systems were built,

2292
01:16:22,964 --> 01:16:24,535
which is separation of content from format

2293
01:16:24,535 --> 01:16:27,952
or separation of content from appearance.

2294
01:16:28,871 --> 01:16:31,210
And that's still, people don't really use that anymore

2295
01:16:31,210 --> 01:16:32,786
'cause everybody wants to determine how things look

2296
01:16:32,786 --> 01:16:35,150
and so they use CSS but it's still in there

2297
01:16:35,150 --> 01:16:37,574
that you can just let the browser do all the work.

2298
01:16:37,574 --> 01:16:41,407
- I still like the like really basic websites,

2299
01:16:42,338 --> 01:16:44,372
but that could be just old school,

2300
01:16:44,372 --> 01:16:47,923
kids these days with their fancy responsive websites

2301
01:16:47,923 --> 01:16:49,739
that don't actually have much content,

2302
01:16:49,739 --> 01:16:51,428
but have a lot of visual elements.

2303
01:16:51,428 --> 01:16:52,947
- Well that's one of the things that's fun about chat,

2304
01:16:52,947 --> 01:16:54,454
you know, about ChatGPT like.

2305
01:16:54,454 --> 01:16:56,069
- [Lex] Back to the basics.

2306
01:16:56,069 --> 01:16:56,959
- Back to just text.

2307
01:16:56,959 --> 01:16:58,008
- [Lex] Yeah.

2308
01:16:58,008 --> 01:16:58,902
- Right? And it, you know,

2309
01:16:58,902 --> 01:17:01,962
there is this pattern in human creativity and media

2310
01:17:01,962 --> 01:17:04,875
where you end up back at text and I think there's, you know,

2311
01:17:04,875 --> 01:17:06,316
there's something powerful in there.

2312
01:17:06,316 --> 01:17:07,439
- Is there some other stuff

2313
01:17:07,439 --> 01:17:09,013
you remember like the purple links?

2314
01:17:09,013 --> 01:17:10,713
There were some interesting design decisions

2315
01:17:10,713 --> 01:17:13,543
that to kind of come up that we have today

2316
01:17:13,543 --> 01:17:16,835
or we don't have today that were temporary.

2317
01:17:16,835 --> 01:17:19,408
- So I made the background 'cause I hated reading texts

2318
01:17:19,408 --> 01:17:22,597
on white background, so I made the background gray.

2319
01:17:22,597 --> 01:17:23,663
Everybody can--

2320
01:17:23,663 --> 01:17:25,413
- Do you go ahead to?

2321
01:17:25,413 --> 01:17:26,246
- No. No, no.

2322
01:17:26,246 --> 01:17:28,074
That decision I think has been reversed.

2323
01:17:28,074 --> 01:17:30,794
But now I'm happy though because now dark mode is the thing.

2324
01:17:30,794 --> 01:17:33,053
- So it wasn't about gray,

2325
01:17:33,053 --> 01:17:34,934
it was just you didn't want white background.

2326
01:17:34,934 --> 01:17:36,253
- [Marc] Strain my eyes.

2327
01:17:36,253 --> 01:17:39,680
- Strain your eyes. Interesting.

2328
01:17:39,680 --> 01:17:42,162
And then there's a bunch of other decisions.

2329
01:17:42,162 --> 01:17:44,122
I'm sure there's an interesting history of the development

2330
01:17:44,122 --> 01:17:47,686
of HTML and CSS and Interface and JavaScript

2331
01:17:47,686 --> 01:17:51,587
and there's this whole Java applet thing.

2332
01:17:51,587 --> 01:17:54,588
- Well the big one probably JavaScript, CSS was after me,

2333
01:17:54,588 --> 01:17:55,641
so I didn't, that was not me.

2334
01:17:55,641 --> 01:17:57,135
But JavaScript was the big,

2335
01:17:57,135 --> 01:17:59,394
JavaScript maybe was the biggest of the whole thing.

2336
01:17:59,394 --> 01:18:00,227
That was us.

2337
01:18:00,227 --> 01:18:03,834
And that was basically a bet, it was a bet on two things.

2338
01:18:03,834 --> 01:18:05,105
One is that the world wanted

2339
01:18:05,105 --> 01:18:07,135
a new front end scripting language.

2340
01:18:07,135 --> 01:18:08,317
And then the other was

2341
01:18:08,317 --> 01:18:09,513
I thought at the time the world wanted

2342
01:18:09,513 --> 01:18:11,275
a new backend scripting language.

2343
01:18:11,275 --> 01:18:13,391
So JavaScript was designed from the beginning

2344
01:18:13,391 --> 01:18:15,254
to be both front end and backend.

2345
01:18:15,254 --> 01:18:17,775
And then it failed as a backend scripting language.

2346
01:18:17,775 --> 01:18:20,018
And Java won for a long time.

2347
01:18:20,018 --> 01:18:22,754
And then Python Pearl and other things, PHP and Ruby.

2348
01:18:22,754 --> 01:18:26,005
But now JavaScript is back. And so.

2349
01:18:26,005 --> 01:18:28,651
- I wonder if everything in the end will run on JavaScript.

2350
01:18:28,651 --> 01:18:31,009
- It seems like it is the, and by the way,

2351
01:18:31,009 --> 01:18:34,734
lemme give a shout out to, to Brendan Eich was

2352
01:18:34,734 --> 01:18:38,095
basically the one man inventor of of JavaScript.

2353
01:18:38,095 --> 01:18:40,410
- If you're interested to learn more about Brendan Eich,

2354
01:18:40,410 --> 01:18:42,509
he's been on his podcast previously.

2355
01:18:42,509 --> 01:18:44,598
- Exactly. So he wrote JavaScript over a summer

2356
01:18:44,598 --> 01:18:46,906
and I mean I think it is fair,

2357
01:18:46,906 --> 01:18:48,850
it is fair to say now that it's the most widely used

2358
01:18:48,850 --> 01:18:50,820
language in the world and it seems to only be gaining

2359
01:18:50,820 --> 01:18:53,560
in its in its range of adoption.

2360
01:18:53,560 --> 01:18:55,143
- You know, in the software world

2361
01:18:55,143 --> 01:18:56,577
there's quite a few stories of somebody

2362
01:18:56,577 --> 01:19:00,559
over a week weekend or over a week or over a summer writing

2363
01:19:00,559 --> 01:19:04,213
some of the most impactful revolutionary pieces

2364
01:19:04,213 --> 01:19:07,879
of software ever. That should be inspiring. Yes.

2365
01:19:07,879 --> 01:19:09,428
- Very inspiring. I'll give you another one.

2366
01:19:09,428 --> 01:19:12,785
SSL. So SSL with the security protocol, that was us.

2367
01:19:12,785 --> 01:19:14,536
And that was a crazy idea at the time,

2368
01:19:14,536 --> 01:19:16,129
which was let's take all the native protocols

2369
01:19:16,129 --> 01:19:17,785
and let's wrap them in a security wrapper.

2370
01:19:17,785 --> 01:19:19,420
That was a guy named Kip Hickman who wrote

2371
01:19:19,420 --> 01:19:21,272
that over a summer, one guy.

2372
01:19:21,272 --> 01:19:24,087
And then look today, sitting here today,

2373
01:19:24,087 --> 01:19:25,969
like the transformer like at Google was

2374
01:19:25,969 --> 01:19:27,204
a small handful of people.

2375
01:19:27,204 --> 01:19:28,463
And then, you know,

2376
01:19:28,463 --> 01:19:31,710
the number of people who have did like the core work on GPT.

2377
01:19:31,710 --> 01:19:33,347
It's not that many people,

2378
01:19:33,347 --> 01:19:35,015
it's a pretty small handful of people.

2379
01:19:35,015 --> 01:19:36,018
And so yeah,

2380
01:19:36,018 --> 01:19:37,694
the pattern in software repeatedly

2381
01:19:37,694 --> 01:19:39,566
over a very long time has been,

2382
01:19:39,566 --> 01:19:42,647
it's Jeff Bezos always had the two pizza rule

2383
01:19:42,647 --> 01:19:44,127
for teams at Amazon,

2384
01:19:44,127 --> 01:19:46,332
which is any team needs to be able to be fed

2385
01:19:46,332 --> 01:19:47,462
with two pieces.

2386
01:19:47,462 --> 01:19:49,244
If you need the third pizza, you have too many people.

2387
01:19:49,244 --> 01:19:53,175
And I think it's actually the one pizza rule.

2388
01:19:53,175 --> 01:19:55,064
For the really creative work.

2389
01:19:55,064 --> 01:19:57,655
I think it's two people, three people.

2390
01:19:57,655 --> 01:19:58,951
- Well that's, you see that

2391
01:19:58,951 --> 01:20:00,393
with certain open source projects,

2392
01:20:00,393 --> 01:20:02,761
like so much is done by like one or two people.

2393
01:20:02,761 --> 01:20:04,948
Like it's so incredible and that's why you see

2394
01:20:04,948 --> 01:20:08,447
that gives me so much hope about the open source movement

2395
01:20:08,447 --> 01:20:12,287
in this new age of AI where, you know,

2396
01:20:12,287 --> 01:20:14,144
just recently having had a conversation

2397
01:20:14,144 --> 01:20:16,093
with Marc Zuckerberg of all people

2398
01:20:16,093 --> 01:20:17,973
who's all in on open source,

2399
01:20:17,973 --> 01:20:22,151
which is so interesting to see and so inspiring to see

2400
01:20:22,151 --> 01:20:25,224
'cause like releasing these models, it is scary.

2401
01:20:25,224 --> 01:20:28,679
It is potentially very dangerous and we'll talk about that.

2402
01:20:28,679 --> 01:20:30,435
But it's also,

2403
01:20:30,435 --> 01:20:33,799
if you believe in the goodness of most people

2404
01:20:33,799 --> 01:20:36,076
and in the skillset of most people

2405
01:20:36,076 --> 01:20:38,311
and the desire to go do good in the world,

2406
01:20:38,311 --> 01:20:39,558
that's really exciting.

2407
01:20:39,558 --> 01:20:41,654
'cause it's not putting it these models

2408
01:20:41,654 --> 01:20:44,145
into the centralized control of big corporations,

2409
01:20:44,145 --> 01:20:45,344
the government and so on.

2410
01:20:45,344 --> 01:20:47,744
It's putting it in the hands of a teen,

2411
01:20:47,744 --> 01:20:50,056
teenage kid with like a dream in his eyes.

2412
01:20:50,056 --> 01:20:52,639
I don't know. That's beautiful.

2413
01:20:53,518 --> 01:20:54,488
- Look, this stuff,

2414
01:20:54,488 --> 01:20:56,669
AI ought to make the individual coder obviously

2415
01:20:56,669 --> 01:20:58,128
far more productive right?

2416
01:20:58,128 --> 01:20:59,833
By like, you know, a thousand X or something.

2417
01:20:59,833 --> 01:21:02,368
And so you ought to open source like,

2418
01:21:02,368 --> 01:21:04,265
not just the future of open source AI,

2419
01:21:04,265 --> 01:21:06,143
but the future of open source everything.

2420
01:21:06,143 --> 01:21:08,145
We ought to have a world now of super coders, right?

2421
01:21:08,145 --> 01:21:10,177
Who are building things as open source

2422
01:21:10,177 --> 01:21:12,357
with one or two people that were inconceivable,

2423
01:21:12,357 --> 01:21:14,010
you know, five years ago.

2424
01:21:14,010 --> 01:21:16,108
You know, the level of kind of hyper productivity

2425
01:21:16,108 --> 01:21:17,547
we're gonna get out of our best and brightest

2426
01:21:17,547 --> 01:21:18,764
I think is gonna go way up.

2427
01:21:18,764 --> 01:21:19,726
- It's gonna be interesting.

2428
01:21:19,726 --> 01:21:20,559
We'll talk about it,

2429
01:21:20,559 --> 01:21:24,130
but let's just to linger a little bit on Netscape.

2430
01:21:24,130 --> 01:21:28,547
Netscape was acquired in 1999 for 4.3 billion by AOL.

2431
01:21:29,627 --> 01:21:31,735
What was that like?

2432
01:21:31,735 --> 01:21:34,394
What were some memorable aspects of that?

2433
01:21:34,394 --> 01:21:37,800
- Well that was the height of the.com boom bubble bust.

2434
01:21:37,800 --> 01:21:40,034
I mean that was the frenzy.

2435
01:21:40,034 --> 01:21:41,182
If you watch succession,

2436
01:21:41,182 --> 01:21:43,581
that was like what they did in the fourth season

2437
01:21:43,581 --> 01:21:45,710
with Gojo and the merger with their,

2438
01:21:45,710 --> 01:21:47,706
so it was like the height of like one

2439
01:21:47,706 --> 01:21:49,432
of those kind of dynamics. And so.

2440
01:21:49,432 --> 01:21:51,804
- Would you recommend succession, by the way?

2441
01:21:51,804 --> 01:21:53,758
I'm more of a Yellowstone guy.

2442
01:21:53,758 --> 01:21:55,149
- Yellowstone's very American.

2443
01:21:55,149 --> 01:21:57,665
I'm very proud of you. That's, that is.

2444
01:21:57,665 --> 01:21:59,431
- I just talked to Matthew McConaughey

2445
01:21:59,431 --> 01:22:01,749
and I'm full on Texan at this point.

2446
01:22:01,749 --> 01:22:02,582
- Good. I approve.

2447
01:22:02,582 --> 01:22:06,376
- And he'll be doing the SQL to Yellowstone.

2448
01:22:06,376 --> 01:22:07,799
- [Marc] Yeah, just exciting.

2449
01:22:07,799 --> 01:22:08,632
- Very exciting. Anyway.

2450
01:22:08,632 --> 01:22:09,738
- [Marc] Can't wait.

2451
01:22:09,738 --> 01:22:14,655
- So that's a rude interruption by me by way of succession.

2452
01:22:15,697 --> 01:22:17,895
So, that was at the height of the--

2453
01:22:17,895 --> 01:22:20,585
- Deal making and money and just the fur flying

2454
01:22:20,585 --> 01:22:21,737
and like craziness.

2455
01:22:21,737 --> 01:22:23,731
And so yeah, it was just one of those,

2456
01:22:23,731 --> 01:22:24,919
it was just like, I mean, and this,

2457
01:22:24,919 --> 01:22:25,752
the entire (indistinct) thing

2458
01:22:25,752 --> 01:22:27,226
from start to finish was four years,

2459
01:22:27,226 --> 01:22:29,497
which was like for one of these companies,

2460
01:22:29,497 --> 01:22:30,823
it's just like incredibly fast.

2461
01:22:30,823 --> 01:22:31,804
You know, it went,

2462
01:22:31,804 --> 01:22:33,472
we went public 18 months after we got moved

2463
01:22:33,472 --> 01:22:35,534
where we were founded, which virtually never happens.

2464
01:22:35,534 --> 01:22:37,290
So it was just this incredibly fast

2465
01:22:37,290 --> 01:22:39,408
kind of meteor streaking across the sky.

2466
01:22:39,408 --> 01:22:40,833
And then of course it was this,

2467
01:22:40,833 --> 01:22:42,478
and then there was just this explosion, right?

2468
01:22:42,478 --> 01:22:44,260
That happened 'cause then it was almost immediately

2469
01:22:44,260 --> 01:22:45,651
followed by the.com crash.

2470
01:22:45,651 --> 01:22:48,655
It was then followed by AOL, by Time Warner,

2471
01:22:48,655 --> 01:22:50,049
which again is like the succession guys

2472
01:22:50,049 --> 01:22:51,303
kinda play with that,

2473
01:22:51,303 --> 01:22:53,463
which turned out to be a disastrous deal.

2474
01:22:53,463 --> 01:22:55,118
You know, one of the famous, you know,

2475
01:22:55,118 --> 01:22:56,445
kind of disastrous in business history.

2476
01:22:56,445 --> 01:22:58,639
And then, you know, what became

2477
01:22:58,639 --> 01:23:01,091
an internet depression on the other side of that.

2478
01:23:01,091 --> 01:23:02,836
But then in that depression in the two thousands was

2479
01:23:02,836 --> 01:23:04,317
the beginning of broadband

2480
01:23:04,317 --> 01:23:07,086
and smartphones and Web 2.0 right?

2481
01:23:07,086 --> 01:23:09,602
And then social media and search and every SaaS

2482
01:23:09,602 --> 01:23:10,717
and everything that came out of that.

2483
01:23:10,717 --> 01:23:13,146
- What did you learn from just the acquisition?

2484
01:23:13,146 --> 01:23:15,238
I mean this is so much money.

2485
01:23:15,238 --> 01:23:19,854
What's interesting 'cause I must have been very new to you,

2486
01:23:19,854 --> 01:23:22,021
that these software stuff,

2487
01:23:23,141 --> 01:23:25,206
you can make so much money.

2488
01:23:25,206 --> 01:23:26,947
There's so much money swimming around.

2489
01:23:26,947 --> 01:23:28,533
I mean, I'm sure the ideas of investment was

2490
01:23:28,533 --> 01:23:30,400
starting to get born there.

2491
01:23:30,400 --> 01:23:31,948
- Yes. Let me get, so let me lay it.

2492
01:23:31,948 --> 01:23:33,196
So here's, here's the thing.

2493
01:23:33,196 --> 01:23:35,121
I dunno if I figured it out then, but figured it out later,

2494
01:23:35,121 --> 01:23:37,849
which is software is a technology that it,

2495
01:23:37,849 --> 01:23:40,235
it's like a, you know, the concept of the philosopher stone,

2496
01:23:40,235 --> 01:23:41,577
the philosopher stone in alchemy,

2497
01:23:41,577 --> 01:23:43,619
transient is led into gold and Newton spent 20 years trying

2498
01:23:43,619 --> 01:23:44,948
to find the philosopher stone.

2499
01:23:44,948 --> 01:23:45,781
Never got there.

2500
01:23:45,781 --> 01:23:46,970
Nobody's ever figured it out.

2501
01:23:46,970 --> 01:23:48,934
Software is our modern philosopher stone.

2502
01:23:48,934 --> 01:23:53,880
And in economic terms, it transmutes labor into capital,

2503
01:23:53,880 --> 01:23:55,831
which is like a super interesting thing.

2504
01:23:55,831 --> 01:23:57,626
And by the way, like Carl Marcs is rolling

2505
01:23:57,626 --> 01:23:58,568
over in his grave right now.

2506
01:23:58,568 --> 01:24:00,010
'Cause of course that's complete reputation

2507
01:24:00,010 --> 01:24:01,755
of his entire theory.

2508
01:24:01,755 --> 01:24:03,773
Trans labor and capital which is as follows,

2509
01:24:03,773 --> 01:24:07,411
is somebody sits down at a keyboard

2510
01:24:07,411 --> 01:24:09,358
and types a bunch of stuff in,

2511
01:24:09,358 --> 01:24:11,426
and a capital asset comes out the other side

2512
01:24:11,426 --> 01:24:13,241
and then somebody buys that capital asset

2513
01:24:13,241 --> 01:24:14,409
for a billion dollars.

2514
01:24:14,409 --> 01:24:17,082
Like that's amazing, right?

2515
01:24:17,082 --> 01:24:19,285
It's literally creating value right out of thin air,

2516
01:24:19,285 --> 01:24:22,316
right out of purely human thought, right?

2517
01:24:22,316 --> 01:24:24,785
And so that, there are many things

2518
01:24:24,785 --> 01:24:26,612
that make software magical and special,

2519
01:24:26,612 --> 01:24:27,766
but that's the economics.

2520
01:24:27,766 --> 01:24:29,832
- I wonder what Marx would've thought about that?

2521
01:24:29,832 --> 01:24:31,194
- Oh, he would've completely broke his brain

2522
01:24:31,194 --> 01:24:33,797
because of course the whole thing was it was he could,

2523
01:24:33,797 --> 01:24:36,034
you know, that kind of technology was inconceivable

2524
01:24:36,034 --> 01:24:37,216
when he was alive.

2525
01:24:37,216 --> 01:24:38,955
It was all industrial era stuff.

2526
01:24:38,955 --> 01:24:41,795
And so, any kind of machinery necessarily involved

2527
01:24:41,795 --> 01:24:43,277
huge amounts of capital.

2528
01:24:43,277 --> 01:24:44,110
And then labor was

2529
01:24:44,110 --> 01:24:46,181
on the receiving end of the abuse.

2530
01:24:46,181 --> 01:24:47,014
- [Lex] Yep.

2531
01:24:47,014 --> 01:24:48,744
Right? But like software eng software,

2532
01:24:48,744 --> 01:24:51,062
a software engineer is somebody who basically transmutes

2533
01:24:51,062 --> 01:24:52,111
his own labor into actual,

2534
01:24:52,111 --> 01:24:54,776
an actual capital asset creates permanent value.

2535
01:24:54,776 --> 01:24:57,025
Well, and in fact it's actually very inspiring.

2536
01:24:57,025 --> 01:24:58,890
That's actually more true today than before.

2537
01:24:58,890 --> 01:24:59,944
So when I was doing software,

2538
01:24:59,944 --> 01:25:02,012
the assumption was all new software basically has

2539
01:25:02,012 --> 01:25:05,408
a sort of a parabolic sort of lifecycle, right?

2540
01:25:05,408 --> 01:25:08,169
So you ship the thing, people buy it at some point,

2541
01:25:08,169 --> 01:25:09,639
everybody who wants it has bought it

2542
01:25:09,639 --> 01:25:10,770
and then it becomes obsolete.

2543
01:25:10,770 --> 01:25:11,603
And it's like bananas.

2544
01:25:11,603 --> 01:25:13,586
Nobody, nobody buys old software.

2545
01:25:13,586 --> 01:25:16,503
These days, Minecraft, Mathematica,

2546
01:25:18,936 --> 01:25:21,092
you know, Facebook, Google,

2547
01:25:21,092 --> 01:25:24,310
you have the software assets that are, you know,

2548
01:25:24,310 --> 01:25:26,206
have been around for 30 years that are gaining

2549
01:25:26,206 --> 01:25:27,660
in value every year, right?

2550
01:25:27,660 --> 01:25:30,266
And they're just, they're being a world of warcraft, right,

2551
01:25:30,266 --> 01:25:31,894
salesforce.com, like they're being

2552
01:25:31,894 --> 01:25:33,096
every single year they're being polished and polished

2553
01:25:33,096 --> 01:25:34,007
and polished and polished.

2554
01:25:34,007 --> 01:25:35,610
They're getting better and better, more powerful,

2555
01:25:35,610 --> 01:25:36,930
more powerful, more valuable, more valuable.

2556
01:25:36,930 --> 01:25:38,345
So we've entered this era where you can actually have

2557
01:25:38,345 --> 01:25:40,032
these things that actually build out over decades.

2558
01:25:40,032 --> 01:25:41,125
Which by the way is what's happening

2559
01:25:41,125 --> 01:25:43,228
right now with like ChatGPT.

2560
01:25:43,228 --> 01:25:46,501
And so now, this is why, you know,

2561
01:25:46,501 --> 01:25:47,879
there is always, you know,

2562
01:25:47,879 --> 01:25:49,478
sort of a constant investment frenzy around software is

2563
01:25:49,478 --> 01:25:52,044
because, you know, look, when you start one of these things,

2564
01:25:52,044 --> 01:25:52,969
it doesn't always succeed.

2565
01:25:52,969 --> 01:25:55,146
But when it does now you might be building an asset

2566
01:25:55,146 --> 01:25:56,999
that builds value for, you know, four or five,

2567
01:25:56,999 --> 01:25:58,167
six decades to come.

2568
01:25:58,167 --> 01:26:00,056
You know, if you have a team of people

2569
01:26:00,056 --> 01:26:01,968
who have the level of devotion required

2570
01:26:01,968 --> 01:26:03,387
to keep making it better.

2571
01:26:03,387 --> 01:26:05,539
And then the fact that of course everybody's online,

2572
01:26:05,539 --> 01:26:07,392
you know, there's 5 billion people

2573
01:26:07,392 --> 01:26:08,975
that are a click away from any new piece of software.

2574
01:26:08,975 --> 01:26:11,407
So the potential market size for any of these things is,

2575
01:26:11,407 --> 01:26:12,510
you know, nearly infinite.

2576
01:26:12,510 --> 01:26:14,866
- [Lex] It must have been surreal back then though.

2577
01:26:14,866 --> 01:26:16,287
- Yeah. Yeah. This was all brand new, right?

2578
01:26:16,287 --> 01:26:17,553
Yeah. Back then, this was all brand new.

2579
01:26:17,553 --> 01:26:19,197
These were all, you know, brand new.

2580
01:26:19,197 --> 01:26:22,076
Had you rolled out that theory in even 1999,

2581
01:26:22,076 --> 01:26:23,592
people would've thought you were smoking crack.

2582
01:26:23,592 --> 01:26:25,925
So that's emerged over time.

2583
01:26:27,069 --> 01:26:31,127
- Well, let's now turn back into the future.

2584
01:26:31,127 --> 01:26:34,776
You wrote the essay "Why AI Will Save The World?"

2585
01:26:34,776 --> 01:26:36,732
Let's start the very high level.

2586
01:26:36,732 --> 01:26:38,242
What's the main thesis of the essay?

2587
01:26:38,242 --> 01:26:39,691
- Yeah, so the main thesis on the essay is

2588
01:26:39,691 --> 01:26:42,130
that what we're dealing with here is intelligence.

2589
01:26:42,130 --> 01:26:43,844
And it's really important to kind of talk

2590
01:26:43,844 --> 01:26:46,409
about the sort of very nature of what intelligence is.

2591
01:26:46,409 --> 01:26:50,205
And fortunately we have a predecessor

2592
01:26:50,205 --> 01:26:52,682
to machine intelligence, which is human intelligence.

2593
01:26:52,682 --> 01:26:53,620
And we've got, you know,

2594
01:26:53,620 --> 01:26:56,187
observations and theories over thousands of years

2595
01:26:56,187 --> 01:26:58,112
for what intelligence is in the hands of humans

2596
01:26:58,112 --> 01:26:59,631
and what intelligence is, right?

2597
01:26:59,631 --> 01:27:01,790
I mean, what it literally is the way to,

2598
01:27:01,790 --> 01:27:04,281
you know, capture, process, analyze, synthesize information,

2599
01:27:04,281 --> 01:27:05,660
solve problems.

2600
01:27:05,660 --> 01:27:09,678
But the observation of intelligence in human hands is

2601
01:27:09,678 --> 01:27:12,756
that intelligence quite literally makes everything better.

2602
01:27:12,756 --> 01:27:15,677
And what I mean by that is every kind of outcome

2603
01:27:15,677 --> 01:27:18,192
of like human quality of life,

2604
01:27:18,192 --> 01:27:20,578
whether it's education outcomes or success

2605
01:27:20,578 --> 01:27:23,250
of your children, or career success

2606
01:27:23,250 --> 01:27:27,621
or health or lifetime satisfaction, by the way,

2607
01:27:27,621 --> 01:27:32,248
propensity to peacefulness as opposed to violence,

2608
01:27:32,248 --> 01:27:35,114
propensity for open-mindedness versus bigotry,

2609
01:27:35,114 --> 01:27:37,826
those are all associated with higher levels of intelligence.

2610
01:27:37,826 --> 01:27:39,177
- Smarter people have better outcomes

2611
01:27:39,177 --> 01:27:40,530
than almost as you write

2612
01:27:40,530 --> 01:27:42,254
in almost every domain of activity.

2613
01:27:42,254 --> 01:27:44,012
Academic achievement, job performance,

2614
01:27:44,012 --> 01:27:46,068
occupational status, income, creativity,

2615
01:27:46,068 --> 01:27:48,899
physical health, longevity, learning new skills,

2616
01:27:48,899 --> 01:27:53,094
managing complex tasks, leadership, entrepreneurial success,

2617
01:27:53,094 --> 01:27:56,023
conflict resolution, reading comprehension,

2618
01:27:56,023 --> 01:27:57,749
financial decision making,

2619
01:27:57,749 --> 01:27:59,740
understanding others perspectives, creative arts,

2620
01:27:59,740 --> 01:28:01,799
parenting outcomes, and life satisfaction.

2621
01:28:01,799 --> 01:28:05,531
One of the more depressing conversations I've had,

2622
01:28:05,531 --> 01:28:07,384
and I don't know why it's depressing,

2623
01:28:07,384 --> 01:28:09,500
I have to really think through why it's depressing,

2624
01:28:09,500 --> 01:28:11,750
but on IQ and the G factor,

2625
01:28:16,187 --> 01:28:20,354
and that that's something in large part is genetic

2626
01:28:22,181 --> 01:28:25,409
and it correlates so much with all of these things

2627
01:28:25,409 --> 01:28:27,856
and success in life.

2628
01:28:27,856 --> 01:28:30,981
It's like all the inspirational stuff we read about,

2629
01:28:30,981 --> 01:28:33,940
like if you work hard and so on,

2630
01:28:33,940 --> 01:28:36,781
it sucks that you're born with the hand

2631
01:28:36,781 --> 01:28:38,194
that you can't change.

2632
01:28:38,194 --> 01:28:39,484
- But what if you could.

2633
01:28:39,484 --> 01:28:41,853
- You're saying basically a really important point,

2634
01:28:41,853 --> 01:28:46,436
and I think it's in your articles, it really helped me.

2635
01:28:48,852 --> 01:28:52,532
It's a nice added perspective to think about.

2636
01:28:52,532 --> 01:28:54,256
Listen, human intelligence,

2637
01:28:54,256 --> 01:28:56,971
the science of intelligence is shown scientifically

2638
01:28:56,971 --> 01:28:59,174
that it just makes life easier

2639
01:28:59,174 --> 01:29:01,936
and better the smarter you are.

2640
01:29:01,936 --> 01:29:06,077
And now let's look at artificial intelligence

2641
01:29:06,077 --> 01:29:10,744
and if that's a way to increase some human intelligence,

2642
01:29:14,189 --> 01:29:16,443
then it's only going to make a better life.

2643
01:29:16,443 --> 01:29:17,276
- [Marc] Yeah.

2644
01:29:17,276 --> 01:29:18,109
- That's the argument.

2645
01:29:18,109 --> 01:29:18,942
- And certainly at the collective level,

2646
01:29:18,942 --> 01:29:19,827
we could talk about the collective effect

2647
01:29:19,827 --> 01:29:21,628
of just having more intelligence in the world,

2648
01:29:21,628 --> 01:29:23,862
which will have very big payoff.

2649
01:29:23,862 --> 01:29:25,333
But there's also just at the individual level,

2650
01:29:25,333 --> 01:29:27,375
like what if every person has a machine?

2651
01:29:27,375 --> 01:29:29,182
You know? And the concept of augment

2652
01:29:29,182 --> 01:29:31,382
Doug Engelbart's concept of augmentation.

2653
01:29:31,382 --> 01:29:34,840
You know, what if everybody has an assistant

2654
01:29:34,840 --> 01:29:36,779
and the assistant is, you know,

2655
01:29:36,779 --> 01:29:39,612
140 IQ and you happen to be 110 IQ

2656
01:29:41,177 --> 01:29:42,761
and you've got, you know,

2657
01:29:42,761 --> 01:29:45,249
something that basically is infinitely patient and knows

2658
01:29:45,249 --> 01:29:47,600
everything about you and is pulling for you

2659
01:29:47,600 --> 01:29:50,415
in every possible way, wants you to be successful.

2660
01:29:50,415 --> 01:29:53,128
And anytime you find anything confusing or wanna learn

2661
01:29:53,128 --> 01:29:54,839
anything or have trouble understanding something

2662
01:29:54,839 --> 01:29:57,103
or wanna figure out what to do in a situation, right?

2663
01:29:57,103 --> 01:29:58,645
Wanna figure out how to prepare for a job interview,

2664
01:29:58,645 --> 01:30:01,395
like any of these things, like it will help you do it.

2665
01:30:01,395 --> 01:30:02,427
And it will therefore,

2666
01:30:02,427 --> 01:30:04,678
the combination will effectively be, you know,

2667
01:30:04,678 --> 01:30:06,193
will effectively raise your raise

2668
01:30:06,193 --> 01:30:08,363
because it will effectively raise your IQ,

2669
01:30:08,363 --> 01:30:09,817
will therefore raise the odds

2670
01:30:09,817 --> 01:30:11,663
of successful life outcomes in all these areas.

2671
01:30:11,663 --> 01:30:15,554
- So people below the, this hypothetical 140 IQ,

2672
01:30:15,554 --> 01:30:18,044
it'll pull them up towards 140 IQ.

2673
01:30:18,044 --> 01:30:19,282
- Yeah, yeah, yeah.

2674
01:30:19,282 --> 01:30:20,540
And then of course, you know,

2675
01:30:20,540 --> 01:30:22,643
people at 140 IQ will be able to have a peer, right.

2676
01:30:22,643 --> 01:30:24,459
To be able to communicate, which is great.

2677
01:30:24,459 --> 01:30:25,602
And then people above 140 IQ will have an assistance

2678
01:30:25,602 --> 01:30:27,178
that they can farm things out to.

2679
01:30:27,178 --> 01:30:29,595
And then look, God willing, you know,

2680
01:30:29,595 --> 01:30:31,304
at some point these things go from future versions go

2681
01:30:31,304 --> 01:30:34,806
from 140 IQ equivalent to 150 to 160 to 180, right?

2682
01:30:34,806 --> 01:30:38,327
Like Einstein was estimated to be on the order of one 60,

2683
01:30:38,327 --> 01:30:42,255
you know, so when we get, you know, one 60 AI,

2684
01:30:42,255 --> 01:30:43,527
like we'll be, you know,

2685
01:30:43,527 --> 01:30:46,226
when one assumes creating Einstein level breakthroughs

2686
01:30:46,226 --> 01:30:49,685
and physics, and then at 180 we'll be, you know,

2687
01:30:49,685 --> 01:30:52,428
carrying cancer and developing warp drive and doing

2688
01:30:52,428 --> 01:30:53,501
all kinds of stuff.

2689
01:30:53,501 --> 01:30:55,601
And so it is quite possibly the case,

2690
01:30:55,601 --> 01:30:57,065
this is the most important thing that's ever happened

2691
01:30:57,065 --> 01:30:58,651
and the best thing that's ever happened

2692
01:30:58,651 --> 01:31:00,307
because precisely because it's a lever

2693
01:31:00,307 --> 01:31:02,949
on this single fundamental factor of intelligence,

2694
01:31:02,949 --> 01:31:06,223
which is the thing that drives so much of everything else.

2695
01:31:06,223 --> 01:31:07,147
- Can you steal, man,

2696
01:31:07,147 --> 01:31:10,498
the case that human plus AI is not always better than human

2697
01:31:10,498 --> 01:31:11,709
for the individual?

2698
01:31:11,709 --> 01:31:12,542
- You may have noticed

2699
01:31:12,542 --> 01:31:14,190
that there's a lot of smart running around.

2700
01:31:14,190 --> 01:31:15,023
- [Lex] Sure. Yes.

2701
01:31:15,023 --> 01:31:16,711
- Right? And so, like smart,

2702
01:31:16,711 --> 01:31:18,927
there are certain people where they get smarter, you know,

2703
01:31:18,927 --> 01:31:20,503
they get to be more arrogant, right?

2704
01:31:20,503 --> 01:31:23,112
So that, you know, there's one huge flaw.

2705
01:31:23,112 --> 01:31:24,944
- Although to push back on that,

2706
01:31:24,944 --> 01:31:28,241
it might be interesting because when the intelligence is not

2707
01:31:28,241 --> 01:31:30,174
all coming from you, but from another system,

2708
01:31:30,174 --> 01:31:34,001
that might actually increase the amount of humility

2709
01:31:34,001 --> 01:31:35,158
even in the assholes.

2710
01:31:35,158 --> 01:31:36,265
- [Marc] One would hope.

2711
01:31:36,265 --> 01:31:37,223
- Yeah.

2712
01:31:37,223 --> 01:31:40,149
- Or it could make assholes more assholes.

2713
01:31:40,149 --> 01:31:40,982
You know, that's in, I mean,

2714
01:31:40,982 --> 01:31:41,927
that's for psychology to study.

2715
01:31:41,927 --> 01:31:42,760
- Yeah, exactly.

2716
01:31:42,760 --> 01:31:45,925
Another one is smart people are very convinced that they,

2717
01:31:45,925 --> 01:31:47,613
you know, have a more rational view of the world,

2718
01:31:47,613 --> 01:31:49,803
and that they have a easier time seeing through conspiracy

2719
01:31:49,803 --> 01:31:51,145
theories and hoaxes and right.

2720
01:31:51,145 --> 01:31:53,039
You know, sort of crazy beliefs and all that.

2721
01:31:53,039 --> 01:31:54,480
There's a theory in psychology,

2722
01:31:54,480 --> 01:31:55,552
which is actually smart people.

2723
01:31:55,552 --> 01:31:58,233
So for sure people who aren't as smart are very susceptible

2724
01:31:58,233 --> 01:31:59,757
to hoaxes and conspiracy theories.

2725
01:31:59,757 --> 01:32:02,185
But it may also be the case that the smarter you get,

2726
01:32:02,185 --> 01:32:04,124
you become susceptible in a different way,

2727
01:32:04,124 --> 01:32:06,807
which is you become very good at marshaling facts

2728
01:32:06,807 --> 01:32:09,318
to fit preconceptions, right.

2729
01:32:09,318 --> 01:32:11,697
You become very, very good at assembling

2730
01:32:11,697 --> 01:32:14,278
whatever theories and frameworks and pieces

2731
01:32:14,278 --> 01:32:16,666
of data and graphs and charts you need to validate

2732
01:32:16,666 --> 01:32:18,016
whatever crazy ideas got in your head.

2733
01:32:18,016 --> 01:32:22,005
And so you're susceptible in a different way, right?

2734
01:32:22,005 --> 01:32:25,790
- We're all sheep, but different colored sheep.

2735
01:32:25,790 --> 01:32:28,024
- Some sheep are better at justifying it. Right.

2736
01:32:28,024 --> 01:32:29,466
And those are the, you know,

2737
01:32:29,466 --> 01:32:30,868
those are the smart sheep, right?

2738
01:32:30,868 --> 01:32:32,417
So yeah. Look like I would say this look like

2739
01:32:32,417 --> 01:32:33,490
there are no panacea.

2740
01:32:33,490 --> 01:32:36,280
I'm not a utopian, there are no panaceas in life.

2741
01:32:36,280 --> 01:32:38,086
There are no, like, you know,

2742
01:32:38,086 --> 01:32:39,842
I don't believe there are like pure positives.

2743
01:32:39,842 --> 01:32:42,302
I'm not a transcendental kind of person like that.

2744
01:32:42,302 --> 01:32:44,438
But, you know, so yeah, there are gonna be issues

2745
01:32:44,438 --> 01:32:47,188
and, you know, look, smart people,

2746
01:32:47,188 --> 01:32:49,073
another maybe you could save about smart people is

2747
01:32:49,073 --> 01:32:50,326
they are more likely to get themselves in situations

2748
01:32:50,326 --> 01:32:51,728
that are, you know, beyond their grasp.

2749
01:32:51,728 --> 01:32:53,009
You know, because they're just more confident

2750
01:32:53,009 --> 01:32:54,200
in their ability to deal with complexity

2751
01:32:54,200 --> 01:32:56,059
and their eyes become bigger,

2752
01:32:56,059 --> 01:32:57,356
their cognitive eyes become bigger

2753
01:32:57,356 --> 01:32:59,040
than their stomach, you know?

2754
01:32:59,040 --> 01:33:01,185
So yeah, you could argue those eight different ways

2755
01:33:01,185 --> 01:33:03,566
nevertheless, on net, right?

2756
01:33:03,566 --> 01:33:05,359
Clearly, overwhelmingly, again,

2757
01:33:05,359 --> 01:33:06,505
if you just extrapolate from what we know

2758
01:33:06,505 --> 01:33:07,656
about human intelligence,

2759
01:33:07,656 --> 01:33:09,809
you're improving so many aspects of life

2760
01:33:09,809 --> 01:33:12,061
if you're upgrading intelligence.

2761
01:33:12,061 --> 01:33:15,799
- So there'll be assistants at all stages of life.

2762
01:33:15,799 --> 01:33:18,303
So when you're younger, there's for education,

2763
01:33:18,303 --> 01:33:21,028
all that kind of stuff for mentorship, all of this.

2764
01:33:21,028 --> 01:33:24,142
And later on as you're doing work and you've developed

2765
01:33:24,142 --> 01:33:25,813
a skill and you're having a profession,

2766
01:33:25,813 --> 01:33:28,168
you'll have an assistant that helps you excel

2767
01:33:28,168 --> 01:33:29,202
at that profession.

2768
01:33:29,202 --> 01:33:30,488
So at all stages of life.

2769
01:33:30,488 --> 01:33:32,293
- Yeah. I mean, look, the theory is augmentation.

2770
01:33:32,293 --> 01:33:33,498
This is the Doug Engelbart's term.

2771
01:33:33,498 --> 01:33:34,331
Doug Engelbart made

2772
01:33:34,331 --> 01:33:36,542
this observation many, many decades ago that, you know,

2773
01:33:36,542 --> 01:33:38,216
basically it's like you can have this oppositional frame

2774
01:33:38,216 --> 01:33:40,097
of technology where it's like us versus the machines,

2775
01:33:40,097 --> 01:33:41,837
but what you really do is you use technology

2776
01:33:41,837 --> 01:33:43,923
to augment human capabilities.

2777
01:33:43,923 --> 01:33:44,756
And by the way,

2778
01:33:44,756 --> 01:33:45,952
that's how actually the economy develops.

2779
01:33:45,952 --> 01:33:47,702
That's, we can talk about the economic side of this,

2780
01:33:47,702 --> 01:33:50,236
but that's actually how the economy grows is

2781
01:33:50,236 --> 01:33:52,960
through technology augmenting human potential.

2782
01:33:52,960 --> 01:33:54,559
And so, yeah.

2783
01:33:54,559 --> 01:33:57,001
And then you basically have a proxy or you know,

2784
01:33:57,001 --> 01:33:59,530
or you know, a sort of prosthetic, you know,

2785
01:33:59,530 --> 01:34:02,151
so like you've got glasses, you've got a wristwatch,

2786
01:34:02,151 --> 01:34:04,638
you know, you've got shoes, you know,

2787
01:34:04,638 --> 01:34:05,671
you've got these things.

2788
01:34:05,671 --> 01:34:07,011
You've got a personal computer,

2789
01:34:07,011 --> 01:34:09,376
you've got a word processor, you've got Mathematica,

2790
01:34:09,376 --> 01:34:10,607
you've got Google.

2791
01:34:10,607 --> 01:34:12,627
This is the latest viewed through that lens.

2792
01:34:12,627 --> 01:34:16,168
AI is the latest in a long series of basically augmentation

2793
01:34:16,168 --> 01:34:18,465
methods to be able to raise human capabilities.

2794
01:34:18,465 --> 01:34:20,625
It's just this one is the most powerful one of all,

2795
01:34:20,625 --> 01:34:22,241
because this is the one that, that goes directly

2796
01:34:22,241 --> 01:34:26,752
to what they call fluid intelligence, which is IQ.

2797
01:34:26,752 --> 01:34:30,301
- Well, there's two categories of folks

2798
01:34:30,301 --> 01:34:34,082
that you outline that worry about or highlight

2799
01:34:34,082 --> 01:34:35,928
the risks of AI, and you highlight

2800
01:34:35,928 --> 01:34:37,116
a bunch of different risks.

2801
01:34:37,116 --> 01:34:39,228
I would love to go through those risks

2802
01:34:39,228 --> 01:34:40,379
and just discuss them,

2803
01:34:40,379 --> 01:34:42,467
brainstorm which ones are serious

2804
01:34:42,467 --> 01:34:44,782
and which ones are less serious.

2805
01:34:44,782 --> 01:34:47,135
But first, the Baptist and the bootleggers,

2806
01:34:47,135 --> 01:34:49,522
what are these two interesting groups of folks

2807
01:34:49,522 --> 01:34:54,189
who worry about the effect of AI and human civilization?

2808
01:34:56,556 --> 01:34:57,784
- [Marc] Or say they do.

2809
01:34:57,784 --> 01:35:00,615
- Say, oh, okay, yes, I'll say they do.

2810
01:35:00,615 --> 01:35:03,399
- The Baptist worry the bootleggers say they do.

2811
01:35:03,399 --> 01:35:05,856
So the Baptist and the bootleggers is a metaphor

2812
01:35:05,856 --> 01:35:08,451
from economics, from what's called development economics.

2813
01:35:08,451 --> 01:35:09,487
And it's this observation

2814
01:35:09,487 --> 01:35:13,056
that when you get social reform movements in a society,

2815
01:35:13,056 --> 01:35:15,027
you tend to get two sets of people showing up,

2816
01:35:15,027 --> 01:35:16,749
arguing for the social reform.

2817
01:35:16,749 --> 01:35:19,384
And the term Baptist and bootleggers comes

2818
01:35:19,384 --> 01:35:22,129
from the American experience with alcohol prohibition.

2819
01:35:22,129 --> 01:35:25,083
And so in the 1900s, 1910s,

2820
01:35:25,083 --> 01:35:27,053
there was this movement that was very passionate

2821
01:35:27,053 --> 01:35:28,355
at the time, which basically said,

2822
01:35:28,355 --> 01:35:31,121
alcohol is evil and is destroying society.

2823
01:35:31,121 --> 01:35:34,054
By the way, there was a lot of evidence to support this.

2824
01:35:34,054 --> 01:35:35,858
There were very high rates

2825
01:35:35,858 --> 01:35:38,754
of very high correlations then, by the way.

2826
01:35:38,754 --> 01:35:42,293
And now between rates of physical violence and alcohol use,

2827
01:35:42,293 --> 01:35:44,904
almost all violent crimes have either the perpetrator

2828
01:35:44,904 --> 01:35:46,913
or the victim, or both drunk almost.

2829
01:35:46,913 --> 01:35:48,412
If you see this actually in the work,

2830
01:35:48,412 --> 01:35:50,503
almost all sexual harassment cases in the workplace,

2831
01:35:50,503 --> 01:35:52,377
it's like at a company party and somebody's drunk.

2832
01:35:52,377 --> 01:35:54,901
Like, it's amazing how often alcohol actually correlates

2833
01:35:54,901 --> 01:35:57,378
to actually dis dysfunction and at leads to domestic abuse

2834
01:35:57,378 --> 01:35:59,095
and so forth, child abuse.

2835
01:35:59,095 --> 01:36:01,359
And so you had this group of people who were like, okay,

2836
01:36:01,359 --> 01:36:03,270
this is bad stuff and we should outlaw it.

2837
01:36:03,270 --> 01:36:04,870
And those were quite literally Baptist.

2838
01:36:04,870 --> 01:36:06,405
Those were super committed, you know,

2839
01:36:06,405 --> 01:36:08,879
hardcore Christian activists in a lot of cases.

2840
01:36:08,879 --> 01:36:11,287
There was this woman whose name was Carrie Nation,

2841
01:36:11,287 --> 01:36:14,054
who was this older woman who had been in this, you know,

2842
01:36:14,054 --> 01:36:15,640
I don't know, disastrous marriage or something.

2843
01:36:15,640 --> 01:36:17,833
And her husband had been abusive and drunk all the time.

2844
01:36:17,833 --> 01:36:21,464
And she became the icon of the Baptist prohibitionist.

2845
01:36:21,464 --> 01:36:24,272
And she was legendary in that era for carrying an ax

2846
01:36:24,272 --> 01:36:26,261
and doing, you know,

2847
01:36:26,261 --> 01:36:28,334
completely on her own doing raids of saloons

2848
01:36:28,334 --> 01:36:30,210
and like taking her ax to all the bottles

2849
01:36:30,210 --> 01:36:32,125
and eggs in the back. And so.

2850
01:36:32,125 --> 01:36:33,375
- [Lex] A true believer.

2851
01:36:33,375 --> 01:36:34,730
- An absolute true believer,

2852
01:36:34,730 --> 01:36:37,446
and with absolutely the purist of intentions.

2853
01:36:37,446 --> 01:36:40,207
And again, there's a very important thing here,

2854
01:36:40,207 --> 01:36:41,166
which is there's,

2855
01:36:41,166 --> 01:36:42,693
you could look at this cynically and you could say

2856
01:36:42,693 --> 01:36:45,161
the Baptists are like delusional, you know, the extremists,

2857
01:36:45,161 --> 01:36:46,716
but you could also say, look, they're right.

2858
01:36:46,716 --> 01:36:48,314
Like she was, you know, she had a point.

2859
01:36:48,314 --> 01:36:51,035
Like she wasn't wrong about a lot of what she said.

2860
01:36:51,035 --> 01:36:51,868
- Yeah.

2861
01:36:51,868 --> 01:36:53,918
- But it turns out the way the story goes is it turns out

2862
01:36:53,918 --> 01:36:55,400
that there were another set of people

2863
01:36:55,400 --> 01:36:57,916
who very badly wanted to outlaw alcohol in those days.

2864
01:36:57,916 --> 01:36:58,825
And those were the bootleggers,

2865
01:36:58,825 --> 01:37:02,074
which was organized crime that stood to make a huge amount

2866
01:37:02,074 --> 01:37:04,781
of money if legal alcohol sales were banned.

2867
01:37:04,781 --> 01:37:05,630
And this was, in fact,

2868
01:37:05,630 --> 01:37:07,531
the way the history goes is this was actually

2869
01:37:07,531 --> 01:37:08,928
the beginning of organized crime in the US.

2870
01:37:08,928 --> 01:37:11,692
This was the big economic opportunity that opened that up.

2871
01:37:11,692 --> 01:37:14,594
And so they went in together and no,

2872
01:37:14,594 --> 01:37:15,613
they didn't go in together.

2873
01:37:15,613 --> 01:37:17,691
Like the Baptist did not even necessarily know

2874
01:37:17,691 --> 01:37:18,524
about the bootleggers

2875
01:37:18,524 --> 01:37:20,232
'cause they were on their moral crusade.

2876
01:37:20,232 --> 01:37:21,628
The bootleggers certainly knew about the Baptists.

2877
01:37:21,628 --> 01:37:22,480
And they were like, wow,

2878
01:37:22,480 --> 01:37:24,612
these people are like the great front people for like.

2879
01:37:24,612 --> 01:37:25,472
You know, it's--

2880
01:37:25,472 --> 01:37:26,305
- [Lex] Good PR.

2881
01:37:26,305 --> 01:37:27,768
- Shenanigans in the background.

2882
01:37:27,768 --> 01:37:30,197
And they got the (indistinct) Act passed, right.

2883
01:37:30,197 --> 01:37:33,178
And they did in fact ban alcohol in the US and you'll notice

2884
01:37:33,178 --> 01:37:35,152
what happened, which is people kept drinking,

2885
01:37:35,152 --> 01:37:38,209
it didn't work, people kept drinking.

2886
01:37:38,209 --> 01:37:40,591
That bootleggers made a tremendous amount of money.

2887
01:37:40,591 --> 01:37:43,213
And then over time it became clear that it made no sense

2888
01:37:43,213 --> 01:37:45,099
to make it illegal and it was causing more problems.

2889
01:37:45,099 --> 01:37:46,304
And so then it was revoked.

2890
01:37:46,304 --> 01:37:48,237
And here we sit with legal alcohol a hundred years later

2891
01:37:48,237 --> 01:37:50,178
with all the same problems.

2892
01:37:50,178 --> 01:37:51,662
And you know,

2893
01:37:51,662 --> 01:37:53,957
the whole thing was this like giant misadventure

2894
01:37:53,957 --> 01:37:56,187
the Baptist got taken advantage of by the bootleggers,

2895
01:37:56,187 --> 01:37:57,722
and the bootleggers got what they wanted.

2896
01:37:57,722 --> 01:37:58,924
And that was that.

2897
01:37:58,924 --> 01:38:01,006
- The same two categories of folks are

2898
01:38:01,006 --> 01:38:03,806
now sort of suggesting that the development

2899
01:38:03,806 --> 01:38:05,838
of artificial intelligence should be regulated.

2900
01:38:05,838 --> 01:38:06,671
- A hundred percent.

2901
01:38:06,671 --> 01:38:07,504
It's the same pattern.

2902
01:38:07,504 --> 01:38:08,337
And the economist will tell you

2903
01:38:08,337 --> 01:38:09,170
it's the same pattern every time.

2904
01:38:09,170 --> 01:38:10,443
Like, this is what happened, nuclear power,

2905
01:38:10,443 --> 01:38:12,814
this is what happens, which is another interesting one.

2906
01:38:12,814 --> 01:38:14,484
But like, yeah, this happens dozens and dozens

2907
01:38:14,484 --> 01:38:16,842
of times throughout the last a hundred years

2908
01:38:16,842 --> 01:38:18,746
and this is what's happening now.

2909
01:38:18,746 --> 01:38:22,633
- And you write that it isn't sufficient to simply identify

2910
01:38:22,633 --> 01:38:24,618
the actors and impugn their motives.

2911
01:38:24,618 --> 01:38:26,669
We should consider the arguments of both the Baptist

2912
01:38:26,669 --> 01:38:28,872
and the bootleggers on their merits.

2913
01:38:28,872 --> 01:38:30,823
So let's do just that.

2914
01:38:30,823 --> 01:38:33,906
Risk number one, will AI kill us all?

2915
01:38:37,502 --> 01:38:38,335
- [Marc] Yes.

2916
01:38:38,335 --> 01:38:41,502
- So what do you think about this one?

2917
01:38:43,509 --> 01:38:47,092
What do you think is the core argument here

2918
01:38:48,389 --> 01:38:52,617
that the development of AGI perhaps better said,

2919
01:38:52,617 --> 01:38:54,621
will destroy human civilization?

2920
01:38:54,621 --> 01:38:56,164
- Well, first of all, you just did a slight of hand

2921
01:38:56,164 --> 01:38:57,432
'cause we went from talking about

2922
01:38:57,432 --> 01:38:58,265
AI to AGI.

2923
01:38:59,673 --> 01:39:01,778
- Is there a fundamental difference there?

2924
01:39:01,778 --> 01:39:03,789
- I don't know. What's AGI?

2925
01:39:03,789 --> 01:39:05,206
- What's AI, what's in intelligence?

2926
01:39:05,206 --> 01:39:07,638
- Well, I know what AI is machine learning.

2927
01:39:07,638 --> 01:39:08,471
What's AGI?

2928
01:39:08,471 --> 01:39:10,731
- I think we don't know what the bottom of the well

2929
01:39:10,731 --> 01:39:13,259
of machine learning is or what the ceiling is.

2930
01:39:13,259 --> 01:39:15,416
Because just to call something machine learning

2931
01:39:15,416 --> 01:39:16,971
or just to call some of the statistics

2932
01:39:16,971 --> 01:39:20,079
or just to call it math or computation doesn't mean,

2933
01:39:20,079 --> 01:39:22,870
you know, nuclear weapons are just physics.

2934
01:39:22,870 --> 01:39:27,075
So to me it's very interesting and surprising

2935
01:39:27,075 --> 01:39:28,836
how far machine learning has taken.

2936
01:39:28,836 --> 01:39:30,020
- No, but we knew that nuclear physics would lead

2937
01:39:30,020 --> 01:39:30,853
to weapons.

2938
01:39:30,853 --> 01:39:32,092
That's why the scientists of that era were always

2939
01:39:32,092 --> 01:39:34,146
in some this huge dispute about building the weapons.

2940
01:39:34,146 --> 01:39:35,988
This is different. AGI is different.

2941
01:39:35,988 --> 01:39:37,595
- Does machine learning lead, do we know?

2942
01:39:37,595 --> 01:39:38,935
- We don't know, but this is my point is different.

2943
01:39:38,935 --> 01:39:40,042
We actually don't know.

2944
01:39:40,042 --> 01:39:41,367
But, and this is where you,

2945
01:39:41,367 --> 01:39:42,622
the slide of hand kicks in, right?

2946
01:39:42,622 --> 01:39:44,351
This is where it goes from being a scientific topic

2947
01:39:44,351 --> 01:39:46,223
to being a religious topic.

2948
01:39:46,223 --> 01:39:48,504
And that's why I specifically called out

2949
01:39:48,504 --> 01:39:49,550
'cause that's what happens.

2950
01:39:49,550 --> 01:39:51,184
They do the vocabulary shift and all of a sudden

2951
01:39:51,184 --> 01:39:52,389
you're talking about something totally.

2952
01:39:52,389 --> 01:39:53,525
That's not actually real.

2953
01:39:53,525 --> 01:39:56,077
- Well then maybe you can also, as part of that,

2954
01:39:56,077 --> 01:39:59,738
define the western tradition of Millennialism.

2955
01:39:59,738 --> 01:40:02,032
- [Marc] Yes. Into the world apocalypse.

2956
01:40:02,032 --> 01:40:03,157
- [Lex] What is it?

2957
01:40:03,157 --> 01:40:04,244
- [Marc] Apocalypse cults.

2958
01:40:04,244 --> 01:40:05,095
- [Lex] Apocalypse cults.

2959
01:40:05,095 --> 01:40:06,355
- Well, so we live in,

2960
01:40:06,355 --> 01:40:08,045
we of course live in a Judeo-Christian,

2961
01:40:08,045 --> 01:40:09,869
but primarily Christian kind of saturated, you know,

2962
01:40:09,869 --> 01:40:11,894
kind of Christian, post-Christian, secularized Christian,

2963
01:40:11,894 --> 01:40:13,855
you know, kind of world in the west.

2964
01:40:13,855 --> 01:40:15,933
And of course court of Christianity is

2965
01:40:15,933 --> 01:40:17,970
the idea of the second coming and you know,

2966
01:40:17,970 --> 01:40:19,351
the revelations and you know,

2967
01:40:19,351 --> 01:40:21,507
Jesus returning and the thousand year, you know,

2968
01:40:21,507 --> 01:40:23,100
utopia on earth and then you know,

2969
01:40:23,100 --> 01:40:25,364
the rapture and like all all that stuff, you know,

2970
01:40:25,364 --> 01:40:27,612
you know, we collectively, you know, as a society,

2971
01:40:27,612 --> 01:40:29,826
we don't necessarily take all that fully seriously now.

2972
01:40:29,826 --> 01:40:32,384
So, what we do is we create our secularized versions of that

2973
01:40:32,384 --> 01:40:34,471
we keep looking for utopia.

2974
01:40:34,471 --> 01:40:35,896
We keep looking for, you know,

2975
01:40:35,896 --> 01:40:37,205
basically the end of the world.

2976
01:40:37,205 --> 01:40:38,370
And so what what you see over,

2977
01:40:38,370 --> 01:40:39,673
over decades is that basically a pattern

2978
01:40:39,673 --> 01:40:43,017
of these sort of these of is this is what cults are.

2979
01:40:43,017 --> 01:40:45,138
This is how cults form as they form around some theory

2980
01:40:45,138 --> 01:40:46,239
of the end of the world.

2981
01:40:46,239 --> 01:40:47,585
And so the people's temple cults,

2982
01:40:47,585 --> 01:40:50,590
the Manson cult, the Heavens Gate cult,

2983
01:40:50,590 --> 01:40:52,463
the David Qresh cult,

2984
01:40:52,463 --> 01:40:54,157
you know what they're all organized around is like,

2985
01:40:54,157 --> 01:40:55,723
there's gonna be this thing that's gonna happen

2986
01:40:55,723 --> 01:40:57,861
that's gonna basically bring civilization crashing down.

2987
01:40:57,861 --> 01:41:00,187
And then we have this special elite group of people

2988
01:41:00,187 --> 01:41:02,087
who are gonna see it coming and prepare for it.

2989
01:41:02,087 --> 01:41:04,384
And then they're the people who are either going to stop it

2990
01:41:04,384 --> 01:41:05,382
or are failing, stopping it.

2991
01:41:05,382 --> 01:41:07,383
They're gonna be the people who survived the other side

2992
01:41:07,383 --> 01:41:09,499
and ultimately get credit for having been, right.

2993
01:41:09,499 --> 01:41:11,895
- Why is that so compelling, do you think? Like--

2994
01:41:11,895 --> 01:41:13,995
- Because it satisfies this very deep need

2995
01:41:13,995 --> 01:41:15,551
we have for transcendence

2996
01:41:15,551 --> 01:41:20,484
and meaning that got stripped away when we became secular.

2997
01:41:20,484 --> 01:41:22,634
- Yeah, but why is the transcendence involve

2998
01:41:22,634 --> 01:41:25,673
the destruction of human civilization?

2999
01:41:25,673 --> 01:41:28,492
- Because like how plausible

3000
01:41:28,492 --> 01:41:30,463
it's like a very deep psychological thing

3001
01:41:30,463 --> 01:41:31,734
'cause it's like how plausible,

3002
01:41:31,734 --> 01:41:32,851
how plausible is it that we live in a world

3003
01:41:32,851 --> 01:41:35,472
where everything's just kind of all right? Right.

3004
01:41:35,472 --> 01:41:36,305
How exciting?

3005
01:41:36,305 --> 01:41:37,138
- [Lex] Whoa.

3006
01:41:37,138 --> 01:41:38,017
- How exciting is that? Right?

3007
01:41:38,017 --> 01:41:38,850
- [Lex] But that's.

3008
01:41:38,850 --> 01:41:39,683
- We got more than that.

3009
01:41:39,683 --> 01:41:41,699
- But that's the deep question I'm asking.

3010
01:41:41,699 --> 01:41:44,646
Why is it not exciting to live in a world

3011
01:41:44,646 --> 01:41:46,383
where everything's just all right?

3012
01:41:46,383 --> 01:41:48,957
Is it, I think, you know,

3013
01:41:48,957 --> 01:41:50,710
most of the animal kingdom would be

3014
01:41:50,710 --> 01:41:52,405
so happy with just all right.

3015
01:41:52,405 --> 01:41:54,493
Because that means survival.

3016
01:41:54,493 --> 01:41:57,022
Why are we, maybe that's what it is.

3017
01:41:57,022 --> 01:42:00,880
Why are we conjuring up things to worry about?

3018
01:42:00,880 --> 01:42:03,337
- So CS Lewis called it the God-shaped hole.

3019
01:42:03,337 --> 01:42:06,927
So there's a God-shaped hole in the human experience,

3020
01:42:06,927 --> 01:42:08,502
consciousness, soul, whatever you wanna call it,

3021
01:42:08,502 --> 01:42:11,085
where there's gotta be something that's bigger

3022
01:42:11,085 --> 01:42:12,267
than all this.

3023
01:42:12,267 --> 01:42:13,974
There's gotta be something transcendent.

3024
01:42:13,974 --> 01:42:15,505
There's gotta be something that is bigger, right?

3025
01:42:15,505 --> 01:42:17,226
Bigger purpose. A bigger meaning.

3026
01:42:17,226 --> 01:42:20,979
And so we have run the experiment of, you know,

3027
01:42:20,979 --> 01:42:22,453
we're just gonna use science and rationality

3028
01:42:22,453 --> 01:42:23,354
and kind of, you know,

3029
01:42:23,354 --> 01:42:25,126
everything's just gonna kind of be as it appears.

3030
01:42:25,126 --> 01:42:27,218
And large number of people have found

3031
01:42:27,218 --> 01:42:30,887
that very deeply wanting and have constructed narratives.

3032
01:42:30,887 --> 01:42:33,211
And by this is the story of the 20th century, right?

3033
01:42:33,211 --> 01:42:34,079
Communism, right?

3034
01:42:34,079 --> 01:42:36,587
Was one of those, communism was a was a form of this,

3035
01:42:36,587 --> 01:42:38,583
Nazism was a form of this.

3036
01:42:38,583 --> 01:42:40,412
You know, some people, you know,

3037
01:42:40,412 --> 01:42:42,298
you can see movements like this playing out

3038
01:42:42,298 --> 01:42:43,634
all over the world right now.

3039
01:42:43,634 --> 01:42:45,663
- So you constructed a kind of devil,

3040
01:42:45,663 --> 01:42:47,114
a kind of source of evil,

3041
01:42:47,114 --> 01:42:49,111
and we're going to transcend beyond it.

3042
01:42:49,111 --> 01:42:53,790
- Yeah. And (indistinct) when you see a Miller cult,

3043
01:42:53,790 --> 01:42:55,957
they put a really specific point on it,

3044
01:42:55,957 --> 01:42:57,826
which is end of the world, right,

3045
01:42:57,826 --> 01:42:59,574
there is some change coming.

3046
01:42:59,574 --> 01:43:01,492
And that change that's coming is so profound

3047
01:43:01,492 --> 01:43:02,989
and so important that it's either gonna lead

3048
01:43:02,989 --> 01:43:06,367
to utopia or hell on earth. Right?

3049
01:43:06,367 --> 01:43:09,022
And it is going to, and then, you know,

3050
01:43:09,022 --> 01:43:10,460
it's like what if you actually knew

3051
01:43:10,460 --> 01:43:11,976
that was going to happen, right?

3052
01:43:11,976 --> 01:43:13,931
What would you do? Right?

3053
01:43:13,931 --> 01:43:15,824
How would you prepare yourself for it?

3054
01:43:15,824 --> 01:43:16,782
How would you come together

3055
01:43:16,782 --> 01:43:18,885
with a group of like-minded people, right?

3056
01:43:18,885 --> 01:43:20,085
How would you, what would you do?

3057
01:43:20,085 --> 01:43:22,179
Would you plan like Cassius of weapons in the woods?

3058
01:43:22,179 --> 01:43:23,038
Would you like, you know,

3059
01:43:23,038 --> 01:43:25,384
I don't know if create underground buckers, would you,

3060
01:43:25,384 --> 01:43:27,135
you know, spend your life trying to figure out

3061
01:43:27,135 --> 01:43:28,661
a way to avoid having it happen?

3062
01:43:28,661 --> 01:43:32,027
- Yeah. That's a really compelling, exciting idea

3063
01:43:32,027 --> 01:43:33,694
to have a club over.

3064
01:43:34,686 --> 01:43:36,503
To have a little bit of travel,

3065
01:43:36,503 --> 01:43:39,229
like a get together on a Saturday night and drink some beers

3066
01:43:39,229 --> 01:43:41,098
and talk about the end of the world

3067
01:43:41,098 --> 01:43:44,063
and how you are the only ones who have figured it out.

3068
01:43:44,063 --> 01:43:45,964
- Yeah. And then once you lock in on that,

3069
01:43:45,964 --> 01:43:47,609
like how can you do anything else with your life?

3070
01:43:47,609 --> 01:43:49,190
Like this is obviously the thing that you have to do.

3071
01:43:49,190 --> 01:43:51,772
And then there's a psychological effect that you alluded to.

3072
01:43:51,772 --> 01:43:52,686
There's a psychological effect.

3073
01:43:52,686 --> 01:43:53,772
If you take a set of true believers and you leave them

3074
01:43:53,772 --> 01:43:55,948
to themselves, they get more radical. Right.

3075
01:43:55,948 --> 01:43:57,886
'Cause they self radicalize each other.

3076
01:43:57,886 --> 01:44:00,339
- That said, it doesn't mean

3077
01:44:00,339 --> 01:44:02,273
they're not sometimes right.

3078
01:44:02,273 --> 01:44:03,209
- Yeah. The end of the world might be.

3079
01:44:03,209 --> 01:44:05,046
Yes. Correct. Like they might be right.

3080
01:44:05,046 --> 01:44:05,879
- [Lex] Yeah.

3081
01:44:05,879 --> 01:44:06,712
- But like--

3082
01:44:06,712 --> 01:44:07,563
- [Lex] I have some pamphlets for you.

3083
01:44:07,563 --> 01:44:08,396
- Exactly.

3084
01:44:09,261 --> 01:44:11,942
- But I mean we'll talk about nuclear weapons

3085
01:44:11,942 --> 01:44:14,042
'cause you have a really interesting little moment

3086
01:44:14,042 --> 01:44:16,977
that I learned about in your essay, but you know,

3087
01:44:16,977 --> 01:44:18,321
sometimes it could be right.

3088
01:44:18,321 --> 01:44:19,154
- [Marc] Yeah.

3089
01:44:19,154 --> 01:44:20,123
- 'Cause we're still,

3090
01:44:20,123 --> 01:44:22,413
you were developing more and more powerful technologies

3091
01:44:22,413 --> 01:44:24,473
in this case, and we don't know

3092
01:44:24,473 --> 01:44:27,037
what the impact it will have on human civilization

3093
01:44:27,037 --> 01:44:29,267
while we can highlight all the different predictions

3094
01:44:29,267 --> 01:44:30,694
about how it'll be positive,

3095
01:44:30,694 --> 01:44:34,487
but the risks are there and you discuss some of them.

3096
01:44:34,487 --> 01:44:36,747
- Well, the steel man, the steel man is the steel man.

3097
01:44:36,747 --> 01:44:38,086
Well actually, the steel man and his reputation are

3098
01:44:38,086 --> 01:44:39,660
the same, which is you can't predict

3099
01:44:39,660 --> 01:44:41,110
what's gonna happen. Right.

3100
01:44:41,110 --> 01:44:44,469
You can't rule out that this will not end everything. Right.

3101
01:44:44,469 --> 01:44:46,669
But the response to that is you have just made

3102
01:44:46,669 --> 01:44:48,215
a completely non-scientific claim.

3103
01:44:48,215 --> 01:44:50,356
You've made a religious claim, not a scientific claim.

3104
01:44:50,356 --> 01:44:51,710
- How does it get disproven?

3105
01:44:51,710 --> 01:44:52,543
- And there's no,

3106
01:44:52,543 --> 01:44:53,923
by definition with these kinds of claims,

3107
01:44:53,923 --> 01:44:55,949
there's no way to disprove them. Right?

3108
01:44:55,949 --> 01:44:58,260
And so there there's no, you just go right on the list.

3109
01:44:58,260 --> 01:44:59,416
There's no hypothesis,

3110
01:44:59,416 --> 01:45:01,562
there's no testability of the hypothesis.

3111
01:45:01,562 --> 01:45:04,362
There's no way to falsify the hypothesis,

3112
01:45:04,362 --> 01:45:07,989
there's no way to measure progress along the arc.

3113
01:45:07,989 --> 01:45:09,812
Like it's just all completely missing.

3114
01:45:09,812 --> 01:45:12,089
And so it's not scientific and.

3115
01:45:12,089 --> 01:45:14,160
- I don't think it's completely missing.

3116
01:45:14,160 --> 01:45:15,447
It's somewhat missing.

3117
01:45:15,447 --> 01:45:16,800
So for example, the people

3118
01:45:16,800 --> 01:45:19,511
that say AI's gonna kill all of us.

3119
01:45:19,511 --> 01:45:22,543
I mean, they usually have ideas about how to do that.

3120
01:45:22,543 --> 01:45:26,248
Whether it's the people club maximizer or, you know,

3121
01:45:26,248 --> 01:45:29,896
it escapes there's mechanism by which you can imagine it

3122
01:45:29,896 --> 01:45:31,019
killing all humans.

3123
01:45:31,019 --> 01:45:31,852
- [Marc] Models.

3124
01:45:31,852 --> 01:45:34,769
- And you can disprove it by saying

3125
01:45:35,983 --> 01:45:38,316
there's a limit to the speed

3126
01:45:41,236 --> 01:45:44,220
at which intelligence increases.

3127
01:45:44,220 --> 01:45:49,220
Maybe show that like the sort of rigorously really described

3128
01:45:50,159 --> 01:45:54,332
model, like how it could happen and say, no, there,

3129
01:45:54,332 --> 01:45:55,745
here's a physics limitation.

3130
01:45:55,745 --> 01:45:58,998
There's like a physical limitation to how these systems

3131
01:45:58,998 --> 01:46:01,147
would actually do damage to human civilization.

3132
01:46:01,147 --> 01:46:04,043
And it is possible they will kill 10 to 20%

3133
01:46:04,043 --> 01:46:05,201
of the population,

3134
01:46:05,201 --> 01:46:09,171
but it seems impossible for them to kill 99%.

3135
01:46:09,171 --> 01:46:10,278
- It was practical counterarguments. Right.

3136
01:46:10,278 --> 01:46:11,655
So you mentioned basically what I described

3137
01:46:11,655 --> 01:46:13,296
as the thermodynamic counterargument,

3138
01:46:13,296 --> 01:46:14,523
which, so sitting here today,

3139
01:46:14,523 --> 01:46:16,924
it's like where with the evil AGI get the GPU.

3140
01:46:16,924 --> 01:46:18,685
'Cause like they don't exist.

3141
01:46:18,685 --> 01:46:21,056
So if you're gonna have a very frustrated baby evil AGI,

3142
01:46:21,056 --> 01:46:23,399
who's gonna be like trying to buy Nvidia stock or something

3143
01:46:23,399 --> 01:46:25,439
to get them to finally make some chips, right?

3144
01:46:25,439 --> 01:46:27,397
So the serious form of that is the thermodynamic argument,

3145
01:46:27,397 --> 01:46:30,043
which is like, okay, where's the energy gonna come from?

3146
01:46:30,043 --> 01:46:31,385
Where's the processor gonna be running?

3147
01:46:31,385 --> 01:46:32,812
Where's the data center gonna be happening?

3148
01:46:32,812 --> 01:46:34,358
How is this gonna be happening in secret such that,

3149
01:46:34,358 --> 01:46:35,607
you know, it's not, you know,

3150
01:46:35,607 --> 01:46:37,375
so that's a practical counter argument

3151
01:46:37,375 --> 01:46:38,803
to the runaway AGI thing.

3152
01:46:38,803 --> 01:46:41,478
I have a but I have and we can argue that, discuss that.

3153
01:46:41,478 --> 01:46:42,844
I have a deeper objection to it,

3154
01:46:42,844 --> 01:46:44,599
which is it's, this is all forecasting.

3155
01:46:44,599 --> 01:46:47,181
It's all modeling, it's all future prediction.

3156
01:46:47,181 --> 01:46:49,436
It's all future hypothesizing.

3157
01:46:49,436 --> 01:46:51,532
It's not science.

3158
01:46:51,532 --> 01:46:52,858
- [Lex] Sure.

3159
01:46:52,858 --> 01:46:55,021
- It is not. It is the opposite of science.

3160
01:46:55,021 --> 01:46:57,473
So the, I'll pull up Carl Sagan extraordinary claims require

3161
01:46:57,473 --> 01:46:59,035
extraordinary proof, right?

3162
01:46:59,035 --> 01:47:00,419
These are extraordinary claims.

3163
01:47:00,419 --> 01:47:04,036
The policies that are being called for right to prevent this

3164
01:47:04,036 --> 01:47:05,636
are of extraordinary magnitude that,

3165
01:47:05,636 --> 01:47:08,556
and I think we're gonna cause extraordinary damage.

3166
01:47:08,556 --> 01:47:10,499
And this is all being done on the basis of something

3167
01:47:10,499 --> 01:47:11,874
that is literally not scientific.

3168
01:47:11,874 --> 01:47:13,373
It's not a testable hypothesis.

3169
01:47:13,373 --> 01:47:15,458
- So the moment you say AI's gonna kill all of us,

3170
01:47:15,458 --> 01:47:16,616
therefore we should ban it,

3171
01:47:16,616 --> 01:47:18,905
or that we should regulate all that kind of stuff,

3172
01:47:18,905 --> 01:47:20,416
that's when it starts getting serious.

3173
01:47:20,416 --> 01:47:22,619
- Or start, you know, military airstrikes and data centers.

3174
01:47:22,619 --> 01:47:23,469
- [Lex] Oh boy.

3175
01:47:23,469 --> 01:47:24,969
- Right? And like.

3176
01:47:26,703 --> 01:47:28,285
- Yeah. This once get starts.

3177
01:47:28,285 --> 01:47:30,161
Well, so starts getting real weird.

3178
01:47:30,161 --> 01:47:31,480
- So here's the problem with Arian cults.

3179
01:47:31,480 --> 01:47:34,116
They have a hard time staying away from violence.

3180
01:47:34,116 --> 01:47:36,699
- Yeah. But violence is so fun.

3181
01:47:38,177 --> 01:47:40,880
- If you're on the right end of it,

3182
01:47:40,880 --> 01:47:42,069
they have a hard time avoiding violence.

3183
01:47:42,069 --> 01:47:43,404
The reason they have a hard time avoiding violence is

3184
01:47:43,404 --> 01:47:46,810
if you actually believe the claim. Right.

3185
01:47:46,810 --> 01:47:48,959
Then what would you do to stop the end of the world?

3186
01:47:48,959 --> 01:47:51,146
Well, you would do anything, right?

3187
01:47:51,146 --> 01:47:53,379
And so, and this is where you get, and again,

3188
01:47:53,379 --> 01:47:55,444
if you just look at the history of Arian and cults,

3189
01:47:55,444 --> 01:47:57,142
this is where you get the people's temple and everybody

3190
01:47:57,142 --> 01:47:58,320
killing themselves in the jungle.

3191
01:47:58,320 --> 01:47:59,709
And this is where you get Charles Manson and, you know,

3192
01:47:59,709 --> 01:48:01,538
sending in to kill the pigs.

3193
01:48:01,538 --> 01:48:03,805
Like, this is the problem with these.

3194
01:48:03,805 --> 01:48:06,032
They have a very hard time to run the line

3195
01:48:06,032 --> 01:48:06,994
at actual violence.

3196
01:48:06,994 --> 01:48:10,351
And I think in this case, I mean, they're already calling

3197
01:48:10,351 --> 01:48:12,734
for it like today and you know,

3198
01:48:12,734 --> 01:48:14,654
where this goes from here is they get more worked up.

3199
01:48:14,654 --> 01:48:16,826
Like I think is like really concerning.

3200
01:48:16,826 --> 01:48:18,523
- Okay. But that's kind of the extremes.

3201
01:48:18,523 --> 01:48:22,647
So, you know, the extremes of anything are I was concerning.

3202
01:48:22,647 --> 01:48:25,247
It's also possible to kind of believe that AI has

3203
01:48:25,247 --> 01:48:28,286
a very high likelihood of killing all of us.

3204
01:48:28,286 --> 01:48:31,786
But and therefore we should maybe consider

3205
01:48:33,644 --> 01:48:36,225
slowing development or regulating,

3206
01:48:36,225 --> 01:48:38,219
so not violence or any of these kinds of things.

3207
01:48:38,219 --> 01:48:39,471
But it's saying like, all right,

3208
01:48:39,471 --> 01:48:41,520
let's take a pause here.

3209
01:48:41,520 --> 01:48:43,923
You know, you biological weapons, nuclear weapons.

3210
01:48:43,923 --> 01:48:45,542
Like whoa, whoa, whoa, whoa, whoa.

3211
01:48:45,542 --> 01:48:49,291
This is like serious stuff. We should be careful.

3212
01:48:49,291 --> 01:48:51,481
So it is possible to kinda have

3213
01:48:51,481 --> 01:48:53,205
a more rational response, right?

3214
01:48:53,205 --> 01:48:55,486
If you believe this risk is real.

3215
01:48:55,486 --> 01:48:56,319
- [Marc] Believe.

3216
01:48:56,319 --> 01:48:58,504
- Yes. So what is it possible to be,

3217
01:48:58,504 --> 01:49:02,667
have a scientific approach to the prediction of the future?

3218
01:49:02,667 --> 01:49:04,500
- I mean, we just went through this with COVID.

3219
01:49:04,500 --> 01:49:06,172
What do we know about modeling?

3220
01:49:06,172 --> 01:49:07,005
- [Lex] Well, I mean.

3221
01:49:07,005 --> 01:49:10,006
- What did we learn about modeling with COVID?

3222
01:49:10,006 --> 01:49:11,441
- [Lex] There's a lot of lessons.

3223
01:49:11,441 --> 01:49:12,839
- They didn't work at all.

3224
01:49:12,839 --> 01:49:14,136
- [Lex] They worked poorly.

3225
01:49:14,136 --> 01:49:16,525
- The models were terrible, the models were useless.

3226
01:49:16,525 --> 01:49:20,146
- I don't know if the models were useless or the people

3227
01:49:20,146 --> 01:49:23,334
interpreting the models and then decentralized institutions

3228
01:49:23,334 --> 01:49:25,888
that were creating policy rapidly based on the models

3229
01:49:25,888 --> 01:49:27,610
and leveraging the models

3230
01:49:27,610 --> 01:49:29,813
in order to support their narratives

3231
01:49:29,813 --> 01:49:32,298
versus actually interpreting the error bars

3232
01:49:32,298 --> 01:49:33,774
and the models and all that kind of stuff.

3233
01:49:33,774 --> 01:49:34,607
- What you had with COVID,

3234
01:49:34,607 --> 01:49:36,416
my view you had with COVID is you had these experts

3235
01:49:36,416 --> 01:49:39,139
showing up and they claimed to be scientists

3236
01:49:39,139 --> 01:49:41,114
and they had no testable hypotheses whatsoever.

3237
01:49:41,114 --> 01:49:42,520
They had a bunch of models.

3238
01:49:42,520 --> 01:49:44,312
They had a bunch of forecasts and they had a bunch

3239
01:49:44,312 --> 01:49:45,251
of theories and they laid these out

3240
01:49:45,251 --> 01:49:46,091
in front of policy makers

3241
01:49:46,091 --> 01:49:48,475
and policy makers freaked out and panicked. Right.

3242
01:49:48,475 --> 01:49:50,031
And implemented a whole bunch of like,

3243
01:49:50,031 --> 01:49:51,725
really like terrible decisions that we're still living

3244
01:49:51,725 --> 01:49:53,674
with the consequences of,

3245
01:49:53,674 --> 01:49:56,426
and there was never any empirical foundation

3246
01:49:56,426 --> 01:49:57,696
to any of the models.

3247
01:49:57,696 --> 01:49:58,933
None of them ever came true.

3248
01:49:58,933 --> 01:49:59,967
- Yeah. To push back.

3249
01:49:59,967 --> 01:50:01,881
There were certainly Baptist and bootleggers

3250
01:50:01,881 --> 01:50:03,714
in the context of this pandemic,

3251
01:50:03,714 --> 01:50:06,413
but there's still a usefulness to models. No.

3252
01:50:06,413 --> 01:50:07,913
- So not if they're,

3253
01:50:07,913 --> 01:50:09,287
I mean not if they're reliably wrong, right?

3254
01:50:09,287 --> 01:50:11,023
Then they're actually like anti-useful. Right.

3255
01:50:11,023 --> 01:50:11,873
They're actually damaging.

3256
01:50:11,873 --> 01:50:13,251
- But what do you do with the pandemic?

3257
01:50:13,251 --> 01:50:15,713
What do you do with any kind of threat?

3258
01:50:15,713 --> 01:50:19,387
Don't you want to kind of have several models to play

3259
01:50:19,387 --> 01:50:22,255
with as part of this discussion of like,

3260
01:50:22,255 --> 01:50:23,731
what the hell do we do here?

3261
01:50:23,731 --> 01:50:24,765
- I mean, do they work?

3262
01:50:24,765 --> 01:50:27,821
Because they're an expectation that they actually like work

3263
01:50:27,821 --> 01:50:29,969
that they have actual predictive value.

3264
01:50:29,969 --> 01:50:32,260
I mean, as far as I can tell with COVID,

3265
01:50:32,260 --> 01:50:34,055
the policymakers just si up themselves into believing

3266
01:50:34,055 --> 01:50:35,713
that there was sub, I mean, look, the scientists,

3267
01:50:35,713 --> 01:50:37,053
the scientists were at fault.

3268
01:50:37,053 --> 01:50:39,394
The quote unquote scientists showed up.

3269
01:50:39,394 --> 01:50:40,606
So I had some insight into this.

3270
01:50:40,606 --> 01:50:41,602
So there was a,

3271
01:50:41,602 --> 01:50:43,145
or remember the Imperial College models

3272
01:50:43,145 --> 01:50:44,907
out of London were the ones that were like,

3273
01:50:44,907 --> 01:50:46,484
these are the gold standard models.

3274
01:50:46,484 --> 01:50:48,218
So a friend of mine runs a big software company

3275
01:50:48,218 --> 01:50:50,007
and he was like, wow, this is like, COVID is really scary.

3276
01:50:50,007 --> 01:50:50,840
And he is like, you know,

3277
01:50:50,840 --> 01:50:52,371
he contacted this research and he is like, you know,

3278
01:50:52,371 --> 01:50:53,204
do you need some help?

3279
01:50:53,204 --> 01:50:54,885
You've been just building this model on your own

3280
01:50:54,885 --> 01:50:55,718
for 20 years.

3281
01:50:55,718 --> 01:50:56,551
Do you need some,

3282
01:50:56,551 --> 01:50:58,165
would you like us our coders to basically restructure it

3283
01:50:58,165 --> 01:50:59,731
so it can be fully adapted for COVID?

3284
01:50:59,731 --> 01:51:01,866
And the guy said yes and sent over the code

3285
01:51:01,866 --> 01:51:03,918
and my friend said it was like the worst spaghetti code

3286
01:51:03,918 --> 01:51:04,751
he's ever seen.

3287
01:51:04,751 --> 01:51:07,208
- That doesn't mean it's not possible to construct

3288
01:51:07,208 --> 01:51:09,755
a good model of pandemic with the correct air bars,

3289
01:51:09,755 --> 01:51:12,563
with a high number of parameters that are continuously,

3290
01:51:12,563 --> 01:51:15,689
many times a day updated as we get more data

3291
01:51:15,689 --> 01:51:16,812
about a pandemic.

3292
01:51:16,812 --> 01:51:20,774
I would like to believe when a pandemic hits the world,

3293
01:51:20,774 --> 01:51:22,763
the best computer scientists in the world,

3294
01:51:22,763 --> 01:51:25,890
the best software engineers respond aggressively

3295
01:51:25,890 --> 01:51:29,333
and as input take the data that we know about the virus

3296
01:51:29,333 --> 01:51:33,293
and it's an output say here is what's happening

3297
01:51:33,293 --> 01:51:35,167
in terms of how quickly it's spreading,

3298
01:51:35,167 --> 01:51:38,019
what that lead in terms of hospitalization and deaths

3299
01:51:38,019 --> 01:51:39,053
and all that kind of stuff.

3300
01:51:39,053 --> 01:51:41,485
Here's how likely, how contagious it likely is.

3301
01:51:41,485 --> 01:51:43,961
Here's how deadly it likely is based

3302
01:51:43,961 --> 01:51:45,169
on different conditions,

3303
01:51:45,169 --> 01:51:46,898
based on different ages and demographics

3304
01:51:46,898 --> 01:51:48,095
and all that kind of stuff.

3305
01:51:48,095 --> 01:51:49,869
So here's the best kinds of policy.

3306
01:51:49,869 --> 01:51:53,214
It feels like you could have models,

3307
01:51:53,214 --> 01:51:56,131
machine learning that like kind of,

3308
01:51:57,128 --> 01:51:59,152
they don't perfectly predict the future,

3309
01:51:59,152 --> 01:52:01,865
but they help you do something

3310
01:52:01,865 --> 01:52:05,532
'cause there's pandemics that are like, meh,

3311
01:52:07,534 --> 01:52:09,040
they don't really do much harm.

3312
01:52:09,040 --> 01:52:10,838
And there's pandemics, you can imagine them,

3313
01:52:10,838 --> 01:52:13,112
they could do a huge amount of harm.

3314
01:52:13,112 --> 01:52:14,978
Like they can kill a lot of people.

3315
01:52:14,978 --> 01:52:19,115
So you should probably have some kind of data-driven models

3316
01:52:19,115 --> 01:52:20,316
that keep updating,

3317
01:52:20,316 --> 01:52:22,957
that allow you to make decisions that based like where,

3318
01:52:22,957 --> 01:52:24,298
how bad is this thing?

3319
01:52:24,298 --> 01:52:28,742
Now you can criticize how horrible all that went

3320
01:52:28,742 --> 01:52:30,601
with the response to this pandemic,

3321
01:52:30,601 --> 01:52:32,865
but I just feel like there might be some value to models.

3322
01:52:32,865 --> 01:52:34,079
- So to be useful at some point

3323
01:52:34,079 --> 01:52:35,452
it has to be predictive. Right?

3324
01:52:35,452 --> 01:52:39,638
So and the easy thing for me to do is to say,

3325
01:52:39,638 --> 01:52:40,610
obviously you're right.

3326
01:52:40,610 --> 01:52:42,060
Obviously I wanna see that just as much as you do.

3327
01:52:42,060 --> 01:52:43,531
'cause anything that makes it easier to navigate

3328
01:52:43,531 --> 01:52:45,291
through society through a wrenching, you know, risk like

3329
01:52:45,291 --> 01:52:46,749
that sounds great.

3330
01:52:46,749 --> 01:52:48,602
You know, the harder objection

3331
01:52:48,602 --> 01:52:50,998
to it is just simply you are trying to model

3332
01:52:50,998 --> 01:52:54,406
a complex dynamic system with 8 billion moving parts.

3333
01:52:54,406 --> 01:52:55,239
Like not possible.

3334
01:52:55,239 --> 01:52:56,127
- [Lex] It's very tough.

3335
01:52:56,127 --> 01:52:58,291
- Can't be done, complex systems can't be done.

3336
01:52:58,291 --> 01:53:00,385
- Machine learning says hold my beer.

3337
01:53:00,385 --> 01:53:01,902
But well, it's possible. No?

3338
01:53:01,902 --> 01:53:02,735
- I don't know.

3339
01:53:02,735 --> 01:53:04,062
I would like to believe that it is.

3340
01:53:04,062 --> 01:53:04,895
I'll put it this way.

3341
01:53:04,895 --> 01:53:06,570
I think where you and I would agree is I think

3342
01:53:06,570 --> 01:53:08,607
we would like that to be the case.

3343
01:53:08,607 --> 01:53:10,626
We are strongly in favor of it.

3344
01:53:10,626 --> 01:53:12,252
I think we would also agree that no such thing

3345
01:53:12,252 --> 01:53:14,330
with respect to COVID or pandemics no such thing.

3346
01:53:14,330 --> 01:53:16,405
At least neither you nor I think are aware.

3347
01:53:16,405 --> 01:53:18,207
I'm not aware of anything like that today.

3348
01:53:18,207 --> 01:53:21,152
- My main worry with the response to the pandemic is

3349
01:53:21,152 --> 01:53:24,022
that same as with aliens,

3350
01:53:24,022 --> 01:53:27,510
is that even if such a thing existed,

3351
01:53:27,510 --> 01:53:29,861
and it's possible it existed,

3352
01:53:29,861 --> 01:53:33,444
the policymakers were not paying attention.

3353
01:53:34,751 --> 01:53:37,231
Like there was no mechanism that allowed those kinds

3354
01:53:37,231 --> 01:53:38,623
of models to percolate all.

3355
01:53:38,623 --> 01:53:40,165
- Oh, I think we had the opposite problem during COVID.

3356
01:53:40,165 --> 01:53:41,122
I think the policymakers,

3357
01:53:41,122 --> 01:53:44,322
I think these people with basically fixed science had

3358
01:53:44,322 --> 01:53:46,738
too much access to the policymakers.

3359
01:53:46,738 --> 01:53:47,571
- Well, right.

3360
01:53:47,571 --> 01:53:49,709
And well, but the policy makers also wanted,

3361
01:53:49,709 --> 01:53:51,719
they had a narrative in mind and they also wanted

3362
01:53:51,719 --> 01:53:54,317
to use whatever model that fit that narrative

3363
01:53:54,317 --> 01:53:55,150
- [Marc] Oh, sure.

3364
01:53:55,150 --> 01:53:55,983
- To help them out.

3365
01:53:55,983 --> 01:53:56,851
So like, it felt like there was a lot of politics

3366
01:53:56,851 --> 01:53:58,070
and not enough science.

3367
01:53:58,070 --> 01:53:59,147
- Although a big part of what was happening,

3368
01:53:59,147 --> 01:54:01,511
a big reason we got lockdowns for as long as we did,

3369
01:54:01,511 --> 01:54:02,935
was because these scientists came in with these

3370
01:54:02,935 --> 01:54:04,014
like doomsday scenarios that were like,

3371
01:54:04,014 --> 01:54:05,692
just like completely off the hook.

3372
01:54:05,692 --> 01:54:07,450
- Scientists in quotes, let's not--

3373
01:54:07,450 --> 01:54:09,139
- [Marc] Quote unquote scientists.

3374
01:54:09,139 --> 01:54:11,162
- Let's not, okay, let's give love science.

3375
01:54:11,162 --> 01:54:12,415
So here's science that is the way out.

3376
01:54:12,415 --> 01:54:14,426
- Science is a process of testing hypotheses.

3377
01:54:14,426 --> 01:54:17,707
Modeling does not involve testable hypotheses. Right.

3378
01:54:17,707 --> 01:54:18,735
Like, I don't even know that.

3379
01:54:18,735 --> 01:54:19,933
I actually don't even know

3380
01:54:19,933 --> 01:54:22,374
that modeling actually qualifies as science.

3381
01:54:22,374 --> 01:54:24,078
Maybe that's a side conversation.

3382
01:54:24,078 --> 01:54:25,619
We could have some time over a beer.

3383
01:54:25,619 --> 01:54:26,954
- Oh, that's a really interesting part.

3384
01:54:26,954 --> 01:54:28,492
What do we do about the future?

3385
01:54:28,492 --> 01:54:29,325
I mean, what's--

3386
01:54:29,325 --> 01:54:31,222
- So number one is when we start with number one,

3387
01:54:31,222 --> 01:54:32,566
humility goes back to this thing

3388
01:54:32,566 --> 01:54:34,364
of how do we determine the truth.

3389
01:54:34,364 --> 01:54:36,152
Number two is we don't believe, you know,

3390
01:54:36,152 --> 01:54:36,985
it's the old,

3391
01:54:36,985 --> 01:54:38,511
I've gotta hammer everything looks like a nail, right?

3392
01:54:38,511 --> 01:54:41,521
I've got, oh, this is one of the reasons I gave you,

3393
01:54:41,521 --> 01:54:42,500
I gave Alexa book,

3394
01:54:42,500 --> 01:54:44,664
which the topic of the book is what happens

3395
01:54:44,664 --> 01:54:46,845
when scientists basically stray off the path

3396
01:54:46,845 --> 01:54:49,292
of technical knowledge and start to weigh in on politics

3397
01:54:49,292 --> 01:54:50,494
and societal issues.

3398
01:54:50,494 --> 01:54:51,943
- In this case, philosophers.

3399
01:54:51,943 --> 01:54:52,977
- Well in this case philosophers.

3400
01:54:52,977 --> 01:54:54,923
But he actually talks in this book about, like Einstein,

3401
01:54:54,923 --> 01:54:56,586
he talks about, actually about the nuclear age in Einstein.

3402
01:54:56,586 --> 01:54:59,198
He talks about the physicists actually doing

3403
01:54:59,198 --> 01:55:00,799
very similar things at the time.

3404
01:55:00,799 --> 01:55:03,339
- The book is When Reason Goes On Holiday,

3405
01:55:03,339 --> 01:55:06,734
Philosophers in Politics by Nevin.

3406
01:55:06,734 --> 01:55:07,567
- And it's just a story.

3407
01:55:07,567 --> 01:55:08,449
It's a story.

3408
01:55:08,449 --> 01:55:09,920
There are other books on this topic,

3409
01:55:09,920 --> 01:55:11,037
but this is a new one that's really good

3410
01:55:11,037 --> 01:55:12,093
this is just a story

3411
01:55:12,093 --> 01:55:14,144
of what happens when experts in a certain domain decide

3412
01:55:14,144 --> 01:55:16,551
to weigh in and become basically social engineers

3413
01:55:16,551 --> 01:55:19,530
and political, you know, basically political advisors.

3414
01:55:19,530 --> 01:55:22,442
And it's just a story of just inning catastrophe. Right.

3415
01:55:22,442 --> 01:55:25,073
And I think that's what happened with COVID again.

3416
01:55:25,073 --> 01:55:26,839
- Yeah. I found this book a highly entertaining

3417
01:55:26,839 --> 01:55:29,035
and eye-opening read filled with amazing anecdote

3418
01:55:29,035 --> 01:55:32,564
of a rationality and craziness by famous Resa philosophers.

3419
01:55:32,564 --> 01:55:34,337
- I definitely, after you read this book,

3420
01:55:34,337 --> 01:55:35,712
you will not look at Einstein the same.

3421
01:55:35,712 --> 01:55:36,592
- [Lex] Oh boy.

3422
01:55:36,592 --> 01:55:37,467
- Yeah.

3423
01:55:37,467 --> 01:55:38,830
- Don't destroy my heroes.

3424
01:55:38,830 --> 01:55:41,683
- He will not be a hero of yours anymore.

3425
01:55:41,683 --> 01:55:43,712
Sorry. You probably couldn't, you shouldn't read the book.

3426
01:55:43,712 --> 01:55:44,545
- All right.

3427
01:55:44,545 --> 01:55:45,378
- But here's the thing.

3428
01:55:45,378 --> 01:55:46,961
The AI risk people,

3429
01:55:47,974 --> 01:55:50,401
they don't even have the COVID model,

3430
01:55:50,401 --> 01:55:51,317
at least not that I'm aware of.

3431
01:55:51,317 --> 01:55:52,150
- [Lex] No.

3432
01:55:52,150 --> 01:55:53,586
- Like there's not even the equivalent of the COVID model.

3433
01:55:53,586 --> 01:55:55,382
They don't even have the spaghetti code.

3434
01:55:55,382 --> 01:55:58,502
They've got a theory and a warning and a this and the that.

3435
01:55:58,502 --> 01:56:01,059
And like, if you ask like, okay, well here's, I mean,

3436
01:56:01,059 --> 01:56:03,652
the ultimate example is, okay, how do we know, right?

3437
01:56:03,652 --> 01:56:04,921
How do we know that an AI is running away?

3438
01:56:04,921 --> 01:56:05,754
Like how do we know

3439
01:56:05,754 --> 01:56:07,943
that the boom takeoff thing is actually happening?

3440
01:56:07,943 --> 01:56:09,563
And the only answer that any of these guys have given

3441
01:56:09,563 --> 01:56:12,138
that I've ever seen is, oh, it's when the loss rate,

3442
01:56:12,138 --> 01:56:15,278
the loss function and the training drops, right?

3443
01:56:15,278 --> 01:56:17,407
That's when you need to like shut down the data center.

3444
01:56:17,407 --> 01:56:18,395
Right? And it's like,

3445
01:56:18,395 --> 01:56:19,292
well that's also what happens

3446
01:56:19,292 --> 01:56:21,086
when you're successfully training a model.

3447
01:56:21,086 --> 01:56:24,086
Like, what even this is not science,

3448
01:56:26,935 --> 01:56:28,637
this is not, it's not anything, it's not a model,

3449
01:56:28,637 --> 01:56:29,637
it's not anything.

3450
01:56:29,637 --> 01:56:30,970
There's nothing to arguing with.

3451
01:56:30,970 --> 01:56:32,543
It is like, you know, punching jello, like there,

3452
01:56:32,543 --> 01:56:34,091
there's what do you even respond to?

3453
01:56:34,091 --> 01:56:35,784
- So just put push back on that.

3454
01:56:35,784 --> 01:56:38,721
I don't think they have good metrics

3455
01:56:38,721 --> 01:56:40,103
of when the film is happening.

3456
01:56:40,103 --> 01:56:41,814
But I think it's possible to have that.

3457
01:56:41,814 --> 01:56:44,611
Like just as you speak now,

3458
01:56:44,611 --> 01:56:47,888
I mean it's possible to imagine there could be measures.

3459
01:56:47,888 --> 01:56:48,951
- It's been 20 years.

3460
01:56:48,951 --> 01:56:49,784
- No, for sure.

3461
01:56:49,784 --> 01:56:52,895
But it is been only weeks since we had a big enough

3462
01:56:52,895 --> 01:56:54,302
breakthrough in language models.

3463
01:56:54,302 --> 01:56:56,391
We can start to actually have this,

3464
01:56:56,391 --> 01:56:59,565
the thing is the AI doer stuff didn't have

3465
01:56:59,565 --> 01:57:01,590
any actual systems to really work with.

3466
01:57:01,590 --> 01:57:04,164
And now there's real systems you can start to analyze like,

3467
01:57:04,164 --> 01:57:05,430
how does this stuff go wrong?

3468
01:57:05,430 --> 01:57:07,873
And I think you kind of agree that there is

3469
01:57:07,873 --> 01:57:09,614
a lot of risks that we can analyze.

3470
01:57:09,614 --> 01:57:11,923
The benefits outweigh the risks in many cases.

3471
01:57:11,923 --> 01:57:13,556
- Well, the risks are not existential.

3472
01:57:13,556 --> 01:57:14,623
- [Lex] Yes. Well.

3473
01:57:14,623 --> 01:57:17,403
- Not in the phone paper clip. Let me, okay.

3474
01:57:17,403 --> 01:57:19,408
There's another slide of hand that you just alluded to.

3475
01:57:19,408 --> 01:57:20,467
There's another slide of hand that happens,

3476
01:57:20,467 --> 01:57:21,300
which is very interesting.

3477
01:57:21,300 --> 01:57:23,237
- I'm very good at the slide of hand thing.

3478
01:57:23,237 --> 01:57:24,551
- Which is very not scientific.

3479
01:57:24,551 --> 01:57:26,367
So the book Super Intelligence, right,

3480
01:57:26,367 --> 01:57:27,884
which is like the Nick Bostrom's book,

3481
01:57:27,884 --> 01:57:29,557
which is like the origin of a lot of this stuff,

3482
01:57:29,557 --> 01:57:30,741
which was written, you know, whatever,

3483
01:57:30,741 --> 01:57:32,145
10 years ago or something.

3484
01:57:32,145 --> 01:57:33,915
So he does this really fascinating thing in the book,

3485
01:57:33,915 --> 01:57:37,996
which is he basically says there are many possible routes

3486
01:57:37,996 --> 01:57:40,861
to machine intelligence, to artificial intelligence.

3487
01:57:40,861 --> 01:57:42,568
And he describes all the different routes

3488
01:57:42,568 --> 01:57:44,431
to artificial intelligence, all the different possible,

3489
01:57:44,431 --> 01:57:46,415
everything from biological augmentation through to,

3490
01:57:46,415 --> 01:57:48,704
you know, all these different things.

3491
01:57:48,704 --> 01:57:51,075
One of the ones that he does not describe is

3492
01:57:51,075 --> 01:57:52,957
large language models because of course

3493
01:57:52,957 --> 01:57:54,736
the book was written before they were invented.

3494
01:57:54,736 --> 01:57:56,628
And so they didn't exist.

3495
01:57:56,628 --> 01:57:58,904
In the book, he describes them all

3496
01:57:58,904 --> 01:57:59,964
and then he proceeds to treat

3497
01:57:59,964 --> 01:58:02,128
them all as if they're exactly the same thing.

3498
01:58:02,128 --> 01:58:04,075
He presents them all as sort of an equivalent risk to be

3499
01:58:04,075 --> 01:58:05,651
dealt with in an equivalent way to be thought

3500
01:58:05,651 --> 01:58:06,484
about the same way.

3501
01:58:06,484 --> 01:58:07,867
And then the risk, the quote unquote risk

3502
01:58:07,867 --> 01:58:09,089
that's actually emerged is actually

3503
01:58:09,089 --> 01:58:10,223
a completely different technology

3504
01:58:10,223 --> 01:58:11,249
than he was even imagining.

3505
01:58:11,249 --> 01:58:12,817
And yet all of his theories and beliefs are being

3506
01:58:12,817 --> 01:58:14,440
transplanted by this movement,

3507
01:58:14,440 --> 01:58:15,634
like straight onto this new technology.

3508
01:58:15,634 --> 01:58:17,636
And so again, like there's no other area

3509
01:58:17,636 --> 01:58:20,573
of science or technology where you do that.

3510
01:58:20,573 --> 01:58:23,184
Like when you're dealing with like organic chemistry

3511
01:58:23,184 --> 01:58:26,038
versus inorganic chemistry, you don't just like say, oh,

3512
01:58:26,038 --> 01:58:28,207
with respect to like either one, basically maybe, you know,

3513
01:58:28,207 --> 01:58:30,023
growing up in eating the world or something,

3514
01:58:30,023 --> 01:58:31,529
like they're just gonna operate the same way.

3515
01:58:31,529 --> 01:58:32,491
Like you don't.

3516
01:58:32,491 --> 01:58:33,816
- But you can start talking about like,

3517
01:58:33,816 --> 01:58:36,717
as we get more and more actual systems

3518
01:58:36,717 --> 01:58:38,766
that start to get more and more intelligent,

3519
01:58:38,766 --> 01:58:39,832
you can start to actually have

3520
01:58:39,832 --> 01:58:41,735
more scientific arguments here.

3521
01:58:41,735 --> 01:58:42,568
- [Marc] Oh yeah.

3522
01:58:42,568 --> 01:58:44,246
- Like, you know, high level,

3523
01:58:44,246 --> 01:58:46,290
you can talk about the threat of autonomous weapon systems

3524
01:58:46,290 --> 01:58:49,662
back before we had any automation in the military.

3525
01:58:49,662 --> 01:58:52,101
And that would be like very fuzzy kind of logic.

3526
01:58:52,101 --> 01:58:55,554
But the more and more you have drones that are becoming

3527
01:58:55,554 --> 01:58:58,252
more and more autonomous, you can start imagining, okay,

3528
01:58:58,252 --> 01:59:00,656
what does that actually look like and what's the actual

3529
01:59:00,656 --> 01:59:02,101
threat of autonomous weapons systems?

3530
01:59:02,101 --> 01:59:03,202
How does it go wrong?

3531
01:59:03,202 --> 01:59:05,788
And still it's very vague,

3532
01:59:05,788 --> 01:59:09,057
but you start to get a sense of like, all right,

3533
01:59:09,057 --> 01:59:11,711
it should probably be illegal

3534
01:59:11,711 --> 01:59:15,878
or wrong or not allowed to do like mass deployment

3535
01:59:17,061 --> 01:59:18,912
of fully autonomous drones

3536
01:59:18,912 --> 01:59:21,797
that are doing aerial strikes.

3537
01:59:21,797 --> 01:59:22,630
- [Marc] Oh no.

3538
01:59:22,630 --> 01:59:23,463
- On large areas.

3539
01:59:23,463 --> 01:59:24,309
- [Marc] I think it should be required.

3540
01:59:24,309 --> 01:59:25,421
- Right? So that's a no.

3541
01:59:25,421 --> 01:59:26,444
- No, no. I think it should be required

3542
01:59:26,444 --> 01:59:30,558
that only aerial vehicles are automated.

3543
01:59:30,558 --> 01:59:31,773
- Okay. So you wanna go the other way?

3544
01:59:31,773 --> 01:59:32,666
- I wanna go the other way.

3545
01:59:32,666 --> 01:59:34,082
- So that, okay.

3546
01:59:34,082 --> 01:59:35,669
- I think it's obvious that the machine is gonna make

3547
01:59:35,669 --> 01:59:38,427
a better decision than the human pilot.

3548
01:59:38,427 --> 01:59:40,338
I think it's obvious that it's in the best interest

3549
01:59:40,338 --> 01:59:42,598
of both the attacker and the defender and humanity at large.

3550
01:59:42,598 --> 01:59:44,179
If machines are making more of these decisions

3551
01:59:44,179 --> 01:59:45,012
than not people,

3552
01:59:45,012 --> 01:59:47,430
I think people make terrible decisions in times of war.

3553
01:59:47,430 --> 01:59:50,275
- But like, there's ways this can go wrong too, right?

3554
01:59:50,275 --> 01:59:53,071
- Well, it wars go terribly wrong now.

3555
01:59:53,071 --> 01:59:54,692
This goes back to the whole,

3556
01:59:54,692 --> 01:59:56,462
this is that whole thing about like the self-drive.

3557
01:59:56,462 --> 01:59:57,532
Does the self-driving car need to be perfect

3558
01:59:57,532 --> 02:00:00,052
versus does it need to be better than the human driver?

3559
02:00:00,052 --> 02:00:01,668
Does the automated drone need to be perfect

3560
02:00:01,668 --> 02:00:02,946
or does it need to be better

3561
02:00:02,946 --> 02:00:05,080
than a human pilot at making decisions

3562
02:00:05,080 --> 02:00:07,458
under enormous amounts of stress and uncertainty?

3563
02:00:07,458 --> 02:00:09,541
- Yeah, well, on average,

3564
02:00:10,793 --> 02:00:14,424
the worry that AI folks have is the runaway.

3565
02:00:14,424 --> 02:00:15,890
- They're gonna come alive. Right?

3566
02:00:15,890 --> 02:00:17,355
That then again, that's the slight of hand, right.

3567
02:00:17,355 --> 02:00:20,544
- Or not not come alive. Well, no, hold on a second.

3568
02:00:20,544 --> 02:00:22,254
You lose control as well.

3569
02:00:22,254 --> 02:00:23,087
You lose control.

3570
02:00:23,087 --> 02:00:24,746
- But then they're gonna develop goals of their own.

3571
02:00:24,746 --> 02:00:26,353
They're gonna develop a mind of their own,

3572
02:00:26,353 --> 02:00:27,795
they're gonna develop their own. Right.

3573
02:00:27,795 --> 02:00:30,802
- No more, more like Chernobyl style meltdown,

3574
02:00:30,802 --> 02:00:34,969
like just bugs in the code accidentally, you know,

3575
02:00:36,414 --> 02:00:39,580
force you like the results in the bombing

3576
02:00:39,580 --> 02:00:42,494
of like large civilian areas.

3577
02:00:42,494 --> 02:00:43,327
- [Marc] Okay.

3578
02:00:43,327 --> 02:00:45,647
And to a degree that's not possible

3579
02:00:45,647 --> 02:00:49,354
in the current military strategies,

3580
02:00:49,354 --> 02:00:50,356
- [Marc] I don't know.

3581
02:00:50,356 --> 02:00:51,189
- Control by humans.

3582
02:00:51,189 --> 02:00:52,442
- Well, actually we've been doing a lot of mass bombings

3583
02:00:52,442 --> 02:00:53,690
to cities for a very long time.

3584
02:00:53,690 --> 02:00:55,655
- Yes. And a lot of civilians died.

3585
02:00:55,655 --> 02:00:56,643
- And a lot of civilians died.

3586
02:00:56,643 --> 02:00:59,401
And if you watch the documentary, the Fog of War McNamara,

3587
02:00:59,401 --> 02:01:01,367
it spends a big part of it talking about the fire bombing

3588
02:01:01,367 --> 02:01:02,790
of the Japanese cities.

3589
02:01:02,790 --> 02:01:05,041
Burning them straight to the ground. Right.

3590
02:01:05,041 --> 02:01:06,074
The devastation in Japan,

3591
02:01:06,074 --> 02:01:08,885
American military fire bombing the cities in Japan was

3592
02:01:08,885 --> 02:01:11,297
considerably bigger devastation than the use of nukes.

3593
02:01:11,297 --> 02:01:13,214
Right. So we've been doing that for a long time.

3594
02:01:13,214 --> 02:01:14,486
We also did that to Germany,

3595
02:01:14,486 --> 02:01:16,459
by the way Germany did that to us, right?

3596
02:01:16,459 --> 02:01:17,918
Like that's an old tradition.

3597
02:01:17,918 --> 02:01:19,122
The minute we got airplanes,

3598
02:01:19,122 --> 02:01:20,539
we started doing indiscriminate bombing.

3599
02:01:20,539 --> 02:01:21,530
- So one of the things--

3600
02:01:21,530 --> 02:01:22,363
- [Marc] We're still doing it.

3601
02:01:22,363 --> 02:01:24,680
- The modern US military can do

3602
02:01:24,680 --> 02:01:26,371
with technology with automation,

3603
02:01:26,371 --> 02:01:27,930
but technology more broadly is

3604
02:01:27,930 --> 02:01:30,122
higher and higher precision strikes.

3605
02:01:30,122 --> 02:01:31,014
- Yeah, I was saying,

3606
02:01:31,014 --> 02:01:32,817
so precision is obviously precision

3607
02:01:32,817 --> 02:01:34,545
and this is a (indistinct) right?

3608
02:01:34,545 --> 02:01:35,527
So there was this big advance

3609
02:01:35,527 --> 02:01:37,265
this big advance called the (indistinct)

3610
02:01:37,265 --> 02:01:39,267
which basically was strapping a GPS transceiver

3611
02:01:39,267 --> 02:01:41,096
to an unguided bomb and turning it

3612
02:01:41,096 --> 02:01:42,354
into a guided bomb.

3613
02:01:42,354 --> 02:01:43,331
And yeah, that's great.

3614
02:01:43,331 --> 02:01:44,539
Like look, that's been a big advance,

3615
02:01:44,539 --> 02:01:46,876
but, and that's like a baby version of this question,

3616
02:01:46,876 --> 02:01:48,763
which is okay, do you want like the human pilot,

3617
02:01:48,763 --> 02:01:49,960
like guessing where the bomb's gonna land?

3618
02:01:49,960 --> 02:01:51,292
Or do you want like the machine like guiding the bomb

3619
02:01:51,292 --> 02:01:52,471
to his destination?

3620
02:01:52,471 --> 02:01:54,178
That's a baby version of the question.

3621
02:01:54,178 --> 02:01:55,206
The next version of the question is,

3622
02:01:55,206 --> 02:01:56,604
do you want the human or the machine deciding

3623
02:01:56,604 --> 02:01:57,791
whether to drop the bomb?

3624
02:01:57,791 --> 02:01:59,665
Everybody just assumes the human's gonna do a better job

3625
02:01:59,665 --> 02:02:02,071
for what I think are fundamentally suspicious reasons.

3626
02:02:02,071 --> 02:02:03,811
- Emotional, psychological reasons.

3627
02:02:03,811 --> 02:02:05,870
- Yeah. I think it's very clear that the machine's gonna do

3628
02:02:05,870 --> 02:02:06,835
a better job making that decision

3629
02:02:06,835 --> 02:02:10,327
'cause the humans making that decision are got awful.

3630
02:02:10,327 --> 02:02:11,176
Just terrible.

3631
02:02:11,176 --> 02:02:12,009
- [Lex] Yeah.

3632
02:02:12,009 --> 02:02:12,842
- Right. And so yeah.

3633
02:02:12,842 --> 02:02:14,095
So this is the thing.

3634
02:02:14,095 --> 02:02:15,469
And then let's get to the, there was,

3635
02:02:15,469 --> 02:02:16,455
can I one more slide of hand?

3636
02:02:16,455 --> 02:02:17,288
- [Lex] Yes.

3637
02:02:17,288 --> 02:02:18,121
- It was in--

3638
02:02:18,121 --> 02:02:19,105
- Sure. Please.

3639
02:02:19,105 --> 02:02:20,525
I'm a magician. You could say.

3640
02:02:20,525 --> 02:02:21,358
- One more slight of hand.

3641
02:02:21,358 --> 02:02:23,304
These things are gonna be so smart, right?

3642
02:02:23,304 --> 02:02:25,029
That they're gonna be able to destroy the world and wreak

3643
02:02:25,029 --> 02:02:26,718
havoc and like do all this stuff and plan and do all this

3644
02:02:26,718 --> 02:02:28,766
stuff and evade us and have all their secret things

3645
02:02:28,766 --> 02:02:30,840
and their secret factories and all this stuff.

3646
02:02:30,840 --> 02:02:33,415
But they're so stupid that they're gonna get like,

3647
02:02:33,415 --> 02:02:34,570
tangled up in their code and that's

3648
02:02:34,570 --> 02:02:35,663
they're not gonna come alive,

3649
02:02:35,663 --> 02:02:37,030
but there's gonna be some bug that's gonna cause them

3650
02:02:37,030 --> 02:02:38,878
to like turn us all on a paper like that.

3651
02:02:38,878 --> 02:02:40,815
They're not gonna be genius in every way other

3652
02:02:40,815 --> 02:02:43,634
than the actual bad goal.

3653
02:02:43,634 --> 02:02:45,488
And it's just like, and that's just like a,

3654
02:02:45,488 --> 02:02:47,626
like ridiculous like discrepancy.

3655
02:02:47,626 --> 02:02:49,627
And you can prove this today,

3656
02:02:49,627 --> 02:02:52,587
you can actually address this today for the first time

3657
02:02:52,587 --> 02:02:54,342
with LLMs which is you can actually ask

3658
02:02:54,342 --> 02:02:56,925
LLMs to resolve moral dilemmas.

3659
02:02:58,131 --> 02:03:00,504
So you can create the scenario, you know, dot, dot,

3660
02:03:00,504 --> 02:03:02,300
dot this, that, this, that, this, that.

3661
02:03:02,300 --> 02:03:04,534
What would you as the AI do in the circumstance?

3662
02:03:04,534 --> 02:03:05,838
And they don't just say destroy all humans,

3663
02:03:05,838 --> 02:03:06,786
destroy all humans.

3664
02:03:06,786 --> 02:03:09,907
They will give you actually very nuanced moral,

3665
02:03:09,907 --> 02:03:12,689
practical trade-off oriented answers.

3666
02:03:12,689 --> 02:03:14,558
And so we actually already have the kind of AI

3667
02:03:14,558 --> 02:03:16,320
that can actually like, think this through

3668
02:03:16,320 --> 02:03:17,628
and can actually like,

3669
02:03:17,628 --> 02:03:19,228
you know, reason about goals.

3670
02:03:19,228 --> 02:03:22,180
- Well, the hope is that AGI

3671
02:03:22,180 --> 02:03:23,874
or like various superintelligent

3672
02:03:23,874 --> 02:03:26,396
systems have some of the nuance that LLMs have

3673
02:03:26,396 --> 02:03:28,391
and the intuition is they most likely will

3674
02:03:28,391 --> 02:03:32,162
because even these LLMs have the nuance.

3675
02:03:32,162 --> 02:03:35,175
- LLMs are really, this is actually worth spending a moment

3676
02:03:35,175 --> 02:03:36,530
on LLMs are really interesting

3677
02:03:36,530 --> 02:03:38,245
to have moral conversations with.

3678
02:03:38,245 --> 02:03:40,379
And that I just,

3679
02:03:40,379 --> 02:03:42,403
I didn't expect I'd be having a moral conversation

3680
02:03:42,403 --> 02:03:43,776
with the machine in my lifetime.

3681
02:03:43,776 --> 02:03:45,656
- Wait, and let's remember we're not really having

3682
02:03:45,656 --> 02:03:46,840
a conversation with the machine

3683
02:03:46,840 --> 02:03:48,342
where we're having a conversation

3684
02:03:48,342 --> 02:03:49,971
with the entirety of the collective intelligence

3685
02:03:49,971 --> 02:03:51,041
of the human species.

3686
02:03:51,041 --> 02:03:52,696
- Exactly. Yes. Correct.

3687
02:03:52,696 --> 02:03:55,311
- But it's possible to imagine autonomous weapons systems

3688
02:03:55,311 --> 02:03:57,311
that are not using LLMs.

3689
02:03:58,193 --> 02:04:01,277
- But if they're smart enough to be scary,

3690
02:04:01,277 --> 02:04:05,201
where are they not smart enough to be wise?

3691
02:04:05,201 --> 02:04:06,695
Like, that's the part where it's like,

3692
02:04:06,695 --> 02:04:08,427
I don't know how you get the one without the other.

3693
02:04:08,427 --> 02:04:10,173
- Is it possible to be super intelligent

3694
02:04:10,173 --> 02:04:11,636
without being super wise?

3695
02:04:11,636 --> 02:04:13,074
- Well, again, you're back to that.

3696
02:04:13,074 --> 02:04:15,139
I mean, then you're back to a classic autistic computer,

3697
02:04:15,139 --> 02:04:18,165
right? Like you're back to just like a blind rule follower.

3698
02:04:18,165 --> 02:04:20,047
I've got this like core, it's the paperclip thing.

3699
02:04:20,047 --> 02:04:21,688
I've got this core rule and I'm just gonna follow it

3700
02:04:21,688 --> 02:04:22,521
to the end of the earth.

3701
02:04:22,521 --> 02:04:23,354
And it's like, well,

3702
02:04:23,354 --> 02:04:24,721
but everything you're gonna be doing execute that rule is

3703
02:04:24,721 --> 02:04:26,126
gonna be super genius level that humans aren't gonna

3704
02:04:26,126 --> 02:04:27,270
be able to counter.

3705
02:04:27,270 --> 02:04:29,825
It's a mismatch in the definition

3706
02:04:29,825 --> 02:04:32,002
of what the system's capable of.

3707
02:04:32,002 --> 02:04:33,754
- Unlikely but not impossible, I think.

3708
02:04:33,754 --> 02:04:35,849
- But again, here you get to like, okay, like.

3709
02:04:35,849 --> 02:04:39,864
- No, I'm not saying when it's unlikely but not impossible.

3710
02:04:39,864 --> 02:04:41,528
If it's unlikely, that means

3711
02:04:41,528 --> 02:04:43,792
the fear should be correctly calibrated.

3712
02:04:43,792 --> 02:04:45,978
- Extraordinary claims require extraordinary proof.

3713
02:04:45,978 --> 02:04:48,695
- Well, okay, so one interesting sort of tangent,

3714
02:04:48,695 --> 02:04:50,345
I would love to take on this because you mentioned this

3715
02:04:50,345 --> 02:04:54,382
in the essay about nuclear, which was also, I mean,

3716
02:04:54,382 --> 02:04:58,793
you don't shy away from a little bit of of a spicy take.

3717
02:04:58,793 --> 02:05:02,212
So Robert Oppenheimer famously said,

3718
02:05:02,212 --> 02:05:04,580
now I am become death the destroyer of worlds

3719
02:05:04,580 --> 02:05:07,453
as he witnessed the first destination of a nuclear weapon

3720
02:05:07,453 --> 02:05:09,036
on July 16th, 1945.

3721
02:05:10,128 --> 02:05:13,775
And you write an interesting historical perspective,

3722
02:05:13,775 --> 02:05:16,623
"Recall that John Van Neuman responded

3723
02:05:16,623 --> 02:05:19,525
to Robert Oppenheimer's famous hand wringing about the role

3724
02:05:19,525 --> 02:05:21,020
of creating nuclear weapons,

3725
02:05:21,020 --> 02:05:24,187
which you note helped end World War II

3726
02:05:25,144 --> 02:05:29,236
and prevent World War III with some people confess

3727
02:05:29,236 --> 02:05:32,024
guilt to claim credit for the sin."

3728
02:05:32,024 --> 02:05:34,023
And you also mentioned that Truman was harsher

3729
02:05:34,023 --> 02:05:35,783
after meeting Oppenheimer.

3730
02:05:35,783 --> 02:05:39,199
He said that "Don't let that cry baby in here again."

3731
02:05:39,199 --> 02:05:42,949
- Real quote, by the way, from Dean Atchison.

3732
02:05:45,125 --> 02:05:45,995
- Boy.

3733
02:05:45,995 --> 02:05:49,124
- 'Cause Oppenheimer didn't just say the famous line.

3734
02:05:49,124 --> 02:05:49,957
- [Lex] Yeah.

3735
02:05:49,957 --> 02:05:51,429
- He then spent years going around basically moaning him,

3736
02:05:51,429 --> 02:05:52,775
you know, going on TV and going into going

3737
02:05:52,775 --> 02:05:53,940
into the White House and basically like,

3738
02:05:53,940 --> 02:05:55,465
just like doing this hair shirt, you know,

3739
02:05:55,465 --> 02:05:57,647
thing self, you know, this sort of self-critical like,

3740
02:05:57,647 --> 02:05:59,518
oh my god, I can't believe how awful I am.

3741
02:05:59,518 --> 02:06:03,101
- So he's widely considered perhaps of the,

3742
02:06:04,336 --> 02:06:07,158
because of the hang ringing as the father of the tom bomb.

3743
02:06:07,158 --> 02:06:08,005
- [Marc] Yeah.

3744
02:06:08,005 --> 02:06:11,818
- This is Van Norman's criticism of him is he tried to have

3745
02:06:11,818 --> 02:06:12,996
his cake and eat it too.

3746
02:06:12,996 --> 02:06:13,829
Like he wanted to

3747
02:06:13,829 --> 02:06:16,244
and Van Norman of course a very different

3748
02:06:16,244 --> 02:06:18,348
kind of personality and he's just like, yeah, good.

3749
02:06:18,348 --> 02:06:20,981
This is like an incredibly useful thing. I'm glad we did it.

3750
02:06:20,981 --> 02:06:25,414
- Yeah. Well Van Norman is is widely credit as being

3751
02:06:25,414 --> 02:06:28,195
one of the smartest humans of the 20th century.

3752
02:06:28,195 --> 02:06:30,787
Certain people. Everybody says like,

3753
02:06:30,787 --> 02:06:32,281
this is the smartest person I've ever met

3754
02:06:32,281 --> 02:06:33,459
when they've met him.

3755
02:06:33,459 --> 02:06:37,709
Anyway, that doesn't mean, smart doesn't mean wise.

3756
02:06:39,340 --> 02:06:41,834
So yeah, I would love to sort of,

3757
02:06:41,834 --> 02:06:44,675
can you make the case both for and against the critique

3758
02:06:44,675 --> 02:06:45,667
of Oppenheimer here?

3759
02:06:45,667 --> 02:06:49,154
'Cause we're talking about nuclear weapons.

3760
02:06:49,154 --> 02:06:50,917
Boy, do they seem dangerous?

3761
02:06:50,917 --> 02:06:52,347
- Well so, the critique goes deeper

3762
02:06:52,347 --> 02:06:53,381
and I left this out.

3763
02:06:53,381 --> 02:06:54,340
Here's the real substance,

3764
02:06:54,340 --> 02:06:56,160
I left it out 'cause I didn't wanna dwell

3765
02:06:56,160 --> 02:06:58,171
on nukes in my AI paper.

3766
02:06:58,171 --> 02:07:00,541
But here's the deeper thing that happened

3767
02:07:00,541 --> 02:07:02,206
and I'm really curious, this movie coming out this summer,

3768
02:07:02,206 --> 02:07:03,897
I'm really curious to see how far he pushes this.

3769
02:07:03,897 --> 02:07:05,837
'cause this is the real drama in the story, which is,

3770
02:07:05,837 --> 02:07:07,872
it wasn't just a question of our nukes, good or bad,

3771
02:07:07,872 --> 02:07:10,373
it was a question of should Russia also have them?

3772
02:07:10,373 --> 02:07:13,553
And what actually happened was Russia got

3773
02:07:13,553 --> 02:07:15,581
the American invented the bomb.

3774
02:07:15,581 --> 02:07:16,839
Russia got the bomb,

3775
02:07:16,839 --> 02:07:18,830
they got the bomb through espionage,

3776
02:07:18,830 --> 02:07:20,197
they got American and you know,

3777
02:07:20,197 --> 02:07:22,269
they got American scientists and foreign scientists working

3778
02:07:22,269 --> 02:07:23,551
on the American project.

3779
02:07:23,551 --> 02:07:26,774
Some combination of the two basically gave the Russians

3780
02:07:26,774 --> 02:07:28,168
the designs for the bomb.

3781
02:07:28,168 --> 02:07:29,912
And that's how the Russians got the bomb.

3782
02:07:29,912 --> 02:07:33,175
There's this dispute to this day of Oppenheimer's role

3783
02:07:33,175 --> 02:07:36,357
in that if you read all the histories,

3784
02:07:36,357 --> 02:07:38,483
the kind of composite picture, and by the way,

3785
02:07:38,483 --> 02:07:39,981
we now know a lot actually about Soviet espionage

3786
02:07:39,981 --> 02:07:41,226
in that era 'cause there's been

3787
02:07:41,226 --> 02:07:43,122
all this declassified material in the last 20 years

3788
02:07:43,122 --> 02:07:46,227
that actually shows a lot of very interesting things.

3789
02:07:46,227 --> 02:07:47,241
But if you kinda read all the histories,

3790
02:07:47,241 --> 02:07:49,231
which you kinda get is Oppenheimer himself probably was not

3791
02:07:49,231 --> 02:07:52,105
he probably did not hand over the nuclear secrets himself.

3792
02:07:52,105 --> 02:07:54,419
However, he was close to many people who did.

3793
02:07:54,419 --> 02:07:56,021
Including family members.

3794
02:07:56,021 --> 02:07:58,001
And there were other members of the Manhattan Project

3795
02:07:58,001 --> 02:08:01,548
who were Russian, Soviet SS and did hand over the bomb.

3796
02:08:01,548 --> 02:08:05,202
And so the view of that Oppenheimer and people like him had

3797
02:08:05,202 --> 02:08:07,937
that this thing is awful and terrible and oh my god.

3798
02:08:07,937 --> 02:08:08,770
And you know,

3799
02:08:08,770 --> 02:08:11,789
all this stuff you could argue fed into this ethos

3800
02:08:11,789 --> 02:08:13,773
at the time that resulted in people thinking

3801
02:08:13,773 --> 02:08:15,075
that the Baptists thinking

3802
02:08:15,075 --> 02:08:16,864
that the only principle thing to do was to give

3803
02:08:16,864 --> 02:08:18,395
the Russians the bomb.

3804
02:08:18,395 --> 02:08:21,074
And so the moral beliefs

3805
02:08:21,074 --> 02:08:23,067
on this thing and the public discussion

3806
02:08:23,067 --> 02:08:25,737
and the role that the inventors of this technology play,

3807
02:08:25,737 --> 02:08:26,743
this is the point of this book,

3808
02:08:26,743 --> 02:08:28,587
when they kind of take on this sort of public intellectual,

3809
02:08:28,587 --> 02:08:31,808
moral kind of thing, it can have real consequences, right?

3810
02:08:31,808 --> 02:08:34,028
Because we live in a very different world today

3811
02:08:34,028 --> 02:08:35,922
because Russia got the bomb than we would've lived

3812
02:08:35,922 --> 02:08:37,497
in had they not gotten the bomb right.

3813
02:08:37,497 --> 02:08:38,446
The entire 20th century,

3814
02:08:38,446 --> 02:08:40,006
second half of the 20th century would've played out

3815
02:08:40,006 --> 02:08:42,123
very different had those people not given Russia the bomb.

3816
02:08:42,123 --> 02:08:44,836
And so the stakes were very high then.

3817
02:08:44,836 --> 02:08:48,416
The good news today is nobody's sitting here today,

3818
02:08:48,416 --> 02:08:50,963
I don't think worrying about like an analogous situation

3819
02:08:50,963 --> 02:08:51,955
with respect to like,

3820
02:08:51,955 --> 02:08:53,971
I'm not really worried that Sam Altman's gonna decide

3821
02:08:53,971 --> 02:08:56,946
to give, you know, the Chinese, the design for AI,

3822
02:08:56,946 --> 02:08:59,052
although he did just speak at a Chinese conference,

3823
02:08:59,052 --> 02:08:59,966
which is in interesting.

3824
02:08:59,966 --> 02:09:02,538
But however, I don't think that's what's at play here,

3825
02:09:02,538 --> 02:09:04,657
but what's at play here are all these other fundamental

3826
02:09:04,657 --> 02:09:06,608
issues around what do we believe about this

3827
02:09:06,608 --> 02:09:08,383
and then what laws and regulations and restrictions

3828
02:09:08,383 --> 02:09:09,671
that we're gonna put on it.

3829
02:09:09,671 --> 02:09:12,347
And that's where I draw like a direct straight line.

3830
02:09:12,347 --> 02:09:14,435
And anyway, and my reading of the history on nukes is

3831
02:09:14,435 --> 02:09:17,179
like the people who were doing the full hair shirt public,

3832
02:09:17,179 --> 02:09:18,066
this is awful.

3833
02:09:18,066 --> 02:09:18,899
This is terrible.

3834
02:09:18,899 --> 02:09:20,589
Actually had like catastrophically bad results

3835
02:09:20,589 --> 02:09:22,577
from taking those views.

3836
02:09:22,577 --> 02:09:24,649
And that's what I'm worried it's gonna happen again.

3837
02:09:24,649 --> 02:09:26,493
- But is there a case to be made that you really need

3838
02:09:26,493 --> 02:09:28,132
to wake the public up to the dangers

3839
02:09:28,132 --> 02:09:30,264
of nuclear weapons when they were first dropped?

3840
02:09:30,264 --> 02:09:33,113
Like really like educate them on like,

3841
02:09:33,113 --> 02:09:35,706
this is extremely dangerous and destructive weapon.

3842
02:09:35,706 --> 02:09:38,134
- I think the education kind of happened quick

3843
02:09:38,134 --> 02:09:38,967
and early, like--

3844
02:09:38,967 --> 02:09:39,800
- [Lex] How?

3845
02:09:39,800 --> 02:09:40,689
- It was pretty obvious.

3846
02:09:40,689 --> 02:09:41,522
- [Lex] How?

3847
02:09:41,522 --> 02:09:43,442
- We dropped one bomb and destroyed an entire city.

3848
02:09:43,442 --> 02:09:45,322
- Yeah. So 80,000 people dead.

3849
02:09:45,322 --> 02:09:46,189
- [Marc] Yep.

3850
02:09:46,189 --> 02:09:47,022
- But.

3851
02:09:47,022 --> 02:09:47,980
- [Marc] And look. But--

3852
02:09:47,980 --> 02:09:50,048
- I don't like the reporting of that.

3853
02:09:50,048 --> 02:09:52,256
You can report that in all kinds of ways.

3854
02:09:52,256 --> 02:09:53,089
- [Marc] Oh, there wars.

3855
02:09:53,089 --> 02:09:54,234
- You can do all kinds of slants.

3856
02:09:54,234 --> 02:09:56,470
Like war is horrible. War is terrible.

3857
02:09:56,470 --> 02:10:00,119
You can do, you can make it seem like nuclear,

3858
02:10:00,119 --> 02:10:02,402
the use of nuclear weapons is just a part of war

3859
02:10:02,402 --> 02:10:03,506
and all that kind of stuff.

3860
02:10:03,506 --> 02:10:06,025
Something about the reporting and the discussion

3861
02:10:06,025 --> 02:10:09,627
of nuclear weapons resulted in us being terrified

3862
02:10:09,627 --> 02:10:13,085
in awe of the power of nuclear weapons

3863
02:10:13,085 --> 02:10:17,516
and that potentially fed in a positive way towards

3864
02:10:17,516 --> 02:10:21,605
the game theory of mutual issue destruction.

3865
02:10:21,605 --> 02:10:23,124
- Well, so this gets to what actually,

3866
02:10:23,124 --> 02:10:23,957
let's get to what actually happens.

3867
02:10:23,957 --> 02:10:25,473
- [Lex] Some of us, me playing devil's advocate here.

3868
02:10:25,473 --> 02:10:26,306
- Yeah, yeah, sure.

3869
02:10:26,306 --> 02:10:27,679
Of course. Let's get to what actually happened and then kind

3870
02:10:27,679 --> 02:10:28,512
of back into that.

3871
02:10:28,512 --> 02:10:29,821
So what actually happened, I believe,

3872
02:10:29,821 --> 02:10:31,836
and again I think this is a reasonable reading of history,

3873
02:10:31,836 --> 02:10:33,071
is what actually happened was nukes then prevented

3874
02:10:33,071 --> 02:10:35,756
World War III and they prevented World War III

3875
02:10:35,756 --> 02:10:37,270
through the game theory of mutually assured

3876
02:10:37,270 --> 02:10:39,935
destruction had nukes not existed. Right.

3877
02:10:39,935 --> 02:10:41,658
There would've been no reason

3878
02:10:41,658 --> 02:10:43,797
why the Cold War did not go hot. Right.

3879
02:10:43,797 --> 02:10:44,873
And then there and then, you know,

3880
02:10:44,873 --> 02:10:46,112
and the military planners at the time, right,

3881
02:10:46,112 --> 02:10:48,255
thought both on both sides thought that there was gonna be

3882
02:10:48,255 --> 02:10:49,242
World War III on the planes of Europe

3883
02:10:49,242 --> 02:10:50,866
and they thought there was gonna be like

3884
02:10:50,866 --> 02:10:52,300
a hundred million people dead. Right?

3885
02:10:52,300 --> 02:10:54,046
It was like the most obvious thing in the world to happen.

3886
02:10:54,046 --> 02:10:56,305
Right? And it's the dog that didn't bark right?

3887
02:10:56,305 --> 02:10:59,273
Like it may be like the best single net thing that happened

3888
02:10:59,273 --> 02:11:01,438
in the entire 20th century is that like that didn't happen.

3889
02:11:01,438 --> 02:11:03,554
- Yeah. Actually, just on that point,

3890
02:11:03,554 --> 02:11:04,931
you say a lot of really brilliant things.

3891
02:11:04,931 --> 02:11:08,014
It hit me just as you were saying it.

3892
02:11:09,508 --> 02:11:11,494
I don't know why it hit me for the first time,

3893
02:11:11,494 --> 02:11:15,411
but we got two wars in a span of like 20 years.

3894
02:11:17,320 --> 02:11:20,336
Like we could have kept getting more and more world wars

3895
02:11:20,336 --> 02:11:22,379
and more and more ruthless.

3896
02:11:22,379 --> 02:11:25,744
It actually, you could have had a US versus Russia war.

3897
02:11:25,744 --> 02:11:27,756
- You could, by the way you haven't,

3898
02:11:27,756 --> 02:11:29,272
there's another hypothetical scenario.

3899
02:11:29,272 --> 02:11:30,666
The other hypothetical scenario is

3900
02:11:30,666 --> 02:11:33,176
that Americans got the bomb, the Russians didn't.

3901
02:11:33,176 --> 02:11:34,427
Right? And then America's the big dog

3902
02:11:34,427 --> 02:11:36,171
and then maybe America would've had the capability

3903
02:11:36,171 --> 02:11:38,553
to actually roll back the iron curtain.

3904
02:11:38,553 --> 02:11:40,479
I don't know whether that would've happened,

3905
02:11:40,479 --> 02:11:42,746
but like it's entirely possible. Right?

3906
02:11:42,746 --> 02:11:44,191
And the act of these people

3907
02:11:44,191 --> 02:11:45,869
who had these moral positions about,

3908
02:11:45,869 --> 02:11:47,267
'cause they could forecast, they could model,

3909
02:11:47,267 --> 02:11:48,991
they could forecast the future of how the technology would

3910
02:11:48,991 --> 02:11:50,809
get used, made a horrific mistake.

3911
02:11:50,809 --> 02:11:51,858
'cause they basically ensured

3912
02:11:51,858 --> 02:11:53,536
that the iron curtain would continue for 50 years

3913
02:11:53,536 --> 02:11:54,515
longer than it would've otherwise.

3914
02:11:54,515 --> 02:11:55,834
Like, and again, like these are counter-factuals,

3915
02:11:55,834 --> 02:11:57,508
I don't know that that's what, what would've happened,

3916
02:11:57,508 --> 02:12:00,675
but like the decision to hand the bomb

3917
02:12:01,533 --> 02:12:03,860
over was a big decision made

3918
02:12:03,860 --> 02:12:07,286
by people who were very full of themselves.

3919
02:12:07,286 --> 02:12:09,360
- Yeah. But so me as an America,

3920
02:12:09,360 --> 02:12:11,280
me as a person that loves America,

3921
02:12:11,280 --> 02:12:13,415
I also wonder if US was the only ones

3922
02:12:13,415 --> 02:12:15,498
with the nuclear weapons.

3923
02:12:17,553 --> 02:12:18,824
- That was the argument for handing

3924
02:12:18,824 --> 02:12:20,710
that was the guys who (indistinct)

3925
02:12:20,710 --> 02:12:22,255
the guys who handed over the bomb.

3926
02:12:22,255 --> 02:12:23,803
That was actually their moral argument.

3927
02:12:23,803 --> 02:12:26,743
- Yeah. I would probably not hand it over to,

3928
02:12:26,743 --> 02:12:28,470
I would be careful about the regimes.

3929
02:12:28,470 --> 02:12:29,822
You hand it over to there,

3930
02:12:29,822 --> 02:12:33,436
maybe give it to like the British or something,

3931
02:12:33,436 --> 02:12:37,500
or like a democratically-elected government.

3932
02:12:37,500 --> 02:12:38,833
- Well, look, there are people to this day

3933
02:12:38,833 --> 02:12:40,041
who think that those bias Soviet spies did

3934
02:12:40,041 --> 02:12:41,592
the right thing because they created a balance

3935
02:12:41,592 --> 02:12:43,419
of terror as opposed to the US having just,

3936
02:12:43,419 --> 02:12:44,642
and by the way, let me--

3937
02:12:44,642 --> 02:12:45,839
- Balance of terror.

3938
02:12:45,839 --> 02:12:47,217
- [Marc] Let's tell the full version story has--

3939
02:12:47,217 --> 02:12:48,050
- Such a sexy ring to it.

3940
02:12:48,050 --> 02:12:48,883
- Okay. So the full version of the story is

3941
02:12:48,883 --> 02:12:51,098
John Van Norman is a hero of both yours and mind.

3942
02:12:51,098 --> 02:12:52,640
The full version of the story is he advocated

3943
02:12:52,640 --> 02:12:53,966
for a first strike.

3944
02:12:53,966 --> 02:12:57,313
So when the US had the bomb and Russia did not,

3945
02:12:57,313 --> 02:12:58,778
he advocated for, he said,

3946
02:12:58,778 --> 02:13:01,646
we need to strike them right now.

3947
02:13:01,646 --> 02:13:03,312
- Strike Russia.

3948
02:13:03,312 --> 02:13:04,565
- [Marc] Yes.

3949
02:13:04,565 --> 02:13:05,398
- Van Norman.

3950
02:13:05,398 --> 02:13:09,278
- Yes, because he said World War III is inevitable.

3951
02:13:09,278 --> 02:13:11,381
He was very hardcore.

3952
02:13:11,381 --> 02:13:15,348
His theory was World War III is inevitable.

3953
02:13:15,348 --> 02:13:17,005
We're definitely gonna have World War III.

3954
02:13:17,005 --> 02:13:18,381
The only way to stop World War III is we have to take them

3955
02:13:18,381 --> 02:13:20,253
out right now and we have to take them out right now

3956
02:13:20,253 --> 02:13:21,149
before they get the bomb.

3957
02:13:21,149 --> 02:13:23,252
'Cause this is our last chance.

3958
02:13:23,252 --> 02:13:24,210
Now again, like--

3959
02:13:24,210 --> 02:13:25,976
- Is this an example of philosophers and politics?

3960
02:13:25,976 --> 02:13:27,408
- I don't know if that's in there or not,

3961
02:13:27,408 --> 02:13:28,436
but this is in the standard.

3962
02:13:28,436 --> 02:13:29,269
- No, but it is meaning is that.

3963
02:13:29,269 --> 02:13:30,348
- Yeah, this is on the other side.

3964
02:13:30,348 --> 02:13:31,872
So, most of the case studies,

3965
02:13:31,872 --> 02:13:33,826
most of the case studies in books like this are

3966
02:13:33,826 --> 02:13:36,662
the crazy people on the left.

3967
02:13:36,662 --> 02:13:37,978
Van Norman is a story arguably

3968
02:13:37,978 --> 02:13:39,657
of the crazy people on the right.

3969
02:13:39,657 --> 02:13:41,602
- Yes. Stick to computing, John.

3970
02:13:41,602 --> 02:13:42,435
- Well. This is the thing,

3971
02:13:42,435 --> 02:13:43,723
and this is the general principle.

3972
02:13:43,723 --> 02:13:45,487
Getting back to our core thing, which is like,

3973
02:13:45,487 --> 02:13:47,064
I don't know whether any of these people should be making

3974
02:13:47,064 --> 02:13:48,539
any of these calls.

3975
02:13:48,539 --> 02:13:50,728
Because there's nothing in either Van Norman's background

3976
02:13:50,728 --> 02:13:52,091
or Oppenheimer's background

3977
02:13:52,091 --> 02:13:53,293
or any of these people's background

3978
02:13:53,293 --> 02:13:55,191
that qualifies them as moral authorities.

3979
02:13:55,191 --> 02:13:58,935
- Yeah. Well this actually brings up the point of, in AI,

3980
02:13:58,935 --> 02:13:59,842
who are the good people

3981
02:13:59,842 --> 02:14:02,622
to reason about the morality of the ethics,

3982
02:14:02,622 --> 02:14:04,168
the outside of these risks,

3983
02:14:04,168 --> 02:14:06,702
outside of like the more complicated stuff that you,

3984
02:14:06,702 --> 02:14:08,932
you agree on is, you know,

3985
02:14:08,932 --> 02:14:11,065
this will go into the hands of bad guys

3986
02:14:11,065 --> 02:14:13,542
and all the kinds of ways they'll do is interesting

3987
02:14:13,542 --> 02:14:17,583
and dangerous, is dangerous in interesting

3988
02:14:17,583 --> 02:14:18,792
unpredictable ways.

3989
02:14:18,792 --> 02:14:19,960
And who is the right person?

3990
02:14:19,960 --> 02:14:22,110
Who are the right kinds of people to make decisions,

3991
02:14:22,110 --> 02:14:25,043
how to respond to it? Or is the tech people?

3992
02:14:25,043 --> 02:14:27,159
- So the history of these fields,

3993
02:14:27,159 --> 02:14:28,477
this is what he talks about in the book,

3994
02:14:28,477 --> 02:14:32,011
the history of these fields, is that the competence

3995
02:14:32,011 --> 02:14:34,132
and capability and intelligence and training

3996
02:14:34,132 --> 02:14:36,788
and accomplishments of senior scientists and technologists

3997
02:14:36,788 --> 02:14:39,544
working on a technology and then being able

3998
02:14:39,544 --> 02:14:42,133
to then make moral judgments in the use of that technology.

3999
02:14:42,133 --> 02:14:43,925
That track record is terrible

4000
02:14:43,925 --> 02:14:46,545
that track record is like catastrophically bad.

4001
02:14:46,545 --> 02:14:47,378
The people--

4002
02:14:47,378 --> 02:14:48,494
- Just the linger,

4003
02:14:48,494 --> 02:14:51,262
the people that develop that technology are usually not

4004
02:14:51,262 --> 02:14:53,792
going to be the right people.

4005
02:14:53,792 --> 02:14:55,122
- Well why would they? So the claim is of course,

4006
02:14:55,122 --> 02:14:56,383
they're the knowledgeable ones.

4007
02:14:56,383 --> 02:14:58,064
But the the problem is they've spent their entire life

4008
02:14:58,064 --> 02:14:59,549
in a lab. Right.

4009
02:14:59,549 --> 02:15:01,687
They're not theologians.

4010
02:15:01,687 --> 02:15:04,138
Well, so what you find, what you find when you read,

4011
02:15:04,138 --> 02:15:05,775
when you read this, when you look at these histories,

4012
02:15:05,775 --> 02:15:06,898
what you find is they generally are

4013
02:15:06,898 --> 02:15:08,822
very thinly informed on history,

4014
02:15:08,822 --> 02:15:12,989
on sociology, on theology, on morality, on ethics.

4015
02:15:14,181 --> 02:15:17,356
They tend to manufacture their own worldviews from scratch.

4016
02:15:17,356 --> 02:15:20,189
They tend to be very sort of thin.

4017
02:15:22,356 --> 02:15:24,779
They're not remotely the arguments that you would be having

4018
02:15:24,779 --> 02:15:26,885
if you got like a group of highly qualified theologians

4019
02:15:26,885 --> 02:15:29,235
or philosophers or, you know.

4020
02:15:29,235 --> 02:15:31,983
- Well, let me sort of, as the devil's advocate,

4021
02:15:31,983 --> 02:15:36,150
takes a simple whiskey say that I agree with that.

4022
02:15:38,925 --> 02:15:40,804
But also it seems like the people who are doing kind

4023
02:15:40,804 --> 02:15:42,768
of the ethics departments

4024
02:15:42,768 --> 02:15:46,756
and these tech companies go sometimes the other way.

4025
02:15:46,756 --> 02:15:48,638
- [Marc] Yes, they're definitely.

4026
02:15:48,638 --> 02:15:52,991
- Which they're not nuanced on history or theology

4027
02:15:52,991 --> 02:15:53,957
or this kind of stuff.

4028
02:15:53,957 --> 02:15:57,449
It almost becomes a kind of outraged activism

4029
02:15:57,449 --> 02:16:01,171
towards directions that don't seem to be

4030
02:16:01,171 --> 02:16:05,551
grounded in history and humility and nuance.

4031
02:16:05,551 --> 02:16:08,196
It's again, drenched with arrogance. So--

4032
02:16:08,196 --> 02:16:09,321
- [Marc] Definitely.

4033
02:16:09,321 --> 02:16:10,627
- I'm not sure which is worse.

4034
02:16:10,627 --> 02:16:11,628
- Oh no, they're both bad.

4035
02:16:11,628 --> 02:16:13,174
Yeah. So definitely not them either.

4036
02:16:13,174 --> 02:16:14,135
- So, but I guess.

4037
02:16:14,135 --> 02:16:16,097
- Well look, this is a hard.

4038
02:16:16,097 --> 02:16:17,053
- Yeah, it's a hard problem.

4039
02:16:17,053 --> 02:16:17,886
- This is a hard problem.

4040
02:16:17,886 --> 02:16:19,067
This goes back to where we started,

4041
02:16:19,067 --> 02:16:20,758
which is, okay, who has the truth?

4042
02:16:20,758 --> 02:16:22,339
And it's like, well, you know,

4043
02:16:22,339 --> 02:16:24,593
like how does societies arrive at like truth

4044
02:16:24,593 --> 02:16:25,582
and how do we figure these things out

4045
02:16:25,582 --> 02:16:28,423
and like our elected leaders play some role in it.

4046
02:16:28,423 --> 02:16:30,571
You know, we all play some role in it.

4047
02:16:30,571 --> 02:16:33,072
There have to be some set of public intellectuals

4048
02:16:33,072 --> 02:16:34,802
at some point that bring, you know,

4049
02:16:34,802 --> 02:16:37,028
rationality and judgment and humility to it.

4050
02:16:37,028 --> 02:16:38,809
Those people are few and far between.

4051
02:16:38,809 --> 02:16:40,523
We should probably prize them very highly.

4052
02:16:40,523 --> 02:16:43,477
- Yeah. So celebrate humility in our public leaders.

4053
02:16:43,477 --> 02:16:45,942
So getting to risk number two,

4054
02:16:45,942 --> 02:16:49,481
will AI ruin our society short version as you write,

4055
02:16:49,481 --> 02:16:51,781
if the murder robots don't get us the hate speech

4056
02:16:51,781 --> 02:16:53,864
and misinformation will.

4057
02:16:53,864 --> 02:16:56,818
And the action you recommend in short,

4058
02:16:56,818 --> 02:17:00,715
don't let the thought police suppress AI.

4059
02:17:00,715 --> 02:17:05,215
Well what is this risk of the effect of misinformation

4060
02:17:08,295 --> 02:17:12,418
of society that's going to be catalyzed by AI?

4061
02:17:12,418 --> 02:17:14,038
- Yeah, so this is the social media,

4062
02:17:14,038 --> 02:17:15,100
this is what you just alluded to.

4063
02:17:15,100 --> 02:17:17,091
It's the activism kind of thing that's popped up

4064
02:17:17,091 --> 02:17:18,492
in these companies in the industry.

4065
02:17:18,492 --> 02:17:20,046
And it's basically, from my perspective,

4066
02:17:20,046 --> 02:17:22,607
it's basically part two of the war that played out

4067
02:17:22,607 --> 02:17:24,416
over social media over the last 10 years,

4068
02:17:24,416 --> 02:17:26,874
'cause you probably remember social media 10 years ago,

4069
02:17:26,874 --> 02:17:28,723
was basically who even wants this?

4070
02:17:28,723 --> 02:17:31,096
Who wants a photo of what your cat had for breakfast?

4071
02:17:31,096 --> 02:17:33,032
Like, this stuff is like silly and trivial

4072
02:17:33,032 --> 02:17:34,341
and why can't these nerds like figure out

4073
02:17:34,341 --> 02:17:36,628
how to invent something like useful and powerful?

4074
02:17:36,628 --> 02:17:37,709
And then, you know,

4075
02:17:37,709 --> 02:17:39,716
certain things happened in the political system.

4076
02:17:39,716 --> 02:17:40,614
And then it sort of,

4077
02:17:40,614 --> 02:17:42,343
the polarity on that discussion switched all the way

4078
02:17:42,343 --> 02:17:44,296
to social media is like the worst, most corrosive,

4079
02:17:44,296 --> 02:17:46,804
most terrible, most awful technology ever invented.

4080
02:17:46,804 --> 02:17:48,779
And then it leads to, you know, terrible of the wrong,

4081
02:17:48,779 --> 02:17:51,359
you know, politicians and policies and politics and like,

4082
02:17:51,359 --> 02:17:52,346
and all this stuff.

4083
02:17:52,346 --> 02:17:55,298
And that all got catalyzed into this very big kind of angry

4084
02:17:55,298 --> 02:17:57,691
movement both inside and outside the companies

4085
02:17:57,691 --> 02:17:59,780
to kind of bring social media to heal.

4086
02:17:59,780 --> 02:18:01,878
And that got focused in particularly on two topics,

4087
02:18:01,878 --> 02:18:04,358
so-called hate speech and so-called misinformation.

4088
02:18:04,358 --> 02:18:06,189
And that's been the saga playing out

4089
02:18:06,189 --> 02:18:07,071
for the last decade.

4090
02:18:07,071 --> 02:18:08,983
And I don't even really want to even argue the pros and cons

4091
02:18:08,983 --> 02:18:10,481
of the sides just to observe

4092
02:18:10,481 --> 02:18:11,683
that's been like a huge fight

4093
02:18:11,683 --> 02:18:12,517
and has had, you know,

4094
02:18:12,517 --> 02:18:15,691
big consequences to how these companies operate.

4095
02:18:15,691 --> 02:18:19,035
Basically that same, those same sets of theories,

4096
02:18:19,035 --> 02:18:20,216
that same activist approach,

4097
02:18:20,216 --> 02:18:23,071
that same energy as being transplanted straight to AI.

4098
02:18:23,071 --> 02:18:24,434
And you see that already happening.

4099
02:18:24,434 --> 02:18:25,971
It's why, you know, ChatGPT will answer,

4100
02:18:25,971 --> 02:18:27,593
let's say certain questions and not others.

4101
02:18:27,593 --> 02:18:30,482
It's why it gives you the canned speech about, you know,

4102
02:18:30,482 --> 02:18:32,368
whenever it starts with, as a large language model,

4103
02:18:32,368 --> 02:18:33,340
I cannot, you know,

4104
02:18:33,340 --> 02:18:34,754
basically means that somebody has reached in there and told

4105
02:18:34,754 --> 02:18:37,480
that it can't talk about certain topics.

4106
02:18:37,480 --> 02:18:39,180
- Do you think some of that is good?

4107
02:18:39,180 --> 02:18:41,223
- So it's an interesting question.

4108
02:18:41,223 --> 02:18:42,910
So a couple observations.

4109
02:18:42,910 --> 02:18:45,093
So, one is the people

4110
02:18:45,093 --> 02:18:46,508
who find this the most frustrating are

4111
02:18:46,508 --> 02:18:50,343
the people who are worried about the murder robots, right?

4112
02:18:50,343 --> 02:18:54,598
So, and in fact so called X risk people, right?

4113
02:18:54,598 --> 02:18:56,181
They started with the term AI safety,

4114
02:18:56,181 --> 02:18:57,587
the term became AI alignment.

4115
02:18:57,587 --> 02:18:59,040
When the term became AI alignment is

4116
02:18:59,040 --> 02:19:00,384
when this switch happened from we're worried

4117
02:19:00,384 --> 02:19:02,112
it's gonna kill us all to we're worried about hate speech

4118
02:19:02,112 --> 02:19:03,154
and misinformation.

4119
02:19:03,154 --> 02:19:03,986
- [Lex] Sure.

4120
02:19:03,986 --> 02:19:05,973
- The AI X risk people have now renamed their thing

4121
02:19:05,973 --> 02:19:08,642
AI not kill everyone-ism,

4122
02:19:08,642 --> 02:19:11,160
which I have to admit is a catchy term.

4123
02:19:11,160 --> 02:19:13,088
And they are very frustrated by the fact that the hate

4124
02:19:13,088 --> 02:19:14,857
speech sort of activist driven hate speech misinformation

4125
02:19:14,857 --> 02:19:16,101
kind of thing is taking over.

4126
02:19:16,101 --> 02:19:17,727
Which is what's happened is taken over,

4127
02:19:17,727 --> 02:19:19,628
the AI ethics field has been taken over by the hate speech

4128
02:19:19,628 --> 02:19:21,477
misinformation people.

4129
02:19:21,477 --> 02:19:22,395
You know, look,

4130
02:19:22,395 --> 02:19:25,186
would I like to live in a world in which like everybody was

4131
02:19:25,186 --> 02:19:26,721
nice to each other all the time and nobody ever said

4132
02:19:26,721 --> 02:19:29,475
anything mean and nobody ever used a bad word and everything

4133
02:19:29,475 --> 02:19:31,004
was always accurate and honest.

4134
02:19:31,004 --> 02:19:32,102
Like, that sounds great.

4135
02:19:32,102 --> 02:19:33,785
Do I wanna live in a world where there's like a centralized

4136
02:19:33,785 --> 02:19:36,504
thought police working through the tech companies to enforce

4137
02:19:36,504 --> 02:19:38,883
the view of a small set of elites that they're gonna

4138
02:19:38,883 --> 02:19:40,686
determine what the rest of us think and feel like?

4139
02:19:40,686 --> 02:19:41,781
Absolutely not.

4140
02:19:41,781 --> 02:19:44,151
- There could be a middle ground somewhere like

4141
02:19:44,151 --> 02:19:45,621
Wikipedia type of moderation.

4142
02:19:45,621 --> 02:19:50,071
There's moderation of Wikipedia that is somehow crowdsourced

4143
02:19:50,071 --> 02:19:53,072
where you don't have centralized elites,

4144
02:19:53,072 --> 02:19:56,737
but it's also not completely just a free for all

4145
02:19:56,737 --> 02:20:01,152
because if you have the entirety of human knowledge

4146
02:20:01,152 --> 02:20:04,404
at your fingertips, you can do a lot of harm.

4147
02:20:04,404 --> 02:20:06,219
Like if you have a good assistant

4148
02:20:06,219 --> 02:20:08,729
that's completely uncensored,

4149
02:20:08,729 --> 02:20:10,295
they can help you build a bomb,

4150
02:20:10,295 --> 02:20:14,962
they can help you mess with people's physical wellbeing.

4151
02:20:17,017 --> 02:20:18,123
Right. If they,

4152
02:20:18,123 --> 02:20:20,465
because that information is out there on the internet

4153
02:20:20,465 --> 02:20:23,715
and so presumably there's, it would be,

4154
02:20:24,745 --> 02:20:28,939
you could see the positives in censoring some aspects

4155
02:20:28,939 --> 02:20:30,069
of an AI model

4156
02:20:30,069 --> 02:20:33,313
when it's helping you commit literal violence.

4157
02:20:33,313 --> 02:20:35,287
- Yeah. And there's a section later section of the essay

4158
02:20:35,287 --> 02:20:37,076
where I talk about bad people doing bad things.

4159
02:20:37,076 --> 02:20:37,909
- [Lex] Yes.

4160
02:20:37,909 --> 02:20:38,878
- Right. Which and there's this,

4161
02:20:38,878 --> 02:20:40,502
there's a set of things that we should discuss there.

4162
02:20:40,502 --> 02:20:41,335
- [Lex] Yeah.

4163
02:20:41,335 --> 02:20:43,423
- What happens in practice is these lines,

4164
02:20:43,423 --> 02:20:44,623
as you alluded to this already,

4165
02:20:44,623 --> 02:20:46,277
these lines are not easy to draw.

4166
02:20:46,277 --> 02:20:47,680
And what I've observed in the social media version

4167
02:20:47,680 --> 02:20:49,361
of this is like, the way I describe it

4168
02:20:49,361 --> 02:20:50,907
as the slippery slope is not a fallacy,

4169
02:20:50,907 --> 02:20:52,292
it's an inevitability.

4170
02:20:52,292 --> 02:20:54,878
The minute you have this kind of activist personality that

4171
02:20:54,878 --> 02:20:56,933
gets in a position to make these decisions

4172
02:20:56,933 --> 02:20:58,230
they take it straight to infinity.

4173
02:20:58,230 --> 02:21:00,760
Like, it goes into the crazy zone like almost immediately

4174
02:21:00,760 --> 02:21:04,126
and never comes back because people become drunk with power.

4175
02:21:04,126 --> 02:21:06,591
Right. And look, if you're in the position to determine

4176
02:21:06,591 --> 02:21:07,537
what the entire world

4177
02:21:07,537 --> 02:21:09,113
thinks and feels and reads and says like,

4178
02:21:09,113 --> 02:21:11,765
you're gonna take it and you know, Elon has, you know,

4179
02:21:11,765 --> 02:21:13,665
ventilated this with the Twitter files over the last,

4180
02:21:13,665 --> 02:21:15,363
you know, three months and it's just like crystal clear,

4181
02:21:15,363 --> 02:21:16,917
like how bad it got there now.

4182
02:21:16,917 --> 02:21:17,750
- [Lex] Yeah.

4183
02:21:17,750 --> 02:21:18,946
- Reason for optimism is what Elon is doing

4184
02:21:18,946 --> 02:21:20,650
with community notes.

4185
02:21:20,650 --> 02:21:24,426
So community notes is actually a very interesting thing.

4186
02:21:24,426 --> 02:21:27,247
So, what Elon is trying to do with community notes is

4187
02:21:27,247 --> 02:21:29,552
he's trying to have it where there's only a community note

4188
02:21:29,552 --> 02:21:32,270
when people who have previously disagreed on many topics

4189
02:21:32,270 --> 02:21:34,270
agree on this one.

4190
02:21:34,270 --> 02:21:36,962
- Yes, that's what I'm trying to get at is like,

4191
02:21:36,962 --> 02:21:40,114
there could be Wikipedia like models or community notes type

4192
02:21:40,114 --> 02:21:44,562
of models where allows you to essentially either provide

4193
02:21:44,562 --> 02:21:48,125
context or sensor in a way that's not resist

4194
02:21:48,125 --> 02:21:49,406
the slippery slope nature. Power.

4195
02:21:49,406 --> 02:21:52,001
- Now there's an entirely different approach here,

4196
02:21:52,001 --> 02:21:55,395
which is basically we have AIs that are producing content.

4197
02:21:55,395 --> 02:21:57,809
We could also have ais that are consuming content. Right?

4198
02:21:57,809 --> 02:22:00,322
And so one of the things that your assistant could do for

4199
02:22:00,322 --> 02:22:02,623
you is help you consume all the content, right?

4200
02:22:02,623 --> 02:22:04,970
And basically tell you when you're getting played.

4201
02:22:04,970 --> 02:22:07,584
So for example, I'm gonna want the AI that my kid uses,

4202
02:22:07,584 --> 02:22:08,867
right, to be very, you know,

4203
02:22:08,867 --> 02:22:11,199
child safe and I'm gonna want it to filter for him all kinds

4204
02:22:11,199 --> 02:22:12,771
of inappropriate stuff that he shouldn't be saying just

4205
02:22:12,771 --> 02:22:13,973
'cause he's a kid. Right?

4206
02:22:13,973 --> 02:22:16,161
And you see what I'm saying is you can implement that.

4207
02:22:16,161 --> 02:22:18,019
The architectural, you could say you can solve this

4208
02:22:18,019 --> 02:22:18,888
on the client side, right?

4209
02:22:18,888 --> 02:22:21,082
You solving on the server side gives you an opportunity

4210
02:22:21,082 --> 02:22:23,249
to dictate for the entire world, which I think is

4211
02:22:23,249 --> 02:22:25,493
where you take the slippery slope to hell,

4212
02:22:25,493 --> 02:22:27,057
there's another architectural approach,

4213
02:22:27,057 --> 02:22:28,758
which is to solve this on the client side,

4214
02:22:28,758 --> 02:22:30,874
which is certainly what I would endorse.

4215
02:22:30,874 --> 02:22:32,083
- It's AI risk number five,

4216
02:22:32,083 --> 02:22:34,879
will AI lead to bad people doing bad things?

4217
02:22:34,879 --> 02:22:37,455
And I can just imagine language models used to do so many

4218
02:22:37,455 --> 02:22:38,288
bad things,

4219
02:22:38,288 --> 02:22:42,485
but the hope is there that you can have large language

4220
02:22:42,485 --> 02:22:45,246
models used to then defend against it by more people,

4221
02:22:45,246 --> 02:22:49,713
by smarter people, by more effective people, skilled people,

4222
02:22:49,713 --> 02:22:51,080
all that kind of stuff.

4223
02:22:51,080 --> 02:22:53,345
- Three-part argument on bad people doing bad things.

4224
02:22:53,345 --> 02:22:55,184
So, number one, right?

4225
02:22:55,184 --> 02:22:56,679
You can use the technology defensively

4226
02:22:56,679 --> 02:22:59,080
and we should be using AI to build like broad spectrum

4227
02:22:59,080 --> 02:23:02,133
vaccines and antibiotics for like bio weapons and we should

4228
02:23:02,133 --> 02:23:03,703
be using AI to like hunt terrorists

4229
02:23:03,703 --> 02:23:04,536
and catch criminals and like,

4230
02:23:04,536 --> 02:23:06,532
we should be doing like all kinds of stuff like that.

4231
02:23:06,532 --> 02:23:07,365
And in fact,

4232
02:23:07,365 --> 02:23:08,198
we should be doing those things

4233
02:23:08,198 --> 02:23:09,469
even just to like go get like, you know,

4234
02:23:09,469 --> 02:23:11,420
basically go eliminate risk from like regular pathogens

4235
02:23:11,420 --> 02:23:12,817
that aren't like constructed by an AI.

4236
02:23:12,817 --> 02:23:16,708
So there's the whole defensive set of things.

4237
02:23:16,708 --> 02:23:18,846
Second is we have many laws on the books

4238
02:23:18,846 --> 02:23:20,821
about as actual bad things, right?

4239
02:23:20,821 --> 02:23:23,074
So it is actually illegal to be a criminal, you know,

4240
02:23:23,074 --> 02:23:25,855
to commit crimes, to commit terrorist acts to, you know,

4241
02:23:25,855 --> 02:23:27,268
build pathogens with the intent

4242
02:23:27,268 --> 02:23:28,642
to deploy them to kill people.

4243
02:23:28,642 --> 02:23:30,277
And so we have those,

4244
02:23:30,277 --> 02:23:32,192
we actually don't need new laws

4245
02:23:32,192 --> 02:23:33,515
for the vast majority of these scenarios.

4246
02:23:33,515 --> 02:23:36,221
We actually already have the laws in the book, on the books.

4247
02:23:36,221 --> 02:23:38,334
The third argument is the minute,

4248
02:23:38,334 --> 02:23:39,900
and this is sort of the foundational one that gets really

4249
02:23:39,900 --> 02:23:41,651
tough, but the minute you get into this thing,

4250
02:23:41,651 --> 02:23:43,797
which you were kind of getting into, which is like, okay,

4251
02:23:43,797 --> 02:23:45,974
but like, don't you need censorship sometimes, right?

4252
02:23:45,974 --> 02:23:46,997
And don't you need restrictions sometimes?

4253
02:23:46,997 --> 02:23:49,669
It's like, okay, what is the cost of that?

4254
02:23:49,669 --> 02:23:52,656
And in particular in the world of open source, right?

4255
02:23:52,656 --> 02:23:57,581
And so is open source AI going to be allowed or not?

4256
02:23:57,581 --> 02:23:59,875
If open source AI is not allowed,

4257
02:23:59,875 --> 02:24:03,545
then what is the regime that's going to be necessary legally

4258
02:24:03,545 --> 02:24:06,586
and technically to prevent it from developing? Right?

4259
02:24:06,586 --> 02:24:09,134
And here again is where you get into and people have

4260
02:24:09,134 --> 02:24:10,134
proposed that these kinds of things.

4261
02:24:10,134 --> 02:24:11,213
You get into I would say

4262
02:24:11,213 --> 02:24:12,496
pretty extreme territory pretty fast.

4263
02:24:12,496 --> 02:24:15,996
Do we have a monitor agent on every CPU and GPU

4264
02:24:15,996 --> 02:24:17,099
that reports back to the government?

4265
02:24:17,099 --> 02:24:18,607
What we're doing with our computers,

4266
02:24:18,607 --> 02:24:22,220
are we seizing GPU clusters that get beyond a certain size?

4267
02:24:22,220 --> 02:24:23,483
Like, and then by the way,

4268
02:24:23,483 --> 02:24:25,422
how are we doing all that globally, right?

4269
02:24:25,422 --> 02:24:28,399
And like if China's developing an LLM beyond the scale

4270
02:24:28,399 --> 02:24:31,924
that we think is allowable, are we gonna invade? Right.

4271
02:24:31,924 --> 02:24:33,753
And you have figures on the AI X risk side

4272
02:24:33,753 --> 02:24:34,894
who are advocating any, you know,

4273
02:24:34,894 --> 02:24:36,692
potentially up to nuclear strikes to prevent, you know,

4274
02:24:36,692 --> 02:24:37,583
this kind of thing.

4275
02:24:37,583 --> 02:24:39,734
And so here you get into this thing

4276
02:24:39,734 --> 02:24:41,621
and again, you know, maybe you could maybe say this is,

4277
02:24:41,621 --> 02:24:43,227
you know, you could even say this is what good,

4278
02:24:43,227 --> 02:24:44,172
bad or indifferent or whatever.

4279
02:24:44,172 --> 02:24:46,902
But like here's the comparison of nukes,

4280
02:24:46,902 --> 02:24:48,643
the comparison of nukes is very dangerous

4281
02:24:48,643 --> 02:24:49,865
because one is just nukes,

4282
02:24:49,865 --> 02:24:52,474
were just, although we can come back to nuclear power.

4283
02:24:52,474 --> 02:24:53,567
But the other thing was like with nukes,

4284
02:24:53,567 --> 02:24:55,369
you could control plutonium, right?

4285
02:24:55,369 --> 02:24:57,247
You could track plutonium and it was like hard to come by.

4286
02:24:57,247 --> 02:24:59,205
AI is just math and code, right?

4287
02:24:59,205 --> 02:25:01,740
And it's in like math textbooks and it's like,

4288
02:25:01,740 --> 02:25:04,051
there are YouTube videos that teach you how to build it.

4289
02:25:04,051 --> 02:25:05,402
And like there's open source, there's already open source.

4290
02:25:05,402 --> 02:25:06,235
You know,

4291
02:25:06,235 --> 02:25:08,000
there's a 40 billion parameter model running around already

4292
02:25:08,000 --> 02:25:10,022
called Falcon Online that anybody can download.

4293
02:25:10,022 --> 02:25:11,105
And so, okay,

4294
02:25:12,505 --> 02:25:14,365
you walk down the logic path that says we need to have

4295
02:25:14,365 --> 02:25:15,374
guardrails on this.

4296
02:25:15,374 --> 02:25:17,794
And you find yourself in an authoritarian,

4297
02:25:17,794 --> 02:25:21,345
totalitarian regime of thought control and machine control

4298
02:25:21,345 --> 02:25:25,087
that would be so brutal that you would've destroyed

4299
02:25:25,087 --> 02:25:26,911
the society that you're trying to protect.

4300
02:25:26,911 --> 02:25:29,414
And so I just don't see how that actually works.

4301
02:25:29,414 --> 02:25:32,343
- So yeah, you have to understand my brain's going

4302
02:25:32,343 --> 02:25:34,244
full steam ahead here

4303
02:25:34,244 --> 02:25:37,116
'cause I agree with basically everything you're saying,

4304
02:25:37,116 --> 02:25:39,795
but I'm trying to play devil's advocate here

4305
02:25:39,795 --> 02:25:41,757
because okay, you're highlighted the fact

4306
02:25:41,757 --> 02:25:44,776
that there is a slippery slope to human nature.

4307
02:25:44,776 --> 02:25:46,520
The moment you censor something,

4308
02:25:46,520 --> 02:25:49,103
you start to censor everything.

4309
02:25:51,098 --> 02:25:54,332
That alignment starts out sounding nice,

4310
02:25:54,332 --> 02:25:57,976
but then you start to align to the beliefs

4311
02:25:57,976 --> 02:26:00,821
of some select group of people.

4312
02:26:00,821 --> 02:26:02,793
And then it's just your beliefs

4313
02:26:02,793 --> 02:26:05,549
the number of people you're aligning to smaller

4314
02:26:05,549 --> 02:26:08,837
and smaller as that group becomes more and more powerful.

4315
02:26:08,837 --> 02:26:11,313
Okay. But that just speaks to the people

4316
02:26:11,313 --> 02:26:13,902
that censor are usually the assholes

4317
02:26:13,902 --> 02:26:15,817
and the assholes get richer.

4318
02:26:15,817 --> 02:26:19,565
I wonder if it's possible to do without that for AI.

4319
02:26:19,565 --> 02:26:22,126
One way to ask this question is

4320
02:26:22,126 --> 02:26:24,121
do you think the base models,

4321
02:26:24,121 --> 02:26:28,816
the baseline foundation models should be open sourced?

4322
02:26:28,816 --> 02:26:32,871
Like, where Marc Zuckerberg is saying they want to do.

4323
02:26:32,871 --> 02:26:35,596
- So look, I mean I think it's totally appropriate

4324
02:26:35,596 --> 02:26:37,550
the companies that are in the business

4325
02:26:37,550 --> 02:26:38,420
of producing a product

4326
02:26:38,420 --> 02:26:40,752
or service should be able to have a wide range

4327
02:26:40,752 --> 02:26:42,316
of policies that they put, right?

4328
02:26:42,316 --> 02:26:43,149
And I'll just, again,

4329
02:26:43,149 --> 02:26:46,067
I want a heavily censored model for my eight year old.

4330
02:26:46,067 --> 02:26:47,448
Like, I actually want that, like,

4331
02:26:47,448 --> 02:26:49,378
like I would pay more money for the ones more heavily

4332
02:26:49,378 --> 02:26:51,099
censored than the one that's not, right.

4333
02:26:51,099 --> 02:26:53,227
And so, like there are certainly scenarios

4334
02:26:53,227 --> 02:26:55,097
where companies will make that decision.

4335
02:26:55,097 --> 02:26:57,007
Look, an interesting thing you brought up

4336
02:26:57,007 --> 02:26:59,256
or is this really a speech issue?

4337
02:26:59,256 --> 02:27:01,471
One of the things that the big tech companies are dealing

4338
02:27:01,471 --> 02:27:04,592
with is that content generated from an LLM is not covered

4339
02:27:04,592 --> 02:27:06,864
under section 230,

4340
02:27:06,864 --> 02:27:09,999
which is the law that protects internet platform companies

4341
02:27:09,999 --> 02:27:13,445
from being sued for the user generated content.

4342
02:27:13,445 --> 02:27:14,764
And so it is actually--

4343
02:27:14,764 --> 02:27:15,764
- [Lex] Oh, wow.

4344
02:27:15,764 --> 02:27:18,229
- Yes and so there, there's actually a question.

4345
02:27:18,229 --> 02:27:19,790
I think there's still a question, which is

4346
02:27:19,790 --> 02:27:21,667
can big American companies actually feel

4347
02:27:21,667 --> 02:27:23,327
generative AI at all?

4348
02:27:23,327 --> 02:27:26,008
Or is the liability actually gonna just ultimately convince

4349
02:27:26,008 --> 02:27:27,106
them that they can't do it?

4350
02:27:27,106 --> 02:27:29,504
Because the minute the thing says something bad,

4351
02:27:29,504 --> 02:27:30,824
and it doesn't even need to be hate speech,

4352
02:27:30,824 --> 02:27:32,464
it could just be like an (indistinct) it could hallucinate

4353
02:27:32,464 --> 02:27:36,061
a product, you know, detail on a vacuum cleaner, you know,

4354
02:27:36,061 --> 02:27:38,738
and all of a sudden the vacuum cleaner company sues

4355
02:27:38,738 --> 02:27:39,635
for misrepresentation.

4356
02:27:39,635 --> 02:27:40,854
And there's asymmetry there, right?

4357
02:27:40,854 --> 02:27:43,456
'Cause the LLMs gonna be producing billions of answers

4358
02:27:43,456 --> 02:27:45,755
to questions and it only needs to get a few wrong to have.

4359
02:27:45,755 --> 02:27:47,483
- [Lex] So, loss has to get updated really quick here.

4360
02:27:47,483 --> 02:27:49,753
- Yeah. And nobody knows what to do with that, right?

4361
02:27:49,753 --> 02:27:51,291
So, so anyway, like there are big,

4362
02:27:51,291 --> 02:27:54,433
there are big questions around how companies operate at all.

4363
02:27:54,433 --> 02:27:55,793
So we talk about those,

4364
02:27:55,793 --> 02:27:57,308
but then there's this other question of like, okay,

4365
02:27:57,308 --> 02:27:58,256
the open source.

4366
02:27:58,256 --> 02:27:59,157
So what about open source?

4367
02:27:59,157 --> 02:28:01,118
And my answer to your question is kind of like,

4368
02:28:01,118 --> 02:28:02,831
obviously yes, the models have,

4369
02:28:02,831 --> 02:28:05,359
there has to be full open source here because to live

4370
02:28:05,359 --> 02:28:08,336
in a world in which that open source is not allowed is

4371
02:28:08,336 --> 02:28:10,998
a world of draconian speech control,

4372
02:28:10,998 --> 02:28:13,364
human control, machine control.

4373
02:28:13,364 --> 02:28:14,343
I mean, you know,

4374
02:28:14,343 --> 02:28:16,647
black helicopters with jackbooted thugs coming out,

4375
02:28:16,647 --> 02:28:19,903
repelling down and seizing your GPU like territory.

4376
02:28:19,903 --> 02:28:20,736
- [Lex] Well.

4377
02:28:20,736 --> 02:28:22,288
- No, no, I'm a hundred percent serious.

4378
02:28:22,288 --> 02:28:25,248
- That's you're saying slippery slope always leads there.

4379
02:28:25,248 --> 02:28:26,081
- No, no, no, no.

4380
02:28:26,081 --> 02:28:26,914
That's what's required to enforce it.

4381
02:28:26,914 --> 02:28:29,530
Like how will you enforce a ban on open source and AI?

4382
02:28:29,530 --> 02:28:31,431
- No. Well you could add friction to it,

4383
02:28:31,431 --> 02:28:32,508
like harder to get the models.

4384
02:28:32,508 --> 02:28:34,596
'Cause people will always be able to get the models,

4385
02:28:34,596 --> 02:28:36,438
but it'll be more in the shadows, right?

4386
02:28:36,438 --> 02:28:38,983
- The leading open source model right now is from the UAE.

4387
02:28:38,983 --> 02:28:42,834
Like the next time they do that, what do we do?

4388
02:28:42,834 --> 02:28:43,667
- [Lex] Yeah.

4389
02:28:43,667 --> 02:28:44,500
- Like.

4390
02:28:44,500 --> 02:28:46,222
- Oh, I see you're like.

4391
02:28:46,222 --> 02:28:49,420
- A 14 year old in Indonesia comes out with a breakthrough.

4392
02:28:49,420 --> 02:28:50,253
You know,

4393
02:28:50,253 --> 02:28:51,481
we talked about most great software comes from a small

4394
02:28:51,481 --> 02:28:52,314
number of people.

4395
02:28:52,314 --> 02:28:53,747
Some kid comes out with some big new breakthrough

4396
02:28:53,747 --> 02:28:54,580
and quantization or something

4397
02:28:54,580 --> 02:28:55,809
and has some huge breakthrough.

4398
02:28:55,809 --> 02:28:57,945
And like, what are we gonna like,

4399
02:28:57,945 --> 02:29:00,037
invade Indonesia and arrest him?

4400
02:29:00,037 --> 02:29:01,755
- It seems like in terms of size of models and effectiveness

4401
02:29:01,755 --> 02:29:02,588
of models,

4402
02:29:02,588 --> 02:29:05,992
the big tech companies will probably lead the way for quite

4403
02:29:05,992 --> 02:29:07,598
a few years and the question is

4404
02:29:07,598 --> 02:29:10,490
of what policies they should use?

4405
02:29:10,490 --> 02:29:14,638
The kid in Indonesia should not be regulated,

4406
02:29:14,638 --> 02:29:19,388
but should Google, Meta, Microsoft, Open AI be regulated?

4407
02:29:20,974 --> 02:29:22,738
- Well, so, but this goes, okay,

4408
02:29:22,738 --> 02:29:26,132
so when does it become dangerous? Right.

4409
02:29:26,132 --> 02:29:28,528
Is the danger that it's as powerful

4410
02:29:28,528 --> 02:29:30,529
as the current leading commercial model?

4411
02:29:30,529 --> 02:29:34,170
Or it is just at some other arbitrary threshold?

4412
02:29:34,170 --> 02:29:36,496
And then by the way, like look, how do we know,

4413
02:29:36,496 --> 02:29:38,655
like what we know today is that you need like a lot of money

4414
02:29:38,655 --> 02:29:39,843
to like train these things.

4415
02:29:39,843 --> 02:29:41,610
But there are advances being made every week on training

4416
02:29:41,610 --> 02:29:43,995
efficiency and, you know, data, all kinds of synthetic,

4417
02:29:43,995 --> 02:29:44,870
you know, look,

4418
02:29:44,870 --> 02:29:45,974
I don't even like the synthetic data thing

4419
02:29:45,974 --> 02:29:46,807
we're talking about.

4420
02:29:46,807 --> 02:29:48,270
Maybe some kid figures out a way

4421
02:29:48,270 --> 02:29:49,392
to auto-generate synthetic data.

4422
02:29:49,392 --> 02:29:50,275
- [Lex] That's gonna change everything.

4423
02:29:50,275 --> 02:29:51,108
- Yeah, exactly.

4424
02:29:51,108 --> 02:29:52,519
And so like sitting here today, like,

4425
02:29:52,519 --> 02:29:54,034
the breakthrough just happened, right?

4426
02:29:54,034 --> 02:29:56,302
You made this point like the breakthrough just happened.

4427
02:29:56,302 --> 02:29:57,789
So we don't know what the shape

4428
02:29:57,789 --> 02:29:59,164
of this technology is gonna be.

4429
02:29:59,164 --> 02:30:03,152
I mean the big shock here is that, you know,

4430
02:30:03,152 --> 02:30:05,641
whatever number of billions of parameters basically

4431
02:30:05,641 --> 02:30:09,022
represents at least a very big percentage of human thought.

4432
02:30:09,022 --> 02:30:11,033
Like who would've imagined that?

4433
02:30:11,033 --> 02:30:12,868
And then there's already work underway.

4434
02:30:12,868 --> 02:30:14,613
There was just this paper that just came out that basically

4435
02:30:14,613 --> 02:30:17,292
takes a gpt three scale model and compresses it down or run

4436
02:30:17,292 --> 02:30:19,526
on a single 32 core CPU.

4437
02:30:19,526 --> 02:30:21,557
Like who would've predicted that?

4438
02:30:21,557 --> 02:30:22,849
- [Lex] Yeah.

4439
02:30:22,849 --> 02:30:23,682
- You know,

4440
02:30:23,682 --> 02:30:25,398
some of these models now you can run on raspberry pies like

4441
02:30:25,398 --> 02:30:27,244
today they're very slow, but like, you know,

4442
02:30:27,244 --> 02:30:28,916
maybe they'll be a, you know,

4443
02:30:28,916 --> 02:30:30,007
perceived you have real perform, you know,

4444
02:30:30,007 --> 02:30:31,724
like it's math and code.

4445
02:30:31,724 --> 02:30:33,112
And here we're back in here,

4446
02:30:33,112 --> 02:30:35,181
we're back in, dude, it's math and code.

4447
02:30:35,181 --> 02:30:36,743
It's math and code, it's math, code and data.

4448
02:30:36,743 --> 02:30:37,590
It's bits.

4449
02:30:37,590 --> 02:30:40,147
- Marc has just like walked away at this point.

4450
02:30:40,147 --> 02:30:41,912
You just screw it.

4451
02:30:41,912 --> 02:30:43,656
I don't know what to do with this.

4452
02:30:43,656 --> 02:30:45,968
You guys created this whole internet thing.

4453
02:30:45,968 --> 02:30:47,016
Yeah, yeah.

4454
02:30:47,016 --> 02:30:49,645
I mean, I'm a huge believer in open source here.

4455
02:30:49,645 --> 02:30:51,468
- So my argument is we're gonna have,

4456
02:30:51,468 --> 02:30:52,417
see here's my argument is a,

4457
02:30:52,417 --> 02:30:53,566
my argument, my full argument is,

4458
02:30:53,566 --> 02:30:55,360
is AI is gonna be like air, it's gonna be everywhere.

4459
02:30:55,360 --> 02:30:56,962
Like this is just gonna be in text.

4460
02:30:56,962 --> 02:30:57,795
It already is,

4461
02:30:57,795 --> 02:30:58,740
it's gonna be in textbooks and kids are gonna grow up

4462
02:30:58,740 --> 02:31:00,376
knowing how to do this. And it's just gonna be a thing.

4463
02:31:00,376 --> 02:31:02,357
It's gonna be in the air and you can't like pull

4464
02:31:02,357 --> 02:31:03,190
this back anymore.

4465
02:31:03,190 --> 02:31:04,023
You can't pull back air.

4466
02:31:04,023 --> 02:31:05,017
And so you just have to figure out how

4467
02:31:05,017 --> 02:31:06,212
to live in this world, right?

4468
02:31:06,212 --> 02:31:08,820
And then that's where I think like all this hand ringing

4469
02:31:08,820 --> 02:31:10,689
about AI risk is basically a complete waste of time,

4470
02:31:10,689 --> 02:31:12,834
'cause the effort should go into okay,

4471
02:31:12,834 --> 02:31:15,180
what is the defensive approach?

4472
02:31:15,180 --> 02:31:17,049
And so if you're worried about you know,

4473
02:31:17,049 --> 02:31:18,979
AI generated pathogens, the right thing to do is to have

4474
02:31:18,979 --> 02:31:20,788
a permanent project warp speed, right?

4475
02:31:20,788 --> 02:31:21,621
Funded lavishly.

4476
02:31:21,621 --> 02:31:23,663
Let's do a Manhattan, let's talk about Manhattan project,

4477
02:31:23,663 --> 02:31:26,470
let's do a Manhattan project for biological defense, right?

4478
02:31:26,470 --> 02:31:28,646
And let's build ais and let's have like broad spectrum

4479
02:31:28,646 --> 02:31:31,115
vaccines where like, we're insulated from every pathogen.

4480
02:31:31,115 --> 02:31:36,115
- And well, the interesting thing is because it's software,

4481
02:31:36,770 --> 02:31:37,956
a kid in his basement,

4482
02:31:37,956 --> 02:31:41,417
teenager could build like a system that defends against like

4483
02:31:41,417 --> 02:31:46,000
the worst, I mean, and to me defense is super exciting.

4484
02:31:48,238 --> 02:31:51,504
It's like, if you believe in the good of human nature

4485
02:31:51,504 --> 02:31:53,577
for that, most people wanna do good,

4486
02:31:53,577 --> 02:31:57,999
to be the savior of humanity is really exciting.

4487
02:31:57,999 --> 02:31:58,832
- Yes.

4488
02:31:58,832 --> 02:32:00,178
- Not, okay, that's a dramatic statement.

4489
02:32:00,178 --> 02:32:01,553
But to help people.

4490
02:32:01,553 --> 02:32:03,206
- Yeah, of course. Help people.

4491
02:32:03,206 --> 02:32:04,039
- Yeah. Okay.

4492
02:32:04,039 --> 02:32:05,367
What about just the jump around,

4493
02:32:05,367 --> 02:32:09,959
what about the risk of will AI lead to crippling inequality?

4494
02:32:09,959 --> 02:32:10,792
You know,

4495
02:32:10,792 --> 02:32:12,407
'cause we're kind of saying everybody's life will

4496
02:32:12,407 --> 02:32:13,740
become better.

4497
02:32:13,740 --> 02:32:16,355
Is it possible that the rich get richer here?

4498
02:32:16,355 --> 02:32:17,227
- Yeah, so this goes,

4499
02:32:17,227 --> 02:32:18,948
this actually ironically goes back to Marxism.

4500
02:32:18,948 --> 02:32:21,543
So 'cause this was the, so the core claim of Marxism, right?

4501
02:32:21,543 --> 02:32:22,686
Basically was that the owner,

4502
02:32:22,686 --> 02:32:24,127
the owners of capital would basically own

4503
02:32:24,127 --> 02:32:25,085
the means of production.

4504
02:32:25,085 --> 02:32:26,638
And then over time they would basically accumulate

4505
02:32:26,638 --> 02:32:29,118
all the wealth the workers would be paying in, you know,

4506
02:32:29,118 --> 02:32:30,860
and getting nothing in return

4507
02:32:30,860 --> 02:32:32,316
'cause they wouldn't be needed anymore, right?

4508
02:32:32,316 --> 02:32:33,480
Marx was very worried about mech what he called

4509
02:32:33,480 --> 02:32:36,552
mechanization or what later became known as automation.

4510
02:32:36,552 --> 02:32:37,615
And that, you know,

4511
02:32:37,615 --> 02:32:39,561
the workers would be immiserated and the the capitalists

4512
02:32:39,561 --> 02:32:40,952
would end up with all.

4513
02:32:40,952 --> 02:32:43,320
And so this was one of the core principles of Marxism.

4514
02:32:43,320 --> 02:32:45,061
Of course it turned out to be wrong about every previous

4515
02:32:45,061 --> 02:32:46,594
wave of technology.

4516
02:32:46,594 --> 02:32:47,468
The reason it,

4517
02:32:47,468 --> 02:32:48,301
it turned out to be wrong

4518
02:32:48,301 --> 02:32:49,560
about every previous wave of technology is

4519
02:32:49,560 --> 02:32:52,753
that the way that the self-interested owner of the machines

4520
02:32:52,753 --> 02:32:54,431
makes the most money is by providing

4521
02:32:54,431 --> 02:32:56,592
the production capability in the form

4522
02:32:56,592 --> 02:32:57,838
of products and services

4523
02:32:57,838 --> 02:33:01,347
to the most people, the most customers as possible, right?

4524
02:33:01,347 --> 02:33:02,310
The the largest,

4525
02:33:02,310 --> 02:33:04,334
and this is one of those funny things where every CEO knows

4526
02:33:04,334 --> 02:33:05,167
this intuitively,

4527
02:33:05,167 --> 02:33:06,707
and yet it's like hard to explain from the outside

4528
02:33:06,707 --> 02:33:09,024
the way you make the most money in any business is

4529
02:33:09,024 --> 02:33:11,548
by selling to the largest market you can possibly get to.

4530
02:33:11,548 --> 02:33:13,444
The largest market you can possibly get to is everybody

4531
02:33:13,444 --> 02:33:14,323
on the planet.

4532
02:33:14,323 --> 02:33:17,092
And so every large company does is everything that it can

4533
02:33:17,092 --> 02:33:19,167
to drive down prices, to be able to get volumes up,

4534
02:33:19,167 --> 02:33:20,647
to be able to get to everybody on the planet.

4535
02:33:20,647 --> 02:33:23,308
And that happened with everything from electricity,

4536
02:33:23,308 --> 02:33:25,306
it happened with telephones, it happened with radio,

4537
02:33:25,306 --> 02:33:27,387
it happened with automobiles, it happened with smartphones,

4538
02:33:27,387 --> 02:33:31,778
it happened with PCs, it happened with the internet,

4539
02:33:31,778 --> 02:33:33,987
it happened with mobile broadband.

4540
02:33:33,987 --> 02:33:36,215
It's happened by the way, with Coca-Cola.

4541
02:33:36,215 --> 02:33:38,459
It's happened with like every, you know,

4542
02:33:38,459 --> 02:33:40,432
basically every industrially produced, you know,

4543
02:33:40,432 --> 02:33:41,415
good or service people,

4544
02:33:41,415 --> 02:33:43,257
you wanna drive it to the largest possible market.

4545
02:33:43,257 --> 02:33:45,612
And then as proof of that, it's already happened, right?

4546
02:33:45,612 --> 02:33:49,095
Which is the early adopters of like ChatGPT

4547
02:33:49,095 --> 02:33:52,695
and Bing are not like, you know, Exxon and Boeing.

4548
02:33:52,695 --> 02:33:55,652
They're, you know, your uncle and your nephew, right?

4549
02:33:55,652 --> 02:33:56,535
It's just like free.

4550
02:33:56,535 --> 02:33:58,091
It's either freely available online or it's available

4551
02:33:58,091 --> 02:33:59,566
for 20 bucks a month or something.

4552
02:33:59,566 --> 02:34:00,399
But the, you know,

4553
02:34:00,399 --> 02:34:01,934
these things went this technology went

4554
02:34:01,934 --> 02:34:03,383
mass market immediately.

4555
02:34:03,383 --> 02:34:06,435
And so look, the owners of the means of production,

4556
02:34:06,435 --> 02:34:08,053
the whoever does this now mentioned

4557
02:34:08,053 --> 02:34:09,028
these trillion dollar questions.

4558
02:34:09,028 --> 02:34:11,295
There are people who are gonna get really rich doing this,

4559
02:34:11,295 --> 02:34:12,128
producing these things,

4560
02:34:12,128 --> 02:34:13,299
but they're gonna get really rich by taking

4561
02:34:13,299 --> 02:34:15,840
this technology to the broadest possible market.

4562
02:34:15,840 --> 02:34:16,815
- So yes, they'll get rich,

4563
02:34:16,815 --> 02:34:20,487
but they'll get rich having a huge positive impact on.

4564
02:34:20,487 --> 02:34:23,537
- Yeah, making the technology available to everybody. Right.

4565
02:34:23,537 --> 02:34:24,839
And again, smartphone, same thing.

4566
02:34:24,839 --> 02:34:28,254
So there's this amazing kind of twist in business history,

4567
02:34:28,254 --> 02:34:31,770
which is you cannot spend $10,000 on a smartphone, right?

4568
02:34:31,770 --> 02:34:33,390
You can't spend a hundred thousand dollars,

4569
02:34:33,390 --> 02:34:34,223
you can't spend a million,

4570
02:34:34,223 --> 02:34:35,414
like I would buy the million dollars smartphone.

4571
02:34:35,414 --> 02:34:36,294
Like I'm signed up for it.

4572
02:34:36,294 --> 02:34:37,127
Like if it's like,

4573
02:34:37,127 --> 02:34:38,669
suppose a million dollar smartphone was like much better

4574
02:34:38,669 --> 02:34:39,885
than the thousand dollar smartphone.

4575
02:34:39,885 --> 02:34:41,697
Like I'm there to buy it, it doesn't exist.

4576
02:34:41,697 --> 02:34:42,530
Why doesn't it exist?

4577
02:34:42,530 --> 02:34:44,632
Apple makes so much more money driving the price

4578
02:34:44,632 --> 02:34:45,895
further down from a thousand dollars

4579
02:34:45,895 --> 02:34:47,781
than they would trying to harvest, right?

4580
02:34:47,781 --> 02:34:49,121
And so it's just this repeating pattern you see over

4581
02:34:49,121 --> 02:34:53,459
and over again where and what's great about it is you,

4582
02:34:53,459 --> 02:34:56,761
you do not need to rely on anybody's enlightened right?

4583
02:34:56,761 --> 02:34:57,850
Generosity to do this.

4584
02:34:57,850 --> 02:35:01,142
You just need to rely on capitalist self-interest.

4585
02:35:01,142 --> 02:35:04,349
- What about AI taking our jobs?

4586
02:35:04,349 --> 02:35:05,714
- Yeah. So very very similar thing here.

4587
02:35:05,714 --> 02:35:08,153
There's sort of a, there's a core fallacy which again was

4588
02:35:08,153 --> 02:35:09,195
very common in Marxism,

4589
02:35:09,195 --> 02:35:11,224
which is what's called the lump of labor fallacy.

4590
02:35:11,224 --> 02:35:13,305
And this is sort of the fallacy that there is

4591
02:35:13,305 --> 02:35:15,408
only a fixed amount of work to be done in the world.

4592
02:35:15,408 --> 02:35:17,715
And it's all being done today by people

4593
02:35:17,715 --> 02:35:19,052
and then if machines do it,

4594
02:35:19,052 --> 02:35:21,303
there's no other work to be done by people.

4595
02:35:21,303 --> 02:35:23,162
And that's just a completely backwards view

4596
02:35:23,162 --> 02:35:25,490
on how the economy develops and grows.

4597
02:35:25,490 --> 02:35:28,186
Because what happens is not in fact that what happens is

4598
02:35:28,186 --> 02:35:31,364
the introduction of technology into production process

4599
02:35:31,364 --> 02:35:32,953
causes prices to fall.

4600
02:35:32,953 --> 02:35:35,803
As prices fall, consumers have more spending power.

4601
02:35:35,803 --> 02:35:37,473
As consumers have more spending power,

4602
02:35:37,473 --> 02:35:38,683
they create new demand.

4603
02:35:38,683 --> 02:35:42,156
That new demand then causes capital and labor to form

4604
02:35:42,156 --> 02:35:44,636
into new enterprises to satisfy nuance and needs.

4605
02:35:44,636 --> 02:35:47,234
And the result is more jobs at higher wages.

4606
02:35:47,234 --> 02:35:50,442
- So nuance and needs, the worries that the creation

4607
02:35:50,442 --> 02:35:54,692
of nuance and needs at a rapid rate will mean

4608
02:35:54,692 --> 02:35:56,272
there's a lot of turnover in jobs.

4609
02:35:56,272 --> 02:35:57,890
So people will lose jobs.

4610
02:35:57,890 --> 02:36:00,874
Just the actual experience of losing a job and having

4611
02:36:00,874 --> 02:36:03,151
to learn new things and new skills is painful

4612
02:36:03,151 --> 02:36:04,649
for the individuals.

4613
02:36:04,649 --> 02:36:05,482
- Well, two things.

4614
02:36:05,482 --> 02:36:06,992
One is the new jobs are often much better.

4615
02:36:06,992 --> 02:36:09,259
So this actually came up that there was this panic

4616
02:36:09,259 --> 02:36:11,202
about a decade ago and all the truck drivers are gonna

4617
02:36:11,202 --> 02:36:12,120
lose their jobs, right?

4618
02:36:12,120 --> 02:36:12,953
And number one,

4619
02:36:12,953 --> 02:36:14,198
that didn't happen 'cause we haven't figured out a way

4620
02:36:14,198 --> 02:36:16,700
to actually finish that yet.

4621
02:36:16,700 --> 02:36:18,624
But the other thing was like, look, truck driver,

4622
02:36:18,624 --> 02:36:20,348
like I grew up in a town that was basically consisted

4623
02:36:20,348 --> 02:36:21,259
of a truck stop, right?

4624
02:36:21,259 --> 02:36:22,669
And I like knew a lot of truck drivers

4625
02:36:22,669 --> 02:36:24,966
and like truck drivers live a decade shorter

4626
02:36:24,966 --> 02:36:26,472
than everybody else.

4627
02:36:26,472 --> 02:36:28,816
Like, it's actually like a very dangerous,

4628
02:36:28,816 --> 02:36:29,704
like, they get,

4629
02:36:29,704 --> 02:36:31,647
like literally they have like higher rates of skin cancer

4630
02:36:31,647 --> 02:36:32,679
and on the left side of their,

4631
02:36:32,679 --> 02:36:33,833
on the left side of their body

4632
02:36:33,833 --> 02:36:35,439
from being in the sun all the time.

4633
02:36:35,439 --> 02:36:36,786
The vibration of being in the truck is actually

4634
02:36:36,786 --> 02:36:39,325
very damaging to your physiology.

4635
02:36:39,325 --> 02:36:41,365
- And there's actually perhaps partially

4636
02:36:41,365 --> 02:36:44,288
because of that reason there's a shortage

4637
02:36:44,288 --> 02:36:47,512
of people who wanna be truck drivers.

4638
02:36:47,512 --> 02:36:50,297
- Yeah. Like, it's not like the question always you wanna

4639
02:36:50,297 --> 02:36:51,740
ask somebody like that is, do you want, you know,

4640
02:36:51,740 --> 02:36:54,036
do you want your kid to be doing this job?

4641
02:36:54,036 --> 02:36:55,666
And like most of them will tell you no.

4642
02:36:55,666 --> 02:36:57,143
Like, I want my kid to be sitting in a cubicle

4643
02:36:57,143 --> 02:36:58,793
somewhere like where they don't have this, like,

4644
02:36:58,793 --> 02:37:00,720
where they don't die 10 years earlier.

4645
02:37:00,720 --> 02:37:01,915
And so, the new jobs, number one,

4646
02:37:01,915 --> 02:37:03,119
the new jobs are often better,

4647
02:37:03,119 --> 02:37:05,258
but you don't get the new jobs until you go through

4648
02:37:05,258 --> 02:37:06,091
the change.

4649
02:37:06,091 --> 02:37:07,740
And then to your point, the training thing,

4650
02:37:07,740 --> 02:37:09,794
you know, is always the issue is can people adapt?

4651
02:37:09,794 --> 02:37:10,627
And again,

4652
02:37:10,627 --> 02:37:11,776
here you need to imagine living in a world

4653
02:37:11,776 --> 02:37:15,142
in which everybody has the AI assistant capability, right?

4654
02:37:15,142 --> 02:37:16,834
To be able to pick up new skills much more quickly

4655
02:37:16,834 --> 02:37:17,967
and be able to have some, you know,

4656
02:37:17,967 --> 02:37:19,402
be able to have a machine to work with

4657
02:37:19,402 --> 02:37:20,235
to augment their skills.

4658
02:37:20,235 --> 02:37:21,157
- It's still gonna be painful,

4659
02:37:21,157 --> 02:37:22,752
but that's the process of life.

4660
02:37:22,752 --> 02:37:24,305
- It's painful for some people. I mean there's no, like,

4661
02:37:24,305 --> 02:37:25,949
there's no question it's painful for some people

4662
02:37:25,949 --> 02:37:27,358
and they're, you know, they're yes,

4663
02:37:27,358 --> 02:37:28,310
it's not, again,

4664
02:37:28,310 --> 02:37:29,460
I'm not a utopian on this and it's not like,

4665
02:37:29,460 --> 02:37:31,078
it's positive for everybody in the moment,

4666
02:37:31,078 --> 02:37:34,196
but it has been overwhelmingly positive for 300 years.

4667
02:37:34,196 --> 02:37:36,273
I mean, look, the concern here, the concern,

4668
02:37:36,273 --> 02:37:37,675
this concern has played out

4669
02:37:37,675 --> 02:37:40,236
for literally centuries and you know,

4670
02:37:40,236 --> 02:37:42,166
this is the sort of Luddite, you know,

4671
02:37:42,166 --> 02:37:44,269
the story of the Luddites that you may remember,

4672
02:37:44,269 --> 02:37:47,336
there was a panic in the two thousands around outsourcing

4673
02:37:47,336 --> 02:37:48,575
was gonna take all the jobs.

4674
02:37:48,575 --> 02:37:51,202
There was a panic in the 2010s that robots were gonna take

4675
02:37:51,202 --> 02:37:52,285
all the jobs.

4676
02:37:53,659 --> 02:37:55,660
In 2019 before COVID

4677
02:37:55,660 --> 02:37:57,998
we had more jobs at higher wages both

4678
02:37:57,998 --> 02:37:59,253
in the country and in the world

4679
02:37:59,253 --> 02:38:00,769
than at any point in human history.

4680
02:38:00,769 --> 02:38:04,215
And so the overwhelming evidence is that the net gain here

4681
02:38:04,215 --> 02:38:06,323
is like, just like wildly positive.

4682
02:38:06,323 --> 02:38:09,431
And most people like overwhelmingly come out the other side

4683
02:38:09,431 --> 02:38:11,436
being huge beneficiaries of this.

4684
02:38:11,436 --> 02:38:14,093
- So you write that the single greatest risk,

4685
02:38:14,093 --> 02:38:15,801
this is the risk you're most convinced

4686
02:38:15,801 --> 02:38:17,909
by the single greatest risk of AI is

4687
02:38:17,909 --> 02:38:20,707
that China wins global AI dominance

4688
02:38:20,707 --> 02:38:23,737
and we the United States and the West do not.

4689
02:38:23,737 --> 02:38:25,211
Can you elaborate?

4690
02:38:25,211 --> 02:38:28,210
- Yeah. So this is the other thing which is

4691
02:38:28,210 --> 02:38:29,869
a lot of this sort of AI risk debates today sort

4692
02:38:29,869 --> 02:38:31,660
of assume that we're the only game in town, right?

4693
02:38:31,660 --> 02:38:33,143
And so we have the ability to kind of sit

4694
02:38:33,143 --> 02:38:35,360
in the United States and criticize ourselves and do,

4695
02:38:35,360 --> 02:38:36,755
you know, have our government like, you know,

4696
02:38:36,755 --> 02:38:38,108
beat up on our companies and we'll figure out a way

4697
02:38:38,108 --> 02:38:40,453
to restrict what our companies can do and you know,

4698
02:38:40,453 --> 02:38:41,604
we're gonna, you know, we're gonna ban this

4699
02:38:41,604 --> 02:38:43,118
and ban that, restrict this and do that.

4700
02:38:43,118 --> 02:38:44,991
And then there's this like other like force out there

4701
02:38:44,991 --> 02:38:46,941
that like doesn't believe we have any power

4702
02:38:46,941 --> 02:38:49,374
over them whatsoever and they have no desire to sign up

4703
02:38:49,374 --> 02:38:51,555
for whatever rules we decide to put in place

4704
02:38:51,555 --> 02:38:53,886
and they're gonna do whatever it is they're gonna do.

4705
02:38:53,886 --> 02:38:56,122
And we have no control over it at all.

4706
02:38:56,122 --> 02:38:59,427
And it's China and specifically the Chinese Communist party

4707
02:38:59,427 --> 02:39:03,790
and they have a completely publicized open, you know,

4708
02:39:03,790 --> 02:39:06,776
plan for what they're gonna do with AI.

4709
02:39:06,776 --> 02:39:08,802
And it is not what we have in mind.

4710
02:39:08,802 --> 02:39:10,794
And not only do they have that as a vision

4711
02:39:10,794 --> 02:39:11,830
and a plan for their society,

4712
02:39:11,830 --> 02:39:13,464
but they also have it as a vision and plan

4713
02:39:13,464 --> 02:39:14,624
for the rest of the world.

4714
02:39:14,624 --> 02:39:16,301
- So their plan is what? Surveillance?

4715
02:39:16,301 --> 02:39:17,786
- Authoritarian control.

4716
02:39:17,786 --> 02:39:21,291
So authoritarian population control you know,

4717
02:39:21,291 --> 02:39:23,081
good old-fashioned communist authoritarian control

4718
02:39:23,081 --> 02:39:27,539
and surveillance and enforcement and social credit scores

4719
02:39:27,539 --> 02:39:28,588
and all the rest of it.

4720
02:39:28,588 --> 02:39:31,000
And you are gonna be monitored and metered

4721
02:39:31,000 --> 02:39:33,747
within an inch of everything all the time.

4722
02:39:33,747 --> 02:39:35,184
And it's gonna, you know,

4723
02:39:35,184 --> 02:39:36,660
it's basically the end of human freedom

4724
02:39:36,660 --> 02:39:37,671
and that's their goal.

4725
02:39:37,671 --> 02:39:39,082
And you know, they justify it on the basis

4726
02:39:39,082 --> 02:39:40,504
of that's what leads to peace.

4727
02:39:40,504 --> 02:39:44,191
- You're worried that the regulating

4728
02:39:44,191 --> 02:39:46,853
in the United States will haul progress enough

4729
02:39:46,853 --> 02:39:50,737
to where the Chinese government would win that race.

4730
02:39:50,737 --> 02:39:51,611
- So their plan, yeah.

4731
02:39:51,611 --> 02:39:52,488
Yes, yes.

4732
02:39:52,488 --> 02:39:53,712
And the reason for that is they, and again,

4733
02:39:53,712 --> 02:39:54,571
they're very public on this.

4734
02:39:54,571 --> 02:39:56,244
They have, their plan is to proliferate

4735
02:39:56,244 --> 02:39:57,479
their approach around the world

4736
02:39:57,479 --> 02:39:58,613
and they have this program called

4737
02:39:58,613 --> 02:40:00,046
the Digital Silk Road, right.

4738
02:40:00,046 --> 02:40:02,243
Which is building on their Silk Road investment program.

4739
02:40:02,243 --> 02:40:03,320
And they've got,

4740
02:40:03,320 --> 02:40:04,856
they've been laying networking infrastructure

4741
02:40:04,856 --> 02:40:06,961
all over the world with their 5G, right.

4742
02:40:06,961 --> 02:40:08,560
Work with their company Huawei.

4743
02:40:08,560 --> 02:40:10,392
And so, they've been laying all this fabric,

4744
02:40:10,392 --> 02:40:12,613
but financial and technological fabric all over the world.

4745
02:40:12,613 --> 02:40:13,446
And their plan is

4746
02:40:13,446 --> 02:40:15,414
to roll out their vision of AI on top of that and to have

4747
02:40:15,414 --> 02:40:17,459
every other country be running their version.

4748
02:40:17,459 --> 02:40:20,846
And then if you're a country prone to, you know,

4749
02:40:20,846 --> 02:40:22,419
authoritarianism, you're gonna find this to be

4750
02:40:22,419 --> 02:40:24,656
an incredible way to become more authoritarian.

4751
02:40:24,656 --> 02:40:26,455
If you're a country, by the way,

4752
02:40:26,455 --> 02:40:27,564
not prone to authoritarianism,

4753
02:40:27,564 --> 02:40:29,529
you're gonna have the Chinese Communist Party running

4754
02:40:29,529 --> 02:40:32,537
your infrastructure and having backdoor into it. Right.

4755
02:40:32,537 --> 02:40:34,094
Which is also not good.

4756
02:40:34,094 --> 02:40:37,269
- What's your sense of where they stand in terms of the race

4757
02:40:37,269 --> 02:40:41,558
towards super intelligence as compared to the United States?

4758
02:40:41,558 --> 02:40:42,854
- Yeah, so good news is they're behind,

4759
02:40:42,854 --> 02:40:44,722
but bad news is they, you know,

4760
02:40:44,722 --> 02:40:46,375
let's just say they get access to everything we do.

4761
02:40:46,375 --> 02:40:49,511
So they're probably a year behind at each point in time,

4762
02:40:49,511 --> 02:40:50,509
but they get, you know,

4763
02:40:50,509 --> 02:40:52,309
downloads I think of basically all of our work

4764
02:40:52,309 --> 02:40:55,549
on a regular basis through a variety of means.

4765
02:40:55,549 --> 02:40:57,822
And they are, you know, at least we'll see,

4766
02:40:57,822 --> 02:40:59,076
they're at least putting out reports of very,

4767
02:40:59,076 --> 02:41:00,376
they just put out a report last week

4768
02:41:00,376 --> 02:41:02,876
of a GPT 3.5 analog.

4769
02:41:02,876 --> 02:41:05,712
They put out this report, forget what it's called,

4770
02:41:05,712 --> 02:41:07,867
but they put out this report of this and they did

4771
02:41:07,867 --> 02:41:09,785
and they, you know, the way when open AI you know,

4772
02:41:09,785 --> 02:41:12,026
puts out, one of the ways they test,

4773
02:41:12,026 --> 02:41:13,902
you know, GPT they run it

4774
02:41:13,902 --> 02:41:16,716
through standardized exams like the SAT. Right.

4775
02:41:16,716 --> 02:41:18,805
Just how you can kind of gauge how smart it is.

4776
02:41:18,805 --> 02:41:20,158
And so the Chinese report,

4777
02:41:20,158 --> 02:41:23,307
they ran their LLM through the Chinese equivalent

4778
02:41:23,307 --> 02:41:26,352
of the SAT and it includes a section on Marxism

4779
02:41:26,352 --> 02:41:29,565
and a section on, I say tongue of thought.

4780
02:41:29,565 --> 02:41:31,537
And it turns out their AI does very well

4781
02:41:31,537 --> 02:41:33,247
on both of those topics.

4782
02:41:33,247 --> 02:41:34,497
- That's right.

4783
02:41:35,441 --> 02:41:36,274
- So like.

4784
02:41:36,274 --> 02:41:37,796
- Oh, this alignment thing.

4785
02:41:37,796 --> 02:41:38,832
- Communist AI, right?

4786
02:41:38,832 --> 02:41:40,441
Like literal communist AI. Right?

4787
02:41:40,441 --> 02:41:42,777
And so their vision is like, that's the, you know,

4788
02:41:42,777 --> 02:41:45,776
so you know, you can just imagine like you're a school,

4789
02:41:45,776 --> 02:41:48,115
you know, you're a kid 10 years from now in Argentina

4790
02:41:48,115 --> 02:41:52,032
or in Germany or in who knows where, Indonesia.

4791
02:41:52,947 --> 02:41:53,780
And you ask the AI,

4792
02:41:53,780 --> 02:41:55,702
I'd explain to you like how the economy works

4793
02:41:55,702 --> 02:41:57,027
and it gives you the most cheery,

4794
02:41:57,027 --> 02:41:58,562
upbeat explanation of Chinese style communism

4795
02:41:58,562 --> 02:41:59,840
you've ever heard. Right.

4796
02:41:59,840 --> 02:42:03,680
So like the stakes here are like really big.

4797
02:42:03,680 --> 02:42:05,078
- Well, as we've been talking about,

4798
02:42:05,078 --> 02:42:07,059
my hope is not just with the United States,

4799
02:42:07,059 --> 02:42:09,323
but with just the kid in his basement.

4800
02:42:09,323 --> 02:42:10,375
The open source LLM.

4801
02:42:10,375 --> 02:42:12,875
'Cause I don't know if I trust

4802
02:42:14,231 --> 02:42:17,495
large centralized institutions with super powerful AI

4803
02:42:17,495 --> 02:42:21,662
no matter what their ideology as a power corrupts.

4804
02:42:23,507 --> 02:42:26,134
You've been investing in tech companies for about,

4805
02:42:26,134 --> 02:42:27,429
let's say 20 years.

4806
02:42:27,429 --> 02:42:32,018
And about 15 of which was with Andreessen Horowitz.

4807
02:42:32,018 --> 02:42:35,314
What interesting trends in tech have you seen

4808
02:42:35,314 --> 02:42:36,189
over that time?

4809
02:42:36,189 --> 02:42:38,067
Let's just talk about companies and just the evolution

4810
02:42:38,067 --> 02:42:39,206
of the tech industry.

4811
02:42:39,206 --> 02:42:42,619
- I mean the big shift over 20 years has been that tech used

4812
02:42:42,619 --> 02:42:46,547
to be a tools industry for basically from like 1940 through

4813
02:42:46,547 --> 02:42:47,524
to about 2010,

4814
02:42:47,524 --> 02:42:50,168
almost all the big successful companies were pick

4815
02:42:50,168 --> 02:42:51,001
and shovels companies.

4816
02:42:51,001 --> 02:42:53,853
So PC, database, smartphone, you know,

4817
02:42:53,853 --> 02:42:57,175
some tool that somebody else would pick up and use.

4818
02:42:57,175 --> 02:43:00,845
Since 2010, most of the big wins have been in applications.

4819
02:43:00,845 --> 02:43:04,071
So a company that starts you know,

4820
02:43:04,071 --> 02:43:06,597
starts in an existing industry and goes directly

4821
02:43:06,597 --> 02:43:08,968
to the customer in that industry.

4822
02:43:08,968 --> 02:43:09,801
And you know,

4823
02:43:09,801 --> 02:43:11,932
the earliest examples there were like Uber and Lyft

4824
02:43:11,932 --> 02:43:12,765
and Airbnb.

4825
02:43:12,765 --> 02:43:15,749
And then that model is kind of elaborating out.

4826
02:43:15,749 --> 02:43:18,772
The AI thing is actually a reversion on that for now

4827
02:43:18,772 --> 02:43:20,976
'cause like most of the AI business right now is actually

4828
02:43:20,976 --> 02:43:24,503
in cloud provision of AI APIs for other people to build on.

4829
02:43:24,503 --> 02:43:26,458
- But the big thing will probably be in app.

4830
02:43:26,458 --> 02:43:29,424
- Yeah. I think most of the money I think probably will be

4831
02:43:29,424 --> 02:43:31,785
in whatever your AI financial advisor

4832
02:43:31,785 --> 02:43:34,845
or your AI doctor or your AI lawyer or, you know,

4833
02:43:34,845 --> 02:43:36,739
take your pick of whatever the domain is.

4834
02:43:36,739 --> 02:43:38,841
And there, and what's interesting is, you know,

4835
02:43:38,841 --> 02:43:40,626
the valley kind of does everything.

4836
02:43:40,626 --> 02:43:43,687
The entrepreneurs kind of elaborate every possible idea.

4837
02:43:43,687 --> 02:43:46,355
And so there will be a set of companies that like make AI

4838
02:43:46,355 --> 02:43:49,599
something that can be purchased and used by large law firms

4839
02:43:49,599 --> 02:43:51,764
and then there will be other companies that just go direct

4840
02:43:51,764 --> 02:43:53,931
to market as an AI lawyer.

4841
02:43:54,886 --> 02:43:58,813
- What advice could you give for a startup founder?

4842
02:43:58,813 --> 02:44:01,864
Just haven't seen so many successful companies,

4843
02:44:01,864 --> 02:44:03,875
so many companies that fail also,

4844
02:44:03,875 --> 02:44:05,835
what advice could you give to a startup founder,

4845
02:44:05,835 --> 02:44:09,614
someone who wants to build the next super successful startup

4846
02:44:09,614 --> 02:44:14,275
in the tech space? The Googles, the Apples, the Twitters.

4847
02:44:14,275 --> 02:44:15,665
- Yeah. So the great thing

4848
02:44:15,665 --> 02:44:16,937
about the really great founders is

4849
02:44:16,937 --> 02:44:18,216
they don't take any advice.

4850
02:44:18,216 --> 02:44:21,937
So, if you find yourself listening to advice,

4851
02:44:21,937 --> 02:44:23,989
maybe you shouldn't do it.

4852
02:44:23,989 --> 02:44:26,632
- But that's actually, just to elaborate on that,

4853
02:44:26,632 --> 02:44:30,234
if you could also speak to great founders too.

4854
02:44:30,234 --> 02:44:32,417
Like what makes a great founder?

4855
02:44:32,417 --> 02:44:34,855
- So what makes a great founder is super smart,

4856
02:44:34,855 --> 02:44:39,677
coupled with super energetic, coupled with super courageous.

4857
02:44:39,677 --> 02:44:41,745
I think it's some of those three and--

4858
02:44:41,745 --> 02:44:43,510
- Intelligence, passion and courage.

4859
02:44:43,510 --> 02:44:46,145
- The first two are traits and the third one is a choice.

4860
02:44:46,145 --> 02:44:47,839
I think courage is a choice.

4861
02:44:47,839 --> 02:44:52,174
Well 'cause courage is a question of pain tolerance, right?

4862
02:44:52,174 --> 02:44:55,304
So how many times are you willing to get punched

4863
02:44:55,304 --> 02:44:57,410
in the face before you quit?

4864
02:44:57,410 --> 02:45:00,662
And here's maybe the biggest thing people don't understand

4865
02:45:00,662 --> 02:45:03,456
about what it's like to be a startup founder is it gets

4866
02:45:03,456 --> 02:45:04,549
very romanticized, right?

4867
02:45:04,549 --> 02:45:06,297
And even when it, even when they fail,

4868
02:45:06,297 --> 02:45:07,444
it still gets romanticized about like

4869
02:45:07,444 --> 02:45:08,511
what a great adventure it was.

4870
02:45:08,511 --> 02:45:11,986
But like the reality of it is most of what happens is people

4871
02:45:11,986 --> 02:45:13,742
telling you no and then they usually follow

4872
02:45:13,742 --> 02:45:15,923
that with you're stupid, right.

4873
02:45:15,923 --> 02:45:17,505
No, I will not come to work for you.

4874
02:45:17,505 --> 02:45:19,181
I will not leave my cushy job at Google

4875
02:45:19,181 --> 02:45:20,148
to come work for you.

4876
02:45:20,148 --> 02:45:21,642
No, I'm not gonna buy your product, you know, no,

4877
02:45:21,642 --> 02:45:23,073
I'm not gonna run a story about your company.

4878
02:45:23,073 --> 02:45:25,199
No, I'm not this, that, the other thing.

4879
02:45:25,199 --> 02:45:28,045
And so a huge amount of what people have to do is just get

4880
02:45:28,045 --> 02:45:29,269
used to just getting punched

4881
02:45:29,269 --> 02:45:31,151
and the reason people don't understand this is

4882
02:45:31,151 --> 02:45:32,252
because when you're a founder,

4883
02:45:32,252 --> 02:45:33,595
you cannot let on that this is happening

4884
02:45:33,595 --> 02:45:34,922
'cause it will cause people to think

4885
02:45:34,922 --> 02:45:36,959
that you're weak and they'll lose faith in you.

4886
02:45:36,959 --> 02:45:39,109
So you have to pretend that you're having a great time

4887
02:45:39,109 --> 02:45:42,427
when you're dying inside, right?

4888
02:45:42,427 --> 02:45:44,384
You're just in misery.

4889
02:45:44,384 --> 02:45:45,802
- But why did they do it?

4890
02:45:45,802 --> 02:45:47,267
- Why did they do? Yeah, that's the thing.

4891
02:45:47,267 --> 02:45:48,562
It's like it is a level,

4892
02:45:48,562 --> 02:45:50,131
this is actually one of the conclusions I think is

4893
02:45:50,131 --> 02:45:52,142
that I think it's actually for most of these people

4894
02:45:52,142 --> 02:45:54,544
on a risk adjusted basis, it's probably an irrational act.

4895
02:45:54,544 --> 02:45:56,688
They could probably be more financially successful

4896
02:45:56,688 --> 02:45:58,603
on average if they just got like a real job in

4897
02:45:58,603 --> 02:45:59,905
at a big company.

4898
02:45:59,905 --> 02:46:01,427
But there's, you know,

4899
02:46:01,427 --> 02:46:03,627
some people just have an irrational need to do something new

4900
02:46:03,627 --> 02:46:05,639
and build something for themselves and, you know,

4901
02:46:05,639 --> 02:46:07,936
some people just can't tolerate having bosses.

4902
02:46:07,936 --> 02:46:08,769
Oh, here's the fun thing is

4903
02:46:08,769 --> 02:46:10,909
how do you reference check founders, right?

4904
02:46:10,909 --> 02:46:11,742
So you call the, you know,

4905
02:46:11,742 --> 02:46:12,748
normal way you reference check,

4906
02:46:12,748 --> 02:46:14,088
you're hiring somebody is you call the bosses,

4907
02:46:14,088 --> 02:46:15,252
they're their, and you know,

4908
02:46:15,252 --> 02:46:16,727
and you find out if they were good employees

4909
02:46:16,727 --> 02:46:18,977
and now you're trying to reference check Steve Jobs, right?

4910
02:46:18,977 --> 02:46:20,633
And it's like, oh God, he was terrible.

4911
02:46:20,633 --> 02:46:21,921
You know, he was a terrible employee.

4912
02:46:21,921 --> 02:46:24,513
He never did what we told him to do.

4913
02:46:24,513 --> 02:46:26,911
- So what's a good reference?

4914
02:46:26,911 --> 02:46:28,888
Do you want the previous boss to actually say

4915
02:46:28,888 --> 02:46:32,087
they never did what you told him to do?

4916
02:46:32,087 --> 02:46:33,268
That might be a good thing.

4917
02:46:33,268 --> 02:46:35,287
- Well, ideally what you want is I will go,

4918
02:46:35,287 --> 02:46:37,388
I would like to go to work for that person.

4919
02:46:37,388 --> 02:46:39,739
He worked for me here and now I'd like to work for him.

4920
02:46:39,739 --> 02:46:42,541
No, unfortunately, most people can't, their egos can't

4921
02:46:42,541 --> 02:46:44,222
handle that. So they won't say that.

4922
02:46:44,222 --> 02:46:45,635
But that's the ideal.

4923
02:46:45,635 --> 02:46:47,366
- What advice would you give to those folks

4924
02:46:47,366 --> 02:46:51,397
in the space of intelligence, passion and courage?

4925
02:46:51,397 --> 02:46:54,304
- So I think the other big thing is you see people sometimes

4926
02:46:54,304 --> 02:46:55,228
who say, I wanna start a company

4927
02:46:55,228 --> 02:46:56,965
and then they kind of work through the process

4928
02:46:56,965 --> 02:46:58,163
of coming up with an idea.

4929
02:46:58,163 --> 02:47:00,779
And generally those don't work as well as the case

4930
02:47:00,779 --> 02:47:02,316
where somebody has the idea first

4931
02:47:02,316 --> 02:47:04,052
and then they kind of realize

4932
02:47:04,052 --> 02:47:05,835
that there's an opportunity to build a company

4933
02:47:05,835 --> 02:47:07,257
and then they just turn out to be the right kind

4934
02:47:07,257 --> 02:47:08,475
of person to do that.

4935
02:47:08,475 --> 02:47:12,089
- When you say idea, do you mean long-term big vision

4936
02:47:12,089 --> 02:47:15,538
or do you mean specifics of like product?

4937
02:47:15,538 --> 02:47:16,919
- Specific I would say specific,

4938
02:47:16,919 --> 02:47:18,055
like specifically what specifics.

4939
02:47:18,055 --> 02:47:19,317
Like what is the,

4940
02:47:19,317 --> 02:47:20,235
because for the first five years

4941
02:47:20,235 --> 02:47:21,162
you don't get to have vision,

4942
02:47:21,162 --> 02:47:22,420
you just gotta build something people want

4943
02:47:22,420 --> 02:47:24,487
and you gotta figure out a way to sell it to them. Right.

4944
02:47:24,487 --> 02:47:26,763
It's very practical or you never get to big vision.

4945
02:47:26,763 --> 02:47:28,038
- So the first product,

4946
02:47:28,038 --> 02:47:30,876
you have an idea of a set of products of the first product

4947
02:47:30,876 --> 02:47:31,909
that can actually make some money.

4948
02:47:31,909 --> 02:47:33,280
- Yeah. Like it's gotta work.

4949
02:47:33,280 --> 02:47:34,650
The first product's gotta work by which I mean like,

4950
02:47:34,650 --> 02:47:35,587
it has to technically work,

4951
02:47:35,587 --> 02:47:37,868
but then it has to actually fit into the category

4952
02:47:37,868 --> 02:47:39,231
and the customer's mind if something that they want

4953
02:47:39,231 --> 02:47:40,064
and then by the way,

4954
02:47:40,064 --> 02:47:41,867
the other part is they have to be willing to pay for it.

4955
02:47:41,867 --> 02:47:43,153
Like somebody's gotta pay the bills.

4956
02:47:43,153 --> 02:47:44,904
And so you've gotta figure out how to price it

4957
02:47:44,904 --> 02:47:46,543
and whether you can actually extract the money.

4958
02:47:46,543 --> 02:47:49,793
So usually it is much more predictable.

4959
02:47:51,399 --> 02:47:53,127
Success is never predictable,

4960
02:47:53,127 --> 02:47:54,998
but it's more predictable if you start with a great idea

4961
02:47:54,998 --> 02:47:57,407
and then back into starting the company.

4962
02:47:57,407 --> 02:47:59,241
So this is what we did, you know, we had most,

4963
02:47:59,241 --> 02:48:00,203
before we had escape,

4964
02:48:00,203 --> 02:48:01,735
the Google guys had the Google search engine

4965
02:48:01,735 --> 02:48:04,256
working at Stanford. Right.

4966
02:48:04,256 --> 02:48:05,433
You know, yeah.

4967
02:48:05,433 --> 02:48:07,499
Actually there's tons of examples where they, you know,

4968
02:48:07,499 --> 02:48:08,680
Pierre Omaira had eBay working

4969
02:48:08,680 --> 02:48:10,855
before he left his previous job.

4970
02:48:10,855 --> 02:48:13,258
- So I really love that idea of just having a thing,

4971
02:48:13,258 --> 02:48:15,925
a prototype that actually works before you even begin

4972
02:48:15,925 --> 02:48:17,550
to remotely scale. Yeah.

4973
02:48:17,550 --> 02:48:19,663
- By the way, it's also far easier to raise money, right?

4974
02:48:19,663 --> 02:48:21,963
Like the ideal pitch that we receive is,

4975
02:48:21,963 --> 02:48:23,142
here's the thing that works,

4976
02:48:23,142 --> 02:48:24,588
would you like to invest in our company or not?

4977
02:48:24,588 --> 02:48:25,421
Like, that's so much easier

4978
02:48:25,421 --> 02:48:27,774
than here's 30 slides with a dream, right?

4979
02:48:27,774 --> 02:48:31,460
And then we have this concept called the DMAs,

4980
02:48:31,460 --> 02:48:35,219
which our biology of came up with when he was with us.

4981
02:48:35,219 --> 02:48:38,137
So then there's this thing, this goes to mythology,

4982
02:48:38,137 --> 02:48:40,852
which is, you know, there's a mythology that kind of,

4983
02:48:40,852 --> 02:48:42,484
you know, these ideas, you know,

4984
02:48:42,484 --> 02:48:43,317
kind of arrive like magic

4985
02:48:43,317 --> 02:48:44,416
or people kind of stumble into them.

4986
02:48:44,416 --> 02:48:47,192
It's like eBay with the pest dispensers or something.

4987
02:48:47,192 --> 02:48:49,978
The reality usually with the big successes is

4988
02:48:49,978 --> 02:48:53,065
that the founder has been chewing on the problem

4989
02:48:53,065 --> 02:48:54,371
for 5 or 10 years

4990
02:48:54,371 --> 02:48:57,327
before they start the company and they often worked on it

4991
02:48:57,327 --> 02:49:00,462
in school or they even experimented on it

4992
02:49:00,462 --> 02:49:01,751
when they were a kid

4993
02:49:01,751 --> 02:49:03,698
and they've been kind of training up over

4994
02:49:03,698 --> 02:49:05,496
that period of time to be able to do the thing.

4995
02:49:05,496 --> 02:49:07,791
So they're like a true domain expert.

4996
02:49:07,791 --> 02:49:09,583
And it sort of sounds like mom,

4997
02:49:09,583 --> 02:49:10,504
I'm an apple pie, which is yeah,

4998
02:49:10,504 --> 02:49:11,783
you wanna be a domain expert in what you're doing,

4999
02:49:11,783 --> 02:49:14,414
but you would, you know, the mythology is so strong of like,

5000
02:49:14,414 --> 02:49:15,312
oh, I just like had this idea

5001
02:49:15,312 --> 02:49:16,895
in the shower right now I'm doing it.

5002
02:49:16,895 --> 02:49:18,628
Like it's generally not that.

5003
02:49:18,628 --> 02:49:19,628
- No, because it's,

5004
02:49:19,628 --> 02:49:24,043
well, maybe in the shower we had the exact product

5005
02:49:24,043 --> 02:49:27,224
implementation details, but yeah,

5006
02:49:27,224 --> 02:49:30,075
usually you're gonna be for like years if not decades

5007
02:49:30,075 --> 02:49:33,658
thinking about like everything around that.

5008
02:49:35,522 --> 02:49:38,878
- Well we call it the DMAs because the DMAs basically is

5009
02:49:38,878 --> 02:49:40,578
like, there's all these permutations,

5010
02:49:40,578 --> 02:49:41,535
like for any idea,

5011
02:49:41,535 --> 02:49:43,399
there's like all these different permutations,

5012
02:49:43,399 --> 02:49:44,232
who should the customer be?

5013
02:49:44,232 --> 02:49:45,627
What shape forms should the product have

5014
02:49:45,627 --> 02:49:48,108
and how should we take it to market and all these things.

5015
02:49:48,108 --> 02:49:51,452
And so the really smart founders have thought

5016
02:49:51,452 --> 02:49:53,100
through all these scenarios by the time they go out

5017
02:49:53,100 --> 02:49:56,238
to raise money and they have like detailed answers

5018
02:49:56,238 --> 02:49:57,719
on every one of those fronts

5019
02:49:57,719 --> 02:50:00,230
because they put so much thought into it.

5020
02:50:00,230 --> 02:50:03,188
The sort of more haphazard founders haven't thought

5021
02:50:03,188 --> 02:50:04,119
about any of that.

5022
02:50:04,119 --> 02:50:07,393
And it's the detailed ones who tend to do much better.

5023
02:50:07,393 --> 02:50:09,117
- So how do you know when to take a leap

5024
02:50:09,117 --> 02:50:12,340
if you have a cushy job or happy life?

5025
02:50:12,340 --> 02:50:13,389
- I mean the best reason is just

5026
02:50:13,389 --> 02:50:15,029
'cause you can't tolerate not doing it right?

5027
02:50:15,029 --> 02:50:16,396
Like this is the kind of thing where if you have to be

5028
02:50:16,396 --> 02:50:19,017
advised into doing it, you probably shouldn't do it.

5029
02:50:19,017 --> 02:50:20,384
And so it's probably the opposite,

5030
02:50:20,384 --> 02:50:22,185
which is you just have such a burning sense of this has

5031
02:50:22,185 --> 02:50:25,189
to be done, I have to do this, I have no choice.

5032
02:50:25,189 --> 02:50:27,146
- What if it's gonna lead to a lot of pain?

5033
02:50:27,146 --> 02:50:30,019
- It's gonna lead to a lot of pain. I think that's.

5034
02:50:30,019 --> 02:50:33,624
- What if it means losing sort of social relationships

5035
02:50:33,624 --> 02:50:37,387
and damaging your relationship with loved ones

5036
02:50:37,387 --> 02:50:38,697
and all that kind of stuff.

5037
02:50:38,697 --> 02:50:39,530
- Yeah, look, so like,

5038
02:50:39,530 --> 02:50:41,817
it's gonna put you in a social tunnel for sure, right?

5039
02:50:41,817 --> 02:50:43,094
So you're gonna, like, you know,

5040
02:50:43,094 --> 02:50:45,429
there's this game you can play on Twitter,

5041
02:50:45,429 --> 02:50:47,997
which is you can do any whiff of the idea that there's

5042
02:50:47,997 --> 02:50:50,400
basically any such thing as work life balance

5043
02:50:50,400 --> 02:50:52,087
and that people should actually work hard

5044
02:50:52,087 --> 02:50:52,990
and everybody gets mad.

5045
02:50:52,990 --> 02:50:53,823
But like,

5046
02:50:53,823 --> 02:50:55,710
the truth is like all the successful founders are working

5047
02:50:55,710 --> 02:50:58,171
80 hour weeks and they're working, you know, they form very,

5048
02:50:58,171 --> 02:51:00,132
very strong social bonds with the people they work with.

5049
02:51:00,132 --> 02:51:02,516
They tend to lose a lot of friends on the outside or put

5050
02:51:02,516 --> 02:51:03,461
those friendships on ice.

5051
02:51:03,461 --> 02:51:05,955
Like that's just the nature of the thing,

5052
02:51:05,955 --> 02:51:08,311
you know, for most people that's worth the trade off.

5053
02:51:08,311 --> 02:51:09,671
You know, the advantage, you know,

5054
02:51:09,671 --> 02:51:11,024
maybe younger founders have is maybe they have less,

5055
02:51:11,024 --> 02:51:12,950
you know, maybe they're not, you know, for example,

5056
02:51:12,950 --> 02:51:14,229
if they're not married yet or don't have kids yet,

5057
02:51:14,229 --> 02:51:15,974
that's an easier thing to bite off.

5058
02:51:15,974 --> 02:51:17,117
- Can you be an older founder?

5059
02:51:17,117 --> 02:51:18,599
- Yeah. You definitely can. Yeah.

5060
02:51:18,599 --> 02:51:20,738
Yeah. Many of the most successful founders are second,

5061
02:51:20,738 --> 02:51:21,757
third, fourth time founders.

5062
02:51:21,757 --> 02:51:23,266
They're in their thirties, forties, fifties.

5063
02:51:23,266 --> 02:51:25,736
The good news with being an older founder is, you know,

5064
02:51:25,736 --> 02:51:28,132
more and you, you know, a lot more about what to do,

5065
02:51:28,132 --> 02:51:29,428
which is very helpful. The problem is, okay,

5066
02:51:29,428 --> 02:51:31,969
now you've got like a spouse and a family and kids and like,

5067
02:51:31,969 --> 02:51:34,077
you've gotta go to the baseball game and like,

5068
02:51:34,077 --> 02:51:37,513
you can't go to the base, you know, and so it's.

5069
02:51:37,513 --> 02:51:39,591
- [Lex] Life is full of difficult choices.

5070
02:51:39,591 --> 02:51:40,424
- Yes.

5071
02:51:40,424 --> 02:51:41,389
- Marc Andreessen,

5072
02:51:41,389 --> 02:51:44,425
you've written a blog post on what you've been up to.

5073
02:51:44,425 --> 02:51:47,239
You wrote this in October, 2022,

5074
02:51:47,239 --> 02:51:50,185
"Mostly I try to learn a lot.

5075
02:51:50,185 --> 02:51:51,018
For example,

5076
02:51:51,018 --> 02:51:53,844
the political events of 2014 to 2016 make clear to me

5077
02:51:53,844 --> 02:51:56,795
that I didn't understand politics at all referencing maybe

5078
02:51:56,795 --> 02:51:59,276
some of this book here.

5079
02:51:59,276 --> 02:52:02,333
So I deliberately withdrew from political engagement

5080
02:52:02,333 --> 02:52:06,273
and fundraising and instead read my way back into history

5081
02:52:06,273 --> 02:52:08,620
and as far to the political left

5082
02:52:08,620 --> 02:52:10,679
and political right as I could."

5083
02:52:10,679 --> 02:52:12,239
So just high level question,

5084
02:52:12,239 --> 02:52:14,836
what's your approach to learning?

5085
02:52:14,836 --> 02:52:17,205
- Yeah, so it's basically, I would say,

5086
02:52:17,205 --> 02:52:20,126
I'm an AutoID direct, so it's sort of goes,

5087
02:52:20,126 --> 02:52:22,125
it's going down the rabbit holes.

5088
02:52:22,125 --> 02:52:23,349
So it's a combination.

5089
02:52:23,349 --> 02:52:25,037
I kind of allude to it in that, in that quote,

5090
02:52:25,037 --> 02:52:27,163
it's a combination of breadth and depth.

5091
02:52:27,163 --> 02:52:29,400
And so I tend to, yeah, I tend to,

5092
02:52:29,400 --> 02:52:31,408
I go broad by the nature of what I do, I go broad,

5093
02:52:31,408 --> 02:52:33,621
but then I tend to go deep in a rabbit hole for a while,

5094
02:52:33,621 --> 02:52:35,261
read everything I can and then come out of it.

5095
02:52:35,261 --> 02:52:37,343
And I might not revisit that rabbit hole for,

5096
02:52:37,343 --> 02:52:38,410
you know, another decade.

5097
02:52:38,410 --> 02:52:40,835
- And in that blog post that I recommend

5098
02:52:40,835 --> 02:52:41,986
people go check out,

5099
02:52:41,986 --> 02:52:44,156
you actually list a bunch of different books that you

5100
02:52:44,156 --> 02:52:46,859
recommend on different topics on the American left,

5101
02:52:46,859 --> 02:52:48,786
on the American right.

5102
02:52:48,786 --> 02:52:51,029
It's just a lot of really good stuff.

5103
02:52:51,029 --> 02:52:53,456
The best explanation for the current structure

5104
02:52:53,456 --> 02:52:54,612
of our society and politics.

5105
02:52:54,612 --> 02:52:55,709
You give to recommendations,

5106
02:52:55,709 --> 02:52:57,577
four books on the Spanish Civil War,

5107
02:52:57,577 --> 02:52:59,333
six books on deep history of the American right

5108
02:52:59,333 --> 02:53:01,107
comprehensive biographies.

5109
02:53:01,107 --> 02:53:02,738
These of Adolf Hitler,

5110
02:53:02,738 --> 02:53:06,804
one of which I read can recommend six books on the deep

5111
02:53:06,804 --> 02:53:09,197
history of the American left. So the American right,

5112
02:53:09,197 --> 02:53:12,982
American left looking at the history to give you the context

5113
02:53:12,982 --> 02:53:15,388
biography of later Lennon,

5114
02:53:15,388 --> 02:53:18,219
two of them on the French Revolution. I actually,

5115
02:53:18,219 --> 02:53:20,566
I have never read a biography on Lennon maybe

5116
02:53:20,566 --> 02:53:21,746
that would be useful.

5117
02:53:21,746 --> 02:53:24,249
Everything's been so Marc's focused.

5118
02:53:24,249 --> 02:53:27,149
- The Sebastian biography of Lennon is extraordinary.

5119
02:53:27,149 --> 02:53:28,258
- [Lex] Victor Sebestyen. Okay.

5120
02:53:28,258 --> 02:53:29,424
- Blow your mind. Yeah.

5121
02:53:29,424 --> 02:53:30,683
- [Lex] So it's still useful to read.

5122
02:53:30,683 --> 02:53:31,811
- It's incredible. Yeah, it's incredible.

5123
02:53:31,811 --> 02:53:33,024
I actually think it's the single best book

5124
02:53:33,024 --> 02:53:34,270
on the Soviet Union.

5125
02:53:34,270 --> 02:53:36,325
- So that the perspective of Lennon,

5126
02:53:36,325 --> 02:53:38,546
it might be the best way to look at the Soviet Union versus

5127
02:53:38,546 --> 02:53:41,444
Stalin versus Marx versus, very interesting.

5128
02:53:41,444 --> 02:53:46,444
So two books on fascism and anti-fascism by the same author,

5129
02:53:47,260 --> 02:53:48,177
Paul Gottfried,

5130
02:53:48,177 --> 02:53:50,708
brilliant book on the nature of mass movements

5131
02:53:50,708 --> 02:53:52,095
and collective psychology,

5132
02:53:52,095 --> 02:53:53,536
the definitive work on intellectual life under

5133
02:53:53,536 --> 02:53:56,083
totalitarianism, the Captive Mind,

5134
02:53:56,083 --> 02:53:58,304
the definitive worked on the practical life

5135
02:53:58,304 --> 02:53:59,640
under totalitarianism.

5136
02:53:59,640 --> 02:54:02,038
There's a bunch. There's a bunch.

5137
02:54:02,038 --> 02:54:04,142
And the single best book, first of all,

5138
02:54:04,142 --> 02:54:05,970
the list here is just incredible.

5139
02:54:05,970 --> 02:54:09,562
But you say the single best book I have found on who we are

5140
02:54:09,562 --> 02:54:12,288
and how we got here is the Ancient City

5141
02:54:12,288 --> 02:54:15,205
by Numa Dennis Fustel De Coulanges.

5142
02:54:16,790 --> 02:54:17,869
I like it.

5143
02:54:17,869 --> 02:54:21,538
What did you learn about who we are as a human civilization

5144
02:54:21,538 --> 02:54:22,497
from that book?

5145
02:54:22,497 --> 02:54:23,917
- Yeah, so this is a fascinating book.

5146
02:54:23,917 --> 02:54:25,372
This one's free, it's a free, by the way,

5147
02:54:25,372 --> 02:54:26,982
it's a book in the 1860s.

5148
02:54:26,982 --> 02:54:28,614
You can download it or you can buy printouts

5149
02:54:28,614 --> 02:54:29,447
up prints of it.

5150
02:54:29,447 --> 02:54:32,239
But it was this guy who was a professor at the savant

5151
02:54:32,239 --> 02:54:35,373
in the 1860s and he was apparently a savant on antiquity

5152
02:54:35,373 --> 02:54:37,706
on Greek and Roman antiquity

5153
02:54:39,227 --> 02:54:41,950
and the reason I say that is because his sources are 100%

5154
02:54:41,950 --> 02:54:44,022
original Greek and Roman sources.

5155
02:54:44,022 --> 02:54:46,860
So he wrote a basically history of western civilization

5156
02:54:46,860 --> 02:54:48,765
from, on the order of 4,000 years ago

5157
02:54:48,765 --> 02:54:50,945
to basically the present times entirely working

5158
02:54:50,945 --> 02:54:54,532
on fresh original Greek and Roman sources.

5159
02:54:54,532 --> 02:54:57,427
And what he was specifically trying to do was he was trying

5160
02:54:57,427 --> 02:54:59,106
to reconstruct from the stories

5161
02:54:59,106 --> 02:55:00,121
of the Greeks and the Romans,

5162
02:55:00,121 --> 02:55:02,316
he was trying to reconstruct what life in the west was like

5163
02:55:02,316 --> 02:55:04,149
before the Greeks and the Romans,

5164
02:55:04,149 --> 02:55:05,959
which was in the civilization known

5165
02:55:05,959 --> 02:55:07,266
as the Indo Europeans.

5166
02:55:07,266 --> 02:55:11,993
And the short answer is, and this is sort of 4,000,

5167
02:55:11,993 --> 02:55:14,345
you know, 2000 BC to, you know,

5168
02:55:14,345 --> 02:55:16,444
sort of 500 BC kind of that 1500 year stretch

5169
02:55:16,444 --> 02:55:17,625
for civilization developed.

5170
02:55:17,625 --> 02:55:20,362
And his conclusion was basically cults.

5171
02:55:20,362 --> 02:55:23,945
They were basically cults and civilization was,

5172
02:55:23,945 --> 02:55:25,582
or organized into cults.

5173
02:55:25,582 --> 02:55:28,364
And the intensity of the cults was like

5174
02:55:28,364 --> 02:55:29,669
a million fold beyond anything

5175
02:55:29,669 --> 02:55:31,085
that we would recognize today.

5176
02:55:31,085 --> 02:55:35,256
Like it was a level of all encompassing belief

5177
02:55:35,256 --> 02:55:38,423
and an action around religion that was

5178
02:55:39,406 --> 02:55:40,851
at a level of extremeness

5179
02:55:40,851 --> 02:55:42,795
that we wouldn't even recognize it

5180
02:55:42,795 --> 02:55:46,223
and so specifically he tells the story of basically

5181
02:55:46,223 --> 02:55:48,095
there were three levels of cults.

5182
02:55:48,095 --> 02:55:49,027
There was the family cult,

5183
02:55:49,027 --> 02:55:51,038
the tribal cult, and then the city cult

5184
02:55:51,038 --> 02:55:53,089
as society scaled up.

5185
02:55:53,089 --> 02:55:57,837
And then each cult was a joint cult of family gods,

5186
02:55:57,837 --> 02:55:59,319
which were ancestor gods.

5187
02:55:59,319 --> 02:56:03,962
And then nature gods and then your bonding into a family,

5188
02:56:03,962 --> 02:56:05,603
a tribe or a city was based on your adherence

5189
02:56:05,603 --> 02:56:06,949
to that religion.

5190
02:56:06,949 --> 02:56:11,693
People who were not of your family, tribe, city, worship,

5191
02:56:11,693 --> 02:56:12,526
different gods,

5192
02:56:12,526 --> 02:56:14,448
which gave you not just the right with or responsibility

5193
02:56:14,448 --> 02:56:16,606
to kill them on site.

5194
02:56:16,606 --> 02:56:20,043
- [Lex] So they were serious about their cults.

5195
02:56:20,043 --> 02:56:22,482
- Hardcore, by the way, shocking development.

5196
02:56:22,482 --> 02:56:25,289
I did not realize this zero concept of individual rights.

5197
02:56:25,289 --> 02:56:27,315
Like even even up through the Greeks,

5198
02:56:27,315 --> 02:56:28,651
and even in the Romans, they didn't have,

5199
02:56:28,651 --> 02:56:29,839
have the concept of individual rights.

5200
02:56:29,839 --> 02:56:31,303
Like the idea that as an individual you have like

5201
02:56:31,303 --> 02:56:32,978
some rights just like, nope.

5202
02:56:32,978 --> 02:56:35,133
Right? And you look back and you're just like, wow,

5203
02:56:35,133 --> 02:56:36,558
that's just like cr like fascist in a degree

5204
02:56:36,558 --> 02:56:38,091
that we wouldn't recognize today.

5205
02:56:38,091 --> 02:56:38,934
But it's like, well,

5206
02:56:38,934 --> 02:56:41,667
they were living under extreme pressure for survival.

5207
02:56:41,667 --> 02:56:43,833
And you, and you know, the theory goes,

5208
02:56:43,833 --> 02:56:45,498
you could not have people running around making claims,

5209
02:56:45,498 --> 02:56:46,859
individual rights when you're just trying to get

5210
02:56:46,859 --> 02:56:48,383
like your tribe through the winter, right?

5211
02:56:48,383 --> 02:56:49,976
Like you need like hardcore command and control.

5212
02:56:49,976 --> 02:56:53,256
And actually what if through modern political lens,

5213
02:56:53,256 --> 02:56:55,773
those cults were basically both fascist and communist.

5214
02:56:55,773 --> 02:56:58,312
They were fascist in terms of social control,

5215
02:56:58,312 --> 02:57:00,878
and then they were communist in terms of economics.

5216
02:57:00,878 --> 02:57:03,916
- But you think that's fundamentally that like pull towards

5217
02:57:03,916 --> 02:57:05,499
cults is within us.

5218
02:57:06,965 --> 02:57:10,015
- Well, so my conclusion from this book,

5219
02:57:10,015 --> 02:57:12,971
so the way we naturally think about the world we live

5220
02:57:12,971 --> 02:57:14,076
in today is like,

5221
02:57:14,076 --> 02:57:17,199
we basically have such an improved version of everything

5222
02:57:17,199 --> 02:57:18,279
that came before us, right?

5223
02:57:18,279 --> 02:57:19,720
Like, we have basically,

5224
02:57:19,720 --> 02:57:21,292
we've figured out all these things around morality

5225
02:57:21,292 --> 02:57:22,642
and ethics and democracy and all these things.

5226
02:57:22,642 --> 02:57:24,772
And like, they were basically stupid and retrograde

5227
02:57:24,772 --> 02:57:26,385
and we're like smart and sophisticated.

5228
02:57:26,385 --> 02:57:27,474
And we've improved all this

5229
02:57:27,474 --> 02:57:29,151
after reading that book,

5230
02:57:29,151 --> 02:57:31,489
I now believe in many ways the opposite, which is no,

5231
02:57:31,489 --> 02:57:34,213
actually we are still running in that original model.

5232
02:57:34,213 --> 02:57:37,270
We're just running in an incredibly diluted version of it.

5233
02:57:37,270 --> 02:57:39,342
So we're still running, basically in cults.

5234
02:57:39,342 --> 02:57:42,041
It's just our cults are at like a thousandth or a millionth,

5235
02:57:42,041 --> 02:57:43,584
the level of intensity, right?

5236
02:57:43,584 --> 02:57:45,858
And so our, so just as to take religions, you know,

5237
02:57:45,858 --> 02:57:49,252
the modern experience of a Christian in our time,

5238
02:57:49,252 --> 02:57:51,307
even somebody who considers him a devout Christian,

5239
02:57:51,307 --> 02:57:53,859
is just a shadow of the level of intensity of somebody

5240
02:57:53,859 --> 02:57:55,626
who belonged to a religion back in that period.

5241
02:57:55,626 --> 02:57:57,444
And then by the way, we have cons.

5242
02:57:57,444 --> 02:57:59,511
It goes back to our AI discussion.

5243
02:57:59,511 --> 02:58:02,498
We then sort of endlessly create new cults.

5244
02:58:02,498 --> 02:58:04,642
Like we're trying to fill the void, right?

5245
02:58:04,642 --> 02:58:06,164
And the void is a void of bonding.

5246
02:58:06,164 --> 02:58:06,997
- [Lex] Okay.

5247
02:58:06,997 --> 02:58:10,371
- Living in their era. Like everybody living today,

5248
02:58:10,371 --> 02:58:12,245
transporting that era would view it as just like,

5249
02:58:12,245 --> 02:58:13,681
completely intolerable in terms of like

5250
02:58:13,681 --> 02:58:14,839
the loss of freedom and the level

5251
02:58:14,839 --> 02:58:16,088
of basically of fascist control.

5252
02:58:16,088 --> 02:58:18,717
However, every single person in that era,

5253
02:58:18,717 --> 02:58:19,790
and he really stresses this.

5254
02:58:19,790 --> 02:58:21,501
They knew exactly where they stood.

5255
02:58:21,501 --> 02:58:23,103
They knew exactly where they belonged.

5256
02:58:23,103 --> 02:58:24,481
They knew exactly what their purpose was.

5257
02:58:24,481 --> 02:58:25,941
They knew exactly what they needed to do every day.

5258
02:58:25,941 --> 02:58:27,236
They knew exactly why they were doing it.

5259
02:58:27,236 --> 02:58:29,737
They had total certainty about their place in the universe.

5260
02:58:29,737 --> 02:58:30,770
- So the question of meaning,

5261
02:58:30,770 --> 02:58:32,977
the question of purpose was very distinctly,

5262
02:58:32,977 --> 02:58:34,528
clearly defined for them.

5263
02:58:34,528 --> 02:58:38,229
- Absolutely overwhelmingly undisputably undeniably.

5264
02:58:38,229 --> 02:58:40,876
- As we turn the volume down on the cultism--

5265
02:58:40,876 --> 02:58:41,709
- [Marc] Yes.

5266
02:58:41,709 --> 02:58:42,542
- We start to,

5267
02:58:42,542 --> 02:58:45,192
the search for meaning starts getting harder and harder.

5268
02:58:45,192 --> 02:58:46,413
- Yes. 'cause we don't have that.

5269
02:58:46,413 --> 02:58:47,550
We are ungrounded.

5270
02:58:47,550 --> 02:58:49,911
We are uncentered and we all feel it. Right?

5271
02:58:49,911 --> 02:58:51,727
And that's why we reach for, you know,

5272
02:58:51,727 --> 02:58:53,421
it's why we still reach for religion.

5273
02:58:53,421 --> 02:58:54,435
It's why we reach for,

5274
02:58:54,435 --> 02:58:56,273
you know, we people start to take on, you know,

5275
02:58:56,273 --> 02:58:57,106
let's say, you know,

5276
02:58:57,106 --> 02:58:59,051
a faith in science maybe beyond where they should put it.

5277
02:58:59,051 --> 02:59:01,516
You know and by the way, like, sports teams are like a,

5278
02:59:01,516 --> 02:59:03,215
you know, they're like a tiny little version of a cult.

5279
02:59:03,215 --> 02:59:04,448
And you know,

5280
02:59:04,448 --> 02:59:07,426
apple keynotes are a tiny little version of a cult. Right.

5281
02:59:07,426 --> 02:59:09,590
And, you know, political, you know.

5282
02:59:09,590 --> 02:59:11,039
And there's cult, you know,

5283
02:59:11,039 --> 02:59:12,332
there's full-blown cults on both sides

5284
02:59:12,332 --> 02:59:14,075
of the political spectrum right now. Right.

5285
02:59:14,075 --> 02:59:15,217
You know, operating in plain stuff.

5286
02:59:15,217 --> 02:59:17,714
- But still not full blown compared as to what it was.

5287
02:59:17,714 --> 02:59:18,662
- Compared to what it used to. I mean,

5288
02:59:18,662 --> 02:59:20,437
we would today consider full blown, but like, yes,

5289
02:59:20,437 --> 02:59:21,840
they're at like, I don't know,

5290
02:59:21,840 --> 02:59:23,437
a hundred thousandth or something of the intensity

5291
02:59:23,437 --> 02:59:24,952
of what people had back then.

5292
02:59:24,952 --> 02:59:27,325
So, we live in a world today that in many ways is more

5293
02:59:27,325 --> 02:59:28,954
advanced and moral and so forth.

5294
02:59:28,954 --> 02:59:30,796
And it's certainly a lot nicer, much nicer world to live in.

5295
02:59:30,796 --> 02:59:33,289
But we live in a world that's like very washed out.

5296
02:59:33,289 --> 02:59:36,171
It's like everything has become very colorless and gray

5297
02:59:36,171 --> 02:59:38,287
as compared to how people used to experience things.

5298
02:59:38,287 --> 02:59:41,311
Which is I think why we're so prone to reach for drama.

5299
02:59:41,311 --> 02:59:43,764
'Cause there's something in us

5300
02:59:43,764 --> 02:59:46,151
that's deeply evolved where we want that back.

5301
02:59:46,151 --> 02:59:49,772
- And I wonder where it's all headed as we turn the volume

5302
02:59:49,772 --> 02:59:50,897
down more and more.

5303
02:59:50,897 --> 02:59:53,719
What advice would you give to young folks today

5304
02:59:53,719 --> 02:59:55,877
in high school and college?

5305
02:59:55,877 --> 02:59:57,083
How to be successful in their career?

5306
02:59:57,083 --> 02:59:58,756
How to be successful in their life?

5307
02:59:58,756 --> 03:00:01,802
- Yeah. So the tools that are available today, I mean,

5308
03:00:01,802 --> 03:00:04,506
are just like, I sometimes, you know, bore,

5309
03:00:04,506 --> 03:00:05,743
I sometimes bore, you know,

5310
03:00:05,743 --> 03:00:07,304
kids by describing like what it was like to go look up

5311
03:00:07,304 --> 03:00:08,137
a book, you know,

5312
03:00:08,137 --> 03:00:10,052
to try to like discover a fact in, you know,

5313
03:00:10,052 --> 03:00:12,194
in the old days, the 1970s, 1980s,

5314
03:00:12,194 --> 03:00:13,510
to go to the library and the card catalog

5315
03:00:13,510 --> 03:00:14,567
and the whole thing.

5316
03:00:14,567 --> 03:00:15,758
You go through all that work and then the book is checked

5317
03:00:15,758 --> 03:00:17,070
out and you have to wait two weeks

5318
03:00:17,070 --> 03:00:19,558
and like to be in a world,

5319
03:00:19,558 --> 03:00:21,751
not only where you can get the answer to any question,

5320
03:00:21,751 --> 03:00:22,930
but also the world now, you know,

5321
03:00:22,930 --> 03:00:24,667
the AI world where you've got like the assistant

5322
03:00:24,667 --> 03:00:26,049
that will help you do anything, help you teach,

5323
03:00:26,049 --> 03:00:27,717
learn anything, like your ability both

5324
03:00:27,717 --> 03:00:30,777
to learn and also to produce is just like, I don't know,

5325
03:00:30,777 --> 03:00:33,075
a million fold beyond what it used to be.

5326
03:00:33,075 --> 03:00:34,882
I have a blog post I've been wanting to write,

5327
03:00:34,882 --> 03:00:39,794
which I call where are the hyper-productive people?

5328
03:00:39,794 --> 03:00:40,627
Like--

5329
03:00:40,627 --> 03:00:41,642
- [Lex] That's a good question, right?

5330
03:00:41,642 --> 03:00:43,081
- Like with these tools,

5331
03:00:43,081 --> 03:00:45,479
like there should be authors that are writing like hundreds

5332
03:00:45,479 --> 03:00:47,939
or thousands of like, outstanding books.

5333
03:00:47,939 --> 03:00:50,157
- Well, with the authors there's a consumption question too,

5334
03:00:50,157 --> 03:00:53,307
but yeah. Well, maybe not, maybe not.

5335
03:00:53,307 --> 03:00:54,296
You're right.

5336
03:00:54,296 --> 03:00:56,505
But, so the tools are much more powerful.

5337
03:00:56,505 --> 03:00:57,755
Getting much more powerful.

5338
03:00:57,755 --> 03:00:59,199
- Artists, musicians. Right.

5339
03:00:59,199 --> 03:01:01,359
Why aren't musicians producing a thousand times the number

5340
03:01:01,359 --> 03:01:02,519
of songs, right?

5341
03:01:02,519 --> 03:01:05,838
Like what, like the tools are spectacular.

5342
03:01:05,838 --> 03:01:08,293
- So, what's the explanation?

5343
03:01:08,293 --> 03:01:11,160
And by way of advice, like,

5344
03:01:11,160 --> 03:01:13,840
is motivation starting to be turned down a little bit?

5345
03:01:13,840 --> 03:01:14,724
Or what?

5346
03:01:14,724 --> 03:01:16,461
- I think it might be distraction.

5347
03:01:16,461 --> 03:01:17,294
- [Lex] Distraction.

5348
03:01:17,294 --> 03:01:18,475
- It's so easy to just sit and consume

5349
03:01:18,475 --> 03:01:20,466
that I think people get

5350
03:01:20,466 --> 03:01:24,205
distracted from production. But if you wanted to, you know,

5351
03:01:24,205 --> 03:01:25,612
as a young person, if you wanted to really stand out,

5352
03:01:25,612 --> 03:01:27,222
you could get on a, like

5353
03:01:27,222 --> 03:01:30,148
a hyper productivity curve very early on.

5354
03:01:30,148 --> 03:01:31,944
There's a great, you know, this story,

5355
03:01:31,944 --> 03:01:33,614
there's a great story in Roman history of plenty

5356
03:01:33,614 --> 03:01:36,074
of the elder who was this legendary statesman,

5357
03:01:36,074 --> 03:01:39,290
died in the Vesuvius eruption trying to rescue his friends.

5358
03:01:39,290 --> 03:01:40,758
But he was famous both for being

5359
03:01:40,758 --> 03:01:43,700
basically being a polymath, but also being an author.

5360
03:01:43,700 --> 03:01:45,485
And he wrote apparently like hundreds of books,

5361
03:01:45,485 --> 03:01:46,577
most of us had been lost.

5362
03:01:46,577 --> 03:01:48,937
But he like wrote all these encyclopedias and he literally

5363
03:01:48,937 --> 03:01:51,511
like would be reading and writing all day long no matter

5364
03:01:51,511 --> 03:01:52,701
what else was going on.

5365
03:01:52,701 --> 03:01:54,954
And so he would like travel with like four slaves.

5366
03:01:54,954 --> 03:01:56,543
And two of them were responsible for reading to him,

5367
03:01:56,543 --> 03:01:59,094
and two of them were responsible for taking dictation.

5368
03:01:59,094 --> 03:02:00,797
And so like, he'd be going cross country and like,

5369
03:02:00,797 --> 03:02:03,788
literally he would be writing books like all the time.

5370
03:02:03,788 --> 03:02:05,229
And apparently they were spectacular.

5371
03:02:05,229 --> 03:02:06,261
There's only a few that have survived,

5372
03:02:06,261 --> 03:02:07,748
but apparently they were amazing.

5373
03:02:07,748 --> 03:02:09,425
- There's a lot of value to being somebody

5374
03:02:09,425 --> 03:02:10,836
who finds focus in this life.

5375
03:02:10,836 --> 03:02:12,568
- Yeah. Like and there are examples, like there are,

5376
03:02:12,568 --> 03:02:15,382
you know, there's this guy, judge, what's his name?

5377
03:02:15,382 --> 03:02:17,106
Posner, who wrote like 40 books

5378
03:02:17,106 --> 03:02:19,148
and was also a great federal judge.

5379
03:02:19,148 --> 03:02:21,411
You know, there's our friend Balaji,

5380
03:02:21,411 --> 03:02:23,904
I think is like this, he's one of these, you know,

5381
03:02:23,904 --> 03:02:25,734
where his output is just prodigious.

5382
03:02:25,734 --> 03:02:27,723
And so it's like, yeah, I mean, with these tools, why not?

5383
03:02:27,723 --> 03:02:28,961
And I kind of think

5384
03:02:28,961 --> 03:02:30,720
we're at this interesting kind of freeze frame moment

5385
03:02:30,720 --> 03:02:31,553
where like this,

5386
03:02:31,553 --> 03:02:32,815
these tools are now in everybody's hands

5387
03:02:32,815 --> 03:02:34,135
and everybody's just kind of staring at them trying

5388
03:02:34,135 --> 03:02:36,036
to figure out what to do. The new tools.

5389
03:02:36,036 --> 03:02:36,869
- We have discovered fire.

5390
03:02:36,869 --> 03:02:37,702
- [Marc] Yeah.

5391
03:02:37,702 --> 03:02:39,923
- And trying to figure out how to use it to cook.

5392
03:02:39,923 --> 03:02:41,192
- [Marc] Yeah. Right.

5393
03:02:41,192 --> 03:02:44,773
- You told Tim Ferriss that the perfect day is caffeine

5394
03:02:44,773 --> 03:02:47,583
for 10 hours and alcohol for four hours.

5395
03:02:47,583 --> 03:02:50,535
You didn't think I'd be mentioning this, did you?

5396
03:02:50,535 --> 03:02:53,966
It balances everything out perfectly as you said.

5397
03:02:53,966 --> 03:02:56,503
So, perfect. So let me ask,

5398
03:02:56,503 --> 03:02:59,718
what's the secret to balance and maybe to happiness in life?

5399
03:02:59,718 --> 03:03:02,078
- I don't believe in balance,

5400
03:03:02,078 --> 03:03:03,586
so I'm the wrong person to ask that.

5401
03:03:03,586 --> 03:03:06,183
- Can you elaborate why you don't believe in balance?

5402
03:03:06,183 --> 03:03:09,136
- I mean, I maybe it's just, and I look, I think people,

5403
03:03:09,136 --> 03:03:10,372
I think people are wired differently.

5404
03:03:10,372 --> 03:03:12,454
So, I think it's hard to generalize this kind of thing,

5405
03:03:12,454 --> 03:03:14,485
but I am much happier and more satisfied

5406
03:03:14,485 --> 03:03:16,257
when I'm fully committed to something.

5407
03:03:16,257 --> 03:03:19,428
So I'm very much in favor of all in of imbalance.

5408
03:03:19,428 --> 03:03:21,709
- Imbalance. And that applies to work,

5409
03:03:21,709 --> 03:03:23,214
to life, to everything.

5410
03:03:23,214 --> 03:03:24,679
- Yeah. No, no.

5411
03:03:24,679 --> 03:03:27,094
I happen to have whatever twist of personality traits lead

5412
03:03:27,094 --> 03:03:29,340
that in non-destructive dimensions in including the fact

5413
03:03:29,340 --> 03:03:31,766
that I've actually, I now no longer do the ten-four plan.

5414
03:03:31,766 --> 03:03:32,662
I stopped drinking.

5415
03:03:32,662 --> 03:03:34,249
I do the caffeine, but not the alcohol.

5416
03:03:34,249 --> 03:03:35,976
So there's something in my personality

5417
03:03:35,976 --> 03:03:39,289
where I whatever mal-adaption I have is inclining me

5418
03:03:39,289 --> 03:03:41,405
towards productive things, not unproductive things.

5419
03:03:41,405 --> 03:03:44,731
- So you're one of the wealthiest people in the world.

5420
03:03:44,731 --> 03:03:49,212
What's the relationship between wealth and happiness?

5421
03:03:49,212 --> 03:03:50,587
Money and happiness.

5422
03:03:50,587 --> 03:03:53,231
- So I think happiness,

5423
03:03:53,231 --> 03:03:56,190
I don't think happiness is the thing.

5424
03:03:56,190 --> 03:03:57,023
- To strive for.

5425
03:03:57,023 --> 03:03:58,309
- I think satisfaction is the thing.

5426
03:03:58,309 --> 03:04:02,551
- That just sounds like happiness, but turned down a bit.

5427
03:04:02,551 --> 03:04:04,815
- No deeper. So happiness is, you know,

5428
03:04:04,815 --> 03:04:09,484
a walk in the woods at sunset, an ice cream cone, a kiss,

5429
03:04:09,484 --> 03:04:12,208
the first ice cream cone is great.

5430
03:04:12,208 --> 03:04:15,220
The thousandth ice cream cone, not so much.

5431
03:04:15,220 --> 03:04:16,933
At some point the walks in the woods get boring.

5432
03:04:16,933 --> 03:04:20,271
- What's the distinction between happiness and satisfaction?

5433
03:04:20,271 --> 03:04:22,606
- I think satisfaction is a deeper thing,

5434
03:04:22,606 --> 03:04:24,299
which is like having found a purpose

5435
03:04:24,299 --> 03:04:26,614
and fulfilling it, being useful.

5436
03:04:26,614 --> 03:04:30,137
- So just something that permeates all your days,

5437
03:04:30,137 --> 03:04:33,970
just this general contentment of being useful.

5438
03:04:35,084 --> 03:04:37,547
- That I'm fully satisfying my faculties,

5439
03:04:37,547 --> 03:04:39,391
that I'm fully delivering, right?

5440
03:04:39,391 --> 03:04:41,475
On the gifts that I've been given, that I'm, you know,

5441
03:04:41,475 --> 03:04:42,476
net making the world better,

5442
03:04:42,476 --> 03:04:45,471
that I'm contributing to the people around me, right.

5443
03:04:45,471 --> 03:04:47,696
And that I can look back and say, wow, that was hard,

5444
03:04:47,696 --> 03:04:49,010
but it was worth it.

5445
03:04:49,010 --> 03:04:50,316
Think generally,

5446
03:04:50,316 --> 03:04:52,415
it seems to lead people in a better state than pursuit

5447
03:04:52,415 --> 03:04:54,962
of pleasure, pursuit of quote unquote happiness.

5448
03:04:54,962 --> 03:04:56,695
- Does money have anything to do with that?

5449
03:04:56,695 --> 03:04:58,455
- I think the founders and the founding fathers in the US

5450
03:04:58,455 --> 03:05:00,586
threw this off kilter when they used the phrase pursuit

5451
03:05:00,586 --> 03:05:01,580
of happiness.

5452
03:05:01,580 --> 03:05:03,209
I think they should have said.

5453
03:05:03,209 --> 03:05:04,050
- [Lex] Pursuit of satisfaction.

5454
03:05:04,050 --> 03:05:04,972
- They said, pursuit of satisfaction.

5455
03:05:04,972 --> 03:05:06,244
We might live in a better world today.

5456
03:05:06,244 --> 03:05:07,253
- Well, they, you know,

5457
03:05:07,253 --> 03:05:08,108
they could have elaborated

5458
03:05:08,108 --> 03:05:10,131
on a lot of things right in the box.

5459
03:05:10,131 --> 03:05:11,485
- [Marc] They could have tweaked the second amendment.

5460
03:05:11,485 --> 03:05:13,165
- I think they were smarter than they realized.

5461
03:05:13,165 --> 03:05:13,998
They said, you know

5462
03:05:13,998 --> 03:05:15,261
we're gonna make it ambiguous and let

5463
03:05:15,261 --> 03:05:17,484
these humans figure out the rest,

5464
03:05:17,484 --> 03:05:21,651
these tribal cult-like humans figure out the rest.

5465
03:05:23,244 --> 03:05:25,239
But money empowers that.

5466
03:05:25,239 --> 03:05:26,895
- So I think, and I think there,

5467
03:05:26,895 --> 03:05:28,151
I mean, look, I think Elon is,

5468
03:05:28,151 --> 03:05:29,418
I don't think I'm even a great example,

5469
03:05:29,418 --> 03:05:31,039
but I think Elon would be the great example of this,

5470
03:05:31,039 --> 03:05:33,014
which is like, you know, look, he's a guy who from every,

5471
03:05:33,014 --> 03:05:34,038
every day of his life,

5472
03:05:34,038 --> 03:05:35,258
from the day he started making money at all,

5473
03:05:35,258 --> 03:05:37,522
he just plows into the next thing.

5474
03:05:37,522 --> 03:05:38,955
And so I think,

5475
03:05:38,955 --> 03:05:41,420
I think money is definitely an enabler for satisfaction.

5476
03:05:41,420 --> 03:05:43,417
Way money applied to happiness leads people

5477
03:05:43,417 --> 03:05:45,529
down very dark paths.

5478
03:05:45,529 --> 03:05:47,976
Very destructive avenues.

5479
03:05:47,976 --> 03:05:50,817
Money applied to satisfaction, I think could be,

5480
03:05:50,817 --> 03:05:51,992
is a real tool.

5481
03:05:51,992 --> 03:05:54,330
I always, by the way, I was like, you know,

5482
03:05:54,330 --> 03:05:55,784
Elon is the case study for behavior.

5483
03:05:55,784 --> 03:05:58,318
But the other thing that I always really made me think is

5484
03:05:58,318 --> 03:06:00,013
Larry Page was asked one time

5485
03:06:00,013 --> 03:06:01,402
what his approach to philanthropy was.

5486
03:06:01,402 --> 03:06:02,236
And he said, oh, I'm just,

5487
03:06:02,236 --> 03:06:03,222
my philanthropic plan is just give

5488
03:06:03,222 --> 03:06:04,562
all the money to Elon.

5489
03:06:04,562 --> 03:06:06,822
(both laugh)

5490
03:06:06,822 --> 03:06:10,386
- Well, let me actually ask you about Elon.

5491
03:06:10,386 --> 03:06:12,404
You've interacted with quite

5492
03:06:12,404 --> 03:06:15,816
a lot of successful engineers and business people.

5493
03:06:15,816 --> 03:06:17,537
What do you think is special about Elon?

5494
03:06:17,537 --> 03:06:19,291
We talked about Steve Jobs.

5495
03:06:19,291 --> 03:06:23,104
What do you think is special about him as a leader?

5496
03:06:23,104 --> 03:06:24,227
As an innovator?

5497
03:06:24,227 --> 03:06:26,017
- Yeah. So the core of it is

5498
03:06:26,017 --> 03:06:27,720
he's back to the future.

5499
03:06:27,720 --> 03:06:30,798
So he is doing the most leading-edge things in the world,

5500
03:06:30,798 --> 03:06:33,740
but with a really deeply old-school approach.

5501
03:06:33,740 --> 03:06:35,688
And so to find comparisons to Elon,

5502
03:06:35,688 --> 03:06:38,238
you need to go to like Henry Ford and Thomas Watson

5503
03:06:38,238 --> 03:06:41,616
and Howard Hughes and Andrew Carnegie, right.

5504
03:06:41,616 --> 03:06:45,378
Leland Stanford, John Rockefeller, right.

5505
03:06:45,378 --> 03:06:46,458
You need to go to

5506
03:06:46,458 --> 03:06:48,134
what were called the bourgeois capitalists,

5507
03:06:48,134 --> 03:06:50,913
like the hardcore business owner operators

5508
03:06:50,913 --> 03:06:52,357
who basically built, you know,

5509
03:06:52,357 --> 03:06:56,648
basically built industrialized society, Vanderbilt.

5510
03:06:56,648 --> 03:07:00,481
And it's a level of hands-on commitment

5511
03:07:00,481 --> 03:07:02,648
and depth in the business,

5512
03:07:05,887 --> 03:07:10,887
coupled with an absolute priority towards truth and towards,

5513
03:07:12,559 --> 03:07:13,642
how to put it,

5514
03:07:13,642 --> 03:07:16,064
science and technology town to first principles

5515
03:07:16,064 --> 03:07:18,137
that is just like absolute,

5516
03:07:18,137 --> 03:07:20,479
is just like unbelievably absolute.

5517
03:07:20,479 --> 03:07:22,995
He really is ideal that he's only ever talking to engineers.

5518
03:07:22,995 --> 03:07:24,594
Like he does not tolerate.

5519
03:07:24,594 --> 03:07:27,903
He has less tolerance than anybody I've ever met.

5520
03:07:27,903 --> 03:07:31,037
He wants ground truth on every single topic.

5521
03:07:31,037 --> 03:07:33,753
And he runs his businesses directly day-to-day,

5522
03:07:33,753 --> 03:07:36,522
devoted to getting to ground truth in every single topic.

5523
03:07:36,522 --> 03:07:39,605
- So you think it was a good decision

5524
03:07:40,494 --> 03:07:41,743
for him to buy Twitter?

5525
03:07:41,743 --> 03:07:42,943
- I have developed a view in life to not

5526
03:07:42,943 --> 03:07:44,860
second guess Elon Musk,

5527
03:07:45,694 --> 03:07:50,199
I know this is gonna sound great, crazy and unfounded, but.

5528
03:07:50,199 --> 03:07:53,202
- Well, I mean, he's got a quite a track record.

5529
03:07:53,202 --> 03:07:55,888
- I mean, look, the car was a crazy, I mean, the car was,

5530
03:07:55,888 --> 03:07:56,843
I mean, look.

5531
03:07:56,843 --> 03:07:58,223
- He's done a lot of things that seem crazy.

5532
03:07:58,223 --> 03:07:59,211
- Starting a new car company

5533
03:07:59,211 --> 03:08:00,453
in the United States of America.

5534
03:08:00,453 --> 03:08:02,093
The last time somebody really tried to do that was

5535
03:08:02,093 --> 03:08:04,314
the 1950s and it was called Tucker Automotive.

5536
03:08:04,314 --> 03:08:05,322
And it was such a disaster.

5537
03:08:05,322 --> 03:08:07,806
They made a movie about what a disaster it was,

5538
03:08:07,806 --> 03:08:10,122
and then rockets like, who does that?

5539
03:08:10,122 --> 03:08:12,084
Like, there's obviously no way to start

5540
03:08:12,084 --> 03:08:13,094
a new rocket company.

5541
03:08:13,094 --> 03:08:14,147
Like those days are over.

5542
03:08:14,147 --> 03:08:16,351
And then to do those at the same time.

5543
03:08:16,351 --> 03:08:20,295
So after he pulled those two off, like, okay, fine.

5544
03:08:20,295 --> 03:08:22,400
Like, this is one of my areas of like,

5545
03:08:22,400 --> 03:08:23,998
whatever opinions I had about that, that is just like,

5546
03:08:23,998 --> 03:08:25,411
okay, clearly are not relevant.

5547
03:08:25,411 --> 03:08:26,277
Like this is you just,

5548
03:08:26,277 --> 03:08:28,650
you at some point you just like bet on the person.

5549
03:08:28,650 --> 03:08:29,483
- And in general,

5550
03:08:29,483 --> 03:08:32,592
I wish more people would lean on celebrating and supporting

5551
03:08:32,592 --> 03:08:34,360
versus deriding and destroying.

5552
03:08:34,360 --> 03:08:37,335
- Oh yeah. I mean, look, he drives resentment.

5553
03:08:37,335 --> 03:08:38,176
Like it's a resentment.

5554
03:08:38,176 --> 03:08:41,055
Like he is a magnet for resentment.

5555
03:08:41,055 --> 03:08:44,206
Like his critics are the most miserable, like,

5556
03:08:44,206 --> 03:08:45,402
resentful people in the world.

5557
03:08:45,402 --> 03:08:49,021
Like it's almost a perfect match of like the most idealized,

5558
03:08:49,021 --> 03:08:50,671
you know, technologist, you know,

5559
03:08:50,671 --> 03:08:52,153
of the century coupled with like,

5560
03:08:52,153 --> 03:08:54,596
just his critics are just bitter as can be.

5561
03:08:54,596 --> 03:08:58,567
And I mean, it's sort of very darkly comic to watch.

5562
03:08:58,567 --> 03:09:02,087
- Well, he fuels the fire of that by being

5563
03:09:02,087 --> 03:09:03,645
on Twitter at times.

5564
03:09:03,645 --> 03:09:06,645
And which is fascinating to watch the drama

5565
03:09:06,645 --> 03:09:07,755
of human civilization,

5566
03:09:07,755 --> 03:09:11,088
given our cult roots just fully on fire.

5567
03:09:12,641 --> 03:09:15,122
- [Marc] He's running a cult.

5568
03:09:15,122 --> 03:09:16,038
- You could say that.

5569
03:09:16,038 --> 03:09:17,085
- [Marc] Very successfully.

5570
03:09:17,085 --> 03:09:19,827
- So now that our cults have gone and we searched

5571
03:09:19,827 --> 03:09:21,974
for meaning, what do you think is the meaning

5572
03:09:21,974 --> 03:09:22,807
of this whole thing?

5573
03:09:22,807 --> 03:09:24,383
What's the meaning of life Marc Andreessen?

5574
03:09:24,383 --> 03:09:26,794
- I don't know the answer to that. I think the meaning

5575
03:09:26,794 --> 03:09:29,211
of the closest I get to it is

5576
03:09:30,566 --> 03:09:32,162
what I said about satisfaction.

5577
03:09:32,162 --> 03:09:33,163
So it's basically like, okay,

5578
03:09:33,163 --> 03:09:34,322
we were given what we have,

5579
03:09:34,322 --> 03:09:36,347
like we should basically do our best.

5580
03:09:36,347 --> 03:09:38,175
- What's the role of love in that mix?

5581
03:09:38,175 --> 03:09:39,611
- I mean, like, what's the point of life

5582
03:09:39,611 --> 03:09:42,195
if you're without love, like, yeah.

5583
03:09:42,195 --> 03:09:44,407
- So love is a big part of that satisfaction.

5584
03:09:44,407 --> 03:09:46,045
- Yeah. And look like taking care of people is

5585
03:09:46,045 --> 03:09:47,170
like a wonderful thing.

5586
03:09:47,170 --> 03:09:48,898
Like it, you know, mentality, you know,

5587
03:09:48,898 --> 03:09:51,462
there are pathological forms of taking care of people,

5588
03:09:51,462 --> 03:09:53,249
but there's also a very fundamental, you know,

5589
03:09:53,249 --> 03:09:55,037
kind of aspect of taking care of people.

5590
03:09:55,037 --> 03:09:55,870
Like, for example,

5591
03:09:55,870 --> 03:09:57,503
I happen to be somebody who believes that capitalism

5592
03:09:57,503 --> 03:09:58,489
and taking care of people are actually,

5593
03:09:58,489 --> 03:10:00,277
they're actually the same thing.

5594
03:10:00,277 --> 03:10:01,694
Somebody once said,

5595
03:10:01,694 --> 03:10:03,756
capitalism is how you take care of people you don't know.

5596
03:10:03,756 --> 03:10:06,723
Right, right. And so like, yeah,

5597
03:10:06,723 --> 03:10:08,694
I think it's like deeply woven into the whole thing,

5598
03:10:08,694 --> 03:10:10,519
you know, there's a long conversation

5599
03:10:10,519 --> 03:10:12,630
to be had about that, but yeah.

5600
03:10:12,630 --> 03:10:15,018
- Yeah. Creating products that are used

5601
03:10:15,018 --> 03:10:16,490
by millions of people and bring them joy

5602
03:10:16,490 --> 03:10:18,067
in smaller, big ways.

5603
03:10:18,067 --> 03:10:22,086
And then capitalism kind of enables that, encourages that.

5604
03:10:22,086 --> 03:10:22,919
- David Friedman says,

5605
03:10:22,919 --> 03:10:24,931
there's only three ways to get somebody to do something

5606
03:10:24,931 --> 03:10:26,239
for somebody else.

5607
03:10:26,239 --> 03:10:28,775
Love, money and force.

5608
03:10:28,775 --> 03:10:31,275
And love and money are better.

5609
03:10:34,352 --> 03:10:35,413
- [Lex] Yeah. Of course.

5610
03:10:35,413 --> 03:10:37,093
That's a good ordering. I think.

5611
03:10:37,093 --> 03:10:38,435
- We should bet on those.

5612
03:10:38,435 --> 03:10:39,268
- Try love first.

5613
03:10:39,268 --> 03:10:40,761
If that doesn't work, then money.

5614
03:10:40,761 --> 03:10:41,594
- [Marc] Yes.

5615
03:10:41,594 --> 03:10:42,546
- And then force.

5616
03:10:42,546 --> 03:10:43,705
Well, don't even try that one.

5617
03:10:43,705 --> 03:10:45,200
Marc, you're an incredible person.

5618
03:10:45,200 --> 03:10:46,103
I've been a huge fan.

5619
03:10:46,103 --> 03:10:48,136
I'm glad to finally got a chance to talk.

5620
03:10:48,136 --> 03:10:50,165
I'm a fan of everything you do, everything you do,

5621
03:10:50,165 --> 03:10:51,697
including on Twitter.

5622
03:10:51,697 --> 03:10:53,917
It's a huge honor to meet you, to talk with you.

5623
03:10:53,917 --> 03:10:55,190
Thanks again for doing this.

5624
03:10:55,190 --> 03:10:56,878
- Awesome. Thank you, Lex.

5625
03:10:56,878 --> 03:10:58,553
- Thanks for listening to this conversation

5626
03:10:58,553 --> 03:10:59,471
with Marc Andreessen.

5627
03:10:59,471 --> 03:11:00,628
To support this podcast,

5628
03:11:00,628 --> 03:11:03,653
please check out our sponsors in the description.

5629
03:11:03,653 --> 03:11:05,600
And now let me leave you with some words

5630
03:11:05,600 --> 03:11:07,249
from Marc Andreessen himself.

5631
03:11:07,249 --> 03:11:10,475
"The world is a very malleable place.

5632
03:11:10,475 --> 03:11:13,423
If you know what you want and you go for it,

5633
03:11:13,423 --> 03:11:16,431
with maximum energy and drive and passion,

5634
03:11:16,431 --> 03:11:19,122
the world will often reconfigure itself around you

5635
03:11:19,122 --> 03:11:23,245
much more quickly and easily than you would think."

5636
03:11:23,245 --> 03:11:27,745
Thank you for listening and hope to see you next time.

