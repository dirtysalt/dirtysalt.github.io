1
00:00:00,080 --> 00:00:07,279
the following is a conversation with jeff hawkins a neuroscientist seeking to understand the structure function

2
00:00:07,279 --> 00:00:10,240
 and origin of intelligence in the human brain

3
00:00:10,240 --> 00:00:14,880
 he previously wrote the seminal book on the subject titled on intelligence

4
00:00:14,880 --> 00:00:18,560
 and recently a new book called a thousand brains

5
00:00:18,560 --> 00:00:21,119
 which presents a new theory of intelligence

6
00:00:21,119 --> 00:00:27,519
 that richard dawkins for example has been raving about calling the book quote brilliant

7
00:00:27,519 --> 00:00:29,119
 and exhilarating

8
00:00:29,119 --> 00:00:31,039
 i can't read those two words

9
00:00:31,039 --> 00:00:34,800
 and not think of him saying it in his british accent

10
00:00:34,800 --> 00:00:37,760
 quick mention of our sponsors codecademy

11
00:00:37,760 --> 00:00:39,120
 bio optimizers

12
00:00:39,120 --> 00:00:41,040
 expressvpn a-sleep

13
00:00:41,040 --> 00:00:45,200
 and blinkist check them out in the description to support this podcast

14
00:00:45,200 --> 00:00:47,840
 as a side note let me say that one small

15
00:00:47,840 --> 00:00:51,360
 but powerful idea that jeff hawkins mentions in his new book

16
00:00:51,360 --> 00:00:55,920
 is that if human civilization were to destroy itself all of knowledge

17
00:00:55,920 --> 00:00:58,960
 all our creations will go with us

18
00:00:58,960 --> 00:01:01,039
 he proposes that we should think about

19
00:01:01,039 --> 00:01:06,400
 how to save that knowledge in a way that long outlives us whether that's on earth

20
00:01:06,400 --> 00:01:07,920
 in orbit around earth

21
00:01:07,920 --> 00:01:09,760
 or in deep space

22
00:01:09,760 --> 00:01:16,960
 and then to send messages that advertise this backup of human knowledge to other intelligent alien civilizations

23
00:01:16,960 --> 00:01:22,080
 the main message of this advertisement is not that we are here

24
00:01:22,080 --> 00:01:26,159
 but that we were once here

25
00:01:26,159 --> 00:01:27,600
 this little difference

26
00:01:27,600 --> 00:01:33,920
 somehow was deeply humbling to me that we may with some non-zero likelihood destroy ourselves

27
00:01:33,920 --> 00:01:36,640
 and that an alien civilization thousands

28
00:01:36,640 --> 00:01:40,400
 or millions of years from now may come across this knowledge store

29
00:01:40,400 --> 00:01:43,520
 and they would only with some low probability

30
00:01:43,520 --> 00:01:47,200
 even notice it not to mention be able to interpret it

31
00:01:47,200 --> 00:01:52,799
 and the deeper question here for me is what information in all of human knowledge is even essential

32
00:01:52,799 --> 00:01:54,560
 does wikipedia capture it

33
00:01:54,560 --> 00:01:58,399
 or not at all this thought experiment forces me to wonder

34
00:01:58,399 --> 00:02:00,560
 what are the things we've accomplished

35
00:02:00,560 --> 00:02:03,759
 and are hoping to still accomplish that will outlive us

36
00:02:03,759 --> 00:02:10,800
 is it things like complex buildings bridges cars rockets is it ideas like science physics

37
00:02:10,800 --> 00:02:13,040
 and mathematics is it music

38
00:02:13,040 --> 00:02:17,120
 and art is it computers computational systems

39
00:02:17,120 --> 00:02:19,760
 or even artificial intelligence systems

40
00:02:19,760 --> 00:02:24,560
 i personally can't imagine that aliens wouldn't already have all of these things

41
00:02:24,560 --> 00:02:26,319
 in fact much more

42
00:02:26,319 --> 00:02:32,560
 and much better to me the only unique thing we may have is consciousness itself

43
00:02:32,560 --> 00:02:38,800
 and the actual subjective experience of suffering of happiness of hatred of love

44
00:02:38,800 --> 00:02:43,040
 if we can record these experiences in the highest resolution directly from the human brain

45
00:02:43,040 --> 00:02:45,920
 such that aliens will be able to replay them

46
00:02:45,920 --> 00:02:47,599
 that is what we should store

47
00:02:47,599 --> 00:02:49,519
 and send as a message

48
00:02:49,519 --> 00:02:50,879
 not wikipedia

49
00:02:50,879 --> 00:02:53,840
 but the extremes of conscious experiences

50
00:02:53,840 --> 00:02:57,840
 the most important of which of course is love

51
00:02:57,840 --> 00:02:59,840
 this is the lex friedman podcast

52
00:02:59,840 --> 00:03:04,080
 and here is my conversation with jeff hawkins

53
00:03:04,080 --> 00:03:05,680
 we previously

54
00:03:05,680 --> 00:03:07,519
 talked over two years ago

55
00:03:07,519 --> 00:03:12,159
 do you think there's still neurons in your brain that remember that conversation

56
00:03:12,159 --> 00:03:13,440
 that remember me

57
00:03:13,440 --> 00:03:14,239
 and got excited

58
00:03:14,239 --> 00:03:18,239
 like there's a lex neuron in your brain that just like finally has a purpose

59
00:03:18,239 --> 00:03:19,760
 i do remember our conversation

60
00:03:19,760 --> 00:03:21,519
 or i have some memories of it

61
00:03:21,519 --> 00:03:25,280
 and i formed additional memories of you in the meantime

62
00:03:25,280 --> 00:03:27,519
 um i wouldn't say there's a neuron

63
00:03:27,519 --> 00:03:33,120
 or a neurons in my brain that know you there are synapses in my brain that have formed

64
00:03:33,120 --> 00:03:35,040
 that reflect my knowledge of you

65
00:03:35,040 --> 00:03:37,120
 and the model i have of you in the world

66
00:03:37,120 --> 00:03:38,560
 and whether

67
00:03:38,560 --> 00:03:40,080
 the exact same synapses were formed

68
00:03:40,080 --> 00:03:41,920
 two years ago it's hard to say because these things

69
00:03:41,920 --> 00:03:42,879
 come and go all the time

70
00:03:42,879 --> 00:03:44,720
 but we know from

71
00:03:44,720 --> 00:03:46,480
 one thing to know about brains is that

72
00:03:46,480 --> 00:03:48,239
 when you think of things you often erase the memory

73
00:03:48,239 --> 00:03:49,120
 and rewrite it again

74
00:03:49,120 --> 00:03:49,760
 so

75
00:03:49,760 --> 00:03:54,080
 yes but i have a memory of you and i have that's instantiated in synapses

76
00:03:54,080 --> 00:03:56,879
 there's a simpler way to think about it like so you have

77
00:03:56,879 --> 00:03:59,680
 we have a model of the world in your head

78
00:03:59,680 --> 00:04:02,400
 and that model is continually being updated

79
00:04:02,400 --> 00:04:07,200
 i updated this morning you offered me this water you said it was from the refrigerator

80
00:04:07,200 --> 00:04:08,400
 i remember these things

81
00:04:08,400 --> 00:04:10,959
 and so we and so the model includes

82
00:04:10,959 --> 00:04:15,680
 where we live the places we know the words the objects in the world it's a monstrous model

83
00:04:15,680 --> 00:04:17,440
 and it's constantly being updated

84
00:04:17,440 --> 00:04:19,358
 and people are just part of that model

85
00:04:19,358 --> 00:04:20,238
 so we're animals

86
00:04:20,238 --> 00:04:22,079
 or other physical objects

87
00:04:22,079 --> 00:04:24,240
 so our events we've done

88
00:04:24,240 --> 00:04:24,960
 so

89
00:04:24,960 --> 00:04:29,759
 um it's there's no special in my mind special place for the memories of humans

90
00:04:29,759 --> 00:04:31,120
 i mean obviously

91
00:04:31,120 --> 00:04:32,400
 i know

92
00:04:32,400 --> 00:04:34,479
 you know i know a lot about my wife

93
00:04:34,479 --> 00:04:35,120
 um

94
00:04:35,120 --> 00:04:35,440
 but

95
00:04:35,440 --> 00:04:41,759
 and friends and so on but it's not like a special place for humans over here

96
00:04:41,759 --> 00:04:42,720
 but we model everything

97
00:04:42,720 --> 00:04:46,160
 and we model other people's behaviors too so if i said you're a

98
00:04:46,160 --> 00:04:50,080
 copy of your mind in my mind it's just because i know how humans i've learned

99
00:04:50,080 --> 00:04:51,520
 how humans behave

100
00:04:51,520 --> 00:04:51,919
 and

101
00:04:51,919 --> 00:04:52,400
 um

102
00:04:52,400 --> 00:04:54,639
 and i've learned some things about you

103
00:04:54,639 --> 00:04:57,120
 and that's part of my world model

104
00:04:57,120 --> 00:05:02,320
 well i just also mean the collective intelligence of the human species

105
00:05:02,320 --> 00:05:05,680
 i wonder if there's something

106
00:05:05,680 --> 00:05:08,479
 fundamental to the brain that enables that

107
00:05:08,479 --> 00:05:12,160
 so modeling other humans with their ideas

108
00:05:12,160 --> 00:05:16,160
 you're actually jumping into a lot of big topics like collective intelligence is a separate topic

109
00:05:16,160 --> 00:05:19,360
 that a lot of people like to talk about we can talk about that

110
00:05:19,360 --> 00:05:19,759
 but

111
00:05:19,759 --> 00:05:21,039
 um

112
00:05:21,039 --> 00:05:24,639
 and so that's interesting like you know we're not just individuals we live in society

113
00:05:24,639 --> 00:05:25,919
 and so on

114
00:05:25,919 --> 00:05:28,160
 but from our research point of view

115
00:05:28,160 --> 00:05:30,960
 and so again let's just talk we study the neocortex

116
00:05:30,960 --> 00:05:35,039
 it's a sheet of neural tissue it's about 75 of your brain

117
00:05:35,039 --> 00:05:39,680
 it runs on this very repetitive algorithm it's a very repetitive circuit

118
00:05:39,680 --> 00:05:40,000
 and

119
00:05:40,000 --> 00:05:44,479
 so you can apply that algorithm to lots of different problems

120
00:05:44,479 --> 00:05:47,759
 but it's all underneath it's the same thing we're just building this model

121
00:05:47,759 --> 00:05:49,440
 so from our point of view

122
00:05:49,440 --> 00:05:51,840
 we wouldn't look for these special circuit someplace

123
00:05:51,840 --> 00:05:54,400
 buried in your brain that might be related to other

124
00:05:54,400 --> 00:05:57,440
 you know understanding of the humans it's more like

125
00:05:57,440 --> 00:05:58,960
 you know how do we build a model of anything

126
00:05:58,960 --> 00:05:59,840
 how do we understand

127
00:05:59,840 --> 00:06:04,800
 anything in the world and humans are just another part of the things we understand

128
00:06:04,800 --> 00:06:06,560
 so there's nothing

129
00:06:06,560 --> 00:06:11,120
 there's nothing to the brain that knows the emergent phenomena of collecting the intelligence

130
00:06:11,120 --> 00:06:14,400
 well i certainly know about that i've heard the terms i've read

131
00:06:14,400 --> 00:06:16,800
 no but that's right right well okay right as an idea

132
00:06:16,800 --> 00:06:18,240
 well i think we have language

133
00:06:18,240 --> 00:06:20,319
 which is is sort of built into our brains

134
00:06:20,319 --> 00:06:22,479
 and that's a key part of collective intelligence

135
00:06:22,479 --> 00:06:26,479
 so there are some you know prior assumptions about

136
00:06:26,479 --> 00:06:28,240
 the world we're going to live in when we're born

137
00:06:28,240 --> 00:06:30,400
 we're not just a blank slate

138
00:06:30,400 --> 00:06:30,960
 um

139
00:06:30,960 --> 00:06:35,520
 and so you know did we evolve to take advantage of those situations

140
00:06:35,520 --> 00:06:35,919
 yes

141
00:06:35,919 --> 00:06:38,319
 but again we study only part of the brain the neocortex

142
00:06:38,319 --> 00:06:42,639
 there's other parts of the brain are very much involved in societal interactions

143
00:06:42,639 --> 00:06:43,759
 and human emotions

144
00:06:43,759 --> 00:06:44,479
 and

145
00:06:44,479 --> 00:06:45,120
 um

146
00:06:45,120 --> 00:06:46,160
 and how we interact

147
00:06:46,160 --> 00:06:47,840
 and even societal

148
00:06:47,840 --> 00:06:49,120
 um

149
00:06:49,120 --> 00:06:50,319
 issues about you know

150
00:06:50,319 --> 00:06:54,240
 how we are how we interact with other people when we support them when we're greedy

151
00:06:54,240 --> 00:06:55,599
 and things like that

152
00:06:55,599 --> 00:07:00,240
 i mean certainly the brain is a great place

153
00:07:00,240 --> 00:07:05,360
 where to study intelligence i wonder if it's the fundamental

154
00:07:05,360 --> 00:07:10,560
 atom of intelligence well i would say it's it's it's absolutely an essential component

155
00:07:10,560 --> 00:07:13,520
 even if you believe in collective intelligence as

156
00:07:13,520 --> 00:07:14,160
 um

157
00:07:14,160 --> 00:07:16,319
 hey that's where it's all happening that's what we need to study

158
00:07:16,319 --> 00:07:18,479
 which i don't believe that by the way i think it's really important

159
00:07:18,479 --> 00:07:20,160
 but i don't think that is the thing

160
00:07:20,160 --> 00:07:20,560
 um

161
00:07:20,560 --> 00:07:24,800
 but even if you do believe that then you have to understand

162
00:07:24,800 --> 00:07:26,880
 how the brain works in doing that

163
00:07:26,880 --> 00:07:29,680
 um it's you know it's more like we are intelligent

164
00:07:29,680 --> 00:07:31,360
 and we are intelligent individuals

165
00:07:31,360 --> 00:07:33,599
 and together we are much more magnified

166
00:07:33,599 --> 00:07:36,560
 our intelligence we can do things that we couldn't do individually

167
00:07:36,560 --> 00:07:39,120
 but even as individuals we're pretty damn smart

168
00:07:39,120 --> 00:07:40,479
 and we can model things

169
00:07:40,479 --> 00:07:42,960
 and understand the world and interact with it

170
00:07:42,960 --> 00:07:43,440
 so

171
00:07:43,440 --> 00:07:45,440
 um to me if you're going to start some place

172
00:07:45,440 --> 00:07:47,680
 you need to start with the brain

173
00:07:47,680 --> 00:07:50,080
 then you could say well how do brains interact with each other

174
00:07:50,080 --> 00:07:50,400
 and

175
00:07:50,400 --> 00:07:52,240
 what is the nature of language

176
00:07:52,240 --> 00:07:52,639
 and

177
00:07:52,639 --> 00:07:53,440
 how do we

178
00:07:53,440 --> 00:07:54,720
 share models that i've learned

179
00:07:54,720 --> 00:07:55,520
 something about the world

180
00:07:55,520 --> 00:07:56,479
 how do i share it with you

181
00:07:56,479 --> 00:07:57,919
 which is really what

182
00:07:57,919 --> 00:08:02,160
 you know sort of communal intelligence is i know something you know something

183
00:08:02,160 --> 00:08:04,560
 we've had different experiences in the world i've

184
00:08:04,560 --> 00:08:05,520
 learned something about brains

185
00:08:05,520 --> 00:08:07,680
 maybe i can impart that to you you've learned something about

186
00:08:07,680 --> 00:08:09,039
 you know whatever physics

187
00:08:09,039 --> 00:08:11,680
 and you can part that to me

188
00:08:11,680 --> 00:08:16,720
 but it also comes down to even just the epistemological question of well what is knowledge

189
00:08:16,720 --> 00:08:19,120
 and how do you represent it in the brain right

190
00:08:19,120 --> 00:08:24,800
 and it's not that's where it's going to reside right or in our writings it's obvious that

191
00:08:24,800 --> 00:08:27,680
 human collaboration human interaction is

192
00:08:27,680 --> 00:08:29,680
 how we build societies right

193
00:08:29,680 --> 00:08:32,080
 but some of the things you talk about

194
00:08:32,080 --> 00:08:34,559
 and work on

195
00:08:34,559 --> 00:08:40,320
 some of those elements of what makes up an intelligent entity is there with a single person

196
00:08:40,320 --> 00:08:41,039
 oh absolutely

197
00:08:41,039 --> 00:08:44,240
 i mean it'd be we can't deny that the brain is the core

198
00:08:44,240 --> 00:08:47,680
 element here in in at least i can't i think it's obvious

199
00:08:47,680 --> 00:08:51,120
 the brain is the core element in all theories of intelligence

200
00:08:51,120 --> 00:08:55,120
 it's where knowledge is represented it's where knowledge is created

201
00:08:55,120 --> 00:08:58,720
 we interact we share we build upon each other's work

202
00:08:58,720 --> 00:09:03,920
 but without a brain you'd have nothing you know there would be no intelligence without brains

203
00:09:03,920 --> 00:09:04,560
 and so

204
00:09:04,560 --> 00:09:05,839
 um

205
00:09:05,839 --> 00:09:07,120
 so that's where we start

206
00:09:07,120 --> 00:09:09,279
 i got into this field because i just was curious

207
00:09:09,279 --> 00:09:11,200
 as to who i am you know how

208
00:09:11,200 --> 00:09:13,680
 you know how do i think what's going on in my head when i'm

209
00:09:13,680 --> 00:09:14,560
 what i'm thinking

210
00:09:14,560 --> 00:09:16,399
 what does it mean to know something

211
00:09:16,399 --> 00:09:19,120
 you know i can ask what it means for me to know something independent

212
00:09:19,120 --> 00:09:20,880
 of how i learned it from you

213
00:09:20,880 --> 00:09:22,800
 or from someone else or from society

214
00:09:22,800 --> 00:09:25,200
 so what does it mean for me to know that i have a model

215
00:09:25,200 --> 00:09:27,600
 of you in my head what does it mean to know i know what this microphone

216
00:09:27,600 --> 00:09:31,200
 does and how it works physically even though i can't see it right now

217
00:09:31,200 --> 00:09:32,720
 how do i know that

218
00:09:32,720 --> 00:09:33,360
 what does it mean

219
00:09:33,360 --> 00:09:36,240
 how the neurons do that at the fundamental level of neurons

220
00:09:36,240 --> 00:09:36,959
 and synapses

221
00:09:36,959 --> 00:09:40,320
 and so on those are really fascinating questions

222
00:09:40,320 --> 00:09:46,399
 and i'm happy to be just happy to understand those if i could

223
00:09:46,480 --> 00:09:50,640
 so in your um in your new book

224
00:09:50,640 --> 00:09:56,000
 you talk about our brain our mind as being made up of many brains

225
00:09:56,000 --> 00:09:58,640
 so the book is called the thousand brains

226
00:09:58,640 --> 00:10:00,240
 a thousand brain theory of intelligence

227
00:10:00,240 --> 00:10:05,680
 what is the key idea of this book the book has three sections

228
00:10:05,680 --> 00:10:08,399
 and it has sort of maybe three big ideas

229
00:10:08,399 --> 00:10:11,279
 so the first section is all about what we've learned about the neurocortex

230
00:10:11,279 --> 00:10:13,120
 and that's the thousand brains theory

231
00:10:13,120 --> 00:10:15,760
 just did we complete the picture the second section is all about ai

232
00:10:15,760 --> 00:10:19,120
 and the third section is about the future of humanity

233
00:10:19,120 --> 00:10:22,240
 so the thousand brains theory

234
00:10:22,240 --> 00:10:28,800
 the the big idea there if i had to summarize into one big idea

235
00:10:28,800 --> 00:10:33,440
 is that we think of the the brain the neocortex is learning this model of the world

236
00:10:33,440 --> 00:10:39,040
 but what we learned is actually there's tens of thousands of independent modeling systems going on

237
00:10:39,040 --> 00:10:40,079
 and so each

238
00:10:40,079 --> 00:10:42,640
 what we call a column in the cortex is about 150

239
00:10:42,640 --> 00:10:45,519
 000 of them is a complete modeling system

240
00:10:45,519 --> 00:10:49,120
 so it's a collective intelligence in your head in some sense

241
00:10:49,120 --> 00:10:51,200
 so the thousand brains theory says well

242
00:10:51,200 --> 00:10:53,680
 where do i have knowledge about you know this coffee cup

243
00:10:53,680 --> 00:10:55,839
 where is the model of this cell phone

244
00:10:55,839 --> 00:10:59,279
 it's not in one place it's in thousands of separate models that are complementary

245
00:10:59,279 --> 00:11:01,440
 and they communicate with each other through voting

246
00:11:01,440 --> 00:11:04,959
 so this idea that we have we feel like we're one person

247
00:11:04,959 --> 00:11:07,120
 you know that's our experience we can explain that

248
00:11:07,120 --> 00:11:10,880
 but reality there's lots of these like almost like little brands like

249
00:11:10,880 --> 00:11:14,640
 but they're they're sophisticated modeling systems about 150

250
00:11:14,640 --> 00:11:17,519
 000 of them in each of the human brain

251
00:11:17,519 --> 00:11:19,760
 and that's a totally different way of thinking about

252
00:11:19,760 --> 00:11:21,839
 how the neural cortex is structured than

253
00:11:21,839 --> 00:11:25,040
 we or anyone else thought of even just five years ago

254
00:11:25,040 --> 00:11:27,279
 so you mentioned you started

255
00:11:27,279 --> 00:11:28,560
 this journey

256
00:11:28,560 --> 00:11:31,839
 and just looking in the mirror trying to understand who you are

257
00:11:31,839 --> 00:11:34,399
 so if you have many brains

258
00:11:34,399 --> 00:11:35,839
 who are you then

259
00:11:35,839 --> 00:11:36,399
 so

260
00:11:36,399 --> 00:11:38,480
 it's interesting we have a singular perception right

261
00:11:38,480 --> 00:11:40,880
 you know we think oh i'm just here i'm looking at you

262
00:11:40,880 --> 00:11:43,360
 but it's it's composed of all these things like there's sounds

263
00:11:43,360 --> 00:11:43,839
 and there's

264
00:11:43,839 --> 00:11:45,519
 and there's this vision

265
00:11:45,519 --> 00:11:46,240
 and there's touch

266
00:11:46,240 --> 00:11:47,920
 and all kinds of inputs

267
00:11:47,920 --> 00:11:49,600
 yeah we have the singular perception

268
00:11:49,600 --> 00:11:51,920
 and what the thousand brain theory says we have these models

269
00:11:51,920 --> 00:11:52,720
 that are visual models

270
00:11:52,720 --> 00:11:53,920
 we have a lot of models of auditory

271
00:11:53,920 --> 00:11:55,360
 models models of toxin models

272
00:11:55,360 --> 00:11:56,160
 and so on

273
00:11:56,160 --> 00:11:57,680
 but they vote

274
00:11:57,680 --> 00:11:58,399
 and so

275
00:11:58,399 --> 00:12:00,000
 um they send in the cortex

276
00:12:00,000 --> 00:12:01,200
 you can think about these

277
00:12:01,200 --> 00:12:04,399
 columns as that like little grains of rice 150

278
00:12:04,399 --> 00:12:06,399
 000 stacked next to each other

279
00:12:06,399 --> 00:12:09,600
 and each one is its own little modeling system

280
00:12:09,600 --> 00:12:12,639
 but they have these long-range connections that go between them

281
00:12:12,639 --> 00:12:14,959
 and we call those voting connections

282
00:12:14,959 --> 00:12:16,320
 or voting neurons

283
00:12:16,320 --> 00:12:17,120
 um

284
00:12:17,120 --> 00:12:17,440
 and

285
00:12:17,440 --> 00:12:19,839
 so the different columns

286
00:12:19,839 --> 00:12:20,959
 try to reach the consensus

287
00:12:20,959 --> 00:12:24,320
 like what am i looking at okay you know each one has some ambiguity

288
00:12:24,320 --> 00:12:25,519
 but they come to a consensus

289
00:12:25,519 --> 00:12:27,920
 oh there's a water bottle i'm looking at

290
00:12:27,920 --> 00:12:30,320
 um we are only consciously

291
00:12:30,320 --> 00:12:32,000
 able to perceive the voting

292
00:12:32,000 --> 00:12:35,360
 we're not able to perceive anything that goes on under the hood

293
00:12:35,360 --> 00:12:37,760
 so the voting is what we're

294
00:12:37,760 --> 00:12:39,519
 we're aware of the results

295
00:12:39,519 --> 00:12:42,480
 of the vote yeah the velocity well it's it's you can imagine it this way

296
00:12:42,480 --> 00:12:44,320
 we were just talking about eye movements a moment ago

297
00:12:44,320 --> 00:12:47,920
 so as i'm looking at something my eyes are moving about three times a second

298
00:12:47,920 --> 00:12:50,000
 and with each movement a completely

299
00:12:50,000 --> 00:12:52,399
 new input is coming into the brain it's not repetitive

300
00:12:52,399 --> 00:12:54,480
 it's not shifting it around it's completely new

301
00:12:54,480 --> 00:12:57,440
 i'm totally unaware of it i can't perceive it

302
00:12:57,440 --> 00:12:58,720
 but yet if i looked at the neurons

303
00:12:58,720 --> 00:13:00,959
 in your brain they're going on and off i don't know

304
00:13:00,959 --> 00:13:04,959
 but the voting neurons are not the voting neurons are saying you know we all agree

305
00:13:04,959 --> 00:13:07,839
 even though i'm looking at different parts of this is a water bottle right now

306
00:13:07,839 --> 00:13:09,519
 and that's not changing

307
00:13:09,519 --> 00:13:10,720
 and it's in some position

308
00:13:10,720 --> 00:13:11,040
 and

309
00:13:11,040 --> 00:13:12,959
 and pose relative to me

310
00:13:12,959 --> 00:13:13,920
 so i have this perception

311
00:13:13,920 --> 00:13:17,120
 of the water bottle about two feet away from me at a certain pose to me

312
00:13:17,120 --> 00:13:17,680
 um

313
00:13:17,680 --> 00:13:19,279
 that is not changing that's the only

314
00:13:19,279 --> 00:13:20,320
 part i'm aware of i can't

315
00:13:20,320 --> 00:13:22,000
 be aware of the fact that the inputs

316
00:13:22,000 --> 00:13:23,040
 from the eyes are moving

317
00:13:23,040 --> 00:13:23,600
 and changing

318
00:13:23,600 --> 00:13:25,040
 and all this others happening

319
00:13:25,040 --> 00:13:27,440
 so these long range connections

320
00:13:27,440 --> 00:13:34,399
 are the part we can be conscious of the individual activity in each column is doesn't go anywhere else

321
00:13:34,399 --> 00:13:35,440
 it doesn't get shared

322
00:13:35,440 --> 00:13:36,560
 anywhere else it doesn't

323
00:13:36,560 --> 00:13:38,320
 there's no way to extract it

324
00:13:38,320 --> 00:13:39,440
 and talk about it

325
00:13:39,440 --> 00:13:42,399
 or extract it and even remember it to say oh

326
00:13:42,399 --> 00:13:44,000
 yes i can recall that

327
00:13:44,000 --> 00:13:44,639
 um

328
00:13:44,639 --> 00:13:45,199
 so

329
00:13:45,199 --> 00:13:48,800
 but these long-range connections are the things that are accessible to language

330
00:13:48,800 --> 00:13:51,040
 and to our you know it's like the hippocampus

331
00:13:51,040 --> 00:13:54,000
 or our memories you know our short-term memory systems

332
00:13:54,000 --> 00:13:54,800
 and so on

333
00:13:54,800 --> 00:13:57,839
 so we're not aware of 95

334
00:13:57,839 --> 00:14:01,600
 or maybe it's even 98 of what's going on in your brain

335
00:14:01,600 --> 00:14:05,519
 we're only aware of this sort of stable somewhat stable

336
00:14:05,519 --> 00:14:10,000
 voting outcome of all these things that are going on underneath the hood

337
00:14:10,000 --> 00:14:10,320
 so

338
00:14:10,320 --> 00:14:17,839
 what would you say is the basic element in the thousand brains theory of intelligence of intelligence

339
00:14:17,839 --> 00:14:22,800
 like what's the atom of intelligence when you think about it is it the individual brains

340
00:14:22,800 --> 00:14:25,440
 and then what is a brain well let's let's

341
00:14:25,440 --> 00:14:27,839
 can we just talk about what intelligence is first

342
00:14:27,839 --> 00:14:28,399
 and then

343
00:14:28,399 --> 00:14:30,399
 and then we can talk about the elements are

344
00:14:30,399 --> 00:14:35,920
 so in my in my book intelligence is the ability to learn a model of the world

345
00:14:35,920 --> 00:14:39,120
 so to build internal to your head

346
00:14:39,120 --> 00:14:41,920
 a model that represents the structure of everything

347
00:14:41,920 --> 00:14:43,839
 you know to know what this is a table

348
00:14:43,839 --> 00:14:47,920
 and that's a coffee cup and this is a gooseneck lamp and all this to know these things

349
00:14:47,920 --> 00:14:48,800
 i have to have a model

350
00:14:48,800 --> 00:14:51,279
 in my head i just don't look at them and go what is that

351
00:14:51,279 --> 00:14:55,040
 i already have internal representations of these things in my head

352
00:14:55,040 --> 00:14:58,320
 and i had to learn them i wasn't born of any of that knowledge

353
00:14:58,320 --> 00:14:58,959
 you were

354
00:14:58,959 --> 00:15:00,320
 you know we have some lights in the room here

355
00:15:00,320 --> 00:15:01,120
 i you know that's

356
00:15:01,120 --> 00:15:02,160
 not part of my evolutionary

357
00:15:02,160 --> 00:15:04,320
 heritage right it's not in my genes

358
00:15:04,320 --> 00:15:04,720
 so

359
00:15:04,720 --> 00:15:05,519
 um

360
00:15:05,519 --> 00:15:06,480
 we have this incredible

361
00:15:06,480 --> 00:15:07,440
 model and the model includes

362
00:15:07,440 --> 00:15:10,399
 not only what things look like and feel like but where they are relative

363
00:15:10,399 --> 00:15:12,079
 to each other and how they behave

364
00:15:12,079 --> 00:15:13,920
 i've never picked up this water bottle before

365
00:15:13,920 --> 00:15:15,199
 but i know that if i took my hand

366
00:15:15,199 --> 00:15:16,560
 on that blue thing and i turn it it'll

367
00:15:16,560 --> 00:15:17,839
 probably make a funny little sound

368
00:15:17,839 --> 00:15:19,920
 as the little plastic things detach

369
00:15:19,920 --> 00:15:20,800
 and then it'll rotate

370
00:15:20,800 --> 00:15:22,480
 and it'll look a certain way it'll come off

371
00:15:22,480 --> 00:15:25,279
 how do i know that right because i have this model in my head

372
00:15:25,279 --> 00:15:28,639
 so the essence of intelligence as our ability to learn a model

373
00:15:28,639 --> 00:15:34,880
 and the more sophisticated our model is the smarter we are not that there is a single intelligence

374
00:15:34,880 --> 00:15:35,279
 because

375
00:15:35,279 --> 00:15:35,920
 you can know about

376
00:15:35,920 --> 00:15:38,959
 you know a lot about things that i don't know and i know about things you don't know

377
00:15:38,959 --> 00:15:40,399
 and we can both be very smart

378
00:15:40,399 --> 00:15:43,600
 but we both learn the model of the world through interacting with it

379
00:15:43,600 --> 00:15:46,480
 so that is the essence of intelligence then we can ask ourselves

380
00:15:46,480 --> 00:15:49,680
 what are the mechanisms in the brain that allow us to do that

381
00:15:49,680 --> 00:15:52,320
 and what are the mechanisms of learning not just the neural mechanisms

382
00:15:52,320 --> 00:15:53,440
 what is the general process

383
00:15:53,440 --> 00:15:54,800
 but how we learn a model

384
00:15:54,800 --> 00:15:57,759
 so that was a big insight for us it's like what are the

385
00:15:57,759 --> 00:15:59,360
 what is the actual things that

386
00:15:59,360 --> 00:16:02,560
 how do you learn this stuff it turns out you have to learn it through movement

387
00:16:02,560 --> 00:16:04,480
 um you can't learn it just by

388
00:16:04,480 --> 00:16:06,720
 that's how we learn we learn through movement we learn

389
00:16:06,720 --> 00:16:07,360
 um so

390
00:16:07,360 --> 00:16:09,759
 you build up this model by observing things and touching

391
00:16:09,759 --> 00:16:11,040
 them and moving them and walking

392
00:16:11,040 --> 00:16:15,120
 around the world and so on so either you move or the thing moves somehow

393
00:16:15,120 --> 00:16:16,399
 yeah you obviously

394
00:16:16,399 --> 00:16:18,160
 can learn things just by reading a book something

395
00:16:18,160 --> 00:16:20,160
 like that but think about if i were to say oh

396
00:16:20,160 --> 00:16:20,959
 here's a new house

397
00:16:20,959 --> 00:16:22,720
 yeah i want you to learn you know

398
00:16:22,720 --> 00:16:23,920
 what do you do you have to walk

399
00:16:23,920 --> 00:16:27,040
 you have to walk from room to the room you have to open the doors

400
00:16:27,040 --> 00:16:29,680
 look around see what's on the left what's on the right

401
00:16:29,680 --> 00:16:32,560
 as you do this you're building a model in your head it's just

402
00:16:32,560 --> 00:16:33,519
 that's what you're doing

403
00:16:33,519 --> 00:16:36,320
 you can't just sit there and say i'm going gonna grock the house no

404
00:16:36,320 --> 00:16:37,600
 you know or you could

405
00:16:37,600 --> 00:16:40,240
 you don't even want to sit there and read some description of it right

406
00:16:40,240 --> 00:16:40,720
 yeah

407
00:16:40,720 --> 00:16:42,160
 you literally physically interactive

408
00:16:42,160 --> 00:16:43,199
 the same with like a smartphone

409
00:16:43,199 --> 00:16:43,839
 if i want to

410
00:16:43,839 --> 00:16:46,160
 learn a new app i touch it and i move things around

411
00:16:46,160 --> 00:16:47,920
 i see what happens when i when i

412
00:16:47,920 --> 00:16:49,680
 do things with it so that's the basic

413
00:16:49,680 --> 00:16:53,920
 way we learn in the world and by the way when you say model you mean something

414
00:16:53,920 --> 00:16:58,160
 that can be used for prediction in the future it's it's used for prediction

415
00:16:58,160 --> 00:16:59,680
 and for behavior

416
00:16:59,680 --> 00:17:00,959
 and planning

417
00:17:00,959 --> 00:17:01,920
 right um

418
00:17:01,920 --> 00:17:04,640
 and does a pretty good job in doing so

419
00:17:04,640 --> 00:17:05,199
 yeah

420
00:17:05,199 --> 00:17:06,799
 here's the way to think about the model

421
00:17:06,799 --> 00:17:08,880
 a lot of people get hung up on this so

422
00:17:08,880 --> 00:17:10,160
 um

423
00:17:10,160 --> 00:17:13,439
 you can imagine an architect making a model of a house

424
00:17:13,439 --> 00:17:16,000
 right so there's a physical model that's small

425
00:17:16,000 --> 00:17:18,799
 and why do they do that well we do that because you can imagine

426
00:17:18,799 --> 00:17:20,240
 what it would look like from different angles

427
00:17:20,240 --> 00:17:20,959
 you could say okay

428
00:17:20,959 --> 00:17:22,959
 look at them here look in there and you can also say well

429
00:17:22,959 --> 00:17:23,359
 how

430
00:17:23,359 --> 00:17:25,839
 how far to get from from the garage to the

431
00:17:25,839 --> 00:17:28,240
 to the swimming pool or something like that right you can imagine

432
00:17:28,240 --> 00:17:30,480
 looking at this you can say what would be the view from this location

433
00:17:30,480 --> 00:17:33,520
 so we built these physical models to let you imagine the future

434
00:17:33,520 --> 00:17:35,919
 and imagine that behaviors

435
00:17:35,919 --> 00:17:37,520
 now we can take that same model

436
00:17:37,520 --> 00:17:38,480
 and put it in a computer

437
00:17:38,480 --> 00:17:41,679
 so we now today they'll build models of houses

438
00:17:41,679 --> 00:17:42,240
 and a computer

439
00:17:42,240 --> 00:17:42,880
 and they

440
00:17:42,880 --> 00:17:45,039
 and they do that using a set of

441
00:17:45,039 --> 00:17:46,320
 um

442
00:17:46,320 --> 00:17:49,039
 we'll come back to this term in a moment reference frames but eventually

443
00:17:49,039 --> 00:17:50,960
 you assign a reference frame for the house

444
00:17:50,960 --> 00:17:53,679
 and you assign different things for the house in different locations

445
00:17:53,679 --> 00:17:55,679
 and then the computer can generate an image

446
00:17:55,679 --> 00:17:57,600
 and say okay this is what it looks like in this direction

447
00:17:57,600 --> 00:17:59,600
 the brain is doing something remarkably

448
00:17:59,600 --> 00:18:01,679
 similar to this surprising

449
00:18:01,679 --> 00:18:06,000
 um it's using reference frames it's building these it's similar to a model in a computer

450
00:18:06,000 --> 00:18:07,840
 which has the same benefits of building a physical

451
00:18:07,840 --> 00:18:09,919
 model it allows me to say what would this thing

452
00:18:09,919 --> 00:18:12,080
 look like if it was in this orientation

453
00:18:12,080 --> 00:18:15,600
 what would likely happen if i push this button i've never pushed this button before

454
00:18:15,600 --> 00:18:16,080
 or

455
00:18:16,080 --> 00:18:19,200
 how would i accomplish something i want to i want to

456
00:18:19,200 --> 00:18:20,240
 um

457
00:18:20,240 --> 00:18:22,000
 convey a new idea i've learned

458
00:18:22,000 --> 00:18:25,360
 how would i do that i can imagine in my head well i could talk about it

459
00:18:25,360 --> 00:18:26,720
 i could write a book

460
00:18:26,720 --> 00:18:28,880
 i could do some podcasts

461
00:18:28,880 --> 00:18:29,600
 i could

462
00:18:29,600 --> 00:18:32,640
 um you know maybe tell my neighbor you know

463
00:18:32,640 --> 00:18:33,440
 and i can imagine

464
00:18:33,440 --> 00:18:36,000
 the outcomes of all these things before i do any of them

465
00:18:36,000 --> 00:18:38,799
 that's what the model lets you do it let's just plan the future

466
00:18:38,799 --> 00:18:42,720
 and imagine the consequences of our actions prediction

467
00:18:42,720 --> 00:18:44,320
 you asked about prediction

468
00:18:44,320 --> 00:18:49,679
 prediction is not the goal of the model prediction is an inherent property of it

469
00:18:49,679 --> 00:18:52,320
 and it's how the model corrects itself

470
00:18:52,320 --> 00:18:57,440
 so prediction is fundamental to intelligence it's fundamental to building a model

471
00:18:57,440 --> 00:18:59,120
 and the model's intelligent

472
00:18:59,120 --> 00:19:02,000
 and let me go back and be very precise about this prediction

473
00:19:02,000 --> 00:19:02,720
 you can think of prediction

474
00:19:02,720 --> 00:19:03,760
 two ways one is like

475
00:19:03,760 --> 00:19:06,720
 hey what would happen if i did this that's the type of prediction

476
00:19:06,720 --> 00:19:08,640
 um that's a key part of intelligence

477
00:19:08,640 --> 00:19:11,360
 but using predictions like oh what's this this is

478
00:19:11,360 --> 00:19:14,320
 this water bottle gonna feel like when i pick it up you know

479
00:19:14,320 --> 00:19:16,080
 and that doesn't seem very intelligent

480
00:19:16,080 --> 00:19:19,679
 but the way to think one way to think about intelligence prediction is

481
00:19:19,679 --> 00:19:21,600
 it's a way for us to learn

482
00:19:21,600 --> 00:19:23,120
 where our model is wrong

483
00:19:23,120 --> 00:19:24,880
 so if i picked up this water bottle

484
00:19:24,880 --> 00:19:27,520
 and it felt hot i'd be very surprised

485
00:19:27,520 --> 00:19:30,480
 or if i picked up was very light it would be very i'd be surprised

486
00:19:30,480 --> 00:19:32,480
 or if i turned this top

487
00:19:32,480 --> 00:19:35,760
 and it didn't i had to turn the other way i'd be surprised

488
00:19:35,760 --> 00:19:36,720
 and so almost

489
00:19:36,720 --> 00:19:39,200
 might have a prediction like okay i'm gonna do it i'll drink some water

490
00:19:39,200 --> 00:19:42,000
 i'm okay okay do this there it is i feel opening right

491
00:19:42,000 --> 00:19:42,240
 what

492
00:19:42,240 --> 00:19:44,880
 if i had to turn it the other way or what if it it split in two

493
00:19:44,880 --> 00:19:47,120
 then i say oh my gosh i i misunderstood

494
00:19:47,120 --> 00:19:49,360
 this i didn't have the right model of this thing my attention

495
00:19:49,360 --> 00:19:51,039
 would be drawn to i'll be looking at it going well how

496
00:19:51,039 --> 00:19:52,080
 the hell did that happen

497
00:19:52,080 --> 00:19:54,160
 you know why did it open up that way

498
00:19:54,160 --> 00:19:55,760
 and i would update my model

499
00:19:55,760 --> 00:19:56,880
 by doing it just by looking

500
00:19:56,880 --> 00:19:57,919
 at it and playing around with that update

501
00:19:57,919 --> 00:19:59,840
 and say this is a new type of water bottle

502
00:19:59,840 --> 00:20:01,120
 but you

503
00:20:01,120 --> 00:20:05,120
 so you're talking about sort of complicated things like a water bottle

504
00:20:05,120 --> 00:20:09,919
 but this also applies for just basic vision just like seeing things

505
00:20:09,919 --> 00:20:15,360
 it's almost like a precondition of just perceiving the world is predicting

506
00:20:15,360 --> 00:20:22,240
 it's just everything that you see is first passed through your prediction everything you see

507
00:20:22,240 --> 00:20:23,039
 and feel

508
00:20:23,039 --> 00:20:27,440
 in fact this this is the insight i had back in the late 80s

509
00:20:27,440 --> 00:20:28,960
 and excuse me early 80s

510
00:20:28,960 --> 00:20:29,360
 and

511
00:20:29,360 --> 00:20:34,799
 um another people reach the same idea is that every sensory input you get not just vision

512
00:20:34,799 --> 00:20:35,679
 but touch

513
00:20:35,679 --> 00:20:39,360
 and hearing you have an expectation about it

514
00:20:39,360 --> 00:20:40,080
 and

515
00:20:40,080 --> 00:20:44,720
 um a prediction sometimes you can pick very accurately sometimes you can't i can't predict

516
00:20:44,720 --> 00:20:46,559
 what next word is going to come out of your mouth

517
00:20:46,559 --> 00:20:49,280
 but as you start talking about better and better predictions

518
00:20:49,280 --> 00:20:52,559
 and if you talk about some topics i'd be very surprised

519
00:20:52,559 --> 00:20:56,000
 so i have this sort of background prediction that's going on all the time

520
00:20:56,000 --> 00:20:58,080
 for all my senses

521
00:20:58,080 --> 00:21:00,799
 again the way i think about that

522
00:21:00,799 --> 00:21:04,960
 is this is how we learn it's it's more about how we learn

523
00:21:04,960 --> 00:21:08,159
 it's the test of our understanding our predictions are our test

524
00:21:08,159 --> 00:21:11,600
 did is this really a water bottle if it is i shouldn't see

525
00:21:11,600 --> 00:21:13,840
 you know a little finger sticking out the side

526
00:21:13,840 --> 00:21:14,720
 and if i saw a little finger

527
00:21:14,720 --> 00:21:15,280
 stick and i was like

528
00:21:15,280 --> 00:21:16,240
 what the hell is going on

529
00:21:16,240 --> 00:21:18,640
 you know that's not normal

530
00:21:18,640 --> 00:21:19,200
 um

531
00:21:19,200 --> 00:21:23,679
 i mean that's fascinating that just let me linger on this

532
00:21:23,679 --> 00:21:29,039
 for a second i it really honestly feels that prediction is fundamental

533
00:21:29,039 --> 00:21:33,200
 to everything to the way our mind operates to intelligence

534
00:21:33,200 --> 00:21:34,880
 so like

535
00:21:34,880 --> 00:21:37,280
 it's just a different way to see intelligence

536
00:21:37,280 --> 00:21:39,840
 which is like everything starts at prediction

537
00:21:39,840 --> 00:21:42,000
 and prediction requires a model

538
00:21:42,000 --> 00:21:45,600
 you can't predict something unless you have a model of it right

539
00:21:45,600 --> 00:21:50,159
 but the action is prediction it's like the the thing the model does is prediction

540
00:21:50,159 --> 00:21:51,200
 and

541
00:21:51,200 --> 00:21:51,919
 but it also

542
00:21:51,919 --> 00:21:52,240
 yeah

543
00:21:52,240 --> 00:21:55,440
 and you but you can then extend it to things like

544
00:21:55,440 --> 00:21:59,600
 what would happen if i took this today i went and did this

545
00:21:59,600 --> 00:22:00,880
 what would be like that

546
00:22:00,880 --> 00:22:01,280
 or

547
00:22:01,280 --> 00:22:04,960
 how you can extend predictions like oh i want to get a promotion at work

548
00:22:04,960 --> 00:22:05,600
 um

549
00:22:05,600 --> 00:22:07,039
 what action should i take

550
00:22:07,039 --> 00:22:08,720
 and you can say if i did this i predict

551
00:22:08,720 --> 00:22:09,760
 what might happen if i

552
00:22:09,760 --> 00:22:11,120
 spoke to someone i predict what

553
00:22:11,120 --> 00:22:13,360
 might happen so it's not just low level predictions

554
00:22:13,360 --> 00:22:16,480
 yeah it's all prediction it's all predictions like this black box

555
00:22:16,480 --> 00:22:18,159
 so you can ask basically any question

556
00:22:18,159 --> 00:22:20,720
 low level or highlight so we start off with that observation

557
00:22:20,720 --> 00:22:23,760
 it's all it's like this non-stop prediction

558
00:22:23,760 --> 00:22:25,360
 and i write about this in the book about

559
00:22:25,360 --> 00:22:26,480
 and then we ask

560
00:22:26,480 --> 00:22:28,480
 how do neurons actually make predictions

561
00:22:28,480 --> 00:22:31,440
 physically like what does the neuron do when it makes a prediction

562
00:22:31,440 --> 00:22:31,840
 and

563
00:22:31,840 --> 00:22:32,400
 um

564
00:22:32,400 --> 00:22:34,720
 what the neural tissue does when it makes predictions

565
00:22:34,720 --> 00:22:36,400
 and then we ask what are the mechanisms

566
00:22:36,400 --> 00:22:38,799
 by how we build a model that allows you to make prediction

567
00:22:38,799 --> 00:22:43,360
 so we started with prediction as sort of the fundamental

568
00:22:43,360 --> 00:22:46,159
 research agenda if in some sense like

569
00:22:46,159 --> 00:22:47,360
 and say well we understand

570
00:22:47,360 --> 00:22:49,600
 how the brain makes predictions we'll understand

571
00:22:49,600 --> 00:22:50,559
 how it builds these models

572
00:22:50,559 --> 00:22:51,360
 and how it learns

573
00:22:51,360 --> 00:22:52,799
 and that's core of intelligence

574
00:22:52,799 --> 00:22:55,679
 so it was like it was the key that got us in the door

575
00:22:55,679 --> 00:22:59,360
 to say that is our research agenda understand predictions

576
00:22:59,360 --> 00:23:01,120
 so in this whole process

577
00:23:01,120 --> 00:23:04,559
 where does intelligence originate

578
00:23:04,559 --> 00:23:06,320
 would you say

579
00:23:06,320 --> 00:23:08,720
 so it

580
00:23:08,720 --> 00:23:12,640
 if we look at things that are much less intelligent to humans

581
00:23:12,640 --> 00:23:16,080
 and you start to build up a human the process of evolution

582
00:23:16,080 --> 00:23:21,360
 where is this magic thing that has a prediction model

583
00:23:21,360 --> 00:23:23,520
 or a model that's able to predict

584
00:23:23,520 --> 00:23:27,919
 that starts to look a lot more like intelligence is there a place where

585
00:23:27,919 --> 00:23:32,640
 richard dawkins wrote an introduction to your to your book an excellent introduction

586
00:23:32,640 --> 00:23:35,760
 i mean it puts a lot of things into context

587
00:23:35,760 --> 00:23:39,039
 and it's funny just looking at parallels for your book

588
00:23:39,039 --> 00:23:40,720
 and darwin's origin of species

589
00:23:40,720 --> 00:23:45,440
 so darwin wrote about the origin of species

590
00:23:45,440 --> 00:23:47,200
 so

591
00:23:47,200 --> 00:23:49,200
 what is the origin of intelligence

592
00:23:49,200 --> 00:23:52,480
 well we have a theory about it and it's just that it's a theory

593
00:23:52,480 --> 00:23:54,240
 theory goes as follows

594
00:23:54,240 --> 00:23:57,120
 as soon as living things started to move

595
00:23:57,120 --> 00:23:59,600
 they're not just floating in sea they're not just

596
00:23:59,600 --> 00:24:03,600
 a plant you know grounded some place as soon as they started the move

597
00:24:03,600 --> 00:24:08,159
 there was an advantage to moving intelligently to moving in certain ways

598
00:24:08,159 --> 00:24:11,440
 and there's some very simple things you can do you know bacteria

599
00:24:11,440 --> 00:24:15,919
 or single cell organisms can move towards a source of gradient of food

600
00:24:15,919 --> 00:24:17,200
 or something like that

601
00:24:17,200 --> 00:24:19,520
 but an animal that might know where it is

602
00:24:19,520 --> 00:24:20,400
 and know where it's been

603
00:24:20,400 --> 00:24:22,240
 and how to get back to that place or an animal

604
00:24:22,240 --> 00:24:23,440
 that might say oh

605
00:24:23,440 --> 00:24:25,120
 there was a source of food someplace

606
00:24:25,120 --> 00:24:27,600
 how do i get to it or there was a danger

607
00:24:27,600 --> 00:24:28,960
 how do i get to there was a mate

608
00:24:28,960 --> 00:24:30,480
 how do i get to them

609
00:24:30,480 --> 00:24:31,279
 um

610
00:24:31,279 --> 00:24:32,640
 there was a big evolution

611
00:24:32,640 --> 00:24:36,559
 advantage to that so early on there was a pressure to start understanding

612
00:24:36,559 --> 00:24:38,960
 your environment like where am i

613
00:24:38,960 --> 00:24:39,279
 and

614
00:24:39,279 --> 00:24:40,320
 where have i been

615
00:24:40,320 --> 00:24:43,360
 and what happened in those different places

616
00:24:43,360 --> 00:24:47,440
 so we still have this neural mechanism in our brains

617
00:24:47,440 --> 00:24:52,000
 um it's in in the in the mammals it's in the hippocampus

618
00:24:52,000 --> 00:24:54,960
 and internal cortex these are older parts of the brain

619
00:24:54,960 --> 00:24:55,520
 um

620
00:24:55,520 --> 00:24:57,600
 and these are very well studied

621
00:24:57,600 --> 00:25:00,640
 um we build a map of the of our environment

622
00:25:00,640 --> 00:25:04,480
 so these neurons in these parts of the brain know where i am in this room

623
00:25:04,480 --> 00:25:04,799
 and

624
00:25:04,799 --> 00:25:06,080
 where the door was

625
00:25:06,080 --> 00:25:07,279
 and things like that

626
00:25:07,279 --> 00:25:11,360
 so a lot of other mammals have this all mammals have this right and

627
00:25:11,360 --> 00:25:13,840
 almost any any animal that knows

628
00:25:13,840 --> 00:25:14,880
 where it is

629
00:25:14,880 --> 00:25:17,279
 and get around must have some mapping system

630
00:25:17,279 --> 00:25:19,600
 must have some way of saying i've learned

631
00:25:19,600 --> 00:25:21,360
 a map of my environment

632
00:25:21,360 --> 00:25:22,960
 i have hummingbirds in my backyard

633
00:25:22,960 --> 00:25:23,360
 and they

634
00:25:23,360 --> 00:25:26,640
 and they go the same places all the time they have to they must know

635
00:25:26,640 --> 00:25:27,600
 where they are they just

636
00:25:27,600 --> 00:25:28,559
 know where they are when they're

637
00:25:28,559 --> 00:25:29,360
 they're not just randomly

638
00:25:29,360 --> 00:25:30,320
 flying around they know

639
00:25:30,320 --> 00:25:31,360
 they know particular flowers

640
00:25:31,360 --> 00:25:32,640
 they come back to

641
00:25:32,640 --> 00:25:34,720
 so we all have this

642
00:25:34,720 --> 00:25:39,039
 and it turns out it's very tricky to get neurons to do this

643
00:25:39,039 --> 00:25:41,039
 to build a map of an environment it's just

644
00:25:41,039 --> 00:25:46,320
 and so we now know there's this these famous studies that's still very active about place cells

645
00:25:46,320 --> 00:25:47,120
 and grid cells

646
00:25:47,120 --> 00:25:49,679
 and these other types of cells in the older parts of the brain

647
00:25:49,679 --> 00:25:51,200
 and how they build these maps

648
00:25:51,200 --> 00:25:54,799
 of the world it's really clever it's obviously been under a lot of evolutionary

649
00:25:54,799 --> 00:25:57,760
 pressure over a long period of time to get good at this

650
00:25:57,760 --> 00:26:00,000
 so animals not know where they are

651
00:26:00,000 --> 00:26:01,919
 what we think has happened

652
00:26:01,919 --> 00:26:05,279
 and there's a lot of evidence to digest this is that that mechanism

653
00:26:05,279 --> 00:26:09,200
 we learn to map like a space

654
00:26:09,200 --> 00:26:12,159
 is was repackaged

655
00:26:12,159 --> 00:26:17,840
 the same type of neurons was repackaged into a more compact form

656
00:26:17,840 --> 00:26:20,320
 and that became the cortical column

657
00:26:20,320 --> 00:26:22,960
 and it was it was in some sense genericized

658
00:26:22,960 --> 00:26:26,480
 if that's a word it was turned into a very specific thing about learning

659
00:26:26,480 --> 00:26:29,919
 maps of environments to learning maps of anything

660
00:26:29,919 --> 00:26:32,320
 learning a model of anything not just your space

661
00:26:32,320 --> 00:26:34,320
 but coffee cups and so on

662
00:26:34,320 --> 00:26:37,520
 and it got sort of repackaged

663
00:26:37,520 --> 00:26:41,279
 into a more compact version a more universal version

664
00:26:41,279 --> 00:26:43,600
 and then replicate it

665
00:26:43,600 --> 00:26:46,320
 so the reason we're so flexible is we have a very generic

666
00:26:46,320 --> 00:26:48,640
 version of this mapping algorithm

667
00:26:48,640 --> 00:26:49,760
 and we have 150

668
00:26:49,760 --> 00:26:54,480
 000 copies of it sounds a lot like the progress of deep learning

669
00:26:54,480 --> 00:27:02,400
 how so so take neural networks that seem to work well for a specific task

670
00:27:02,400 --> 00:27:04,320
 compress them

671
00:27:04,320 --> 00:27:07,520
 and multiply it by a lot

672
00:27:07,520 --> 00:27:10,799
 and then you just stack them on top of it it's like the story of transformers

673
00:27:10,799 --> 00:27:12,400
 and yeah

674
00:27:12,400 --> 00:27:14,000
 but interesting

675
00:27:14,000 --> 00:27:17,279
 networks they end up you're replicating an element

676
00:27:17,279 --> 00:27:21,679
 but you still need the entire network to do anything right here

677
00:27:21,679 --> 00:27:25,919
 what what's going on each individual element is a complete learning system

678
00:27:25,919 --> 00:27:28,080
 this is why i can take a human brain cut it in half

679
00:27:28,080 --> 00:27:30,080
 and it still works

680
00:27:30,080 --> 00:27:35,600
 it's it's pretty amazing it's fundamentally distributed it's fundamentally distributed complete modeling systems

681
00:27:35,600 --> 00:27:36,640
 so

682
00:27:36,640 --> 00:27:38,960
 but that's that's our story we like to tell

683
00:27:38,960 --> 00:27:40,960
 i i i would guess it's

684
00:27:40,960 --> 00:27:43,440
 it's likely largely right

685
00:27:43,440 --> 00:27:43,760
 um

686
00:27:43,760 --> 00:27:49,600
 but you know it's there's a lot of evidence supporting that story this evolutionary story

687
00:27:49,600 --> 00:27:54,000
 the thing which brought me to this idea is that the human brain

688
00:27:54,000 --> 00:27:55,919
 got big very quickly

689
00:27:55,919 --> 00:27:57,919
 so that that

690
00:27:57,919 --> 00:27:59,279
 led to the proposal

691
00:27:59,279 --> 00:28:01,679
 a long time ago that well there's this common element just

692
00:28:01,679 --> 00:28:03,120
 instead of creating new things

693
00:28:03,120 --> 00:28:04,799
 it just replicated something

694
00:28:04,799 --> 00:28:11,279
 we also are extremely flexible we can learn things that we had no history about right

695
00:28:11,279 --> 00:28:11,840
 and

696
00:28:11,840 --> 00:28:16,640
 so that tells it that the learning algorithm is very generic it's very kind of universal

697
00:28:16,640 --> 00:28:21,039
 because it's it doesn't assume any prior knowledge about what it's learning

698
00:28:21,039 --> 00:28:21,760
 and

699
00:28:21,760 --> 00:28:24,240
 so you combine those things together

700
00:28:24,240 --> 00:28:26,000
 and you say okay well how did that come about

701
00:28:26,000 --> 00:28:26,960
 where did that universal

702
00:28:26,960 --> 00:28:29,600
 algorithm come from it had to come from something that wasn't universal

703
00:28:29,600 --> 00:28:31,679
 it came from something that was more specific

704
00:28:31,679 --> 00:28:32,080
 and

705
00:28:32,080 --> 00:28:35,279
 so anyway this led to our hypothesis that you would find grid cells

706
00:28:35,279 --> 00:28:38,080
 and place cell equivalents in the neocortex

707
00:28:38,080 --> 00:28:41,600
 and when we first published our first papers on this theory

708
00:28:41,600 --> 00:28:42,799
 we didn't know of evidence

709
00:28:42,799 --> 00:28:45,919
 for that it turns out there was some but we didn't know about it

710
00:28:45,919 --> 00:28:46,960
 and since then

711
00:28:46,960 --> 00:28:50,640
 um so then we became aware of evidence for grid cells in parts of the neural cortex

712
00:28:50,640 --> 00:28:51,200
 and then

713
00:28:51,200 --> 00:28:54,320
 now there's been new evidence coming out there's some

714
00:28:54,320 --> 00:28:56,720
 interesting papers that came out just january of this year

715
00:28:56,720 --> 00:29:00,720
 so our one of our predictions was if this evolutionary hypothesis

716
00:29:00,720 --> 00:29:04,880
 is correct we would see grid cell place cell equivalents cells that work like them

717
00:29:04,880 --> 00:29:06,480
 through every column in the near cortex

718
00:29:06,480 --> 00:29:08,000
 and that's starting to be seen

719
00:29:08,000 --> 00:29:12,000
 what does it mean that why is it important that they're present

720
00:29:12,000 --> 00:29:16,080
 because it tells us well we're asking about the evolutionary origin of intelligence right

721
00:29:16,080 --> 00:29:22,720
 so our theory is that these columns in the cortex are working on the same principles

722
00:29:22,720 --> 00:29:24,480
 they're modeling systems

723
00:29:24,480 --> 00:29:25,440
 and it's hard to imagine

724
00:29:25,440 --> 00:29:27,600
 how neurons do this and so we said

725
00:29:27,600 --> 00:29:28,640
 hey

726
00:29:28,640 --> 00:29:30,320
 it's really hard to imagine how neurons could

727
00:29:30,320 --> 00:29:31,520
 learn these models of things

728
00:29:31,520 --> 00:29:34,080
 we can talk about the details of that if you want

729
00:29:34,080 --> 00:29:35,279
 but let's

730
00:29:35,279 --> 00:29:36,159
 um

731
00:29:36,159 --> 00:29:40,399
 but there's this other part of the brain we know that learns models of environments

732
00:29:40,399 --> 00:29:41,679
 so could that

733
00:29:41,679 --> 00:29:45,760
 mechanism to learn to model this room be used to learn a model the water bottle

734
00:29:45,760 --> 00:29:47,200
 is it the same mechanism

735
00:29:47,200 --> 00:29:50,720
 so we said it's much more likely the brain is using the same mechanism

736
00:29:50,720 --> 00:29:54,159
 which case it would have these equivalent cell types

737
00:29:54,159 --> 00:29:57,360
 so it's basically the whole theory is built on the idea that

738
00:29:57,360 --> 00:29:59,360
 um these columns have reference frames

739
00:29:59,360 --> 00:30:00,640
 and they're learning these models

740
00:30:00,640 --> 00:30:03,360
 and these these grid cells create these reference frames

741
00:30:03,360 --> 00:30:08,000
 so it's it's basically the major in some sense the major predictive

742
00:30:08,000 --> 00:30:09,279
 part of this theory

743
00:30:09,279 --> 00:30:13,679
 is that we will find these equivalent mechanisms in each column in the near cortex

744
00:30:13,679 --> 00:30:15,840
 which tells us that's that that that's

745
00:30:15,840 --> 00:30:19,919
 what they're doing they're learning these sensory motor models of the world

746
00:30:19,919 --> 00:30:22,559
 so just we're pretty confident that would happen

747
00:30:22,559 --> 00:30:23,840
 but now we're seeing the evidence

748
00:30:23,840 --> 00:30:26,960
 so the evolutionary process nature does a lot of copy

749
00:30:26,960 --> 00:30:27,520
 and paste

750
00:30:27,520 --> 00:30:28,559
 and see what happens

751
00:30:28,559 --> 00:30:29,200
 yeah

752
00:30:29,200 --> 00:30:30,880
 yeah there's no direction to it but

753
00:30:30,880 --> 00:30:31,279
 but

754
00:30:31,279 --> 00:30:34,960
 um it just found out like hey if i took this these elements

755
00:30:34,960 --> 00:30:35,520
 and

756
00:30:35,520 --> 00:30:37,039
 and made more of them what happens

757
00:30:37,039 --> 00:30:39,360
 and let's hook them up to the eyes and let's look up the ears

758
00:30:39,360 --> 00:30:40,000
 and

759
00:30:40,000 --> 00:30:40,399
 and

760
00:30:40,399 --> 00:30:42,000
 um and that seems to work pretty well

761
00:30:42,000 --> 00:30:48,960
 yeah like for us again just to take a quick step back to our conversation of collective intelligence

762
00:30:48,960 --> 00:30:50,240
 do you sometimes

763
00:30:50,240 --> 00:30:52,640
 see that as just another

764
00:30:52,640 --> 00:30:53,039
 copy

765
00:30:53,039 --> 00:30:57,440
 and paste aspect is copying pasting these brains

766
00:30:57,440 --> 00:30:58,480
 and humans

767
00:30:58,480 --> 00:31:00,399
 and making a lot of them

768
00:31:00,399 --> 00:31:02,480
 and then creating

769
00:31:02,480 --> 00:31:06,240
 social structures that then almost operates as a single brain

770
00:31:06,240 --> 00:31:10,159
 i wouldn't have said it but you said it sounded pretty good

771
00:31:10,159 --> 00:31:15,840
 so to you the brain is fundamental is is like is its own thing right

772
00:31:15,840 --> 00:31:17,519
 i mean our goal is to understand

773
00:31:17,519 --> 00:31:19,679
 how the neural cortex works we can argue

774
00:31:19,679 --> 00:31:22,799
 how essential that is to understand a human brain

775
00:31:22,799 --> 00:31:25,200
 because it's not the entire human brain you can argue

776
00:31:25,200 --> 00:31:30,640
 how essential that is to understanding human intelligence you can argue how essential it is to

777
00:31:30,640 --> 00:31:34,640
 um to you know a sort of communal intelligence

778
00:31:34,640 --> 00:31:36,480
 um i i'm not

779
00:31:36,480 --> 00:31:38,720
 i didn't our goal was to understand the neocortex

780
00:31:38,720 --> 00:31:40,320
 yeah so what is the neural cortex

781
00:31:40,320 --> 00:31:41,919
 and where does it fit in

782
00:31:41,919 --> 00:31:43,279
 um the various

783
00:31:43,279 --> 00:31:47,840
 aspects of what the brain does like how important is it to you well obviously

784
00:31:47,840 --> 00:31:52,960
 again we i mentioned again in the beginning it's it's it's about 70 to 75

785
00:31:52,960 --> 00:31:54,559
 of the volume of a human brain

786
00:31:54,559 --> 00:31:57,440
 so it's you know it dominates our brain in terms of size

787
00:31:57,440 --> 00:31:58,720
 not in terms of number of neurons

788
00:31:58,720 --> 00:32:00,640
 but in terms of size

789
00:32:00,640 --> 00:32:02,399
 size isn't everything jeff

790
00:32:02,399 --> 00:32:03,600
 i know

791
00:32:03,600 --> 00:32:09,600
 but it's it's nothing it's nothing it's not that we know that all high-level vision hearing

792
00:32:09,600 --> 00:32:13,200
 and touch happens in the air context we know that all language occurs

793
00:32:13,200 --> 00:32:15,039
 and is understood in the neurocortex

794
00:32:15,039 --> 00:32:20,240
 whether that's spoken language written language sign language with language of mathematics language of physics

795
00:32:20,240 --> 00:32:23,760
 music math you know we know that all high-level planning

796
00:32:23,760 --> 00:32:25,440
 and thinking occurs in the new york cortex

797
00:32:25,440 --> 00:32:28,559
 if i were to say you know what part of your brain designed a computer

798
00:32:28,559 --> 00:32:29,840
 and understands programming

799
00:32:29,840 --> 00:32:33,039
 and and creates music it's all the neural cortex

800
00:32:33,039 --> 00:32:37,679
 so then that's kind of undeniable fact if

801
00:32:37,679 --> 00:32:42,000
 but then there's other parts of our brain are important too right our emotional states

802
00:32:42,000 --> 00:32:43,919
 our body regulating our body

803
00:32:43,919 --> 00:32:44,480
 um

804
00:32:44,480 --> 00:32:49,840
 so the way i like to look at it is you know could you can you

805
00:32:49,840 --> 00:32:52,080
 understand the neocortex about the rest of the brain

806
00:32:52,080 --> 00:32:53,200
 and some people say you can't

807
00:32:53,200 --> 00:32:55,760
 and i think absolutely you can

808
00:32:55,760 --> 00:32:57,200
 it's not that they're not interacting

809
00:32:57,200 --> 00:33:01,679
 but you can understand them can you understand the neocortex without understanding the emotions of fear

810
00:33:01,679 --> 00:33:02,960
 yes you can you can understand

811
00:33:02,960 --> 00:33:05,360
 how the system works it's just a modeling system

812
00:33:05,360 --> 00:33:09,120
 i make the analogy in the book that it's it's like a map of the world

813
00:33:09,120 --> 00:33:09,600
 and

814
00:33:09,600 --> 00:33:12,720
 how that map is used depends on who's using it

815
00:33:12,720 --> 00:33:15,919
 so how our map of our world in our neocortex

816
00:33:15,919 --> 00:33:16,399
 how we

817
00:33:16,399 --> 00:33:18,320
 how we manifest as a human

818
00:33:18,320 --> 00:33:21,039
 depends on the rest of our brain what are our motivations

819
00:33:21,039 --> 00:33:24,000
 you know what are my desires am i a nice guy or not a nice guy

820
00:33:24,000 --> 00:33:24,720
 am i a cheater

821
00:33:24,720 --> 00:33:26,799
 or a you know or not a cheater

822
00:33:26,799 --> 00:33:28,480
 um you know

823
00:33:28,480 --> 00:33:29,919
 how important

824
00:33:29,919 --> 00:33:31,519
 different things are in my life

825
00:33:31,519 --> 00:33:32,000
 so

826
00:33:32,000 --> 00:33:33,279
 um

827
00:33:33,279 --> 00:33:33,840
 so

828
00:33:33,840 --> 00:33:36,799
 but the new projects can be understood on its own

829
00:33:36,799 --> 00:33:37,279
 um

830
00:33:37,279 --> 00:33:37,919
 and

831
00:33:37,919 --> 00:33:39,840
 and i say that as a neuroscientist

832
00:33:39,840 --> 00:33:41,360
 i know there's all these interactions

833
00:33:41,360 --> 00:33:42,720
 and i want to

834
00:33:42,720 --> 00:33:45,840
 say i don't know them and we don't think about them but from a layperson's

835
00:33:45,840 --> 00:33:49,440
 point of view you can say it's a modeling system

836
00:33:49,440 --> 00:33:52,399
 i don't tend to think too much about the communal aspect of intelligence

837
00:33:52,399 --> 00:33:54,399
 which you brought a number of times already

838
00:33:54,399 --> 00:33:55,039
 um

839
00:33:55,039 --> 00:33:58,799
 so that's not really been my concern i just wonder if there's a continuum

840
00:33:58,799 --> 00:34:01,840
 from the origin of the universe like

841
00:34:01,840 --> 00:34:06,000
 this com pockets of complexities that form

842
00:34:06,000 --> 00:34:10,000
 yeah living organisms i wonder if if we're just

843
00:34:10,000 --> 00:34:13,119
 if you look at humans we feel like we're at the top

844
00:34:13,119 --> 00:34:15,359
 but i wonder if there's like just

845
00:34:15,359 --> 00:34:20,480
 where everybody probably every living type pocket of complexity

846
00:34:20,480 --> 00:34:24,719
 is probably thinks they're the pardon the french they're the

847
00:34:24,719 --> 00:34:28,399
 yeah they're they're they're at the top of the parent well if they're thinking

848
00:34:28,399 --> 00:34:30,480
 um well then then what is thinking

849
00:34:30,480 --> 00:34:35,040
 what the all right in this sense the whole point is in their

850
00:34:35,040 --> 00:34:38,000
 sense of the world they

851
00:34:38,000 --> 00:34:41,119
 their sense is that they're at the top of it i think

852
00:34:41,119 --> 00:34:41,839
 what is it turtle

853
00:34:41,839 --> 00:34:45,599
 but you're you're you're bringing up you know the the problems of complexity

854
00:34:45,599 --> 00:34:50,639
 and complexity theory are you know it's a huge interesting problem in science

855
00:34:50,639 --> 00:34:51,599
 um

856
00:34:51,599 --> 00:34:54,480
 and you know i think we've made surprisingly

857
00:34:54,480 --> 00:34:58,160
 little progress in understanding complex systems right in general

858
00:34:58,160 --> 00:34:59,119
 um

859
00:34:59,119 --> 00:34:59,440
 and

860
00:34:59,440 --> 00:34:59,839
 so

861
00:34:59,839 --> 00:35:00,960
 you know the santa fe institute

862
00:35:00,960 --> 00:35:03,599
 was founded to to study this and and even the scientists

863
00:35:03,599 --> 00:35:05,200
 there will say it's really hard we haven't

864
00:35:05,200 --> 00:35:08,400
 really been able to figure out exactly you know

865
00:35:08,400 --> 00:35:09,920
 that science isn't really congealed

866
00:35:09,920 --> 00:35:13,760
 yet we're still trying to figure out the basic elements of that science

867
00:35:13,760 --> 00:35:14,800
 what

868
00:35:14,800 --> 00:35:16,480
 you know where does complexity come from

869
00:35:16,480 --> 00:35:19,839
 and what is it and how you define it whether it's dna creating bodies

870
00:35:19,839 --> 00:35:20,560
 or phenotypes

871
00:35:20,560 --> 00:35:22,000
 or if it's

872
00:35:22,000 --> 00:35:23,359
 individuals creating societies

873
00:35:23,359 --> 00:35:23,839
 or ants

874
00:35:23,839 --> 00:35:25,599
 and you know markets

875
00:35:25,599 --> 00:35:30,880
 and so on it's it's a very complex thing i'm not a complexity theorist person right

876
00:35:30,880 --> 00:35:31,680
 um

877
00:35:31,680 --> 00:35:35,359
 and i i think they ask well the brain itself is a complex system

878
00:35:35,359 --> 00:35:37,440
 so can we understand that

879
00:35:37,440 --> 00:35:39,440
 um i think we've made a lot of progress understanding

880
00:35:39,440 --> 00:35:40,560
 how the brain works

881
00:35:40,560 --> 00:35:41,599
 so

882
00:35:41,599 --> 00:35:42,640
 but i haven't

883
00:35:42,640 --> 00:35:46,079
 brought it out to like oh well where are we on the complexity spectrum

884
00:35:46,079 --> 00:35:47,599
 you know it's like

885
00:35:47,599 --> 00:35:50,079
 um that's a great question

886
00:35:50,079 --> 00:35:54,640
 i'd prefer for that answer to be we're not special

887
00:35:54,640 --> 00:35:57,359
 it seems like if we're honest

888
00:35:57,359 --> 00:35:58,720
 most likely we're not special

889
00:35:58,720 --> 00:36:00,240
 so if there is a spectrum

890
00:36:00,240 --> 00:36:03,119
 we're probably not in some kind of significant place

891
00:36:03,119 --> 00:36:05,839
 there's one thing we could say that we are special

892
00:36:05,839 --> 00:36:07,680
 and and again only here on earth

893
00:36:07,680 --> 00:36:12,480
 i'm not saying i'm bad is that if we think about knowledge

894
00:36:12,480 --> 00:36:14,079
 what we know

895
00:36:14,079 --> 00:36:16,240
 um we clearly

896
00:36:16,240 --> 00:36:18,240
 human brains have

897
00:36:18,240 --> 00:36:19,760
 um the only brains

898
00:36:19,760 --> 00:36:21,040
 that have a certain types of knowledge

899
00:36:21,040 --> 00:36:22,320
 we're the only brains on

900
00:36:22,320 --> 00:36:23,760
 on this earth to understand

901
00:36:23,760 --> 00:36:24,800
 what the earth is

902
00:36:24,800 --> 00:36:29,920
 how old it is that the universe is a picture as a whole the only organisms understand dna

903
00:36:29,920 --> 00:36:33,920
 and the origins of you know of species

904
00:36:33,920 --> 00:36:37,280
 no other species on on this planet has that knowledge

905
00:36:37,280 --> 00:36:38,800
 so if we think about

906
00:36:38,800 --> 00:36:40,320
 i like to think about

907
00:36:40,320 --> 00:36:44,720
 you know one of the endeavors of humanity is to understand the universe

908
00:36:44,720 --> 00:36:46,320
 as much as we can

909
00:36:46,320 --> 00:36:47,520
 um

910
00:36:47,520 --> 00:36:51,119
 i think our species is further along in that undeniably

911
00:36:51,119 --> 00:36:53,599
 um whether our theories are right or wrong we can debate

912
00:36:53,599 --> 00:36:56,240
 but at least we have theories you know we we know that

913
00:36:56,240 --> 00:36:58,800
 what the sun is and how it's fusion is and how

914
00:36:58,800 --> 00:37:03,040
 what black holes are and you know we know general theory relativity

915
00:37:03,040 --> 00:37:05,119
 and no other animal has any of this knowledge

916
00:37:05,119 --> 00:37:11,520
 so in that sense that we're special are we special in terms of the the hierarchy of complexity

917
00:37:11,520 --> 00:37:15,040
 in in the universe probably not

918
00:37:16,560 --> 00:37:19,440
 can we look at a neuron

919
00:37:19,440 --> 00:37:22,400
 yeah you say that prediction happens in the neuron

920
00:37:22,400 --> 00:37:23,440
 what does that mean

921
00:37:23,440 --> 00:37:27,440
 so neuron traditionally seen as the basic element of the the brain

922
00:37:27,440 --> 00:37:31,760
 so we i mentioned this earlier that prediction was our research agenda

923
00:37:31,760 --> 00:37:33,520
 yeah we said okay

924
00:37:33,520 --> 00:37:34,240
 um

925
00:37:34,240 --> 00:37:38,320
 how does the brain make a prediction like i i'm about to grab this water bottle

926
00:37:38,320 --> 00:37:39,440
 and my brain is predicting

927
00:37:39,440 --> 00:37:40,400
 what i'm going to feel

928
00:37:40,400 --> 00:37:41,119
 um

929
00:37:41,119 --> 00:37:42,480
 on all my parts of my fingers

930
00:37:42,480 --> 00:37:45,280
 if i felt something really odd on any part here i notice it

931
00:37:45,280 --> 00:37:46,240
 so my brain is predicting

932
00:37:46,240 --> 00:37:48,800
 what it's going to feel as i grab this thing

933
00:37:48,800 --> 00:37:50,560
 so what is that how does that manifest

934
00:37:50,560 --> 00:37:54,640
 itself in neural tissue right we got brains made of neurons

935
00:37:54,640 --> 00:37:56,160
 and there's chemicals

936
00:37:56,160 --> 00:37:57,119
 and there's neurons

937
00:37:57,119 --> 00:37:57,920
 and there's spikes

938
00:37:57,920 --> 00:37:59,119
 and the connect you know

939
00:37:59,119 --> 00:37:59,680
 where

940
00:37:59,680 --> 00:38:02,160
 where is the prediction going on

941
00:38:02,160 --> 00:38:06,240
 and one argument could be that well when i'm predicting something

942
00:38:06,240 --> 00:38:10,400
 um a neuron must be firing in advance it's like okay this neuron represents

943
00:38:10,400 --> 00:38:13,599
 what you're going to feel and it's firing it's sending a spike

944
00:38:13,599 --> 00:38:15,680
 and certainly that happens to some extent

945
00:38:15,680 --> 00:38:18,720
 but our predictions are so ubiquitous

946
00:38:18,720 --> 00:38:19,359
 that we're making

947
00:38:19,359 --> 00:38:22,240
 so many of them which we're totally unaware of just the vast majority

948
00:38:22,240 --> 00:38:24,079
 we have no idea that you're doing this

949
00:38:24,079 --> 00:38:25,680
 um

950
00:38:25,680 --> 00:38:26,560
 that it

951
00:38:26,560 --> 00:38:29,520
 wasn't really we were trying to figure how could this be where where is these

952
00:38:29,520 --> 00:38:31,760
 where are these happening right

953
00:38:31,760 --> 00:38:35,520
 and i won't walk you through the whole story unless you insist upon it but

954
00:38:35,520 --> 00:38:37,680
 we came to the realization

955
00:38:37,680 --> 00:38:39,280
 that

956
00:38:39,280 --> 00:38:42,480
 most of your predictions are occurring inside individual

957
00:38:42,480 --> 00:38:46,400
 neurons especially these the most common are in the pyramidal cells

958
00:38:46,400 --> 00:38:49,520
 and there are there's a property of neurons

959
00:38:49,520 --> 00:38:52,160
 we everyone knows or most people know that a neuron is a cell

960
00:38:52,160 --> 00:38:54,400
 and it has this spike called an action potential

961
00:38:54,400 --> 00:38:56,320
 and it sends information

962
00:38:56,320 --> 00:39:01,119
 but we now know that there's these spikes internal to the neuron they're called dendritic spikes

963
00:39:01,119 --> 00:39:03,680
 they travel along the branches of the neuron

964
00:39:03,680 --> 00:39:06,640
 and they don't leave the neuron they're just internal only

965
00:39:06,640 --> 00:39:10,400
 there's far more dendritic spikes than there are action potentials

966
00:39:10,400 --> 00:39:12,800
 far more they're happening all the time

967
00:39:12,800 --> 00:39:13,760
 and

968
00:39:13,760 --> 00:39:16,320
 what we came to understand that those dendritic

969
00:39:16,320 --> 00:39:19,599
 spikes the ones that are occurring are actually a form of prediction

970
00:39:19,599 --> 00:39:25,200
 they're telling the neuron the neuron is saying i expect that i might become active shortly

971
00:39:25,200 --> 00:39:26,880
 and that internal

972
00:39:26,880 --> 00:39:29,440
 so the internal spike is a way of saying

973
00:39:29,440 --> 00:39:32,480
 you're going to you might be generating external spikes soon

974
00:39:32,480 --> 00:39:34,720
 i predicted you're going to become active

975
00:39:34,720 --> 00:39:35,040
 and

976
00:39:35,040 --> 00:39:38,079
 and we we've we've we wrote a paper in 2016

977
00:39:38,079 --> 00:39:38,800
 which explained

978
00:39:38,800 --> 00:39:39,119
 and

979
00:39:39,119 --> 00:39:42,240
 how this manifests itself in neural tissue

980
00:39:42,240 --> 00:39:42,720
 and

981
00:39:42,720 --> 00:39:45,040
 how it is that this all works together

982
00:39:45,040 --> 00:39:48,640
 but the vast ma we think it's there's a lot of evidence supporting it

983
00:39:48,640 --> 00:39:49,280
 um

984
00:39:49,280 --> 00:39:49,839
 so we

985
00:39:49,839 --> 00:39:52,079
 that's where we think that most of these predictions are internal

986
00:39:52,079 --> 00:39:53,040
 that's why you can't

987
00:39:53,040 --> 00:39:54,160
 be per their internal

988
00:39:54,160 --> 00:39:57,040
 neuron you can't perceive them

989
00:39:57,040 --> 00:40:00,720
 from understanding the the prediction mechanism of a single neuron

990
00:40:00,720 --> 00:40:05,359
 do you think there's deep insights to be gained about the prediction capabilities

991
00:40:05,359 --> 00:40:07,280
 of the mini brains within the bigger brain

992
00:40:07,280 --> 00:40:08,640
 and the brain oh yeah yeah yeah

993
00:40:08,640 --> 00:40:12,800
 so having a prediction side of the individual neuron is not that useful you know what

994
00:40:12,800 --> 00:40:14,400
 so what

995
00:40:14,400 --> 00:40:20,400
 um the way it manifests itself in neural tissue is that

996
00:40:20,400 --> 00:40:24,079
 when a neuron a neuron emits these spikes or a very singular type event

997
00:40:24,079 --> 00:40:28,800
 if a neuron is predicting that it's going to be active it makes it spike very

998
00:40:28,800 --> 00:40:30,640
 a little bit sooner just a few milliseconds

999
00:40:30,640 --> 00:40:32,319
 sooner than it would have otherwise it's like

1000
00:40:32,319 --> 00:40:34,160
 i give the analogy in the book there's like a sprinter

1001
00:40:34,160 --> 00:40:35,200
 on a on a starting

1002
00:40:35,200 --> 00:40:37,040
 blocks in a race

1003
00:40:37,040 --> 00:40:41,440
 and if someone says get ready set you get up and you're ready to go

1004
00:40:41,440 --> 00:40:44,000
 and then when your race starts you get a little bit earlier start

1005
00:40:44,000 --> 00:40:46,400
 so that it's that that ready set is like the prediction

1006
00:40:46,400 --> 00:40:48,560
 and the neuron's like ready to go quicker

1007
00:40:48,560 --> 00:40:49,040
 and

1008
00:40:49,040 --> 00:40:52,079
 what happens is when you have a whole bunch of neurons together

1009
00:40:52,079 --> 00:40:53,839
 and they're all getting these inputs

1010
00:40:53,839 --> 00:40:58,000
 the ones that are in the predictive state the ones that are anticipating to become active

1011
00:40:58,000 --> 00:41:01,040
 if they do become active they they happen sooner they disable

1012
00:41:01,040 --> 00:41:03,520
 everything else and it leads to different representations in the brain

1013
00:41:03,520 --> 00:41:05,680
 so you have to

1014
00:41:05,680 --> 00:41:09,599
 it's not isolated just to the neuron the prediction occurs within the neuron

1015
00:41:09,599 --> 00:41:11,680
 but the network behavior changes

1016
00:41:11,680 --> 00:41:12,000
 so

1017
00:41:12,000 --> 00:41:16,160
 what happens under different predictions different inputs have different representations

1018
00:41:16,160 --> 00:41:17,599
 so how i

1019
00:41:17,599 --> 00:41:19,119
 what i predict

1020
00:41:19,119 --> 00:41:22,160
 um it's going to be different under different contexts you know

1021
00:41:22,160 --> 00:41:24,480
 what my input will be is different under different context

1022
00:41:24,480 --> 00:41:26,880
 so this is this is a key level theory

1023
00:41:26,880 --> 00:41:27,680
 how this works

1024
00:41:27,680 --> 00:41:30,560
 so the theory of the thousand brains

1025
00:41:30,560 --> 00:41:33,040
 if you were to count the number of brains

1026
00:41:33,040 --> 00:41:38,400
 how would you do it the thousand main theory says that basically every cortical column

1027
00:41:38,400 --> 00:41:42,319
 in the in your neurocortex is a complete modeling system

1028
00:41:42,319 --> 00:41:43,599
 and that when i ask

1029
00:41:43,599 --> 00:41:46,079
 where do i have a model of something like a coffee cup

1030
00:41:46,079 --> 00:41:48,960
 it's not in one of those models it's in thousands of those models

1031
00:41:48,960 --> 00:41:53,599
 there's thousands of models of coffee cups that's what the thousand brains there's a voting mechanism

1032
00:41:53,599 --> 00:41:54,720
 then there's a voting mechanism

1033
00:41:54,720 --> 00:41:55,280
 which leads

1034
00:41:55,280 --> 00:41:56,720
 which is the thing you're

1035
00:41:56,720 --> 00:42:00,240
 which you're conscious of which leads to your singular perception

1036
00:42:00,240 --> 00:42:02,880
 um that's why you perceive something

1037
00:42:02,880 --> 00:42:06,240
 so that's the thousand brains theory the details

1038
00:42:06,240 --> 00:42:08,400
 how we got to that theory

1039
00:42:08,400 --> 00:42:10,480
 um are complicated

1040
00:42:10,480 --> 00:42:12,240
 it wasn't you just thought of it one day

1041
00:42:12,240 --> 00:42:14,079
 and one of those details is we had to ask

1042
00:42:14,079 --> 00:42:16,000
 how does a a model make predictions

1043
00:42:16,000 --> 00:42:18,720
 and we've talked about just these predictive neurons

1044
00:42:18,720 --> 00:42:21,359
 that's part of this theory it's like saying oh it's a detail

1045
00:42:21,359 --> 00:42:23,040
 but it was like a crack in the doors

1046
00:42:23,040 --> 00:42:24,640
 like how are we going to figure out how these neurons

1047
00:42:24,640 --> 00:42:26,720
 build do this you know what is going on here

1048
00:42:26,720 --> 00:42:30,640
 so we just looked at prediction as like well we know that's ubiquitous

1049
00:42:30,640 --> 00:42:33,359
 we know that every part of the cortex is making predictions

1050
00:42:33,359 --> 00:42:36,960
 therefore whatever the predictive system is it's going to be everywhere

1051
00:42:36,960 --> 00:42:39,599
 we know there's a gazillion predictions happening at once

1052
00:42:39,599 --> 00:42:44,000
 so let's see if we can start teasing apart you know ask questions about

1053
00:42:44,000 --> 00:42:45,839
 you know how could neurons be making these predictions

1054
00:42:45,839 --> 00:42:49,599
 and that sort of built up to now what we have the thousand brains theory

1055
00:42:49,599 --> 00:42:52,400
 which is complex you know it's just some i can state it simply

1056
00:42:52,400 --> 00:42:56,640
 but we just didn't think of it we had to get there step by step very

1057
00:42:56,640 --> 00:42:59,200
 it took years to get there

1058
00:42:59,200 --> 00:43:03,520
 and where does reference frames fit in

1059
00:43:03,520 --> 00:43:04,000
 so

1060
00:43:04,000 --> 00:43:04,560
 yeah

1061
00:43:04,560 --> 00:43:05,359
 okay

1062
00:43:05,359 --> 00:43:07,920
 so again a reference frame i mentioned

1063
00:43:07,920 --> 00:43:10,800
 um earlier about the you know a model of a house

1064
00:43:10,800 --> 00:43:13,520
 and i said if you're going to build a model of a house in a computer

1065
00:43:13,520 --> 00:43:16,319
 they have a reference frame and you can then reference them like cartesian

1066
00:43:16,319 --> 00:43:19,200
 coordinates like x y and z axes

1067
00:43:19,200 --> 00:43:21,280
 so i can say oh i'm going to design a house

1068
00:43:21,280 --> 00:43:24,720
 i can say well the the front door is at this location xyz

1069
00:43:24,720 --> 00:43:26,800
 and the roof is at this location xyz

1070
00:43:26,800 --> 00:43:29,440
 and so on that's a type of reference frame

1071
00:43:29,440 --> 00:43:31,760
 so it turns out for you to make a prediction

1072
00:43:31,760 --> 00:43:35,200
 and then i walk you through the thought experiment in the book where i was predicting

1073
00:43:35,200 --> 00:43:37,839
 what my finger was going to feel when i touched the coffee cup

1074
00:43:37,839 --> 00:43:40,560
 it was a ceramic coffee cup but this one will do

1075
00:43:40,560 --> 00:43:41,599
 um

1076
00:43:41,599 --> 00:43:41,920
 and

1077
00:43:41,920 --> 00:43:45,760
 what i realized is that to make a prediction with my finger's

1078
00:43:45,760 --> 00:43:46,800
 going to feel like it's just

1079
00:43:46,800 --> 00:43:47,599
 going to feel different than

1080
00:43:47,599 --> 00:43:48,480
 this which would feel different

1081
00:43:48,480 --> 00:43:49,359
 if i touch the hole

1082
00:43:49,359 --> 00:43:51,119
 or the thing on the bottom

1083
00:43:51,119 --> 00:43:52,319
 make that prediction

1084
00:43:52,319 --> 00:43:56,160
 the cortex needs to know where the finger is the tip of the finger

1085
00:43:56,160 --> 00:43:58,319
 relative to the coffee cup

1086
00:43:58,319 --> 00:44:00,720
 and exactly relative to the coffee cup

1087
00:44:00,720 --> 00:44:02,319
 and to do that i have to have a reference

1088
00:44:02,319 --> 00:44:02,960
 frame for the coffee

1089
00:44:02,960 --> 00:44:04,319
 up it has to have a way of representing

1090
00:44:04,319 --> 00:44:07,359
 the location of my finger to the coffin up

1091
00:44:07,359 --> 00:44:08,480
 and then we realize of course

1092
00:44:08,480 --> 00:44:10,800
 every part of your skin has to have a reference frame relative

1093
00:44:10,800 --> 00:44:12,880
 things to touch and then we did the same thing with vision

1094
00:44:12,880 --> 00:44:13,760
 but

1095
00:44:13,760 --> 00:44:18,319
 so the idea that a reference frame is necessary to make a prediction when you're touching something

1096
00:44:18,319 --> 00:44:20,079
 or when you're seeing something

1097
00:44:20,079 --> 00:44:24,720
 and you're moving your eyes you're moving your fingers it's just a requirement to know what to predict

1098
00:44:24,720 --> 00:44:26,400
 if i have a if i have a structure

1099
00:44:26,400 --> 00:44:28,000
 i'm going to make a prediction i have to

1100
00:44:28,000 --> 00:44:31,119
 i have to know where it is i'm looking or touching it

1101
00:44:31,119 --> 00:44:35,520
 so then we say well how do neurons make reference frames it's not obvious

1102
00:44:35,520 --> 00:44:39,839
 you know xyz coordinates don't exist in the brain it's just not the way it works

1103
00:44:39,839 --> 00:44:42,640
 so that's when we looked at the older part of the brain the hippocampus

1104
00:44:42,640 --> 00:44:44,319
 and the antorano cortex

1105
00:44:44,319 --> 00:44:48,960
 where we knew that in that part of the brain there's a reference frame for a room

1106
00:44:48,960 --> 00:44:50,400
 or reference name for environment

1107
00:44:50,400 --> 00:44:54,319
 remember i talked earlier about how you could know make a map of this room

1108
00:44:54,319 --> 00:44:55,760
 so we said oh

1109
00:44:55,760 --> 00:44:56,800
 um

1110
00:44:56,800 --> 00:44:58,800
 that they are implementing reference frames there

1111
00:44:58,800 --> 00:45:03,280
 so we knew that reference frames needed to exist in every cortical column

1112
00:45:03,280 --> 00:45:05,920
 and so that was a deductive

1113
00:45:05,920 --> 00:45:08,000
 thing we just deduced it has to go

1114
00:45:08,000 --> 00:45:09,040
 so

1115
00:45:09,040 --> 00:45:12,400
 you take the old mammalian

1116
00:45:12,400 --> 00:45:15,920
 ability to know where you are in a particular space

1117
00:45:15,920 --> 00:45:17,520
 and you start applying that to higher

1118
00:45:17,520 --> 00:45:18,319
 and higher levels

1119
00:45:18,319 --> 00:45:21,119
 yeah you first you apply it to physical like where your finger is

1120
00:45:21,119 --> 00:45:22,560
 so here's what i think about it

1121
00:45:22,560 --> 00:45:25,280
 the old part of the brain says where's my body in this room

1122
00:45:25,280 --> 00:45:28,400
 yeah the new part of the brain says where's my finger

1123
00:45:28,400 --> 00:45:30,319
 relative to this this object

1124
00:45:30,319 --> 00:45:31,119
 yeah

1125
00:45:31,119 --> 00:45:34,160
 where is the a section of my retina

1126
00:45:34,160 --> 00:45:35,280
 relative to this object

1127
00:45:35,280 --> 00:45:38,000
 like where where is i'm looking at one little corner where is that relative

1128
00:45:38,000 --> 00:45:39,200
 to this patch of my retina

1129
00:45:39,200 --> 00:45:40,000
 yeah

1130
00:45:40,000 --> 00:45:40,880
 um

1131
00:45:40,880 --> 00:45:46,319
 and then we take the same thing and apply it to concepts mathematics physics

1132
00:45:46,319 --> 00:45:51,200
 you know humanity whatever you want to think eventually you're pondering your own mortality well whatever

1133
00:45:51,200 --> 00:45:56,000
 but the point is when we think about the world when we have knowledge about the world

1134
00:45:56,000 --> 00:45:58,000
 how is that knowledge organized lex

1135
00:45:58,000 --> 00:46:01,760
 where do you where is it in your head the answer is it's in reference frames

1136
00:46:01,760 --> 00:46:05,520
 so the way i learn the structure of this water bottle

1137
00:46:05,520 --> 00:46:09,200
 where the features are relative to each other when i think about history

1138
00:46:09,200 --> 00:46:10,160
 or democracy

1139
00:46:10,160 --> 00:46:11,280
 or mathematics

1140
00:46:11,280 --> 00:46:13,440
 the same basic underlying structures

1141
00:46:13,440 --> 00:46:16,480
 happening there's reference frames for where the knowledge that you're assigning

1142
00:46:16,480 --> 00:46:19,280
 things to so in the book i go through examples like mathematics

1143
00:46:19,280 --> 00:46:20,240
 and language

1144
00:46:20,240 --> 00:46:22,000
 and politics

1145
00:46:22,000 --> 00:46:25,920
 but the evidence is very clear in the neuroscience the same mechanism

1146
00:46:25,920 --> 00:46:30,160
 that we use to model this coffee cup we're going to use to model high level thoughts

1147
00:46:30,160 --> 00:46:34,240
 your your your demise of the humanity whatever you want to think about

1148
00:46:34,240 --> 00:46:35,520
 it's interesting to think about

1149
00:46:35,520 --> 00:46:41,359
 how different are the representations of those higher dimensional concepts

1150
00:46:41,359 --> 00:46:42,960
 higher level concepts

1151
00:46:42,960 --> 00:46:47,920
 how different the representation there is in terms of reference frames versus spatial

1152
00:46:47,920 --> 00:46:51,200
 but interesting thing it's it's it's a different application

1153
00:46:51,200 --> 00:46:53,760
 but it's the exact same mechanism

1154
00:46:53,760 --> 00:47:00,880
 but isn't there some aspect to higher level concepts that they seem to be hierarchical

1155
00:47:00,880 --> 00:47:03,839
 like they just seem to integrate a lot of information into

1156
00:47:03,839 --> 00:47:06,880
 so is our physical objects

1157
00:47:06,880 --> 00:47:11,200
 so take this water bottle i'm not particular to this brand

1158
00:47:11,200 --> 00:47:13,280
 but this is a fiji water bottle

1159
00:47:13,280 --> 00:47:14,160
 and it has

1160
00:47:14,160 --> 00:47:15,280
 um a logo

1161
00:47:15,280 --> 00:47:20,079
 and i use this example in my book our company's coffee cup has a logo on it

1162
00:47:20,079 --> 00:47:22,480
 but this object is hierarchical

1163
00:47:22,480 --> 00:47:24,640
 it is it's got like a cylinder

1164
00:47:24,640 --> 00:47:26,240
 and a cap but then has this logo

1165
00:47:26,240 --> 00:47:27,599
 on it and the logo has a word

1166
00:47:27,599 --> 00:47:28,640
 the word has letters

1167
00:47:28,640 --> 00:47:30,720
 the letters of different features

1168
00:47:30,720 --> 00:47:31,440
 and

1169
00:47:31,440 --> 00:47:32,720
 so i don't have to remember

1170
00:47:32,720 --> 00:47:35,200
 i don't think about this so i said oh there's a fiji logo

1171
00:47:35,200 --> 00:47:36,000
 on this water bottle

1172
00:47:36,000 --> 00:47:37,359
 i don't have to go through and say

1173
00:47:37,359 --> 00:47:38,559
 oh what is the fiji logo

1174
00:47:38,559 --> 00:47:41,680
 it's the f and i and the j and i and there's a hibiscus flower

1175
00:47:41,680 --> 00:47:42,319
 and

1176
00:47:42,319 --> 00:47:42,800
 and

1177
00:47:42,800 --> 00:47:44,400
 oh it has the pest you know the stamen

1178
00:47:44,400 --> 00:47:46,000
 on it i don't have to do that i just incorporate

1179
00:47:46,000 --> 00:47:49,359
 all of that in some sort of hierarchical representation i say

1180
00:47:49,359 --> 00:47:52,400
 um you know put this logo on this water bottle

1181
00:47:52,400 --> 00:47:52,800
 yeah

1182
00:47:52,800 --> 00:47:53,280
 and

1183
00:47:53,280 --> 00:47:53,680
 and

1184
00:47:53,680 --> 00:47:57,440
 and then the logo has a word and the word has letters all hierarchical

1185
00:47:57,440 --> 00:48:00,400
 just all that stuff is big it's amazing that the brain instantly

1186
00:48:00,400 --> 00:48:02,800
 just does all that yeah the idea that there's

1187
00:48:02,800 --> 00:48:04,160
 there's water it's liquid

1188
00:48:04,160 --> 00:48:09,599
 and the idea that you can drink it when you're thirsty the idea that there's brands

1189
00:48:09,599 --> 00:48:10,000
 yeah

1190
00:48:10,000 --> 00:48:13,760
 and then there's like all of that information is instantly

1191
00:48:13,760 --> 00:48:16,640
 like built into the whole thing once you proceed

1192
00:48:16,640 --> 00:48:19,520
 so i wanted to get back to your point about hierarchical representation

1193
00:48:19,520 --> 00:48:22,160
 the world itself is hierarchical right

1194
00:48:22,160 --> 00:48:24,640
 and i can take this microphone in front of me i know inside

1195
00:48:24,640 --> 00:48:25,839
 there's going to be some electronics

1196
00:48:25,839 --> 00:48:26,960
 i know there's going to be some wires

1197
00:48:26,960 --> 00:48:30,400
 and i know there's going to be a little diaphragm that moves back and forth

1198
00:48:30,400 --> 00:48:32,720
 i don't see that but i know it

1199
00:48:32,720 --> 00:48:34,720
 so everything in the world is hierarchical

1200
00:48:34,720 --> 00:48:38,559
 you just go into room it's composed of other components the kitchen has a refrigerator

1201
00:48:38,559 --> 00:48:42,000
 you know the refrigerator has a door the door has a hinge the hinge has screws

1202
00:48:42,000 --> 00:48:43,200
 and pin yeah i mean

1203
00:48:43,200 --> 00:48:48,079
 so anyway the the the modeling system that exists in every cortical column

1204
00:48:48,079 --> 00:48:51,520
 learns the hierarchical structure of objects

1205
00:48:51,520 --> 00:48:53,280
 so it's a very sophisticated modeling

1206
00:48:53,280 --> 00:48:54,319
 system in this grain of rice

1207
00:48:54,319 --> 00:48:55,119
 it's hard to imagine

1208
00:48:55,119 --> 00:48:57,200
 but this grain of ice can do really sophisticated

1209
00:48:57,200 --> 00:49:00,240
 things it's got a hundred thousand neurons in it

1210
00:49:00,240 --> 00:49:01,760
 it's very sophisticated

1211
00:49:01,760 --> 00:49:03,119
 so

1212
00:49:03,119 --> 00:49:06,640
 that same mechanism that can model a water bottle

1213
00:49:06,640 --> 00:49:12,240
 or a coffee cup can model conceptual objects as well it's if that's the beauty of

1214
00:49:12,240 --> 00:49:16,559
 this discovery that this guy vernon mount castle made many many years ago which is that

1215
00:49:16,559 --> 00:49:20,880
 there's there's a single cortical algorithm underlying everything we're doing

1216
00:49:20,880 --> 00:49:21,200
 so

1217
00:49:21,200 --> 00:49:23,280
 so common sense concepts

1218
00:49:23,280 --> 00:49:28,319
 and higher level concepts are all represented in the same way they're set in the same mechanisms

1219
00:49:28,319 --> 00:49:33,040
 yeah it's a little bit like computers right all computers are universal turing machines

1220
00:49:33,040 --> 00:49:36,480
 even the little teeny one that's in my toaster

1221
00:49:36,480 --> 00:49:39,599
 and the big one that's you know running some cloud server or someplace

1222
00:49:39,599 --> 00:49:42,960
 um they're all running on the same principle they can apply different things

1223
00:49:42,960 --> 00:49:45,200
 so the brain is all built on the same principle

1224
00:49:45,200 --> 00:49:47,119
 it's all about learning these models

1225
00:49:47,119 --> 00:49:49,440
 structured models using movement

1226
00:49:49,440 --> 00:49:51,280
 and reference frames

1227
00:49:51,280 --> 00:49:53,440
 and it can be applied to something

1228
00:49:53,440 --> 00:49:54,960
 as simple as a water bottle in a coffee

1229
00:49:54,960 --> 00:49:55,680
 cup and it can be

1230
00:49:55,680 --> 00:49:56,720
 just thinking like what's

1231
00:49:56,720 --> 00:49:57,680
 the future of humanity

1232
00:49:57,680 --> 00:49:59,839
 and you know

1233
00:49:59,839 --> 00:50:05,520
 why do you have a hedgehog on your on your desk i don't know nobody knows

1234
00:50:05,520 --> 00:50:06,720
 i think it's hedgehog

1235
00:50:06,720 --> 00:50:09,359
 that's right it's a hedgehog in the fog

1236
00:50:09,359 --> 00:50:10,880
 it's a russian reference

1237
00:50:10,880 --> 00:50:14,079
 does it give you any

1238
00:50:14,079 --> 00:50:14,880
 inclination

1239
00:50:14,880 --> 00:50:19,200
 or hope about how difficult it is to engineer common sense reasoning

1240
00:50:19,200 --> 00:50:19,760
 so

1241
00:50:19,760 --> 00:50:21,839
 how complicated this is this whole process

1242
00:50:21,839 --> 00:50:24,559
 so looking at the brain

1243
00:50:24,559 --> 00:50:27,200
 is this a marvel of engineering

1244
00:50:27,200 --> 00:50:32,240
 or is it pretty dumb stuff stacked on top of each other over and over

1245
00:50:32,240 --> 00:50:35,599
 can it be both can it be both right

1246
00:50:35,599 --> 00:50:37,440
 i don't know if it can be both

1247
00:50:37,440 --> 00:50:43,040
 because if it's an incredible engineering job that means it's v

1248
00:50:43,040 --> 00:50:47,119
 so evolution did a lot of work it yeah but then

1249
00:50:47,119 --> 00:50:49,359
 but then it just copied that

1250
00:50:49,359 --> 00:50:50,240
 right so

1251
00:50:50,240 --> 00:50:53,599
 as i said earlier the figuring out how to model something

1252
00:50:53,599 --> 00:50:55,760
 like a space is really hard

1253
00:50:55,760 --> 00:50:57,760
 and evolution had to go through a lot of trick

1254
00:50:57,760 --> 00:50:58,480
 and these

1255
00:50:58,480 --> 00:51:01,760
 these these cells i was talking about these grid cells and place cells they're really complicated

1256
00:51:01,760 --> 00:51:03,040
 this is not simple stuff

1257
00:51:03,040 --> 00:51:07,760
 this neural tissue works on these really unexpected weird mechanisms

1258
00:51:07,760 --> 00:51:08,720
 um

1259
00:51:08,720 --> 00:51:10,880
 but it did it it figured it out

1260
00:51:10,880 --> 00:51:11,200
 but

1261
00:51:11,200 --> 00:51:13,599
 but now you can just make lots of copies of it

1262
00:51:13,599 --> 00:51:15,119
 but then finding

1263
00:51:15,119 --> 00:51:21,359
 yeah so it's a very interesting idea that's a lot of copies of a basic mini brain

1264
00:51:21,359 --> 00:51:23,359
 but the question is

1265
00:51:23,359 --> 00:51:26,079
 how difficult it is to find that mini brain that you can copy

1266
00:51:26,079 --> 00:51:28,960
 and paste effectively

1267
00:51:28,960 --> 00:51:30,720
 okay today

1268
00:51:30,720 --> 00:51:34,880
 we know enough to build this i'm sitting here with

1269
00:51:34,880 --> 00:51:36,960
 you know i know the steps we have to go there's

1270
00:51:36,960 --> 00:51:38,800
 still some engineering problems to solve

1271
00:51:38,800 --> 00:51:41,040
 but we know enough

1272
00:51:41,040 --> 00:51:43,520
 and this is not like oh this is an interesting idea

1273
00:51:43,520 --> 00:51:45,839
 we have to go think about it for another few decades no

1274
00:51:45,839 --> 00:51:48,160
 we actually understand in pretty well details

1275
00:51:48,160 --> 00:51:50,000
 so not all the details

1276
00:51:50,000 --> 00:51:51,839
 but most of them

1277
00:51:51,839 --> 00:51:53,440
 so it's complicated

1278
00:51:53,440 --> 00:51:55,359
 but it is an engineering problem

1279
00:51:55,359 --> 00:51:59,440
 so in my company we are working on that we are basically a road map

1280
00:51:59,440 --> 00:52:00,800
 how we do this

1281
00:52:00,800 --> 00:52:04,640
 um it's not going to take decades it's better a few years

1282
00:52:04,640 --> 00:52:06,880
 um [music] optimistically

1283
00:52:06,880 --> 00:52:08,720
 but i think that's possible

1284
00:52:08,720 --> 00:52:09,760
 um

1285
00:52:09,760 --> 00:52:12,800
 it's you know complex things if you understand them you can build them

1286
00:52:12,800 --> 00:52:16,480
 so in which domain do you think it's best to

1287
00:52:16,480 --> 00:52:18,880
 build them are we talking about

1288
00:52:18,880 --> 00:52:21,680
 robotics like entities

1289
00:52:21,680 --> 00:52:22,960
 that operate in the physical

1290
00:52:22,960 --> 00:52:26,160
 world that are able to interact with that world are we talking about entities

1291
00:52:26,160 --> 00:52:31,040
 that operate in the digital world are we talking about something more like

1292
00:52:31,040 --> 00:52:34,319
 more specific like is done in the machine learning community

1293
00:52:34,319 --> 00:52:36,480
 where you look at natural language

1294
00:52:36,480 --> 00:52:38,720
 or computer vision

1295
00:52:38,720 --> 00:52:41,119
 where do you think is easiest

1296
00:52:41,119 --> 00:52:44,839
 it's the first it's the first two more than the third one i would say

1297
00:52:44,839 --> 00:52:46,240
 um

1298
00:52:46,240 --> 00:52:50,160
 again again let's just use computers as an analogy

1299
00:52:50,160 --> 00:52:52,880
 um the pioneers of computing people like john van noyman

1300
00:52:52,880 --> 00:52:53,200
 and

1301
00:52:53,200 --> 00:52:57,359
 um turing they created this thing you know we now call the universal turing machine

1302
00:52:57,359 --> 00:52:59,200
 which is the computer right

1303
00:52:59,200 --> 00:53:00,800
 did they know how it was going to be applied

1304
00:53:00,800 --> 00:53:01,920
 where it was going to be used

1305
00:53:01,920 --> 00:53:02,880
 you know could they

1306
00:53:02,880 --> 00:53:07,520
 envision any of the future no they just said this is like a really interesting computational

1307
00:53:07,520 --> 00:53:09,599
 idea about algorithms

1308
00:53:09,599 --> 00:53:09,920
 and

1309
00:53:09,920 --> 00:53:13,599
 how you can implement them in in a machine

1310
00:53:13,599 --> 00:53:19,359
 and we're doing something similar to that today like we are we are building this sort of universal

1311
00:53:19,359 --> 00:53:21,200
 learning principle

1312
00:53:21,200 --> 00:53:24,480
 that can be applied to many many different things

1313
00:53:24,480 --> 00:53:27,599
 but the the robotics piece of that okay the interactive

1314
00:53:27,599 --> 00:53:29,680
 okay all right let's be specific

1315
00:53:29,680 --> 00:53:31,040
 you can think of this cortical column

1316
00:53:31,040 --> 00:53:32,640
 as this what we call a sensory motor

1317
00:53:32,640 --> 00:53:33,839
 learning system it has the idea

1318
00:53:33,839 --> 00:53:35,119
 that there's a sensor

1319
00:53:35,119 --> 00:53:36,720
 and then it's moving

1320
00:53:36,720 --> 00:53:39,520
 that sensor can be physical it could be like my finger

1321
00:53:39,520 --> 00:53:42,000
 and it's moving in the world it could like my eye

1322
00:53:42,000 --> 00:53:45,599
 and it's physically moving it can also be virtual

1323
00:53:45,599 --> 00:53:46,960
 so it could be

1324
00:53:46,960 --> 00:53:51,680
 um an example would be i could have a system that lives in the internet

1325
00:53:51,680 --> 00:53:54,640
 that that actually samples information on the internet

1326
00:53:54,640 --> 00:53:58,079
 and moves by following links that's that's a sensory motor system

1327
00:53:58,079 --> 00:53:59,359
 so

1328
00:53:59,359 --> 00:54:00,480
 something that echoes

1329
00:54:00,480 --> 00:54:02,240
 the the process of a finger

1330
00:54:02,240 --> 00:54:06,720
 moving along a car but in a very very loose sense it's it's like

1331
00:54:06,720 --> 00:54:10,160
 again learning is inherently about the subbing the structure in the world

1332
00:54:10,160 --> 00:54:10,720
 and discover

1333
00:54:10,720 --> 00:54:12,880
 the structure of the world you have to move through the world

1334
00:54:12,880 --> 00:54:14,400
 even if it's a virtual world

1335
00:54:14,400 --> 00:54:16,240
 even if it's a conceptual world

1336
00:54:16,240 --> 00:54:19,520
 you have to move through it you don't it doesn't exist in one

1337
00:54:19,520 --> 00:54:21,359
 it has some structure to it

1338
00:54:21,359 --> 00:54:22,559
 so

1339
00:54:22,559 --> 00:54:25,040
 here's here's a couple of predictions that getting

1340
00:54:25,040 --> 00:54:28,079
 what you're talking about in humans

1341
00:54:28,079 --> 00:54:33,440
 the same algorithm is does robotics right it moves my arms my eyes my body right

1342
00:54:33,440 --> 00:54:34,480
 um

1343
00:54:34,480 --> 00:54:37,200
 and so in my in the future to me robotics

1344
00:54:37,200 --> 00:54:40,000
 and ai will merge they're not going to be separate fields

1345
00:54:40,000 --> 00:54:43,760
 because they're going to the the the algorithms to really controlling

1346
00:54:43,760 --> 00:54:46,400
 robots are going to be the same algorithms we have in our brand the

1347
00:54:46,400 --> 00:54:48,720
 brain at these sensory motor algorithms i

1348
00:54:48,720 --> 00:54:51,200
 today we're not there but i think that's going to happen

1349
00:54:51,200 --> 00:54:52,960
 and

1350
00:54:52,960 --> 00:54:53,520
 and then

1351
00:54:53,520 --> 00:54:53,920
 so

1352
00:54:53,920 --> 00:54:57,119
 but not all ai systems will have b robotics

1353
00:54:57,119 --> 00:55:00,079
 you can have systems that have very different types of embodiments

1354
00:55:00,079 --> 00:55:03,280
 some will have physical movements some will have non-physical movements

1355
00:55:03,280 --> 00:55:05,040
 it's a very generic

1356
00:55:05,040 --> 00:55:07,680
 learning system again it's like computers

1357
00:55:07,680 --> 00:55:10,640
 the turing machine is it's like it doesn't say how it's supposed to be implemented

1358
00:55:10,640 --> 00:55:13,200
 it doesn't tell how big it is doesn't tell you what you apply it to

1359
00:55:13,200 --> 00:55:16,559
 but it's an interesting it's a computational principle

1360
00:55:16,559 --> 00:55:21,280
 cortical column equivalent is a computational principle is about learning it's about how you learn

1361
00:55:21,280 --> 00:55:24,559
 and it can be applied to a gazillion things this is what i think this is

1362
00:55:24,559 --> 00:55:27,119
 i think this impact of ai is going to be as

1363
00:55:27,119 --> 00:55:28,160
 large if not larger

1364
00:55:28,160 --> 00:55:30,960
 than computing has been in the last century by far

1365
00:55:30,960 --> 00:55:32,160
 because

1366
00:55:32,160 --> 00:55:34,880
 it's it's getting at a fundamental thing it's not a vision system

1367
00:55:34,880 --> 00:55:38,559
 or a learning system it's a it's not a vision system or a hearing system

1368
00:55:38,559 --> 00:55:40,640
 it is a learning system it's a fundamental principle

1369
00:55:40,640 --> 00:55:42,160
 how you learn the structure in the world

1370
00:55:42,160 --> 00:55:43,280
 how you can gain knowledge

1371
00:55:43,280 --> 00:55:44,559
 and be intelligent

1372
00:55:44,559 --> 00:55:48,400
 and that's what the thousand brain says what's going on and we have a particular implementation

1373
00:55:48,400 --> 00:55:50,799
 in our head but doesn't have to be like that at all

1374
00:55:50,799 --> 00:55:54,480
 do you think there's going to be some kind of impact

1375
00:55:54,480 --> 00:55:56,799
 okay let me ask it another way

1376
00:55:56,799 --> 00:56:04,720
 what do increasingly intelligent ai systems do with us humans in the following way like

1377
00:56:04,720 --> 00:56:07,200
 how hard is the human in the loop problem

1378
00:56:07,200 --> 00:56:10,559
 how hard is it to to interact

1379
00:56:10,559 --> 00:56:15,599
 the finger on the coffee cup equivalent of having a conversation with a human being

1380
00:56:15,599 --> 00:56:20,160
 so how hard is it to fit into our little human world

1381
00:56:20,160 --> 00:56:25,200
 i don't i think it's a lot of engineering problems i don't think it's a fundamental problem

1382
00:56:25,200 --> 00:56:26,640
 i could ask you the same question

1383
00:56:26,640 --> 00:56:30,319
 how hard is for computers to fit into a human world right that i mean that's

1384
00:56:30,319 --> 00:56:30,720
 essentially

1385
00:56:30,720 --> 00:56:33,280
 what i'm asking like how

1386
00:56:33,280 --> 00:56:34,400
 um

1387
00:56:34,400 --> 00:56:38,240
 much are we elitist are we as humans

1388
00:56:38,240 --> 00:56:44,559
 like we try to keep out systems i don't know i i sure i think

1389
00:56:44,559 --> 00:56:46,720
 i'm not sure that's the right question

1390
00:56:46,720 --> 00:56:49,119
 let's let's look at computers as an analogy

1391
00:56:49,119 --> 00:56:52,559
 computers are million times faster than us they do things we can't understand

1392
00:56:52,559 --> 00:56:56,000
 most people have no idea what's going on when they use computers right

1393
00:56:56,000 --> 00:56:58,079
 how do we integrate them in our society

1394
00:56:58,079 --> 00:56:58,799
 um

1395
00:56:58,799 --> 00:57:03,680
 well they're that we don't think of them as their own entities they're not living things

1396
00:57:03,680 --> 00:57:06,240
 um we don't afford them rights

1397
00:57:06,240 --> 00:57:12,480
 um we we rely on them our survival as a seven billion people

1398
00:57:12,480 --> 00:57:14,640
 or something like that is relying on computers

1399
00:57:14,640 --> 00:57:15,520
 now

1400
00:57:15,520 --> 00:57:18,319
 um don't you think that's a fundamental problem

1401
00:57:18,319 --> 00:57:22,400
 that we see them as something we can't we don't give rights to

1402
00:57:22,400 --> 00:57:23,280
 so computers

1403
00:57:23,280 --> 00:57:23,599
 so

1404
00:57:23,599 --> 00:57:24,400
 yeah computers

1405
00:57:24,400 --> 00:57:30,000
 so robots computers intelligence systems it feels like for them to operate successfully

1406
00:57:30,000 --> 00:57:32,240
 they would need to have

1407
00:57:32,240 --> 00:57:37,839
 a lot of the elements that we would start having to think about like

1408
00:57:37,839 --> 00:57:42,559
 should this entity have rights i i don't think so i i think

1409
00:57:42,559 --> 00:57:44,400
 it's tempting to think that way

1410
00:57:44,400 --> 00:57:45,520
 personally i don't think anyone

1411
00:57:45,520 --> 00:57:47,680
 hardly anyone thinks that for computers today

1412
00:57:47,680 --> 00:57:49,359
 no one says oh this thing needs

1413
00:57:49,359 --> 00:57:51,839
 a right i shouldn't be able to turn it off or you know

1414
00:57:51,839 --> 00:57:53,520
 if i throw it in the trash can you know

1415
00:57:53,520 --> 00:57:55,440
 and hit it with a sledgehammer i might

1416
00:57:55,440 --> 00:57:58,000
 perform a criminal act no no one thinks that

1417
00:57:58,000 --> 00:57:59,280
 um

1418
00:57:59,280 --> 00:58:01,359
 and now we think about intelligent machines

1419
00:58:01,359 --> 00:58:03,280
 which is where you're going

1420
00:58:03,280 --> 00:58:04,480
 um

1421
00:58:04,480 --> 00:58:05,359
 and

1422
00:58:05,359 --> 00:58:06,880
 and all of a sudden like well

1423
00:58:06,880 --> 00:58:08,240
 now we can't do that

1424
00:58:08,240 --> 00:58:12,559
 i think the basic problem we have here is that people think intelligent machines will be like us

1425
00:58:12,559 --> 00:58:14,000
 they're going to have the same emotions

1426
00:58:14,000 --> 00:58:15,200
 as we do the same feelings

1427
00:58:15,200 --> 00:58:16,319
 as we do

1428
00:58:16,319 --> 00:58:19,200
 what if i can build an intelligent machine that have absolutely

1429
00:58:19,200 --> 00:58:21,599
 could care less about whether it was on or off or destroyed

1430
00:58:21,599 --> 00:58:25,440
 or not it just doesn't care it's just like a map it's just a modeling system

1431
00:58:25,440 --> 00:58:27,599
 it has no desires to live

1432
00:58:27,599 --> 00:58:31,040
 nothing is it possible to create a system

1433
00:58:31,040 --> 00:58:34,000
 that can model the world deeply

1434
00:58:34,000 --> 00:58:35,359
 and not care

1435
00:58:35,359 --> 00:58:37,599
 about whether it lives or dies absolutely

1436
00:58:37,599 --> 00:58:41,280
 no question about it to me that's not 100 percent obvious

1437
00:58:41,280 --> 00:58:44,240
 it's obvious to me so okay we can debate it if you want

1438
00:58:44,240 --> 00:58:44,640
 yeah

1439
00:58:44,640 --> 00:58:45,520
 where does your

1440
00:58:45,520 --> 00:58:50,720
 where does your desire to live come from it's an old evolutionary

1441
00:58:50,720 --> 00:58:51,760
 design

1442
00:58:51,760 --> 00:58:56,480
 i mean we could argue does it really matter if we live or not objectively no

1443
00:58:56,480 --> 00:58:58,640
 right we're all going to die eventually

1444
00:58:58,640 --> 00:59:00,559
 um

1445
00:59:00,559 --> 00:59:01,680
 but evolution

1446
00:59:01,680 --> 00:59:03,040
 makes us want to live

1447
00:59:03,040 --> 00:59:06,319
 evolution makes us want to fight to live evolutionists want to care

1448
00:59:06,319 --> 00:59:07,680
 and love one another

1449
00:59:07,680 --> 00:59:09,200
 and to care for our children

1450
00:59:09,200 --> 00:59:10,319
 and our relatives

1451
00:59:10,319 --> 00:59:10,960
 and our family

1452
00:59:10,960 --> 00:59:11,599
 and

1453
00:59:11,599 --> 00:59:12,960
 and so on

1454
00:59:12,960 --> 00:59:15,040
 and those are all good things

1455
00:59:15,040 --> 00:59:17,680
 but they come about not because we're smart

1456
00:59:17,680 --> 00:59:18,880
 because we're animals

1457
00:59:18,880 --> 00:59:21,520
 that grew up you know the the hummingbird in my backyard

1458
00:59:21,520 --> 00:59:23,839
 cares about its offspring you know

1459
00:59:23,839 --> 00:59:28,319
 the every living thing in some sense cares about you know surviving

1460
00:59:28,319 --> 00:59:32,240
 but when we talk about creating intelligent machines we're not creating life

1461
00:59:32,240 --> 00:59:36,319
 we're not creating evolving creatures we're not creating living things

1462
00:59:36,319 --> 00:59:39,920
 we're just creating a machine that can learn really sophisticated stuff

1463
00:59:39,920 --> 00:59:42,559
 and that machine it may even be able to talk to us

1464
00:59:42,559 --> 00:59:45,680
 but it doesn't it's not going to have a desire to live

1465
00:59:45,680 --> 00:59:48,400
 unless somehow we put it into that system

1466
00:59:48,400 --> 00:59:51,280
 well there's learning right the the thing is

1467
00:59:51,280 --> 00:59:56,160
 but you don't learn to like want to live that's built into you it's wow

1468
00:59:56,160 --> 00:59:58,319
 people like ernest becker argue

1469
00:59:58,319 --> 00:59:58,640
 so

1470
00:59:58,640 --> 01:00:02,720
 okay there's the fact the finiteness of life

1471
01:00:02,720 --> 01:00:07,839
 the way we think about it is something we learn perhaps

1472
01:00:07,839 --> 01:00:08,319
 so

1473
01:00:08,319 --> 01:00:08,720
 okay

1474
01:00:08,720 --> 01:00:09,040
 yeah

1475
01:00:09,040 --> 01:00:11,040
 and some people decide they don't want to live

1476
01:00:11,040 --> 01:00:12,880
 and some people decide you know

1477
01:00:12,880 --> 01:00:15,599
 you can but the desire to live is built in dna right

1478
01:00:15,599 --> 01:00:16,559
 but i think

1479
01:00:16,559 --> 01:00:19,920
 what i'm trying to get to is in order to accomplish goals

1480
01:00:19,920 --> 01:00:21,680
 it's useful to have the urgency

1481
01:00:21,680 --> 01:00:25,920
 of mortality is what the stoics talked about is meditating in your mortality

1482
01:00:25,920 --> 01:00:28,720
 yeah it might be a very useful

1483
01:00:28,720 --> 01:00:31,440
 thing to do to die

1484
01:00:31,440 --> 01:00:33,520
 and have the urgency of death

1485
01:00:33,520 --> 01:00:37,839
 and to realize that to conceive yourself as an entity

1486
01:00:37,839 --> 01:00:41,920
 that operates in this world that eventually will no longer be a part of this world

1487
01:00:41,920 --> 01:00:46,319
 and actually conceive of yourself as a conscious entity might be very useful

1488
01:00:46,319 --> 01:00:48,640
 for you to be a system

1489
01:00:48,640 --> 01:00:52,480
 that makes sense of the world otherwise you might get lazy well

1490
01:00:52,480 --> 01:00:55,599
 okay we're going to build these machines right

1491
01:00:55,599 --> 01:00:57,680
 and so we're talking about building ais

1492
01:00:57,680 --> 01:00:58,000
 what

1493
01:00:58,000 --> 01:01:02,160
 but we're we're building the

1494
01:01:02,160 --> 01:01:07,119
 the the the equivalent of the cortical columns the the neocortex the neocortex

1495
01:01:07,119 --> 01:01:08,480
 and the the question is

1496
01:01:08,480 --> 01:01:11,200
 where do they arrive at

1497
01:01:11,200 --> 01:01:13,920
 because we're not hard-coding everything in

1498
01:01:13,920 --> 01:01:18,240
 where well well in terms of if you build the neocortex equivalent

1499
01:01:18,240 --> 01:01:20,319
 it will not have any of these desires

1500
01:01:20,319 --> 01:01:21,200
 or emotional states

1501
01:01:21,200 --> 01:01:22,880
 now you can argue

1502
01:01:22,880 --> 01:01:25,520
 that that neocortex won't be useful

1503
01:01:25,520 --> 01:01:26,960
 unless i give it some agency

1504
01:01:26,960 --> 01:01:28,240
 unless i give it some desire

1505
01:01:28,240 --> 01:01:31,359
 unless i give it some motivation otherwise you'll be as lazy and do nothing

1506
01:01:31,359 --> 01:01:32,880
 right you could argue that

1507
01:01:32,880 --> 01:01:33,520
 um

1508
01:01:33,520 --> 01:01:36,000
 but on its own it's not going to do those things

1509
01:01:36,000 --> 01:01:38,240
 it's just not it's not going to sit there and say

1510
01:01:38,240 --> 01:01:39,680
 i understand the world therefore

1511
01:01:39,680 --> 01:01:40,559
 i care to live

1512
01:01:40,559 --> 01:01:42,720
 no it's not going to do that it's just going to say i understand

1513
01:01:42,720 --> 01:01:44,400
 the world why is that obvious to you

1514
01:01:44,400 --> 01:01:45,839
 why why why don't

1515
01:01:45,839 --> 01:01:46,559
 do you think it's

1516
01:01:46,559 --> 01:01:49,839
 okay let me ask it this way do you think it's possible

1517
01:01:49,839 --> 01:01:51,280
 it will

1518
01:01:51,280 --> 01:01:54,880
 at least assign to itself

1519
01:01:54,880 --> 01:01:55,680
 agency

1520
01:01:55,680 --> 01:01:57,599
 and

1521
01:01:57,599 --> 01:01:58,880
 perceive

1522
01:01:58,880 --> 01:02:03,119
 itself in this world as being a conscious entity

1523
01:02:03,119 --> 01:02:05,200
 as a useful way to operate in the world

1524
01:02:05,200 --> 01:02:09,359
 and and to make sense of the world i think intelligent machine could be conscious

1525
01:02:09,359 --> 01:02:12,400
 but that doesn't not again imply any of these

1526
01:02:12,400 --> 01:02:13,599
 um these desires

1527
01:02:13,599 --> 01:02:14,000
 and goals

1528
01:02:14,000 --> 01:02:14,319
 and

1529
01:02:14,319 --> 01:02:16,240
 and that you're worried about

1530
01:02:16,240 --> 01:02:18,160
 it we can i have a

1531
01:02:18,160 --> 01:02:20,559
 we can talk about what it means for the machine to be conscious

1532
01:02:20,559 --> 01:02:23,920
 and by the way not worry about but get excited about it's not necessarily

1533
01:02:23,920 --> 01:02:27,680
 that we should worry about it so i think there's a legitimate problem

1534
01:02:27,680 --> 01:02:29,200
 or not problem a question asked

1535
01:02:29,200 --> 01:02:32,240
 if you build this modeling system what's it gonna model

1536
01:02:32,240 --> 01:02:34,960
 yes right what's it what's its desire

1537
01:02:34,960 --> 01:02:35,920
 what is it what's its goal

1538
01:02:35,920 --> 01:02:37,839
 what are we applying it to right

1539
01:02:37,839 --> 01:02:39,680
 so that's an interesting question

1540
01:02:39,680 --> 01:02:40,960
 um

1541
01:02:40,960 --> 01:02:44,160
 one thing if it and it depends on the application

1542
01:02:44,160 --> 01:02:45,520
 it's not something that inherent

1543
01:02:45,520 --> 01:02:49,520
 to the modeling system it's something we apply to the modeling system in a particular way

1544
01:02:49,520 --> 01:02:52,319
 so if i wanted to make a really smart car

1545
01:02:52,319 --> 01:02:55,839
 it would have to know about driving in cars

1546
01:02:55,839 --> 01:02:58,319
 and what's important in driving in cars

1547
01:02:58,319 --> 01:02:59,440
 it's not going to figure that out

1548
01:02:59,440 --> 01:03:01,119
 on its own it's not going to sit there and say you know

1549
01:03:01,119 --> 01:03:02,400
 i've understood the world

1550
01:03:02,400 --> 01:03:03,839
 and i've decided

1551
01:03:03,839 --> 01:03:04,720
 you know no no no

1552
01:03:04,720 --> 01:03:05,440
 we have to tell

1553
01:03:05,440 --> 01:03:06,720
 it we're going to have to say like

1554
01:03:06,720 --> 01:03:09,760
 so i imagine i make this car really smart it learns about

1555
01:03:09,760 --> 01:03:12,160
 your driving habits it learns about the world

1556
01:03:12,160 --> 01:03:15,680
 and it's just you know is it one day going to wake up and say

1557
01:03:15,680 --> 01:03:17,760
 you know what i'm tired of driving

1558
01:03:17,760 --> 01:03:18,880
 and doing what you want

1559
01:03:18,880 --> 01:03:19,920
 i think i have better

1560
01:03:19,920 --> 01:03:22,079
 ideas about how to spend my time well

1561
01:03:22,079 --> 01:03:22,720
 okay

1562
01:03:22,720 --> 01:03:24,079
 no it's not going to do that

1563
01:03:24,079 --> 01:03:26,240
 part of me is playing a little bit of devil's advocate

1564
01:03:26,240 --> 01:03:30,880
 but part of me is also trying to think through this because i've

1565
01:03:30,880 --> 01:03:32,400
 studied cars quite a bit

1566
01:03:32,400 --> 01:03:33,760
 and i studied pedestrians

1567
01:03:33,760 --> 01:03:35,280
 and cyclists quite a bit

1568
01:03:35,280 --> 01:03:38,559
 and there's part of me that thinks

1569
01:03:38,559 --> 01:03:41,599
 that there needs to be

1570
01:03:41,760 --> 01:03:46,240
 more intelligence than we realize in order to drive successfully

1571
01:03:46,240 --> 01:03:49,920
 that game theory of human interaction

1572
01:03:49,920 --> 01:03:53,839
 seems to require some deep understanding of

1573
01:03:53,839 --> 01:03:56,839
 of human nature

1574
01:03:56,839 --> 01:03:58,400
 that

1575
01:03:58,400 --> 01:04:02,799
 okay when a pedestrian crosses the street there's some sense

1576
01:04:02,799 --> 01:04:05,599
 they they look at a car usually

1577
01:04:05,599 --> 01:04:07,760
 and then they look away there's

1578
01:04:07,760 --> 01:04:10,720
 some sense in which they say i believe

1579
01:04:10,720 --> 01:04:12,559
 that you're not going to murder me

1580
01:04:12,559 --> 01:04:14,640
 you don't have the guts to murder me

1581
01:04:14,640 --> 01:04:17,760
 this is the little dance of pedestrian car interaction

1582
01:04:17,760 --> 01:04:19,839
 yeah is saying i'm going to look away

1583
01:04:19,839 --> 01:04:23,200
 and i'm going to put my life in your hands

1584
01:04:23,200 --> 01:04:26,160
 because i think you're human you're not gonna kill me

1585
01:04:26,160 --> 01:04:28,720
 and then the car in order to successfully

1586
01:04:28,720 --> 01:04:34,400
 operate in like manhattan streets has to say no no no i am going to kill you

1587
01:04:34,400 --> 01:04:38,559
 like a little bit there's a little bit of this weird inkling of mutual murder

1588
01:04:38,559 --> 01:04:38,960
 yeah

1589
01:04:38,960 --> 01:04:39,280
 yeah

1590
01:04:39,280 --> 01:04:40,160
 and that's a dance

1591
01:04:40,160 --> 01:04:41,680
 and then somehow successfully

1592
01:04:41,680 --> 01:04:47,359
 operate through do you think you were born of that did you learn that social interaction

1593
01:04:47,359 --> 01:04:48,720
 i think it

1594
01:04:48,720 --> 01:04:52,880
 might have a lot of the same elements that you're talking about which is we're leveraging

1595
01:04:52,880 --> 01:04:54,400
 things we were born with

1596
01:04:54,400 --> 01:04:58,079
 and applying them in the context that

1597
01:04:58,079 --> 01:04:59,119
 all right i would i would

1598
01:04:59,119 --> 01:05:02,559
 answer that i would have said that that kind of interaction is learned

1599
01:05:02,559 --> 01:05:05,280
 because you know people in different cultures have different interactions

1600
01:05:05,280 --> 01:05:07,119
 like that if you cross the street in different cities

1601
01:05:07,119 --> 01:05:10,799
 and different around the world they have different ways of interacting i would say that's learned

1602
01:05:10,799 --> 01:05:13,520
 and i would say an intelligent system could learn that too

1603
01:05:13,520 --> 01:05:15,200
 but that does not lead

1604
01:05:15,200 --> 01:05:19,119
 and the intelligent system can understand

1605
01:05:19,119 --> 01:05:24,000
 humans it could understand that you know just like i can study an animal

1606
01:05:24,000 --> 01:05:26,960
 and learn something about that animal you know i could study apes

1607
01:05:26,960 --> 01:05:28,240
 and learn something about their culture

1608
01:05:28,240 --> 01:05:31,119
 and so on i'd have to be an ape to know that

1609
01:05:31,119 --> 01:05:32,640
 um i may not be completely

1610
01:05:32,640 --> 01:05:34,240
 but i can understand something

1611
01:05:34,240 --> 01:05:34,799
 so intel's

1612
01:05:34,799 --> 01:05:38,400
 machine can model that that's this part of the world is this part of the interactions

1613
01:05:38,400 --> 01:05:40,240
 the question we're trying to get at

1614
01:05:40,240 --> 01:05:44,240
 will the intelligent machine have its own personal agency that's beyond

1615
01:05:44,240 --> 01:05:48,000
 you know what we assign to it or it's its own personal you know goals

1616
01:05:48,000 --> 01:05:49,039
 or will it evolve

1617
01:05:49,039 --> 01:05:50,799
 and create these things

1618
01:05:50,799 --> 01:05:56,000
 my confidence comes from understanding the mechanisms i'm talking about creating

1619
01:05:56,000 --> 01:05:57,839
 this is not hand wave stuff

1620
01:05:57,839 --> 01:05:59,680
 it's down in the details we i'm

1621
01:05:59,680 --> 01:06:00,319
 going to build it

1622
01:06:00,319 --> 01:06:01,599
 and i know what it's going to look

1623
01:06:01,599 --> 01:06:02,880
 like and i know it's going to behave

1624
01:06:02,880 --> 01:06:03,920
 i know what the kind of things

1625
01:06:03,920 --> 01:06:05,839
 it could do and the kind of things it can't do

1626
01:06:05,839 --> 01:06:07,440
 just like when i build a computer

1627
01:06:07,440 --> 01:06:10,400
 i know it's not going to on its own decide to put another

1628
01:06:10,400 --> 01:06:12,880
 register inside of it it can't do that

1629
01:06:12,880 --> 01:06:16,640
 no way no matter what your software does it can't add a register to the computer

1630
01:06:16,640 --> 01:06:17,440
 um

1631
01:06:17,440 --> 01:06:20,880
 so in this way when we build ai systems

1632
01:06:20,880 --> 01:06:25,280
 we have to make choices about the the the under the

1633
01:06:25,280 --> 01:06:26,559
 how we embed them

1634
01:06:26,559 --> 01:06:28,319
 so i talked about this in the book i said you know

1635
01:06:28,319 --> 01:06:29,440
 it's a brain intelligence

1636
01:06:29,440 --> 01:06:31,680
 system is not just the neocortex equivalent

1637
01:06:31,680 --> 01:06:33,200
 you have to have that

1638
01:06:33,200 --> 01:06:36,799
 but it has to have some kind of embodiment physical a virtual

1639
01:06:36,799 --> 01:06:39,760
 it has to have some sort of goals it has to have some sort of

1640
01:06:39,760 --> 01:06:42,880
 ideas about dangers about things it shouldn't do like

1641
01:06:42,880 --> 01:06:44,319
 you know like we

1642
01:06:44,319 --> 01:06:46,720
 we build in safeguards into systems

1643
01:06:46,720 --> 01:06:49,200
 we have them in our bodies we have put them into cars

1644
01:06:49,200 --> 01:06:51,760
 right you know my car follows my directions

1645
01:06:51,760 --> 01:06:55,039
 until the day it sees i'm about to hit something and it ignores my directions

1646
01:06:55,039 --> 01:06:56,480
 and puts the brakes on

1647
01:06:56,480 --> 01:06:58,240
 so we can build those things in

1648
01:06:58,240 --> 01:07:00,480
 so that's a very interesting problem

1649
01:07:00,480 --> 01:07:00,960
 um

1650
01:07:00,960 --> 01:07:04,880
 how to build those in i think my my

1651
01:07:04,880 --> 01:07:08,559
 my differing opinion about the risks of ai for most people

1652
01:07:08,559 --> 01:07:12,640
 is that people assume that somehow those things will just appear automatically it'll evolve

1653
01:07:12,640 --> 01:07:15,200
 and intelligence itself

1654
01:07:15,200 --> 01:07:16,319
 begets that stuff

1655
01:07:16,319 --> 01:07:17,599
 or requires it

1656
01:07:17,599 --> 01:07:22,079
 but it's not intelligence of the neural cortex equipment doesn't require this the new cartridge equipment just says

1657
01:07:22,079 --> 01:07:23,520
 i'm a learning system

1658
01:07:23,520 --> 01:07:25,039
 tell me what you want me to learn

1659
01:07:25,039 --> 01:07:25,440
 and

1660
01:07:25,440 --> 01:07:26,880
 i'll tell you ask me questions

1661
01:07:26,880 --> 01:07:28,480
 i'll tell you the answers

1662
01:07:28,480 --> 01:07:33,599
 but in that again it's again like a map it doesn't a map has no intent

1663
01:07:33,599 --> 01:07:35,359
 about things but you can use it

1664
01:07:35,359 --> 01:07:37,359
 um to solve problems

1665
01:07:37,359 --> 01:07:37,680
 okay

1666
01:07:37,680 --> 01:07:41,920
 so the building engineering the neural cortex

1667
01:07:41,920 --> 01:07:48,160
 in itself is just creating an intelligent prediction system modeling system sorry modeling system

1668
01:07:48,160 --> 01:07:50,960
 yeah you can use it to then make predictions

1669
01:07:50,960 --> 01:07:52,480
 and then

1670
01:07:52,480 --> 01:07:56,880
 but you can also put it inside a thing that's actually acting in this world

1671
01:07:56,880 --> 01:07:59,599
 you have to put it inside something it's

1672
01:07:59,599 --> 01:08:03,760
 again think of the map analogy right map on its own doesn't do anything right

1673
01:08:03,760 --> 01:08:06,400
 it's just inert it's just it can learn but it's just

1674
01:08:06,400 --> 01:08:09,440
 so we have to embed it somehow in something to do something

1675
01:08:09,440 --> 01:08:10,319
 so

1676
01:08:10,319 --> 01:08:17,839
 so what's your intuition here you had a conversation with sam harris recently that was sort of um

1677
01:08:17,839 --> 01:08:19,679
 you've had a bit of a disagreement

1678
01:08:19,679 --> 01:08:24,560
 and you're sticking on this point you know elon musk stuart russell

1679
01:08:24,560 --> 01:08:28,560
 kind of have us worry existential

1680
01:08:28,560 --> 01:08:30,319
 threats of ai

1681
01:08:30,319 --> 01:08:38,799
 what's your intuition why if we engineer an increasingly intelligent neural cortex type of system in the computer

1682
01:08:38,799 --> 01:08:42,880
 why that shouldn't be a thing that we it was interesting we used the word intuition

1683
01:08:42,880 --> 01:08:44,960
 and sam harris used the word intuition too

1684
01:08:44,960 --> 01:08:45,679
 and

1685
01:08:45,679 --> 01:08:50,479
 and when he used that intuition that word i immediately stopped and said oh that's the problem

1686
01:08:50,479 --> 01:08:53,439
 he's using intuition i'm not speaking about my intuition

1687
01:08:53,439 --> 01:08:57,359
 yes i'm speaking about something i understand something i'm going to build something i am building

1688
01:08:57,359 --> 01:08:59,439
 something i understand completely

1689
01:08:59,439 --> 01:09:02,399
 or at least well enough to know what it's all i'm guessing

1690
01:09:02,399 --> 01:09:02,719
 i know

1691
01:09:02,719 --> 01:09:04,399
 what this thing's going to do

1692
01:09:04,399 --> 01:09:07,759
 and i think most people who are worried

1693
01:09:07,759 --> 01:09:11,198
 they have trouble separating out they don't have they don't have the um knowledge

1694
01:09:11,198 --> 01:09:13,759
 or the understanding about like what is intelligence

1695
01:09:13,759 --> 01:09:17,759
 how is it manifest in the brain how is it separate from these other functions in the brain

1696
01:09:17,759 --> 01:09:19,520
 and so they imagine it's going to be human-like

1697
01:09:19,520 --> 01:09:23,600
 or animal-like it's going to have it's going to have the same sort of drives

1698
01:09:23,600 --> 01:09:25,040
 and emotions we have

1699
01:09:25,040 --> 01:09:27,040
 but there's no reason for that

1700
01:09:27,040 --> 01:09:28,960
 that's just because there's there's unknown

1701
01:09:28,960 --> 01:09:31,040
 if you're if the unknown is like oh my god

1702
01:09:31,040 --> 01:09:32,799
 you know i don't know what this is going to do we have to be careful

1703
01:09:32,799 --> 01:09:35,120
 it could be like us but really smarter

1704
01:09:35,120 --> 01:09:37,520
 i'm saying no it won't be like us it'll be really smart

1705
01:09:37,520 --> 01:09:39,279
 but it won't be like us at all

1706
01:09:39,279 --> 01:09:39,679
 and

1707
01:09:39,679 --> 01:09:40,640
 um

1708
01:09:40,640 --> 01:09:40,960
 and

1709
01:09:40,960 --> 01:09:45,040
 but i i'm coming from that not because i just guessing i'm not intuitive

1710
01:09:45,040 --> 01:09:46,319
 using intuition i'm basically

1711
01:09:46,319 --> 01:09:47,198
 like okay i understand

1712
01:09:47,198 --> 01:09:48,479
 this thing works this is what it does

1713
01:09:48,479 --> 01:09:50,158
 let me explain it to you

1714
01:09:50,158 --> 01:09:50,640
 okay

1715
01:09:50,640 --> 01:09:52,560
 but to push back

1716
01:09:52,560 --> 01:09:56,640
 so i also disagree with the the intuitions that sam has

1717
01:09:56,640 --> 01:09:58,239
 but

1718
01:09:58,239 --> 01:09:59,440
 but i also disagree with

1719
01:09:59,440 --> 01:10:00,800
 what you just said

1720
01:10:00,800 --> 01:10:03,360
 which you know what's a good analogy

1721
01:10:03,360 --> 01:10:03,679
 so

1722
01:10:03,679 --> 01:10:10,159
 if you look at the twitter algorithm in in the early days just recommender systems you can understand

1723
01:10:10,159 --> 01:10:12,960
 how recommender systems work

1724
01:10:12,960 --> 01:10:16,880
 what you can't understand in the early days is when you apply that recommender

1725
01:10:16,880 --> 01:10:18,480
 system at scale to thousands

1726
01:10:18,480 --> 01:10:19,760
 and millions of people

1727
01:10:19,760 --> 01:10:21,840
 how that can change societies

1728
01:10:21,840 --> 01:10:22,320
 yeah

1729
01:10:22,320 --> 01:10:24,560
 so the question is

1730
01:10:24,560 --> 01:10:29,280
 yes you're just saying this is how an engineer in neurocortex works

1731
01:10:29,280 --> 01:10:33,440
 but the ques like when you have a very useful

1732
01:10:33,440 --> 01:10:38,480
 tic toc type of service that goes viral when your neural cortex goes viral

1733
01:10:38,480 --> 01:10:42,320
 and then millions of people start using it cannot destroy the world no

1734
01:10:42,320 --> 01:10:45,280
 well first of all this is back one thing i want to say is that

1735
01:10:45,280 --> 01:10:46,800
 ai is a dangerous technology

1736
01:10:46,800 --> 01:10:51,120
 i don't i'm not denying that all technology is dangerous well an ai maybe particularly

1737
01:10:51,120 --> 01:10:51,840
 so yeah

1738
01:10:51,840 --> 01:10:52,159
 okay

1739
01:10:52,159 --> 01:10:52,640
 so

1740
01:10:52,640 --> 01:10:53,679
 um

1741
01:10:53,679 --> 01:10:57,120
 am i worried about it yeah i'm totally worried about it the the thing where

1742
01:10:57,120 --> 01:11:00,000
 the narrow component we're talking about now is the existential

1743
01:11:00,000 --> 01:11:01,920
 risk of ai right

1744
01:11:01,920 --> 01:11:03,199
 so i want to make that distinction

1745
01:11:03,199 --> 01:11:05,920
 because i think ai can be applied poorly

1746
01:11:05,920 --> 01:11:08,960
 it can be applied in ways that you know people are going to

1747
01:11:08,960 --> 01:11:12,159
 understand the consequences of it

1748
01:11:12,159 --> 01:11:16,080
 these are all potentially very bad things

1749
01:11:16,080 --> 01:11:20,719
 but they're not the ai system creating this existential risk on its own

1750
01:11:20,719 --> 01:11:23,920
 and that's the only place i disagree with other people right so

1751
01:11:23,920 --> 01:11:25,600
 so i i think the existential

1752
01:11:25,600 --> 01:11:26,960
 risk thing is um

1753
01:11:26,960 --> 01:11:29,280
 humans are really damn good at surviving

1754
01:11:29,280 --> 01:11:34,480
 so to kill off the human race it'd be very very difficult you can even

1755
01:11:34,480 --> 01:11:34,800
 yes

1756
01:11:34,800 --> 01:11:39,280
 but you can even i'll go further i don't think ai systems are ever going to try to

1757
01:11:39,280 --> 01:11:41,520
 i don't think ar systems are ever going to like say

1758
01:11:41,520 --> 01:11:45,360
 i'm going to ignore you i'm going to do what i think is best

1759
01:11:45,360 --> 01:11:46,960
 i don't think that's going to happen

1760
01:11:46,960 --> 01:11:50,560
 at least not in the way i'm talking about it

1761
01:11:50,560 --> 01:11:55,760
 so you the twitter recommendation algorithm this interesting example

1762
01:11:55,760 --> 01:11:59,440
 let's let's use computer as an analogy again right

1763
01:11:59,440 --> 01:12:02,480
 i build a computer it's a universal computing machine i can't predict

1764
01:12:02,480 --> 01:12:05,840
 what people are going to use it for they can build all kinds of things they can

1765
01:12:05,840 --> 01:12:07,600
 they can even create computer viruses

1766
01:12:07,600 --> 01:12:10,000
 it's you know all kinds of stuff

1767
01:12:10,000 --> 01:12:12,800
 so there's some unknown about its utility about

1768
01:12:12,800 --> 01:12:14,080
 where it's going to go

1769
01:12:14,080 --> 01:12:17,199
 but on the other hand i pointed out that once i build a computer

1770
01:12:17,199 --> 01:12:19,199
 it's not going to fundamentally change

1771
01:12:19,199 --> 01:12:21,920
 how it computes it's like i use the example of a register

1772
01:12:21,920 --> 01:12:24,080
 which is a part internal part of a computer

1773
01:12:24,080 --> 01:12:26,560
 um you know i say it can't just say

1774
01:12:26,560 --> 01:12:27,920
 because computers don't evolve

1775
01:12:27,920 --> 01:12:29,600
 they don't replicate they don't evolve

1776
01:12:29,600 --> 01:12:31,280
 they don't you know the physical manifestation

1777
01:12:31,280 --> 01:12:33,440
 of the computer itself is not gonna

1778
01:12:33,440 --> 01:12:35,360
 there's certain things it can't do

1779
01:12:35,360 --> 01:12:36,320
 right so we can

1780
01:12:36,320 --> 01:12:37,520
 break into things like things

1781
01:12:37,520 --> 01:12:39,600
 that are possible to happen we can't predict

1782
01:12:39,600 --> 01:12:41,840
 and things are just impossible to happen

1783
01:12:41,840 --> 01:12:44,560
 unless we go out of our way to make them happen they're not going to happen

1784
01:12:44,560 --> 01:12:46,239
 unless somebody makes them happen

1785
01:12:46,239 --> 01:12:50,159
 yeah so there's there's a bunch of things to say one is the physical aspect

1786
01:12:50,159 --> 01:12:51,840
 which you're absolutely right

1787
01:12:51,840 --> 01:12:53,920
 we have to build a thing

1788
01:12:53,920 --> 01:12:55,760
 for it to operate in the physical world

1789
01:12:55,760 --> 01:13:00,239
 and you can just stop building them you know

1790
01:13:00,239 --> 01:13:01,120
 the moment

1791
01:13:01,120 --> 01:13:04,239
 they're not doing the thing you want them to do or just change the design

1792
01:13:04,239 --> 01:13:05,440
 or change the design

1793
01:13:05,440 --> 01:13:06,880
 the question is i mean there's

1794
01:13:06,880 --> 01:13:08,080
 it's possible in the physical

1795
01:13:08,080 --> 01:13:09,600
 world this is probably longer

1796
01:13:09,600 --> 01:13:12,560
 term is you automate the building

1797
01:13:12,560 --> 01:13:13,120
 it makes

1798
01:13:13,120 --> 01:13:15,920
 it makes a lot of sense to automate the building there's a lot of factories

1799
01:13:15,920 --> 01:13:21,360
 that are doing more and more and more automation to go from raw resources to the final product

1800
01:13:21,360 --> 01:13:28,239
 it's possible to imagine that it's obviously much more efficient to keep to create a factory that's creating

1801
01:13:28,239 --> 01:13:30,080
 robots that do something

1802
01:13:30,080 --> 01:13:35,840
 you know do something extremely useful for society it could be personal assistance it could be

1803
01:13:35,840 --> 01:13:37,600
 it could be it could be your toaster

1804
01:13:37,600 --> 01:13:41,520
 but a toaster that's much has deeper knowledge of your culinary preferences

1805
01:13:41,520 --> 01:13:42,800
 yeah

1806
01:13:42,800 --> 01:13:44,080
 and and that could

1807
01:13:44,080 --> 01:13:45,040
 well i think now

1808
01:13:45,040 --> 01:13:47,040
 you've hit on the right thing the real thing we need to be worried

1809
01:13:47,040 --> 01:13:49,520
 about lex is self-replication

1810
01:13:49,520 --> 01:13:52,080
 right that is the thing that we're in the physical world

1811
01:13:52,080 --> 01:13:52,560
 yeah

1812
01:13:52,560 --> 01:13:55,520
 or even the virtual world self-replication

1813
01:13:55,520 --> 01:13:59,840
 because self-replication is dangerous it's probably more likely to be killed by a virus

1814
01:13:59,840 --> 01:14:02,320
 you know or a human engineered virus

1815
01:14:02,320 --> 01:14:05,840
 anybody can create you know this the technology is getting so almost anybody

1816
01:14:05,840 --> 01:14:06,640
 but not anybody

1817
01:14:06,640 --> 01:14:12,159
 but a lot of people could create a human-engineered virus that could wipe out humanity

1818
01:14:12,159 --> 01:14:16,719
 that is really dangerous no intelligence required just self-replication

1819
01:14:16,719 --> 01:14:17,440
 so

1820
01:14:17,440 --> 01:14:18,320
 um

1821
01:14:18,320 --> 01:14:20,560
 so we need to be careful about that

1822
01:14:20,560 --> 01:14:21,280
 so

1823
01:14:21,280 --> 01:14:23,600
 when i think about you know ai

1824
01:14:23,600 --> 01:14:28,000
 i'm not thinking about robots building robots don't do that don't build a you know

1825
01:14:28,000 --> 01:14:31,600
 just well that's because you're interested in creating intelligence

1826
01:14:31,600 --> 01:14:34,640
 it seems like self-replication

1827
01:14:34,640 --> 01:14:37,760
 is a good way to make a lot of money well fine but

1828
01:14:37,760 --> 01:14:40,159
 so is you know maybe editing

1829
01:14:40,159 --> 01:14:44,239
 viruses is a good way to i don't know the point is if as a society

1830
01:14:44,239 --> 01:14:46,960
 when we want to look at existential risks

1831
01:14:46,960 --> 01:14:53,840
 the existential risks we face that that we can control almost all evolve around self-replication

1832
01:14:53,840 --> 01:14:57,920
 yes the question is i don't see a good

1833
01:14:57,920 --> 01:15:00,400
 way to make a lot of money by engineering viruses

1834
01:15:00,400 --> 01:15:04,320
 and deploying them in the world there could be there will be applications that are useful

1835
01:15:04,320 --> 01:15:06,719
 but let's separate out let's separate out

1836
01:15:06,719 --> 01:15:09,199
 i mean you don't need to you only need some you know terrorists

1837
01:15:09,199 --> 01:15:12,080
 who wants to do it because it doesn't take a lot of money to make viruses

1838
01:15:12,080 --> 01:15:15,040
 um let's just separate out what's risky

1839
01:15:15,040 --> 01:15:16,640
 and what's not risky

1840
01:15:16,640 --> 01:15:18,239
 i'm arguing that the intelligence

1841
01:15:18,239 --> 01:15:22,320
 side of this equation is not risky it's not risky it's not risky at all it's the self-replication

1842
01:15:22,320 --> 01:15:23,920
 side of the equation is risky

1843
01:15:23,920 --> 01:15:28,880
 and i'm not dismissing that i'm scared as hell it's like the paperclip

1844
01:15:28,880 --> 01:15:29,920
 maximizer thing

1845
01:15:29,920 --> 01:15:31,679
 yeah

1846
01:15:31,679 --> 01:15:35,280
 those are often like talked about in the same conversation

1847
01:15:35,280 --> 01:15:36,320
 um

1848
01:15:36,320 --> 01:15:40,719
 i think you're right like creating ultra-intelligent super-intelligent

1849
01:15:40,719 --> 01:15:47,280
 systems is not necessarily coupled with the self-replicating arbitrarily self-replicating systems

1850
01:15:47,280 --> 01:15:50,080
 yeah and you don't get evolution unless you're self-replicating

1851
01:15:50,080 --> 01:15:50,480
 yeah

1852
01:15:50,480 --> 01:15:50,960
 and

1853
01:15:50,960 --> 01:15:51,520
 so

1854
01:15:51,520 --> 01:15:56,719
 i think that's the gist of this argument that people have trouble separating those two out they just think

1855
01:15:56,719 --> 01:15:57,040
 oh

1856
01:15:57,040 --> 01:16:00,960
 yeah intelligence is like us and look how look at the damage we've done to this planet

1857
01:16:00,960 --> 01:16:01,920
 like how we've

1858
01:16:01,920 --> 01:16:03,520
 you know destroyed all these other species

1859
01:16:03,520 --> 01:16:07,199
 yeah well we replicate we're eight billion of us are seven million of us now

1860
01:16:07,199 --> 01:16:08,159
 so

1861
01:16:08,159 --> 01:16:12,239
 um i think the idea is that the the more intelligent

1862
01:16:12,239 --> 01:16:15,679
 we're able to build systems the more tempting

1863
01:16:15,679 --> 01:16:17,120
 it becomes from a capitalist

1864
01:16:17,120 --> 01:16:21,199
 perspective of creating products the more tempting it becomes to create self

1865
01:16:21,199 --> 01:16:23,199
 reproduction systems all right

1866
01:16:23,199 --> 01:16:24,800
 so let's say that's true

1867
01:16:24,800 --> 01:16:28,159
 so does that mean we don't build intelligent systems no that means we regulate

1868
01:16:28,159 --> 01:16:30,719
 we we understand the risks

1869
01:16:30,719 --> 01:16:32,000
 we regulate them

1870
01:16:32,000 --> 01:16:35,760
 yeah you know look there's a lot of things we could do a society

1871
01:16:35,760 --> 01:16:38,320
 which have some sort of financial benefit to someone

1872
01:16:38,320 --> 01:16:40,320
 which could do a lot of harm

1873
01:16:40,320 --> 01:16:42,560
 and we have to learn how to regulate those things

1874
01:16:42,560 --> 01:16:44,400
 we have to learn how to deal with those things

1875
01:16:44,400 --> 01:16:48,560
 i will argue this i would say the opposite i would say having intelligent machines

1876
01:16:48,560 --> 01:16:52,000
 at our disposal will actually help us in the end more

1877
01:16:52,000 --> 01:16:53,280
 because it'll help us understand

1878
01:16:53,280 --> 01:16:55,440
 these risks better and help us mitigate these risk riders

1879
01:16:55,440 --> 01:16:56,880
 there might be ways of saying oh

1880
01:16:56,880 --> 01:16:58,800
 well how do we solve climate change problems

1881
01:16:58,800 --> 01:17:01,920
 you know how do we do this or how do we do that

1882
01:17:01,920 --> 01:17:06,159
 that just like computers are dangerous in the hands of the wrong people

1883
01:17:06,159 --> 01:17:07,120
 but they've been so

1884
01:17:07,120 --> 01:17:08,239
 great for so many other things

1885
01:17:08,239 --> 01:17:09,840
 we live with those dangers

1886
01:17:09,840 --> 01:17:12,800
 and i think we have to do the same with intelligent machines we just

1887
01:17:12,800 --> 01:17:15,199
 but we have to be constantly vigilant about

1888
01:17:15,199 --> 01:17:19,360
 this idea of a bad actors doing bad things with them and b

1889
01:17:19,360 --> 01:17:23,199
 um don't ever ever create a self-replicating system

1890
01:17:23,199 --> 01:17:24,400
 um

1891
01:17:24,400 --> 01:17:27,120
 and by the way i don't even know if you could create a self-replicating

1892
01:17:27,120 --> 01:17:30,320
 system that uses a factory that's really dangerous

1893
01:17:30,320 --> 01:17:34,080
 you know nature's way of self-replicating is so amazing

1894
01:17:34,080 --> 01:17:37,760
 um you know it doesn't require anything it just me know the thing

1895
01:17:37,760 --> 01:17:38,719
 and resources

1896
01:17:38,719 --> 01:17:39,920
 and it goes right

1897
01:17:39,920 --> 01:17:40,960
 yeah

1898
01:17:40,960 --> 01:17:44,000
 if i said to you you know what we have to build

1899
01:17:44,000 --> 01:17:47,920
 our goal is to build a factory that can make that builds new factories

1900
01:17:47,920 --> 01:17:51,120
 and it has to end to end supply chain

1901
01:17:51,120 --> 01:17:52,560
 it has to

1902
01:17:52,560 --> 01:17:55,520
 mine the resources get the energy

1903
01:17:55,520 --> 01:17:58,320
 i mean that's really hard it's

1904
01:17:58,320 --> 01:17:59,760
 you know no one's doing that in the next

1905
01:17:59,760 --> 01:18:02,159
 you know 100 years i've been extremely

1906
01:18:02,159 --> 01:18:04,880
 impressed by the efforts of elon musk

1907
01:18:04,880 --> 01:18:09,840
 and tesla to try to do exactly that not not from raw resource

1908
01:18:09,840 --> 01:18:13,840
 well he actually i think states the goal is to go from raw resource

1909
01:18:13,840 --> 01:18:17,199
 to the the final car in one factory

1910
01:18:17,199 --> 01:18:21,040
 yeah that's that's the main goal of course it's not currently possible

1911
01:18:21,040 --> 01:18:24,159
 but they're taking huge leaps well he's not the only one to do that

1912
01:18:24,159 --> 01:18:25,760
 this has been a goal for many

1913
01:18:25,760 --> 01:18:27,600
 industries for a long long time

1914
01:18:27,600 --> 01:18:30,000
 um it's difficult to do well a lot of people

1915
01:18:30,000 --> 01:18:33,679
 what they do is instead they have like a million suppliers

1916
01:18:33,679 --> 01:18:38,000
 and then they like there's everybody's men they all co-locate them

1917
01:18:38,000 --> 01:18:42,400
 and they tie the systems together it's it's a fundamentally distributed even

1918
01:18:42,400 --> 01:18:45,920
 i think that's that also is not getting at the issue i was just talking about

1919
01:18:45,920 --> 01:18:46,320
 um

1920
01:18:46,320 --> 01:18:49,440
 which is self-replication it's

1921
01:18:49,440 --> 01:18:50,239
 um

1922
01:18:50,239 --> 01:18:52,840
 i mean self-replication means there's

1923
01:18:52,840 --> 01:18:56,960
 no entity involved other than the entity that's replicating

1924
01:18:56,960 --> 01:18:58,000
 um right

1925
01:18:58,000 --> 01:19:02,880
 and so if there's humans in this in the loop that's not really self-replicating right it's

1926
01:19:02,880 --> 01:19:06,480
 unless somehow we're duped

1927
01:19:06,480 --> 01:19:11,520
 but it's also i i don't necessarily

1928
01:19:11,920 --> 01:19:16,320
 agree with you because you've kind of mentioned that ai will not say no to us

1929
01:19:16,320 --> 01:19:18,159
 i i just think they will

1930
01:19:18,159 --> 01:19:18,480
 yeah

1931
01:19:18,480 --> 01:19:18,800
 yeah

1932
01:19:18,800 --> 01:19:21,040
 so like

1933
01:19:21,040 --> 01:19:25,280
 i think it's a useful feature to build in i'm just trying to like

1934
01:19:25,280 --> 01:19:29,760
 put myself in the mind of engineers to sometimes say no

1935
01:19:29,760 --> 01:19:31,040
 you know if you you

1936
01:19:31,040 --> 01:19:32,480
 yeah well

1937
01:19:32,480 --> 01:19:35,280
 i gave an example earlier right i get an example of my car

1938
01:19:35,280 --> 01:19:38,000
 yeah right my car turns the wheel

1939
01:19:38,000 --> 01:19:39,760
 and and applies the accelerator

1940
01:19:39,760 --> 01:19:43,760
 and the brake as i say until it decides there's something dangerous

1941
01:19:43,760 --> 01:19:44,159
 yes

1942
01:19:44,159 --> 01:19:45,440
 and then it doesn't do that

1943
01:19:45,440 --> 01:19:45,920
 yeah

1944
01:19:45,920 --> 01:19:47,280
 now

1945
01:19:47,280 --> 01:19:52,880
 that was something it didn't decide to do is something we programmed into the car

1946
01:19:52,880 --> 01:19:55,920
 and so good it was a good idea right

1947
01:19:55,920 --> 01:20:00,719
 the question again isn't like if we create an intelligent system will it ever

1948
01:20:00,719 --> 01:20:03,199
 ignore our commands of course it will on sometimes

1949
01:20:03,199 --> 01:20:06,880
 is it going to do it because it came up came up with its own goals

1950
01:20:06,880 --> 01:20:08,560
 that serve its purposes

1951
01:20:08,560 --> 01:20:12,480
 and it doesn't care about our purposes no i don't think that's going to happen

1952
01:20:12,480 --> 01:20:16,960
 okay so let me ask you about these super intelligent cortical systems that we engineer

1953
01:20:16,960 --> 01:20:19,840
 and us humans

1954
01:20:20,080 --> 01:20:24,320
 do you think with these entities operating out there in the world

1955
01:20:24,320 --> 01:20:28,800
 what does the future most promising future look like is it us

1956
01:20:28,800 --> 01:20:30,880
 merging with them

1957
01:20:30,880 --> 01:20:33,120
 or is it us

1958
01:20:33,120 --> 01:20:38,960
 like how do we keep us humans around when you have increasingly intelligent beings is it

1959
01:20:38,960 --> 01:20:42,239
 one of the dreams is to upload our minds in the digital space

1960
01:20:42,239 --> 01:20:44,320
 so can we just

1961
01:20:44,320 --> 01:20:47,120
 give our minds to these systems

1962
01:20:47,120 --> 01:20:47,440
 yeah

1963
01:20:47,440 --> 01:20:50,800
 so they can operate on them is there some kind of more interesting merger

1964
01:20:50,800 --> 01:20:51,600
 or is there more

1965
01:20:51,600 --> 01:20:54,320
 more in the third part of my book i talked about all these scenarios

1966
01:20:54,320 --> 01:20:56,639
 and let me just walk through them sure

1967
01:20:56,639 --> 01:20:58,480
 um

1968
01:20:58,480 --> 01:20:59,920
 the uploading the mind one

1969
01:20:59,920 --> 01:21:02,000
 yes extremely

1970
01:21:02,000 --> 01:21:07,360
 really difficult to do like like we have no idea how to do this even remotely right now

1971
01:21:07,360 --> 01:21:08,080
 um

1972
01:21:08,080 --> 01:21:10,400
 so it would be a very long way away

1973
01:21:10,400 --> 01:21:13,600
 but i make the argument you wouldn't like the result

1974
01:21:13,600 --> 01:21:14,239
 um

1975
01:21:14,239 --> 01:21:16,159
 and you wouldn't be pleased with the result

1976
01:21:16,159 --> 01:21:18,159
 it's really not what you think it's going to be

1977
01:21:18,159 --> 01:21:20,880
 um imagine i could upload your brain into into a computer

1978
01:21:20,880 --> 01:21:21,920
 right now and now the computer's

1979
01:21:21,920 --> 01:21:23,840
 sitting there going hey i'm over here great

1980
01:21:23,840 --> 01:21:25,120
 get rid of that old bio

1981
01:21:25,120 --> 01:21:27,520
 person i don't need them you're still sitting here

1982
01:21:27,520 --> 01:21:27,840
 yeah

1983
01:21:27,840 --> 01:21:29,520
 what are you gonna do no no

1984
01:21:29,520 --> 01:21:33,440
 that's not me i'm here right yeah are you gonna feel satisfied that then you

1985
01:21:33,440 --> 01:21:35,520
 but people imagine look i'm on my deathbed

1986
01:21:35,520 --> 01:21:37,360
 and i'm about to you know expire

1987
01:21:37,360 --> 01:21:38,239
 and i push the button

1988
01:21:38,239 --> 01:21:39,199
 and now i'm uploaded

1989
01:21:39,199 --> 01:21:41,440
 but think about it a little differently

1990
01:21:41,440 --> 01:21:42,000
 and and

1991
01:21:42,000 --> 01:21:44,080
 so i don't think it's going to be a thing

1992
01:21:44,080 --> 01:21:47,920
 because people by the time we're able to do this if ever

1993
01:21:47,920 --> 01:21:49,760
 because you have to replicate the entire body

1994
01:21:49,760 --> 01:21:51,679
 not just the brain it's it's really

1995
01:21:51,679 --> 01:21:54,840
 it's i walk through the issues it's really substantial

1996
01:21:54,840 --> 01:21:56,000
 um

1997
01:21:56,000 --> 01:22:00,480
 do you have a sense of what makes us us is there is there a shortcut

1998
01:22:00,480 --> 01:22:02,800
 to what can only save a certain part

1999
01:22:02,800 --> 01:22:04,080
 that makes us truly

2000
01:22:04,080 --> 01:22:08,159
 ours no but i think that machine would feel like it's you too right right

2001
01:22:08,159 --> 01:22:10,159
 if you people just like i have a child

2002
01:22:10,159 --> 01:22:12,400
 i have a child right i have two daughters

2003
01:22:12,400 --> 01:22:15,120
 they're independent people i created them well partly

2004
01:22:15,120 --> 01:22:15,440
 yeah

2005
01:22:15,440 --> 01:22:15,760
 and

2006
01:22:15,760 --> 01:22:18,320
 um

2007
01:22:18,320 --> 01:22:19,199
 i don't

2008
01:22:19,199 --> 01:22:20,639
 just because they're somewhat

2009
01:22:20,639 --> 01:22:22,159
 like me i don't feel i'm them

2010
01:22:22,159 --> 01:22:22,880
 and they don't feel like

2011
01:22:22,880 --> 01:22:24,080
 i'm me so if you split it apart

2012
01:22:24,080 --> 01:22:24,880
 you have two people

2013
01:22:24,880 --> 01:22:27,040
 so we can come back to what what makes

2014
01:22:27,040 --> 01:22:29,520
 what consciousness we want we can talk about that

2015
01:22:29,520 --> 01:22:31,280
 but we don't have a remote consciousness

2016
01:22:31,280 --> 01:22:35,199
 i'm not sitting there going oh i'm conscious of that you know i mean that system over there

2017
01:22:35,199 --> 01:22:37,679
 so let's say let's let's stay on our topic

2018
01:22:37,679 --> 01:22:39,840
 okay so one was uploading a brand

2019
01:22:39,840 --> 01:22:43,679
 yep ain't gonna happen in a hundred years maybe a thousand

2020
01:22:43,679 --> 01:22:47,120
 but i don't think people are gonna wanna do it the

2021
01:22:47,120 --> 01:22:51,760
 merging your mind with you know the neural link thing right like

2022
01:22:51,760 --> 01:22:53,600
 again really really difficult

2023
01:22:53,600 --> 01:22:56,639
 it's it's one thing to make progress to control a prosthetic

2024
01:22:56,639 --> 01:22:58,560
 arm it's another to have like a billion

2025
01:22:58,560 --> 01:23:01,199
 or several billion you know things and understanding

2026
01:23:01,199 --> 01:23:04,400
 what those signals mean like it's the one thing they're like okay

2027
01:23:04,400 --> 01:23:05,360
 i can learn to

2028
01:23:05,360 --> 01:23:07,520
 think some patterns to make something happen

2029
01:23:07,520 --> 01:23:10,320
 it's quite another thing to have a system a computer

2030
01:23:10,320 --> 01:23:11,600
 which actually knows exactly

2031
01:23:11,600 --> 01:23:15,760
 which cells it's talking to and how it's talking to them and interacting in a way like that

2032
01:23:15,760 --> 01:23:18,880
 very very difficult we're not getting anywhere closer to that

2033
01:23:18,880 --> 01:23:23,440
 um interesting can i can i ask a question here

2034
01:23:23,440 --> 01:23:23,760
 what

2035
01:23:23,760 --> 01:23:24,800
 so for me

2036
01:23:24,800 --> 01:23:29,280
 what makes that merger very difficult practically in the next 10 20

2037
01:23:29,280 --> 01:23:34,080
 50 years is like literally the biology side of it which is like

2038
01:23:34,080 --> 01:23:37,679
 it's just hard to do that kind of surgery in a safe way

2039
01:23:37,679 --> 01:23:41,199
 but your intuition is even the machine learning

2040
01:23:41,199 --> 01:23:43,600
 part of it where the machine has to learn

2041
01:23:43,600 --> 01:23:47,199
 what the heck it's talking to that's even hard i think it's even harder

2042
01:23:47,199 --> 01:23:51,679
 and it's not it's it's easy to do when you're talking about hundreds of signals

2043
01:23:51,679 --> 01:23:55,600
 it's it's a totally different thing to say you're talking about billions of signals

2044
01:23:55,600 --> 01:23:57,920
 so you don't think it's the raw

2045
01:23:57,920 --> 01:24:00,159
 it's a machine learning problem you don't think it could be learned

2046
01:24:00,159 --> 01:24:01,360
 well i'm just saying

2047
01:24:01,360 --> 01:24:03,600
 no i think you'd have to have detailed knowledge

2048
01:24:03,600 --> 01:24:04,880
 you'd have to know exactly

2049
01:24:04,880 --> 01:24:07,120
 what the types of neurons you're connecting to

2050
01:24:07,120 --> 01:24:08,880
 i mean in the brain there's these they're neurons

2051
01:24:08,880 --> 01:24:11,840
 that do all different types of things it's not like a neural network it's a very complex

2052
01:24:11,840 --> 01:24:13,360
 organism system up here

2053
01:24:13,360 --> 01:24:15,360
 we talked about the grid cells or the place cells

2054
01:24:15,360 --> 01:24:16,639
 you know you have to know what kind of cells

2055
01:24:16,639 --> 01:24:17,760
 you're talking to and what they're doing

2056
01:24:17,760 --> 01:24:18,960
 and how their timing works

2057
01:24:18,960 --> 01:24:20,639
 and all all this stuff

2058
01:24:20,639 --> 01:24:23,360
 which you can't today there's no way of doing that right

2059
01:24:23,360 --> 01:24:26,000
 but i think it's i think it's a i think the problem

2060
01:24:26,000 --> 01:24:27,360
 you're right that the biological

2061
01:24:27,360 --> 01:24:28,800
 aspect of like who wants to have surgery

2062
01:24:28,800 --> 01:24:31,760
 and have this stuff inserted in your brain that's a problem

2063
01:24:31,760 --> 01:24:34,000
 but this is when we solve that problem

2064
01:24:34,000 --> 01:24:37,440
 i think the the information coding aspect is much worse

2065
01:24:37,440 --> 01:24:38,400
 i think that's much more

2066
01:24:38,400 --> 01:24:40,159
 it's not like what they're doing today today

2067
01:24:40,159 --> 01:24:42,159
 it's simple machine learning stuff

2068
01:24:42,159 --> 01:24:43,920
 because you're doing simple things

2069
01:24:43,920 --> 01:24:46,560
 but if you want to merge your brain like i'm thinking

2070
01:24:46,560 --> 01:24:49,120
 on the internet i'm merge my brain with the machine

2071
01:24:49,120 --> 01:24:50,080
 and we're both doing

2072
01:24:50,080 --> 01:24:51,920
 i that's a totally different issue

2073
01:24:51,920 --> 01:24:54,080
 that's interesting i i tend to think if

2074
01:24:54,080 --> 01:24:54,880
 okay

2075
01:24:54,880 --> 01:24:57,760
 if you have a super clean signal

2076
01:24:57,760 --> 01:24:59,760
 from a bunch of neurons

2077
01:24:59,760 --> 01:25:04,080
 at the start you don't know what those neurons are i think that's

2078
01:25:04,080 --> 01:25:08,159
 much easier than the getting of the clean signal i think

2079
01:25:08,159 --> 01:25:12,480
 if you think about today's machine learning that's what you would conclude

2080
01:25:12,480 --> 01:25:14,960
 right i'm thinking about what's going on in the brain

2081
01:25:14,960 --> 01:25:16,320
 and i don't reach that conclusion

2082
01:25:16,320 --> 01:25:17,760
 so we'll have to see sure

2083
01:25:17,760 --> 01:25:22,560
 but i don't think even even then i think there's kind of a sad future

2084
01:25:22,560 --> 01:25:24,480
 like you know do i

2085
01:25:24,480 --> 01:25:28,320
 do i have to like plug my brain into a computer i'm still a biological organism

2086
01:25:28,320 --> 01:25:30,000
 i assume i'm still going to die

2087
01:25:30,000 --> 01:25:30,480
 so what

2088
01:25:30,480 --> 01:25:32,560
 what have i achieved right you know

2089
01:25:32,560 --> 01:25:36,320
 what have i achieved to do some sort of oh i i disagree

2090
01:25:36,320 --> 01:25:36,719
 we don't

2091
01:25:36,719 --> 01:25:37,920
 know what those are but it seems

2092
01:25:37,920 --> 01:25:40,159
 like there could be a lot of different applications

2093
01:25:40,159 --> 01:25:47,280
 it's like virtual reality is to expand your brain's capability to to to like to read wikipedia

2094
01:25:47,280 --> 01:25:50,080
 yeah but but fine but but you're still a biological organization

2095
01:25:50,080 --> 01:25:53,760
 yes yes you know you're still you're still mortal you're still all right so

2096
01:25:53,760 --> 01:25:59,360
 what are you accomplishing you're making your life in this short period of time better right just like

2097
01:25:59,360 --> 01:26:01,360
 having the internet made our life better yeah

2098
01:26:01,360 --> 01:26:02,000
 yeah okay

2099
01:26:02,000 --> 01:26:05,600
 so i i think that's of of if i think about all the possible

2100
01:26:05,600 --> 01:26:09,600
 gains we can have here that's a marginal one it's an individual

2101
01:26:09,600 --> 01:26:12,560
 hey i'm better you know i'm smarter

2102
01:26:12,560 --> 01:26:13,280
 um

2103
01:26:13,280 --> 01:26:17,760
 but you know fine i'm not against it i just don't think it's earth-changing i

2104
01:26:17,760 --> 01:26:18,639
 but

2105
01:26:18,639 --> 01:26:22,560
 so this is the true of the internet when each of us individuals are smarter

2106
01:26:22,560 --> 01:26:25,520
 we get a chance to then share our smartness we get smarter

2107
01:26:25,520 --> 01:26:29,280
 and smarter together as like as a collective this is kind of like this ant colony

2108
01:26:29,280 --> 01:26:33,520
 but why don't i just create an intelligent machine that doesn't have any of this biological nonsense

2109
01:26:33,520 --> 01:26:38,719
 this is all the same it's it's everything except don't burden it with my brain

2110
01:26:38,719 --> 01:26:42,000
 yeah right it has a brain it is smart it's like my child

2111
01:26:42,000 --> 01:26:43,679
 but it's much much smarter than me

2112
01:26:43,679 --> 01:26:45,360
 so i have a choice between

2113
01:26:45,360 --> 01:26:49,040
 doing some implant doing some hybrid weird you know biological thing that bleeding

2114
01:26:49,040 --> 01:26:50,080
 and all these problems

2115
01:26:50,080 --> 01:26:52,639
 and limited by my brain

2116
01:26:52,639 --> 01:26:53,760
 or creating a system

2117
01:26:53,760 --> 01:26:56,320
 which is super smart that i can talk to

2118
01:26:56,320 --> 01:26:59,840
 um that helps me understand the world they can read the inter you know read wikipedia

2119
01:26:59,840 --> 01:27:04,639
 and talk to me i i guess my the open questions there are

2120
01:27:04,639 --> 01:27:08,480
 what does the manifestation of super intelligence look like

2121
01:27:08,480 --> 01:27:09,600
 so like

2122
01:27:09,600 --> 01:27:10,880
 what are we going to

2123
01:27:10,880 --> 01:27:14,000
 you talked about why do i want to merge with ai like what

2124
01:27:14,000 --> 01:27:16,880
 what's the actual marginal benefit here

2125
01:27:16,880 --> 01:27:20,000
 if i if we have a super intelligent

2126
01:27:20,000 --> 01:27:20,719
 system

2127
01:27:20,719 --> 01:27:22,400
 yeah

2128
01:27:22,400 --> 01:27:24,480
 how will it make our life better

2129
01:27:24,480 --> 01:27:24,960
 so

2130
01:27:24,960 --> 01:27:28,719
 let's let's that's a great question but let's break it down to little pieces all right

2131
01:27:28,719 --> 01:27:29,840
 on the one hand

2132
01:27:29,840 --> 01:27:33,760
 it can make our life better in lots of simple ways you mentioned like a care robot

2133
01:27:33,760 --> 01:27:34,800
 or something that helps me

2134
01:27:34,800 --> 01:27:35,840
 do things it cooks

2135
01:27:35,840 --> 01:27:36,960
 i don't know what it does right

2136
01:27:36,960 --> 01:27:38,880
 little things like that we have soup better smarter

2137
01:27:38,880 --> 01:27:40,719
 cars we can have

2138
01:27:40,719 --> 01:27:42,159
 you know better agents

2139
01:27:42,159 --> 01:27:44,560
 and aids helping us in our work environment

2140
01:27:44,560 --> 01:27:48,960
 and things like that to me that's like the easy stuff the simple stuff in the beginning

2141
01:27:48,960 --> 01:27:50,400
 um

2142
01:27:50,400 --> 01:27:54,239
 and so in the same way that computers made our lives better in ways

2143
01:27:54,239 --> 01:27:57,600
 many many ways i will have those kind of things

2144
01:27:57,600 --> 01:28:00,560
 to me the really exciting thing about ai

2145
01:28:00,560 --> 01:28:06,400
 is sort of its transcendent transcendent quality in terms of humanity we're still biological

2146
01:28:06,400 --> 01:28:08,639
 organisms we're still stuck here on earth

2147
01:28:08,639 --> 01:28:11,199
 it's going to be hard for us to live anywhere else

2148
01:28:11,199 --> 01:28:15,600
 i don't think you and i are going to want to live on mars anytime soon

2149
01:28:15,600 --> 01:28:16,400
 and

2150
01:28:16,400 --> 01:28:17,120
 um

2151
01:28:17,120 --> 01:28:18,800
 and we're flawed

2152
01:28:18,800 --> 01:28:23,600
 you know we may end up destroying ourselves it's totally possible

2153
01:28:23,600 --> 01:28:26,480
 we if not completely we could destroy our civilizations

2154
01:28:26,480 --> 01:28:30,159
 you know it's let's face the fact we have issues here

2155
01:28:30,159 --> 01:28:32,080
 but we can create intelligent machines

2156
01:28:32,080 --> 01:28:35,520
 that can help us in various ways for example one example i gave another

2157
01:28:35,520 --> 01:28:36,400
 sounds a little sci-fi

2158
01:28:36,400 --> 01:28:39,520
 but i believe this if we really wanted to live on mars

2159
01:28:39,520 --> 01:28:42,000
 we'd have to have intelligent systems that go there

2160
01:28:42,000 --> 01:28:44,719
 and build the habitat for us not humans

2161
01:28:44,719 --> 01:28:47,280
 humans are never going to do this it's just too hard

2162
01:28:47,280 --> 01:28:47,760
 um

2163
01:28:47,760 --> 01:28:48,960
 but could we have a thousand

2164
01:28:48,960 --> 01:28:53,760
 or ten thousand you know engineer workers up there doing this stuff building things terraforming

2165
01:28:53,760 --> 01:28:55,600
 mars sure maybe we can move to mars

2166
01:28:55,600 --> 01:28:56,480
 but then

2167
01:28:56,480 --> 01:28:58,639
 if we want to if we want to go around the universe

2168
01:28:58,639 --> 01:29:00,400
 should i send my children around the universe

2169
01:29:00,400 --> 01:29:02,320
 or should i send some intelligent machine

2170
01:29:02,320 --> 01:29:04,000
 which is like a child

2171
01:29:04,000 --> 01:29:09,440
 that represents me and understands our needs here on earth that could travel through space

2172
01:29:09,440 --> 01:29:13,280
 so it's sort of it in some sense intelligence allows us to transcend

2173
01:29:13,280 --> 01:29:17,440
 our the limitations of our biology

2174
01:29:17,440 --> 01:29:17,760
 with

2175
01:29:17,760 --> 01:29:18,159
 and

2176
01:29:18,159 --> 01:29:19,600
 and don't think of it as a negative

2177
01:29:19,600 --> 01:29:21,920
 thing it's in some sense my children transcend

2178
01:29:21,920 --> 01:29:24,239
 my the my biology too

2179
01:29:24,239 --> 01:29:26,000
 because they they live beyond me

2180
01:29:26,000 --> 01:29:26,480
 yeah

2181
01:29:26,480 --> 01:29:27,120
 um

2182
01:29:27,120 --> 01:29:30,000
 and we impart they represent me and they also have their own knowledge

2183
01:29:30,000 --> 01:29:33,040
 and i can impart knowledge to them so intelligent machines will be like that too

2184
01:29:33,040 --> 01:29:34,880
 but not limited like us

2185
01:29:34,880 --> 01:29:37,120
 but the question is um

2186
01:29:37,120 --> 01:29:40,320
 there's so many ways that transcendence can happen

2187
01:29:40,320 --> 01:29:42,320
 and the merger with ai

2188
01:29:42,320 --> 01:29:46,960
 and humans is one of those ways so you said intelligent

2189
01:29:46,960 --> 01:29:48,000
 basically beings

2190
01:29:48,000 --> 01:29:53,199
 or systems propagating throughout the universe representing us humans

2191
01:29:53,199 --> 01:29:55,840
 they represent us humans in the sense they represent our knowledge

2192
01:29:55,840 --> 01:29:57,199
 and our history

2193
01:29:57,199 --> 01:30:00,159
 not us individually

2194
01:30:00,159 --> 01:30:00,960
 right right

2195
01:30:00,960 --> 01:30:02,400
 but

2196
01:30:02,400 --> 01:30:05,600
 i mean the question is is it just the database

2197
01:30:05,600 --> 01:30:11,760
 with with the really damn good model no they're conscious conscious just like us

2198
01:30:11,760 --> 01:30:12,320
 okay

2199
01:30:12,320 --> 01:30:14,560
 but just different they're different

2200
01:30:14,560 --> 01:30:18,159
 just like my children are different they're like me but they're different

2201
01:30:18,159 --> 01:30:20,000
 um these are more different

2202
01:30:20,000 --> 01:30:22,320
 i guess maybe i've already

2203
01:30:22,320 --> 01:30:27,280
 i kind of i take a very broad view of our life here on on earth

2204
01:30:27,280 --> 01:30:30,960
 i say you know why are we living here are we just living because we live

2205
01:30:30,960 --> 01:30:31,920
 is are we surviving

2206
01:30:31,920 --> 01:30:34,719
 because we can survive are we fighting just because

2207
01:30:34,719 --> 01:30:38,400
 we want to just keep going what's the point of it yeah right

2208
01:30:38,400 --> 01:30:42,639
 so to me the point if i ask myself what's the point of life is

2209
01:30:42,639 --> 01:30:44,960
 what transcends that

2210
01:30:44,960 --> 01:30:51,120
 ephemeral sort of biological experience is to me this is my answer

2211
01:30:51,120 --> 01:30:55,760
 is the acquisition of knowledge to understand more about the universe

2212
01:30:55,760 --> 01:30:57,199
 and to explore

2213
01:30:57,199 --> 01:31:00,719
 and that's partly to learn more right

2214
01:31:00,719 --> 01:31:02,719
 i don't view it as

2215
01:31:02,719 --> 01:31:05,840
 a terrible thing if the ultimate

2216
01:31:05,840 --> 01:31:10,800
 outcome of humanity is we create systems that are intelligent that are our offspring

2217
01:31:10,800 --> 01:31:12,639
 but are not like us at all

2218
01:31:12,639 --> 01:31:15,920
 and we stay we stay here and live on earth as long as we can

2219
01:31:15,920 --> 01:31:17,520
 which won't be forever

2220
01:31:17,520 --> 01:31:19,679
 but as long as we can

2221
01:31:19,679 --> 01:31:20,800
 and

2222
01:31:20,800 --> 01:31:22,960
 but that would be a great thing to do

2223
01:31:22,960 --> 01:31:27,280
 it's not a it's not like a negative thing well

2224
01:31:27,280 --> 01:31:31,920
 would you'd be okay then if the human

2225
01:31:31,920 --> 01:31:33,520
 species vanishes

2226
01:31:33,520 --> 01:31:35,520
 but our knowledge is preserved

2227
01:31:35,520 --> 01:31:39,440
 and keeps being expanded by intelligent systems

2228
01:31:39,440 --> 01:31:41,600
 i want our knowledge to be preserved

2229
01:31:41,600 --> 01:31:42,719
 and expanded

2230
01:31:42,719 --> 01:31:46,880
 yeah am i okay with humans dying no i don't want that to happen

2231
01:31:46,880 --> 01:31:49,120
 but if if if it does happen

2232
01:31:49,120 --> 01:31:50,960
 what if we we were sitting here and this is

2233
01:31:50,960 --> 01:31:53,679
 we're the last two people on earth we're saying lex we blew it

2234
01:31:53,679 --> 01:31:55,440
 it's all over right yeah

2235
01:31:55,440 --> 01:31:58,639
 wouldn't i feel better if i knew that our knowledge was preserved

2236
01:31:58,639 --> 01:32:00,080
 and that we had agents

2237
01:32:00,080 --> 01:32:04,159
 represent that knew about that that were trans you know they were that left earth

2238
01:32:04,159 --> 01:32:05,440
 i would want that

2239
01:32:05,440 --> 01:32:08,880
 it's better than not having that you know i make the analogy of like you know the dinosaurs

2240
01:32:08,880 --> 01:32:09,679
 the poor dinosaurs

2241
01:32:09,679 --> 01:32:11,520
 they live for you know tens of millions of years

2242
01:32:11,520 --> 01:32:12,960
 they raised their kids they

2243
01:32:12,960 --> 01:32:14,639
 you know they they fought to survive

2244
01:32:14,639 --> 01:32:16,400
 they were hungry they they

2245
01:32:16,400 --> 01:32:18,000
 they did everything we do

2246
01:32:18,000 --> 01:32:19,280
 and then they're all gone

2247
01:32:19,280 --> 01:32:20,239
 yeah like you know

2248
01:32:20,239 --> 01:32:23,120
 and and if we didn't discover their bones

2249
01:32:23,120 --> 01:32:26,800
 nobody would ever know that they ever existed right

2250
01:32:26,800 --> 01:32:27,920
 do we want to be like that

2251
01:32:27,920 --> 01:32:29,120
 i don't want to be like that but there's

2252
01:32:29,120 --> 01:32:33,679
 a sad aspect to it and it's kind of it's jarring to think about

2253
01:32:33,679 --> 01:32:37,120
 that it's possible that a human-like

2254
01:32:37,120 --> 01:32:40,320
 intelligent civilization has previously existed on earth

2255
01:32:40,320 --> 01:32:43,120
 oh yeah the reason i say this is like

2256
01:32:43,120 --> 01:32:45,280
 it is jarring to think that

2257
01:32:45,280 --> 01:32:49,040
 we would not if they weren't extinct we wouldn't be able to find evidence of them

2258
01:32:49,040 --> 01:32:50,719
 after a sufficient amount

2259
01:32:50,719 --> 01:32:54,000
 after a sufficient amount of time of course there's like

2260
01:32:54,000 --> 01:32:56,719
 look basically humans like if we destroy ourselves

2261
01:32:56,719 --> 01:32:58,080
 now

2262
01:32:58,080 --> 01:32:59,520
 human civilization destroy ourselves

2263
01:32:59,520 --> 01:32:59,920
 now

2264
01:32:59,920 --> 01:33:00,719
 after a sufficient

2265
01:33:00,719 --> 01:33:04,480
 amount of time we would not be we'd find the evidence of the dinosaurs

2266
01:33:04,480 --> 01:33:06,560
 we would not find evidence of those humans

2267
01:33:06,560 --> 01:33:09,840
 yeah that's kind of an odd thing to think about although

2268
01:33:09,840 --> 01:33:14,080
 i'm not sure if we have enough knowledge about species going back

2269
01:33:14,080 --> 01:33:16,159
 for billions of years that we could we could

2270
01:33:16,159 --> 01:33:18,000
 we might be able to eliminate that possibility

2271
01:33:18,000 --> 01:33:21,520
 but it's an interesting question of course this is a similar question to

2272
01:33:21,520 --> 01:33:25,199
 you know there were lots of intelligent species throughout the without our galaxy

2273
01:33:25,199 --> 01:33:26,880
 that have all disappeared

2274
01:33:26,880 --> 01:33:28,239
 yeah that's super sad that

2275
01:33:28,239 --> 01:33:30,320
 um there

2276
01:33:30,320 --> 01:33:35,199
 exactly that there may have been much more intelligent alien civilizations

2277
01:33:35,199 --> 01:33:37,199
 in our galaxy that are no longer there

2278
01:33:37,199 --> 01:33:37,920
 yeah

2279
01:33:37,920 --> 01:33:40,719
 um you actually talked about this

2280
01:33:40,719 --> 01:33:43,199
 um that humans might destroy ourselves

2281
01:33:43,199 --> 01:33:43,920
 yeah

2282
01:33:43,920 --> 01:33:44,239
 and

2283
01:33:44,239 --> 01:33:46,480
 how we might

2284
01:33:46,480 --> 01:33:48,080
 preserve our knowledge

2285
01:33:48,080 --> 01:33:49,360
 yeah

2286
01:33:49,360 --> 01:33:53,360
 and advertise that knowledge to other

2287
01:33:53,360 --> 01:33:55,920
 advertisers a funny word to use

2288
01:33:55,920 --> 01:34:00,080
 from a pr person there's no financial gain in this

2289
01:34:00,719 --> 01:34:05,120
 you know like make it like from a tourism perspective make it interesting can you describe

2290
01:34:05,120 --> 01:34:08,800
 how well there's a couple things i broke it down to the two parts

2291
01:34:08,800 --> 01:34:10,880
 actually three parts one is

2292
01:34:10,880 --> 01:34:12,239
 um

2293
01:34:12,239 --> 01:34:14,960
 you know there's a lot of things we know that

2294
01:34:14,960 --> 01:34:18,800
 what if what if we were to what if we ended up our civilization collapsed

2295
01:34:18,800 --> 01:34:20,239
 yeah i'm not talking tomorrow

2296
01:34:20,239 --> 01:34:23,520
 yeah we could be a thousand years from now alex you know we don't really know but

2297
01:34:23,520 --> 01:34:27,360
 but historically would be likely at some point time flies when you're having fun

2298
01:34:27,360 --> 01:34:29,600
 yeah that's a good way to put it

2299
01:34:29,600 --> 01:34:31,840
 um you know could we

2300
01:34:31,840 --> 01:34:35,120
 and then then intelligent life evolved again on this planet

2301
01:34:35,120 --> 01:34:36,800
 wouldn't they want to know a lot about us

2302
01:34:36,800 --> 01:34:39,600
 and what we knew when they wouldn't be able to ask us questions

2303
01:34:39,600 --> 01:34:42,080
 so one very simple thing i said how would we archive

2304
01:34:42,080 --> 01:34:42,960
 what we know

2305
01:34:42,960 --> 01:34:45,119
 that was a very simple idea i said you know what

2306
01:34:45,119 --> 01:34:46,960
 that wouldn't be that hard but a few satellites

2307
01:34:46,960 --> 01:34:50,560
 you know going around this the sun and we upload wikipedia every day and

2308
01:34:50,560 --> 01:34:52,239
 um that kind of thing

2309
01:34:52,239 --> 01:34:54,560
 so you know we can end up killing ourselves well it's

2310
01:34:54,560 --> 01:34:55,920
 up there and the next intelligence piece

2311
01:34:55,920 --> 01:34:56,639
 will find it and learn

2312
01:34:56,639 --> 01:34:57,840
 something that would be they would like that

2313
01:34:57,840 --> 01:35:00,719
 they would appreciate that

2314
01:35:01,199 --> 01:35:04,560
 so that's one thing the next thing i said well what if you know

2315
01:35:04,560 --> 01:35:07,360
 how to outside of our solar system

2316
01:35:07,360 --> 01:35:10,960
 we have the seti program we're looking for these intelligent signals from everybody

2317
01:35:10,960 --> 01:35:12,560
 and if you do a little bit of math

2318
01:35:12,560 --> 01:35:14,159
 which i did in the book

2319
01:35:14,159 --> 01:35:18,239
 and you say well what if intelligent species only live for 10 000 years

2320
01:35:18,239 --> 01:35:20,480
 before you know technologically intelligent species

2321
01:35:20,480 --> 01:35:23,840
 like ones are really able to do this we're just starting to be able to do

2322
01:35:23,840 --> 01:35:24,480
 um

2323
01:35:24,480 --> 01:35:25,679
 well the chances are we wouldn't

2324
01:35:25,679 --> 01:35:28,800
 be able to see any of them because they would have all been disappeared by now

2325
01:35:28,800 --> 01:35:30,719
 um they would they've lived for 10 000 years

2326
01:35:30,719 --> 01:35:32,080
 and now they're gone

2327
01:35:32,080 --> 01:35:32,400
 and

2328
01:35:32,400 --> 01:35:35,040
 so we're not going to find these signals being sent from these people

2329
01:35:35,040 --> 01:35:36,159
 because

2330
01:35:36,159 --> 01:35:38,480
 i said what kind of signal could you create

2331
01:35:38,480 --> 01:35:42,960
 that would last a million years or a billion years that someone would say

2332
01:35:42,960 --> 01:35:47,040
 damn it someone smart lived there we know that that would be a life-changing event

2333
01:35:47,040 --> 01:35:50,080
 for us to figure that out well what we're looking for today in the study program

2334
01:35:50,080 --> 01:35:51,600
 isn't that we're looking for very

2335
01:35:51,600 --> 01:35:53,840
 coded signals in some sense

2336
01:35:53,840 --> 01:35:54,560
 and so i asked myself

2337
01:35:54,560 --> 01:35:57,440
 what would be a different type of signal one could create

2338
01:35:57,440 --> 01:36:02,159
 i've always thought about this throughout my life and in the book i gave one one possible suggestion

2339
01:36:02,159 --> 01:36:03,040
 which was

2340
01:36:03,040 --> 01:36:04,480
 um

2341
01:36:04,480 --> 01:36:08,320
 we now detect planets going around other other suns

2342
01:36:08,320 --> 01:36:10,159
 other stars excuse

2343
01:36:10,159 --> 01:36:14,159
 me and we do that by seeing this the the slight dimming of the light as the planets

2344
01:36:14,159 --> 01:36:15,119
 move in front of them that's

2345
01:36:15,119 --> 01:36:19,520
 how we detect planets elsewhere in our galaxy

2346
01:36:19,520 --> 01:36:19,920
 um

2347
01:36:19,920 --> 01:36:25,440
 what if we created something like that that just rotated around our around the sun

2348
01:36:25,440 --> 01:36:28,080
 and it blocked out a little bit of light in a particular pattern

2349
01:36:28,080 --> 01:36:29,360
 that someone said hey

2350
01:36:29,360 --> 01:36:30,560
 that's not a planet

2351
01:36:30,560 --> 01:36:31,760
 that is a sign

2352
01:36:31,760 --> 01:36:33,679
 that someone was once there you can say

2353
01:36:33,679 --> 01:36:37,199
 what if it's beating up pi you know three point whatever

2354
01:36:37,199 --> 01:36:37,840
 um

2355
01:36:37,840 --> 01:36:42,880
 so the idea of a distance you can from a distance broadly broadcast

2356
01:36:42,880 --> 01:36:44,719
 takes no continue activation

2357
01:36:44,719 --> 01:36:46,000
 on our part this is the key right

2358
01:36:46,000 --> 01:36:47,520
 no one has to be seen here running a computer

2359
01:36:47,520 --> 01:36:50,320
 and supplying it with power it just goes on

2360
01:36:50,320 --> 01:36:52,639
 so we go it's continues

2361
01:36:52,639 --> 01:36:53,280
 and

2362
01:36:53,280 --> 01:36:57,199
 and i argue that part of the study program should be looking for signals like that

2363
01:36:57,199 --> 01:36:59,600
 and to look for signals like that you ought to figure out what the

2364
01:36:59,600 --> 01:37:01,119
 how would we create a signal

2365
01:37:01,119 --> 01:37:04,400
 like what would we create that would be like that that would persist

2366
01:37:04,400 --> 01:37:05,679
 for millions of years

2367
01:37:05,679 --> 01:37:09,440
 that would be broadcast broadly you could see from a distance that was unequivocal

2368
01:37:09,440 --> 01:37:12,880
 it came from an by an intelligent species

2369
01:37:12,880 --> 01:37:14,560
 and so i gave that one example

2370
01:37:14,560 --> 01:37:16,560
 um because they don't know what i know of actually

2371
01:37:16,560 --> 01:37:19,760
 and then and then finally right

2372
01:37:19,760 --> 01:37:25,520
 if if our ultimately our solar system will die at some point in time you know

2373
01:37:25,520 --> 01:37:27,760
 how do we go beyond that

2374
01:37:27,760 --> 01:37:29,440
 and i think it's possible

2375
01:37:29,440 --> 01:37:32,560
 if at all possible we'll have to create intelligent machines that travel throughout

2376
01:37:32,560 --> 01:37:36,080
 this throughout the the solar system or throughout the galaxy

2377
01:37:36,080 --> 01:37:37,679
 and i don't think that's going to be humans

2378
01:37:37,679 --> 01:37:40,000
 i don't think it's going to be biological organisms

2379
01:37:40,000 --> 01:37:41,600
 so these are just things to think about

2380
01:37:41,600 --> 01:37:43,280
 you know like what's the you know like

2381
01:37:43,280 --> 01:37:44,560
 i don't i don't want to be like the dinosaurs

2382
01:37:44,560 --> 01:37:45,679
 i don't want to just live and okay

2383
01:37:45,679 --> 01:37:47,600
 that was it we're done you know

2384
01:37:47,600 --> 01:37:50,000
 well there is a kind of presumption that we're going to live forever

2385
01:37:50,000 --> 01:37:54,639
 which i i think it is a bit sad

2386
01:37:54,639 --> 01:38:01,679
 to imagine that the message we send as as you talk about is that we were once here

2387
01:38:01,679 --> 01:38:07,280
 instead of we are here well it could be we are still here

2388
01:38:07,280 --> 01:38:09,199
 but it's more of a it's more of an insurance

2389
01:38:09,199 --> 01:38:12,880
 policy in case we're not here you know well

2390
01:38:12,880 --> 01:38:15,360
 i don't know but there's something

2391
01:38:15,360 --> 01:38:19,840
 i think about we as humans don't often think about this but

2392
01:38:19,840 --> 01:38:21,679
 it's like like whenever i

2393
01:38:21,679 --> 01:38:23,760
 um [music]

2394
01:38:23,760 --> 01:38:27,040
 record a video i've done this a couple times in my life i've recorded

2395
01:38:27,040 --> 01:38:28,480
 a video for my future self

2396
01:38:28,480 --> 01:38:30,320
 just for personal just for fun

2397
01:38:30,320 --> 01:38:33,760
 and it's always just fascinating

2398
01:38:33,760 --> 01:38:35,440
 to think about

2399
01:38:35,440 --> 01:38:40,000
 that preserving yourself for future civilizations

2400
01:38:40,000 --> 01:38:42,560
 for me it was preserving myself for future

2401
01:38:42,560 --> 01:38:44,080
 me but that's a little

2402
01:38:44,080 --> 01:38:46,320
 that's a little fun example

2403
01:38:46,320 --> 01:38:52,560
 of archival these podcasts are are preserving you and i in a way yeah for future

2404
01:38:52,560 --> 01:38:53,679
 hopefully well

2405
01:38:53,679 --> 01:38:54,480
 after we're gone

2406
01:38:54,480 --> 01:38:59,840
 but you don't often we're sitting here talking about this

2407
01:39:00,000 --> 01:39:04,480
 you are not thinking about the fact that you and i are going to die

2408
01:39:04,480 --> 01:39:06,239
 and there will be like 10 years

2409
01:39:06,239 --> 01:39:08,960
 after somebody watching this

2410
01:39:08,960 --> 01:39:12,480
 and we're still alive you know in some sense i do

2411
01:39:12,480 --> 01:39:17,840
 i'm here because i want to talk about ideas right and these ideas transcend me

2412
01:39:17,840 --> 01:39:22,080
 and they transcend this time in on our planet

2413
01:39:22,080 --> 01:39:25,440
 um we're talking here about ideas that

2414
01:39:25,440 --> 01:39:28,080
 could be around a thousand years from now or a million years from now

2415
01:39:28,080 --> 01:39:30,320
 i when i wrote my book

2416
01:39:30,320 --> 01:39:32,080
 i had an audience of mine

2417
01:39:32,080 --> 01:39:36,080
 and one of the clearest audiences was aliens no

2418
01:39:36,080 --> 01:39:39,440
 were people reading this 100 years from now yes i said to myself

2419
01:39:39,440 --> 01:39:41,280
 how do i make this book relevant

2420
01:39:41,280 --> 01:39:44,000
 to summer reading this 100 years from now what would they want to

2421
01:39:44,000 --> 01:39:46,159
 know that we were thinking back then

2422
01:39:46,159 --> 01:39:50,239
 what would make it like that was an interesting it's still an interesting book

2423
01:39:50,239 --> 01:39:52,800
 i'm not sure i can achieve that but that was

2424
01:39:52,800 --> 01:39:55,360
 how i thought about it because these ideas

2425
01:39:55,360 --> 01:39:58,159
 like especially in the third part of the book the ones we're just talking about

2426
01:39:58,159 --> 01:40:01,440
 you know these crazy it sounds like crazy ideas about you know storing our knowledge

2427
01:40:01,440 --> 01:40:02,000
 and

2428
01:40:02,000 --> 01:40:04,000
 and you know merging our brains of computers

2429
01:40:04,000 --> 01:40:08,880
 and sending you know our machine down to space is not going to happen in my lifetime

2430
01:40:08,880 --> 01:40:09,760
 um

2431
01:40:09,760 --> 01:40:12,639
 and they may not have been happening the next 100 years it may not happen

2432
01:40:12,639 --> 01:40:15,360
 for a thousand years who knows

2433
01:40:15,360 --> 01:40:20,320
 but we have the unique opportunity right now we you me and other people like this

2434
01:40:20,320 --> 01:40:24,719
 um to sort of at least propose the agenda

2435
01:40:24,719 --> 01:40:30,239
 um that might impact the future like that that's a fascinating way to think both like writing

2436
01:40:30,239 --> 01:40:32,159
 or creating

2437
01:40:32,159 --> 01:40:34,159
 try to make

2438
01:40:34,159 --> 01:40:38,960
 try to create ideas try to create things that hold up in time

2439
01:40:38,960 --> 01:40:40,480
 yeah you know understanding

2440
01:40:40,480 --> 01:40:41,440
 how the brain works

2441
01:40:41,440 --> 01:40:44,560
 we're gonna figure that at once that's it it's gonna be figured out once

2442
01:40:44,560 --> 01:40:46,639
 and after that that's the answer

2443
01:40:46,639 --> 01:40:48,800
 and people will people will study that

2444
01:40:48,800 --> 01:40:50,560
 thousands of years now we still

2445
01:40:50,560 --> 01:40:52,480
 we still you know venerate newton

2446
01:40:52,480 --> 01:40:53,679
 and einstein

2447
01:40:53,679 --> 01:40:54,000
 and

2448
01:40:54,000 --> 01:40:54,960
 um

2449
01:40:54,960 --> 01:40:56,239
 and you know

2450
01:40:56,239 --> 01:40:57,119
 because

2451
01:40:57,119 --> 01:41:01,440
 because ideas are exciting even well into the future

2452
01:41:01,440 --> 01:41:09,440
 well the interesting thing is like big ideas even if they're wrong are still useful like

2453
01:41:09,440 --> 01:41:12,560
 yeah especially if they're not completely wrong like

2454
01:41:12,560 --> 01:41:17,920
 right newton's laws are not wrong they're just einsteins they're better

2455
01:41:17,920 --> 01:41:19,040
 um well it's

2456
01:41:19,040 --> 01:41:19,600
 so yeah

2457
01:41:19,600 --> 01:41:22,880
 i mean but we're talking with newton and einstein we're talking about physics i wonder

2458
01:41:22,880 --> 01:41:25,440
 if we'll ever achieve that kind of clarity

2459
01:41:25,440 --> 01:41:26,480
 but understanding

2460
01:41:26,480 --> 01:41:29,199
 um like complex systems

2461
01:41:29,199 --> 01:41:32,560
 and the this particular manifestation of complex systems

2462
01:41:32,560 --> 01:41:34,800
 which is the human brain i'm

2463
01:41:34,800 --> 01:41:38,320
 totally optimistic we can do that i mean we're making progress at it

2464
01:41:38,320 --> 01:41:41,119
 i don't see any reasons why we can't completely

2465
01:41:41,119 --> 01:41:42,880
 i mean completely understand in the sense

2466
01:41:42,880 --> 01:41:45,679
 um you know we don't really completely understand

2467
01:41:45,679 --> 01:41:48,000
 what all the molecules in this water bottle are doing

2468
01:41:48,000 --> 01:41:50,960
 but you know we have laws that sort of capture it pretty good

2469
01:41:50,960 --> 01:41:51,679
 um

2470
01:41:51,679 --> 01:41:54,159
 and so we'll have that kind of understanding

2471
01:41:54,159 --> 01:41:56,080
 i mean it's not like you're gonna have to know what every

2472
01:41:56,080 --> 01:41:57,760
 neuron in your brain is doing

2473
01:41:57,760 --> 01:41:58,560
 um

2474
01:41:58,560 --> 01:42:01,920
 but enough to first of all to build it

2475
01:42:01,920 --> 01:42:07,520
 and second of all to do you know do what physics does which is like have concrete experiments

2476
01:42:07,520 --> 01:42:09,440
 where we can validate

2477
01:42:09,440 --> 01:42:14,320
 we're we're this is happening right now like it's not this is not some future thing

2478
01:42:14,320 --> 01:42:16,960
 um you know i'm very optimistic about because

2479
01:42:16,960 --> 01:42:19,280
 i know about art our work and what we're doing

2480
01:42:19,280 --> 01:42:20,960
 i have to prove it to people

2481
01:42:20,960 --> 01:42:21,600
 um

2482
01:42:21,600 --> 01:42:22,080
 but

2483
01:42:22,080 --> 01:42:24,400
 um

2484
01:42:24,480 --> 01:42:27,360
 i i consider myself a rational person

2485
01:42:27,360 --> 01:42:28,000
 and

2486
01:42:28,000 --> 01:42:29,199
 um

2487
01:42:29,199 --> 01:42:30,639
 you know until fairly recently

2488
01:42:30,639 --> 01:42:34,239
 i wouldn't have said that but right now i'm where i'm sitting right now i'm saying you know we

2489
01:42:34,239 --> 01:42:35,440
 can this is going to happen

2490
01:42:35,440 --> 01:42:37,679
 there's no big obstacles to it

2491
01:42:37,679 --> 01:42:41,440
 um we finally have a framework for understanding what's going on in the cortex

2492
01:42:41,440 --> 01:42:42,159
 and

2493
01:42:42,159 --> 01:42:43,440
 um

2494
01:42:43,440 --> 01:42:46,880
 and that's liberating it's it's like oh it's happening

2495
01:42:46,880 --> 01:42:50,880
 so i i can't see why we wouldn't be able to understand it i just can't

2496
01:42:50,880 --> 01:42:51,440
 okay

2497
01:42:51,440 --> 01:42:52,000
 oh so

2498
01:42:52,000 --> 01:42:54,840
 i mean on that topic let me ask you to play devil's

2499
01:42:54,840 --> 01:42:59,360
 advocate is it possible for you to imagine

2500
01:42:59,360 --> 01:43:01,840
 luck look a hundred years from now

2501
01:43:01,840 --> 01:43:08,719
 and looking at your book in which ways might your ideas be wrong

2502
01:43:08,719 --> 01:43:10,639
 oh i worry about this all the time

2503
01:43:10,639 --> 01:43:12,960
 um

2504
01:43:13,360 --> 01:43:14,560
 yeah it's still useful

2505
01:43:14,560 --> 01:43:16,080
 yeah

2506
01:43:16,080 --> 01:43:18,320
 yeah

2507
01:43:18,960 --> 01:43:20,480
 i think there's

2508
01:43:20,480 --> 01:43:20,960
 you know

2509
01:43:20,960 --> 01:43:21,840
 um

2510
01:43:21,840 --> 01:43:26,320
 well i can i can best relate it to like things i'm worried about right now

2511
01:43:26,320 --> 01:43:30,639
 so we talk about this voting idea right it's happening there's no question that's happening

2512
01:43:30,639 --> 01:43:34,239
 but it could be far more [music]

2513
01:43:34,239 --> 01:43:38,719
 there's there's enough things i don't know about it that it might be

2514
01:43:38,719 --> 01:43:43,119
 working in ways differently i'm thinking about the kind of what's voting who's voting you know

2515
01:43:43,119 --> 01:43:44,159
 where are representations

2516
01:43:44,159 --> 01:43:47,679
 i talked about you have a thousand models of a coffee cup like that

2517
01:43:47,679 --> 01:43:49,840
 that could turn out to be wrong

2518
01:43:49,840 --> 01:43:51,520
 because it may be

2519
01:43:51,520 --> 01:43:54,080
 maybe there are a thousand models that are sub models

2520
01:43:54,080 --> 01:43:56,159
 but not really a single model the coffee cup

2521
01:43:56,159 --> 01:43:57,119
 um

2522
01:43:57,119 --> 01:44:00,480
 i mean there's things these are all sort of on the edges

2523
01:44:00,480 --> 01:44:02,800
 things that i i present as like oh it's so simple

2524
01:44:02,800 --> 01:44:06,000
 and clean well it's not that it's always going to be more complex

2525
01:44:06,000 --> 01:44:06,639
 and

2526
01:44:06,639 --> 01:44:08,159
 um

2527
01:44:08,159 --> 01:44:10,080
 and there's parts of the theory

2528
01:44:10,080 --> 01:44:13,040
 which i don't understand the complexity well

2529
01:44:13,040 --> 01:44:14,239
 so

2530
01:44:14,239 --> 01:44:18,480
 i think i think the idea is brain is a distributed modeling system is not controversial

2531
01:44:18,480 --> 01:44:21,679
 at all right that's not that's well understood by many people

2532
01:44:21,679 --> 01:44:26,080
 the question then is are each quarter of a column an independent modeling system right

2533
01:44:26,080 --> 01:44:27,760
 um

2534
01:44:27,760 --> 01:44:29,760
 i could be wrong about that

2535
01:44:29,760 --> 01:44:31,360
 um i don't think so

2536
01:44:31,360 --> 01:44:34,960
 but i worry about it my intuition not even thinking

2537
01:44:34,960 --> 01:44:40,480
 why you could be wrong is the same intuition i have about any sort of physicist

2538
01:44:40,480 --> 01:44:42,480
 like strength theory

2539
01:44:42,480 --> 01:44:46,480
 that we as humans desire for a clean explanation

2540
01:44:46,480 --> 01:44:52,639
 and 100 years from now intelligent systems might look back at us

2541
01:44:52,639 --> 01:44:54,080
 and laugh

2542
01:44:54,080 --> 01:44:56,639
 at how we try to get rid of the whole mess

2543
01:44:56,639 --> 01:45:01,840
 by having simple explanation when the reality is it's it's way messier

2544
01:45:01,840 --> 01:45:02,239
 and

2545
01:45:02,239 --> 01:45:07,280
 in fact it's impossible to understand you can only build it it's like this idea of complex systems

2546
01:45:07,280 --> 01:45:08,800
 and cellular automata

2547
01:45:08,800 --> 01:45:11,760
 yeah you can only launch the thing you cannot understand it

2548
01:45:11,760 --> 01:45:18,080
 yeah i think that you know the history of science suggests that's not likely to occur

2549
01:45:18,080 --> 01:45:21,040
 the history of science suggests that look as a theorist

2550
01:45:21,040 --> 01:45:24,800
 and we're theorists you look for simple explanations right

2551
01:45:24,800 --> 01:45:26,000
 fully knowing

2552
01:45:26,000 --> 01:45:30,639
 that whatever simple explanation you're going to come up with is not going to be completely correct

2553
01:45:30,639 --> 01:45:31,840
 i mean it can't be

2554
01:45:31,840 --> 01:45:34,000
 i mean it's just it's just more complexity

2555
01:45:34,000 --> 01:45:39,040
 but that's the role of theorists play they they sort of they give you a framework

2556
01:45:39,040 --> 01:45:41,280
 on which you now can talk about a problem

2557
01:45:41,280 --> 01:45:42,320
 and figure out

2558
01:45:42,320 --> 01:45:42,800
 okay

2559
01:45:42,800 --> 01:45:44,639
 now we can start dig in more details

2560
01:45:44,639 --> 01:45:48,159
 the best frameworks stick around while the details change

2561
01:45:48,159 --> 01:45:50,320
 you know again

2562
01:45:50,320 --> 01:45:54,639
 you know the classic example is newton and einstein right you know

2563
01:45:54,639 --> 01:45:55,520
 um

2564
01:45:55,520 --> 01:46:01,360
 newton's theories are still used they're still valuable they're still practical they're not like wrong

2565
01:46:01,360 --> 01:46:02,560
 it's just they've been refined

2566
01:46:02,560 --> 01:46:05,119
 yeah but that's in physics it's not obvious

2567
01:46:05,119 --> 01:46:07,679
 by the way it's not obvious for physics either

2568
01:46:07,679 --> 01:46:11,760
 that the universe should be such that it's amenable to these simple

2569
01:46:11,760 --> 01:46:12,080
 but

2570
01:46:12,080 --> 01:46:14,239
 so far it appears to be

2571
01:46:14,239 --> 01:46:16,000
 as far as we can tell

2572
01:46:16,000 --> 01:46:17,040
 um

2573
01:46:17,040 --> 01:46:17,440
 yeah

2574
01:46:17,440 --> 01:46:17,920
 i mean

2575
01:46:17,920 --> 01:46:19,679
 but as far as we could tell

2576
01:46:19,679 --> 01:46:20,080
 and

2577
01:46:20,080 --> 01:46:24,719
 but it's also an open question whether the brain is amenable to such clean theories

2578
01:46:24,719 --> 01:46:26,159
 that's the not the brain

2579
01:46:26,159 --> 01:46:28,480
 but intelligence well i i

2580
01:46:28,480 --> 01:46:31,360
 i don't know i would take intelligence out of it just say you know

2581
01:46:31,360 --> 01:46:33,040
 um

2582
01:46:33,040 --> 01:46:33,360
 well

2583
01:46:33,360 --> 01:46:35,119
 okay

2584
01:46:35,119 --> 01:46:41,760
 um the evidence we have suggests that the human brain is a at the one time extremely messy

2585
01:46:41,760 --> 01:46:42,400
 and complex

2586
01:46:42,400 --> 01:46:44,480
 but there's some parts that are very regular

2587
01:46:44,480 --> 01:46:48,320
 and structured that's why we started the neocortex it's extremely

2588
01:46:48,320 --> 01:46:49,679
 regular in its structure

2589
01:46:49,679 --> 01:46:50,159
 yeah

2590
01:46:50,159 --> 01:46:51,199
 and unbelievably

2591
01:46:51,199 --> 01:46:51,520
 so

2592
01:46:51,520 --> 01:46:56,080
 and then i mentioned earlier the other thing is it's it's universal abilities

2593
01:46:56,080 --> 01:46:58,800
 it is so flexible to learn

2594
01:46:58,800 --> 01:47:00,800
 so many things we don't we haven't figured

2595
01:47:00,800 --> 01:47:01,600
 out what it can't learn

2596
01:47:01,600 --> 01:47:02,320
 yet we don't know

2597
01:47:02,320 --> 01:47:03,040
 but we haven't figured

2598
01:47:03,040 --> 01:47:03,840
 out yet but to learn

2599
01:47:03,840 --> 01:47:04,639
 things that it never

2600
01:47:04,639 --> 01:47:06,000
 was evolved to learn

2601
01:47:06,000 --> 01:47:07,760
 so those give us hope

2602
01:47:07,760 --> 01:47:13,920
 um that's why i went into this field because i said you know this regular structure it's

2603
01:47:13,920 --> 01:47:17,199
 doing this amazing number of things there's got to be some underlying principles

2604
01:47:17,199 --> 01:47:18,960
 that are that are common

2605
01:47:18,960 --> 01:47:22,239
 and other other scientists have come up with the same conclusions

2606
01:47:22,239 --> 01:47:23,119
 um

2607
01:47:23,119 --> 01:47:25,280
 and so it's promising it's promising

2608
01:47:25,280 --> 01:47:25,600
 and

2609
01:47:25,600 --> 01:47:26,000
 um

2610
01:47:26,000 --> 01:47:27,119
 and that's

2611
01:47:27,119 --> 01:47:33,920
 and whether the theories play out exactly this way or not that is the role that theorists play

2612
01:47:33,920 --> 01:47:34,320
 and

2613
01:47:34,320 --> 01:47:37,280
 so far it's worked out well even though you know maybe

2614
01:47:37,280 --> 01:47:39,840
 you know we don't understand all the laws of physics

2615
01:47:39,840 --> 01:47:42,560
 but so far it's been pretty damn useful the ones we have

2616
01:47:42,560 --> 01:47:45,520
 are our theories are pretty bit useful

2617
01:47:45,520 --> 01:47:47,760
 you mentioned that

2618
01:47:47,760 --> 01:47:49,840
 we should not necessarily be

2619
01:47:49,840 --> 01:47:55,199
 at least to the degree that we are worried about the existential risks of artificial intelligence

2620
01:47:55,199 --> 01:48:02,719
 relative to human risks from human nature being existential risk

2621
01:48:02,719 --> 01:48:09,600
 what aspect of human nature worries you the most in terms of the survival of the human species

2622
01:48:09,679 --> 01:48:12,080
 i mean i'm disappointed

2623
01:48:12,080 --> 01:48:13,360
 in humanity as humans

2624
01:48:13,360 --> 01:48:17,840
 i mean all of us i'm one so i'm at disappointed myself too

2625
01:48:17,840 --> 01:48:20,400
 it's kind of a sad state

2626
01:48:20,400 --> 01:48:22,719
 there's two things that disappoint me

2627
01:48:22,719 --> 01:48:24,880
 one is

2628
01:48:24,880 --> 01:48:31,119
 how it's difficult for us to separate our rational component of ourselves from our evolutionary heritage

2629
01:48:31,119 --> 01:48:36,639
 which is you know not always pretty you know

2630
01:48:36,800 --> 01:48:40,080
 rape is a is an evolutionary good strategy

2631
01:48:40,080 --> 01:48:41,280
 for reproduction

2632
01:48:41,280 --> 01:48:44,480
 murder can be at times too you know

2633
01:48:44,480 --> 01:48:48,880
 making other people miserable at times is a good strategy for reproduction it's just

2634
01:48:48,880 --> 01:48:49,920
 and it's just and

2635
01:48:49,920 --> 01:48:50,400
 and so

2636
01:48:50,400 --> 01:48:52,159
 now that we know that

2637
01:48:52,159 --> 01:48:52,719
 and yet we have

2638
01:48:52,719 --> 01:48:53,840
 this sort of you know we and i can

2639
01:48:53,840 --> 01:48:55,040
 have this very rational discussion

2640
01:48:55,040 --> 01:48:56,480
 talking about you know intelligence

2641
01:48:56,480 --> 01:48:56,880
 and brains

2642
01:48:56,880 --> 01:48:58,880
 and life and so on

2643
01:48:58,880 --> 01:49:03,360
 so it seems like it's so hard it's just a big transition to get humans

2644
01:49:03,360 --> 01:49:08,800
 all humans to to to make the transition from be like let's pay no attention to all that

2645
01:49:08,800 --> 01:49:12,480
 ugly stuff over here let's just focus on the instances

2646
01:49:12,480 --> 01:49:14,400
 what's unique about humanity is our knowledge

2647
01:49:14,400 --> 01:49:16,159
 and our intellect

2648
01:49:16,159 --> 01:49:19,679
 but the fact that we're striving is in itself amazing right

2649
01:49:19,679 --> 01:49:22,480
 the fact that we're able to overcome that part

2650
01:49:22,480 --> 01:49:25,440
 and it seems like we are more

2651
01:49:25,440 --> 01:49:27,440
 and more becoming successful

2652
01:49:27,440 --> 01:49:30,239
 and overcoming that that is the optimistic view and i agree with you

2653
01:49:30,239 --> 01:49:30,560
 yeah

2654
01:49:30,560 --> 01:49:33,119
 but i worry about it i'm not saying

2655
01:49:33,119 --> 01:49:36,239
 i'm worrying about i think maybe that was your question i still worry about it yes

2656
01:49:36,239 --> 01:49:38,080
 um you know we could be end tomorrow

2657
01:49:38,080 --> 01:49:40,080
 because some terrorists could get nuclear bombs

2658
01:49:40,080 --> 01:49:42,960
 and you know blow us all up who knows right

2659
01:49:42,960 --> 01:49:45,360
 the other thing i think i'm disappointed is

2660
01:49:45,360 --> 01:49:46,639
 and it's just i understand

2661
01:49:46,639 --> 01:49:48,400
 it it's i guess you can't really be disappointed

2662
01:49:48,400 --> 01:49:52,320
 it's just a fact is that we're so prone to false beliefs

2663
01:49:52,320 --> 01:49:55,360
 that we you know we have a model in our head

2664
01:49:55,360 --> 01:50:01,440
 the things we can interact with directly physical objects people that model is pretty good

2665
01:50:01,440 --> 01:50:03,280
 and we can test it all the time

2666
01:50:03,280 --> 01:50:06,719
 right i touch something i look at it i talk to you see my model's correct

2667
01:50:06,719 --> 01:50:09,840
 but so much of what we know is stuff i can't directly

2668
01:50:09,840 --> 01:50:12,800
 interact with i can't i don't know because someone told me about it yeah

2669
01:50:12,800 --> 01:50:13,599
 and so

2670
01:50:13,599 --> 01:50:18,320
 so we're prone inherently prone to having false beliefs

2671
01:50:18,320 --> 01:50:21,920
 because if i'm told something how am i going to know it's right or wrong right

2672
01:50:21,920 --> 01:50:22,400
 and

2673
01:50:22,400 --> 01:50:24,159
 so then we have the scientific process

2674
01:50:24,159 --> 01:50:26,800
 which says we are inherently flawed

2675
01:50:26,800 --> 01:50:28,880
 so the only way we can

2676
01:50:28,880 --> 01:50:32,800
 get closer to the truth is by looking for

2677
01:50:32,800 --> 01:50:34,800
 um contrary evidence

2678
01:50:34,800 --> 01:50:35,280
 yeah

2679
01:50:35,280 --> 01:50:37,119
 um like this

2680
01:50:37,119 --> 01:50:43,520
 conspiracy theory this this theory that scientists keep telling me about that the earth is round

2681
01:50:43,520 --> 01:50:47,040
 as far as i can tell when i look out it looks pretty flat

2682
01:50:47,040 --> 01:50:47,920
 yeah

2683
01:50:47,920 --> 01:50:48,239
 so

2684
01:50:48,239 --> 01:50:49,599
 yeah there is there's a tension

2685
01:50:49,599 --> 01:50:50,840
 but it's also

2686
01:50:50,840 --> 01:50:52,800
 um

2687
01:50:52,800 --> 01:50:58,480
 um i tend to believe that we haven't figured out most of this thing right

2688
01:50:58,480 --> 01:51:01,280
 most of nature around us is a mystery

2689
01:51:01,280 --> 01:51:02,239
 and so it um

2690
01:51:02,239 --> 01:51:04,000
 but that doesn't work does that worry you

2691
01:51:04,000 --> 01:51:07,280
 i mean it's like oh that's that's like a pleasure more to figure out right

2692
01:51:07,280 --> 01:51:08,400
 yeah that's exciting

2693
01:51:08,400 --> 01:51:13,520
 but i'm saying like there's going to be a lot of quote unquote wrong ideas

2694
01:51:13,520 --> 01:51:18,560
 i mean i've been thinking a lot about engineering systems like social networks

2695
01:51:18,560 --> 01:51:19,280
 and so on

2696
01:51:19,280 --> 01:51:21,840
 and i've been worried about censorship

2697
01:51:21,840 --> 01:51:23,280
 and thinking through all that kind of stuff

2698
01:51:23,280 --> 01:51:27,840
 because there's a lot of wrong ideas there's a lot of dangerous ideas

2699
01:51:27,840 --> 01:51:30,960
 but then i also read a history

2700
01:51:30,960 --> 01:51:31,599
 read history

2701
01:51:31,599 --> 01:51:34,960
 and see when you censor ideas that are wrong

2702
01:51:34,960 --> 01:51:38,239
 now this could be a small-scale censorship

2703
01:51:38,239 --> 01:51:40,719
 like a young grad student who comes up

2704
01:51:40,719 --> 01:51:43,760
 who like raises their hand and says some crazy idea

2705
01:51:43,760 --> 01:51:47,679
 yes a form of censorship could be i shouldn't use the word censorship

2706
01:51:47,679 --> 01:51:50,880
 but i think you may just like like de-incentivize

2707
01:51:50,880 --> 01:51:53,119
 them from no no no this is the way it's been

2708
01:51:53,119 --> 01:51:56,400
 yeah yeah you're you're a foolish kid don't do it yeah yeah yeah foolish

2709
01:51:56,400 --> 01:51:59,760
 so in some sense

2710
01:51:59,760 --> 01:52:01,760
 those wrong ideas

2711
01:52:01,760 --> 01:52:04,320
 most of the time end up being wrong

2712
01:52:04,320 --> 01:52:05,599
 but sometimes

2713
01:52:05,599 --> 01:52:06,560
 i agree with you

2714
01:52:06,560 --> 01:52:08,239
 so i don't like the word censorship

2715
01:52:08,239 --> 01:52:09,440
 um

2716
01:52:09,440 --> 01:52:12,239
 at the very end of the book i i

2717
01:52:12,239 --> 01:52:14,719
 ended up with a sort of a a plea

2718
01:52:14,719 --> 01:52:17,520
 or a recommended course of action

2719
01:52:17,520 --> 01:52:20,719
 and the best way i could

2720
01:52:20,719 --> 01:52:21,040
 i know

2721
01:52:21,040 --> 01:52:25,679
 how to deal with this issue that you bring up is if everybody understood

2722
01:52:25,679 --> 01:52:28,239
 as part of your upbringing in life

2723
01:52:28,239 --> 01:52:32,719
 something about how your brain works that it builds a model of the world

2724
01:52:32,719 --> 01:52:35,199
 how it works you know how basically builds that model the world

2725
01:52:35,199 --> 01:52:38,880
 and that the model is not the real world it's just a model

2726
01:52:38,880 --> 01:52:40,960
 and it's never going to reflect the entire world

2727
01:52:40,960 --> 01:52:41,920
 and it can be wrong

2728
01:52:41,920 --> 01:52:43,599
 and it's easy to be wrong

2729
01:52:43,599 --> 01:52:48,320
 and here's all the ways you can get the wrong model in your head right

2730
01:52:48,320 --> 01:52:51,920
 it's not prescribed what's right or wrong just understand that process

2731
01:52:51,920 --> 01:52:54,560
 if we all understood the process then i got together

2732
01:52:54,560 --> 01:52:56,480
 and you say i disagree with you jeff and i said lex

2733
01:52:56,480 --> 01:52:58,000
 i disagree with you that

2734
01:52:58,000 --> 01:52:59,520
 at least we understand

2735
01:52:59,520 --> 01:53:03,440
 that we're both trying to model something we both have different information

2736
01:53:03,440 --> 01:53:05,119
 which leads to our different models

2737
01:53:05,119 --> 01:53:08,159
 and therefore i shouldn't hold it against you and you shouldn't hold it against me

2738
01:53:08,159 --> 01:53:10,000
 and we can at least agree that well

2739
01:53:10,000 --> 01:53:14,239
 what can we look for in in its common ground to test our our beliefs

2740
01:53:14,239 --> 01:53:18,639
 as opposed to so much as our we raise our kids on dogma

2741
01:53:18,639 --> 01:53:20,080
 which is this is a fact

2742
01:53:20,080 --> 01:53:20,960
 and this is a fact

2743
01:53:20,960 --> 01:53:22,320
 and these people are bad

2744
01:53:22,320 --> 01:53:22,719
 and

2745
01:53:22,719 --> 01:53:24,400
 and you know

2746
01:53:24,400 --> 01:53:30,560
 where ever if everyone knew just to to be skeptical of every belief

2747
01:53:30,560 --> 01:53:31,119
 and why

2748
01:53:31,119 --> 01:53:34,960
 and how their brains do that i think we might have a better world

2749
01:53:34,960 --> 01:53:40,159
 do you think the human mind is able to comprehend reality

2750
01:53:40,159 --> 01:53:44,480
 so you talk about sort of this creating models that are better

2751
01:53:44,480 --> 01:53:45,520
 and better

2752
01:53:45,520 --> 01:53:49,360
 how close do you think we get to to reality there's

2753
01:53:49,360 --> 01:53:54,719
 so the wildest ideas is like donald hoffman saying we're very far away from reality

2754
01:53:54,719 --> 01:53:57,119
 do you think we're getting close to reality well

2755
01:53:57,119 --> 01:54:00,159
 i guess it depends on what you define reality

2756
01:54:00,159 --> 01:54:04,000
 we are getting we have a model of the world that's very useful

2757
01:54:04,000 --> 01:54:07,040
 right for basic well for our survival

2758
01:54:07,040 --> 01:54:10,800
 and our the pleasure whatever right

2759
01:54:10,800 --> 01:54:11,360
 um

2760
01:54:11,360 --> 01:54:12,639
 so that's useful

2761
01:54:12,639 --> 01:54:13,360
 um

2762
01:54:13,360 --> 01:54:14,159
 i mean it's really useful

2763
01:54:14,159 --> 01:54:18,320
 oh we can build planes we can build computers we can do these things right

2764
01:54:18,320 --> 01:54:19,840
 i don't think

2765
01:54:19,840 --> 01:54:21,360
 i i don't know the answer to that question

2766
01:54:21,360 --> 01:54:23,040
 um

2767
01:54:23,040 --> 01:54:26,320
 i think that's part of the question we're trying to figure out right like

2768
01:54:26,320 --> 01:54:29,280
 you know obviously if you end up with a theory of everything

2769
01:54:29,280 --> 01:54:31,199
 that really is a theory of everything

2770
01:54:31,199 --> 01:54:34,880
 and all of a sudden everything comes into play and there's no room for something else

2771
01:54:34,880 --> 01:54:37,119
 then you might feel like we have a good model of the world

2772
01:54:37,119 --> 01:54:38,880
 yeah but we if we have a theory of everything

2773
01:54:38,880 --> 01:54:39,840
 and somehow

2774
01:54:39,840 --> 01:54:42,320
 first of all you'll never be able to really conclusively

2775
01:54:42,320 --> 01:54:44,480
 say it's a theory of everything but say somehow

2776
01:54:44,480 --> 01:54:48,239
 we are very damn sure it's the theory of everything we understand

2777
01:54:48,239 --> 01:54:49,599
 what happened at the big bang

2778
01:54:49,599 --> 01:54:50,480
 and how

2779
01:54:50,480 --> 01:54:54,800
 just the entirety of the physical process i'm still not sure that gives us

2780
01:54:54,800 --> 01:54:58,239
 an understanding of the next

2781
01:54:58,239 --> 01:55:00,880
 many layers of the hierarchy

2782
01:55:00,880 --> 01:55:02,800
 yeah abstractions that form well also

2783
01:55:02,800 --> 01:55:04,960
 what if string theory turns out to be true

2784
01:55:04,960 --> 01:55:06,400
 and then you say well

2785
01:55:06,400 --> 01:55:08,159
 we have no reality

2786
01:55:08,159 --> 01:55:10,239
 no modeling what's going on in those other dimensions

2787
01:55:10,239 --> 01:55:13,040
 that are wrapped into it on each other you're right

2788
01:55:13,040 --> 01:55:14,880
 or or the multiverse

2789
01:55:14,880 --> 01:55:16,960
 you know i i honestly don't know

2790
01:55:16,960 --> 01:55:21,599
 how for us for human interaction for ideas of intelligence

2791
01:55:21,599 --> 01:55:26,800
 how it helps us to understand that we're made up of vibrating strings that are

2792
01:55:26,800 --> 01:55:29,840
 like tend to the whatever times smaller than us

2793
01:55:29,840 --> 01:55:33,360
 yeah i don't you know you could probably build better weapons

2794
01:55:33,360 --> 01:55:34,239
 and better rockets

2795
01:55:34,239 --> 01:55:36,719
 but you're not going to be able to understand intelligence

2796
01:55:36,719 --> 01:55:38,639
 i guess i guess maybe better computers

2797
01:55:38,639 --> 01:55:41,679
 no you won't be able i think it's just more purely knowledge

2798
01:55:41,679 --> 01:55:46,239
 you might lead to a better understanding of the of the beginning of the universe

2799
01:55:46,239 --> 01:55:50,000
 right it might lead to a better understanding of

2800
01:55:50,000 --> 01:55:56,320
 i don't know i guess i think the acquisition of knowledge has always been one where you

2801
01:55:56,320 --> 01:55:59,199
 you pursue it for its own pleasure

2802
01:55:59,199 --> 01:55:59,840
 um

2803
01:55:59,840 --> 01:56:01,840
 and you don't always know

2804
01:56:01,840 --> 01:56:03,280
 what is going to make a difference

2805
01:56:03,280 --> 01:56:04,719
 yeah

2806
01:56:04,719 --> 01:56:09,199
 you're pleasantly surprised by the the weird things you find do you think

2807
01:56:09,199 --> 01:56:11,760
 for the for the neocortex in general

2808
01:56:11,760 --> 01:56:16,960
 do you think there's a lot of innovation to be done on the machine side you know

2809
01:56:16,960 --> 01:56:18,800
 you use the computer as a metaphor

2810
01:56:18,800 --> 01:56:20,400
 quite a bit is there a different

2811
01:56:20,400 --> 01:56:22,400
 types of computer that would help us build

2812
01:56:22,400 --> 01:56:25,280
 i mean what are the intelligences like the manifestations of intelligent machines

2813
01:56:25,280 --> 01:56:25,679
 yeah

2814
01:56:25,679 --> 01:56:26,400
 or is it

2815
01:56:26,400 --> 01:56:28,320
 oh no it's going to be totally

2816
01:56:28,320 --> 01:56:32,480
 crazy we have no idea how this is going to look out yet

2817
01:56:32,480 --> 01:56:38,719
 but you can already see this today we of course remodel these things on traditional computers

2818
01:56:38,719 --> 01:56:39,520
 and now

2819
01:56:39,520 --> 01:56:42,560
 now gpus are really popular with with

2820
01:56:42,560 --> 01:56:43,520
 you know neural networks

2821
01:56:43,520 --> 01:56:44,480
 and so on

2822
01:56:44,480 --> 01:56:44,960
 um

2823
01:56:44,960 --> 01:56:50,400
 but there are companies coming up with fundamentally new physical substrates

2824
01:56:50,400 --> 01:56:54,239
 that are just really cool i don't know if they're going to work or not

2825
01:56:54,239 --> 01:56:57,440
 but i think there'll be decades of innovation here

2826
01:56:57,440 --> 01:57:03,280
 yeah totally do you think the final thing will be messy like our biology is messy

2827
01:57:03,280 --> 01:57:04,080
 or do you think

2828
01:57:04,080 --> 01:57:05,199
 um

2829
01:57:05,199 --> 01:57:08,560
 it's it's the it's the old bird versus airplane question

2830
01:57:08,560 --> 01:57:13,199
 or do you think we could just build airplanes

2831
01:57:13,199 --> 01:57:14,719
 yeah

2832
01:57:14,719 --> 01:57:21,280
 that that fly way better than birds in the same way we can build uh electrical

2833
01:57:21,280 --> 01:57:21,679
 and

2834
01:57:21,679 --> 01:57:22,320
 yeah

2835
01:57:22,320 --> 01:57:22,960
 yeah

2836
01:57:22,960 --> 01:57:24,800
 you know can i can i can i refund

2837
01:57:24,800 --> 01:57:27,040
 the bird thing a bit because i think it's interesting

2838
01:57:27,040 --> 01:57:30,480
 people ability misunderstand this the wright brothers

2839
01:57:30,480 --> 01:57:32,080
 um

2840
01:57:32,080 --> 01:57:34,800
 the problem they were trying to solve was controlled flight

2841
01:57:34,800 --> 01:57:36,719
 how to turn an airplane

2842
01:57:36,719 --> 01:57:39,599
 not how to propel an airplane they weren't worried about that interesting

2843
01:57:39,599 --> 01:57:42,880
 yeah they already had at that time there was already wing shapes

2844
01:57:42,880 --> 01:57:46,639
 which they had from studying birds there was already gliders that carry people

2845
01:57:46,639 --> 01:57:48,719
 the problem is if you put a rudder on the back of a glider

2846
01:57:48,719 --> 01:57:51,280
 and you turn it the plane falls out of the sky

2847
01:57:51,280 --> 01:57:54,239
 so the problem was how do you control flight

2848
01:57:54,239 --> 01:57:56,320
 and they studied birds

2849
01:57:56,320 --> 01:57:56,960
 and they

2850
01:57:56,960 --> 01:57:58,239
 actually had birds in captivity

2851
01:57:58,239 --> 01:57:59,679
 they watched birds in wind tunnels

2852
01:57:59,679 --> 01:58:00,800
 they observed in the wild

2853
01:58:00,800 --> 01:58:05,199
 and they discovered the secret was the birds twist their wings when they turn

2854
01:58:05,199 --> 01:58:06,719
 and so that's what they did on the wright brothers

2855
01:58:06,719 --> 01:58:08,400
 flyer they had these sticks you would twist

2856
01:58:08,400 --> 01:58:09,599
 the wing and that was

2857
01:58:09,599 --> 01:58:12,320
 that was their innovation not their propeller

2858
01:58:12,320 --> 01:58:13,760
 and today airplanes

2859
01:58:13,760 --> 01:58:14,880
 still twist their wings

2860
01:58:14,880 --> 01:58:15,920
 we don't twist the entire

2861
01:58:15,920 --> 01:58:18,000
 wing we just just the tail end of it

2862
01:58:18,000 --> 01:58:19,360
 the the the flaps

2863
01:58:19,360 --> 01:58:23,440
 which is the same thing so today's airplanes fly on the same principles as birds

2864
01:58:23,440 --> 01:58:26,159
 which is observed by so everyone get that analogy wrong

2865
01:58:26,159 --> 01:58:30,080
 but let's step back from that right once you understand

2866
01:58:30,080 --> 01:58:32,639
 the principles of flight you can choose

2867
01:58:32,639 --> 01:58:35,360
 how to implement them yeah no one's going to use bones

2868
01:58:35,360 --> 01:58:36,080
 and feathers

2869
01:58:36,080 --> 01:58:37,199
 and muscles

2870
01:58:37,199 --> 01:58:37,599
 um

2871
01:58:37,599 --> 01:58:39,119
 but they do have wings

2872
01:58:39,119 --> 01:58:41,360
 and we don't flap them we have propellers

2873
01:58:41,360 --> 01:58:44,000
 so when we have the principles of

2874
01:58:44,000 --> 01:58:47,760
 of computation that goes on to modeling the world in the brain

2875
01:58:47,760 --> 01:58:50,159
 we understand those principles very clearly

2876
01:58:50,159 --> 01:58:53,199
 we have choices on how to implement them and some of them will be biologically

2877
01:58:53,199 --> 01:58:54,400
 like and some won't

2878
01:58:54,400 --> 01:58:55,840
 and

2879
01:58:55,840 --> 01:58:56,719
 um

2880
01:58:56,719 --> 01:58:59,599
 but i do think there's going to be a huge amount of innovation here

2881
01:58:59,599 --> 01:59:03,920
 just think about the innovation we're in the computers they had to invent the the transistor

2882
01:59:03,920 --> 01:59:08,960
 they invented the the silicon ship they had the invent you know then this software

2883
01:59:08,960 --> 01:59:11,920
 i mean zillions of things they had to do memory systems

2884
01:59:11,920 --> 01:59:16,639
 um we're gonna do it's gonna be similar well it's interesting that the deep learning

2885
01:59:16,639 --> 01:59:17,840
 um

2886
01:59:17,840 --> 01:59:20,400
 the effectiveness of deep learning for a specific

2887
01:59:20,400 --> 01:59:23,119
 task is driving a lot of innovation in the hardware

2888
01:59:23,119 --> 01:59:25,520
 which may have effects

2889
01:59:25,520 --> 01:59:28,880
 for actually allowing us to discover

2890
01:59:28,880 --> 01:59:31,119
 intelligent systems that operate very differently

2891
01:59:31,119 --> 01:59:33,280
 or that's much bigger than deep learning yeah interesting

2892
01:59:33,280 --> 01:59:35,679
 so ultimately

2893
01:59:35,679 --> 01:59:38,320
 it's good to have an application that's making our life better

2894
01:59:38,320 --> 01:59:39,040
 now

2895
01:59:39,040 --> 01:59:41,760
 because the the the capitalist process

2896
01:59:41,760 --> 01:59:44,400
 if you can make money yeah yeah that works

2897
01:59:44,400 --> 01:59:45,440
 i mean the other way

2898
01:59:45,440 --> 01:59:48,080
 i mean neil degrasse tyson writes about this

2899
01:59:48,080 --> 01:59:51,440
 is the other way we fund science of course is through military

2900
01:59:51,440 --> 01:59:53,360
 so like yeah conquest

2901
01:59:53,360 --> 01:59:56,239
 so here here's an interesting thing we're doing on this regard

2902
01:59:56,239 --> 01:59:59,599
 so we've decided we we used to have a series these biological principles

2903
01:59:59,599 --> 02:00:02,000
 and we can see how to build these intelligent machines

2904
02:00:02,000 --> 02:00:07,280
 but we've decided to apply some of these principles to today's machine learning techniques

2905
02:00:07,280 --> 02:00:11,760
 so one of the we didn't talk about this principle one is sparsity in the brain

2906
02:00:11,760 --> 02:00:12,239
 um

2907
02:00:12,239 --> 02:00:15,119
 most of the neurons are active at any point in time as far as and the connectivity

2908
02:00:15,119 --> 02:00:17,760
 is sparse and that's different than deep learning networks

2909
02:00:17,760 --> 02:00:18,560
 um

2910
02:00:18,560 --> 02:00:23,280
 so we've already shown that we can speed up existing deep learning networks

2911
02:00:23,280 --> 02:00:26,159
 anywhere from 10 to a factor of 100

2912
02:00:26,159 --> 02:00:28,239
 i mean literally 100

2913
02:00:28,239 --> 02:00:30,400
 and make it more robust at the same time

2914
02:00:30,400 --> 02:00:33,040
 so this is commercially very very valuable

2915
02:00:33,040 --> 02:00:33,840
 um

2916
02:00:33,840 --> 02:00:34,560
 and

2917
02:00:34,560 --> 02:00:35,280
 so

2918
02:00:35,280 --> 02:00:40,800
 you know if we can prove this actually in the larger systems that are commercially applied today

2919
02:00:40,800 --> 02:00:42,719
 there's a big commercial

2920
02:00:42,719 --> 02:00:49,520
 desire to do this well sparsity is something that doesn't run really well on existing

2921
02:00:49,520 --> 02:00:53,520
 hardware it doesn't really run really well on gpus

2922
02:00:53,520 --> 02:00:54,320
 um

2923
02:00:54,320 --> 02:00:55,920
 and on cpus

2924
02:00:55,920 --> 02:00:56,960
 and so

2925
02:00:56,960 --> 02:00:59,520
 that would be a way of sort of bringing more and

2926
02:00:59,520 --> 02:01:03,920
 more brain principles into the existing system on a on a commercially valuable basis

2927
02:01:03,920 --> 02:01:07,599
 another thing we can think we can do is we're going to use the dendrites

2928
02:01:07,599 --> 02:01:09,760
 models of we

2929
02:01:09,760 --> 02:01:13,199
 i talked earlier about the the prediction occurring inside of neuron

2930
02:01:13,199 --> 02:01:17,119
 that that basic property can be applied to existing neural networks

2931
02:01:17,119 --> 02:01:18,960
 and allow them to learn continuously

2932
02:01:18,960 --> 02:01:20,719
 which something they don't do today

2933
02:01:20,719 --> 02:01:23,599
 and so

2934
02:01:23,599 --> 02:01:26,960
 yeah well we wouldn't model this spikes but the idea that you have

2935
02:01:26,960 --> 02:01:29,840
 that neuro today's neural networks have something called the point neuron

2936
02:01:29,840 --> 02:01:31,920
 which is a very simple model of a neuron

2937
02:01:31,920 --> 02:01:36,639
 and by adding dendrites to them with just one more level of complexity

2938
02:01:36,639 --> 02:01:40,719
 that's in biological systems you can solve problems in continuous learning

2939
02:01:40,719 --> 02:01:41,520
 um

2940
02:01:41,520 --> 02:01:43,119
 and rapid learning

2941
02:01:43,119 --> 02:01:47,760
 so we're trying to take we're trying to bring the existing field

2942
02:01:47,760 --> 02:01:49,679
 and we'll see if we can do it we're trying to bring the existing

2943
02:01:49,679 --> 02:01:52,239
 field of machine learning

2944
02:01:52,239 --> 02:01:52,800
 commercially

2945
02:01:52,800 --> 02:01:56,480
 along with us you brought up this idea of keeping you know paying for it commercially

2946
02:01:56,480 --> 02:02:00,320
 along with us as we move towards the ultimate goal of a true ai system

2947
02:02:00,320 --> 02:02:04,000
 even small innovations on neural networks are really really exciting

2948
02:02:04,000 --> 02:02:04,480
 yeah

2949
02:02:04,480 --> 02:02:08,800
 because it seems like such a trivial model of the brain

2950
02:02:08,800 --> 02:02:11,920
 and applying different insights

2951
02:02:11,920 --> 02:02:15,199
 that just even like you said continuous learning

2952
02:02:15,199 --> 02:02:19,360
 or making it more asynchronous

2953
02:02:19,360 --> 02:02:22,239
 or maybe making more dynamic

2954
02:02:22,239 --> 02:02:24,719
 or like incentivizing

2955
02:02:24,719 --> 02:02:27,599
 making it fast even just from robots

2956
02:02:27,599 --> 02:02:31,199
 and making it somehow much better

2957
02:02:31,199 --> 02:02:33,920
 incentivizing sparsity somehow

2958
02:02:33,920 --> 02:02:39,599
 yeah well if you can make things 100 times faster then there's plenty of incentive

2959
02:02:39,599 --> 02:02:43,280
 people people spending millions of dollars you know just training some of these networks

2960
02:02:43,280 --> 02:02:46,880
 now these these transformer networks

2961
02:02:46,880 --> 02:02:48,560
 let me ask you a big question

2962
02:02:48,560 --> 02:02:52,880
 how for young people listening to this today in high school

2963
02:02:52,880 --> 02:02:53,520
 and college

2964
02:02:53,520 --> 02:02:58,880
 what advice would you give them in terms of which career path to take

2965
02:02:58,880 --> 02:02:59,199
 and

2966
02:02:59,199 --> 02:03:00,400
 um

2967
02:03:00,400 --> 02:03:03,119
 maybe just about life in general

2968
02:03:03,119 --> 02:03:04,960
 well in my case

2969
02:03:04,960 --> 02:03:06,159
 um

2970
02:03:06,159 --> 02:03:08,639
 i didn't start life with any kind of goals

2971
02:03:08,639 --> 02:03:10,000
 i was when i was going to college

2972
02:03:10,000 --> 02:03:11,360
 i was like oh what did i say well

2973
02:03:11,360 --> 02:03:12,239
 maybe i'll do electrical

2974
02:03:12,239 --> 02:03:14,000
 engineering stuff you know

2975
02:03:14,000 --> 02:03:15,119
 um

2976
02:03:15,119 --> 02:03:17,679
 it wasn't like you know today you see some of these young kids are so motivated

2977
02:03:17,679 --> 02:03:21,280
 they're going to change the world i was like you know whatever

2978
02:03:21,280 --> 02:03:21,760
 and

2979
02:03:21,760 --> 02:03:22,639
 um

2980
02:03:22,639 --> 02:03:25,119
 but then i did fall in love with something

2981
02:03:25,119 --> 02:03:27,920
 besides my wife but i fell in love with this like

2982
02:03:27,920 --> 02:03:29,599
 oh my god it would be so cool to understand

2983
02:03:29,599 --> 02:03:30,800
 how the brain works

2984
02:03:30,800 --> 02:03:31,360
 and then i

2985
02:03:31,360 --> 02:03:33,920
 i said to myself that's the most important thing i could work on

2986
02:03:33,920 --> 02:03:35,599
 i i can't imagine anything more important

2987
02:03:35,599 --> 02:03:36,639
 because if we understand

2988
02:03:36,639 --> 02:03:38,239
 how brains work you'd build telescope machines

2989
02:03:38,239 --> 02:03:41,119
 and they could figure out all the other big questions of the world right

2990
02:03:41,119 --> 02:03:41,840
 so

2991
02:03:41,840 --> 02:03:43,280
 and then i said i want to understand

2992
02:03:43,280 --> 02:03:45,199
 how i work so i fell in love with this idea

2993
02:03:45,199 --> 02:03:47,599
 and i became passionate about it

2994
02:03:47,599 --> 02:03:49,119
 and

2995
02:03:49,119 --> 02:03:52,800
 this is you know a trope people say this but it was it's true

2996
02:03:52,800 --> 02:03:56,960
 because i was passionate about it i was able to put up almost

2997
02:03:56,960 --> 02:03:58,400
 so much crap

2998
02:03:58,400 --> 02:03:59,360
 you know

2999
02:03:59,360 --> 02:04:02,400
 you know i was i was in that you know i was like person

3000
02:04:02,400 --> 02:04:03,840
 said you can't do this i was

3001
02:04:03,840 --> 02:04:05,199
 i was a graduate student at berkeley

3002
02:04:05,199 --> 02:04:07,040
 when they said you can't study this problem

3003
02:04:07,040 --> 02:04:10,480
 you know no one's gonna solve this or you can't get funded for it you know

3004
02:04:10,480 --> 02:04:12,320
 then i went to do you know mobile computing

3005
02:04:12,320 --> 02:04:15,760
 and it was like people say you can't do that you can't build a cell phone

3006
02:04:15,760 --> 02:04:16,320
 you know

3007
02:04:16,320 --> 02:04:16,960
 so

3008
02:04:16,960 --> 02:04:18,880
 but all along i kept being motivated

3009
02:04:18,880 --> 02:04:20,400
 because i wanted to work on this problem

3010
02:04:20,400 --> 02:04:21,599
 i said i want to understand

3011
02:04:21,599 --> 02:04:23,119
 the brain works and if i got myself

3012
02:04:23,119 --> 02:04:24,400
 male i got one lifetime

3013
02:04:24,400 --> 02:04:26,880
 i'm gonna figure it out do the best i can

3014
02:04:26,880 --> 02:04:29,280
 so by having that

3015
02:04:29,280 --> 02:04:30,880
 because you know these it's really

3016
02:04:30,880 --> 02:04:32,800
 as you point out lex it's really hard to

3017
02:04:32,800 --> 02:04:34,480
 do these things people it's just

3018
02:04:34,480 --> 02:04:36,880
 there's so many downers along the way

3019
02:04:36,880 --> 02:04:38,960
 so many ways obstacles are getting your way yeah

3020
02:04:38,960 --> 02:04:42,480
 i'm sitting here happy all the time but trust me it's not always like that that's

3021
02:04:42,480 --> 02:04:43,679
 i guess the the happiness

3022
02:04:43,679 --> 02:04:46,159
 that the the passion is a prerequisite

3023
02:04:46,159 --> 02:04:47,599
 for surviving the whole

3024
02:04:47,599 --> 02:04:49,679
 yeah i think so i think that's right

3025
02:04:49,679 --> 02:04:50,400
 um

3026
02:04:50,400 --> 02:04:51,040
 and

3027
02:04:51,040 --> 02:04:51,840
 so i i

3028
02:04:51,840 --> 02:04:54,239
 don't want to sit to someone and say you know you need to find a passion

3029
02:04:54,239 --> 02:04:56,000
 and do it no maybe you don't

3030
02:04:56,000 --> 02:04:59,840
 but if you do find something you're passionate about then

3031
02:04:59,840 --> 02:05:03,119
 then you can follow it as far as your passion will

3032
02:05:03,119 --> 02:05:04,480
 let you put up with it do you remember

3033
02:05:04,480 --> 02:05:06,159
 how you found it this is

3034
02:05:06,159 --> 02:05:09,199
 how the spark happened

3035
02:05:09,199 --> 02:05:10,800
 why specifically for me

3036
02:05:10,800 --> 02:05:13,360
 yeah like because you said it's such an interesting

3037
02:05:13,360 --> 02:05:14,800
 so like almost like later in life

3038
02:05:14,800 --> 02:05:17,360
 by later i mean like not in when you were five

3039
02:05:17,360 --> 02:05:20,000
 yeah you you didn't really know

3040
02:05:20,000 --> 02:05:22,320
 and then all of a sudden you fell in love with that yeah yeah

3041
02:05:22,320 --> 02:05:26,560
 there was there was there's two separate events that compounded one another one

3042
02:05:26,560 --> 02:05:28,960
 when i was probably a teenager might have been 17

3043
02:05:28,960 --> 02:05:29,920
 or 18.

3044
02:05:29,920 --> 02:05:34,079
 i made a list of the most interesting problems i could think of

3045
02:05:34,079 --> 02:05:38,480
 first was why does the universe exist it seems like not existing is more likely

3046
02:05:38,480 --> 02:05:38,800
 yeah

3047
02:05:38,800 --> 02:05:41,599
 the second one was well given exists why does it behave the way it does

3048
02:05:41,599 --> 02:05:42,800
 you know it's laws of physics

3049
02:05:42,800 --> 02:05:45,679
 y is equal to m c squared not m c cubed you know attention

3050
02:05:45,679 --> 02:05:46,960
 question i don't know

3051
02:05:46,960 --> 02:05:49,679
 third one was like what's the origin of life

3052
02:05:49,679 --> 02:05:50,159
 um

3053
02:05:50,159 --> 02:05:52,639
 and the fourth one was what's intelligence

3054
02:05:52,639 --> 02:05:56,000
 and i stopped there i said well that's probably the most interesting one

3055
02:05:56,000 --> 02:05:57,679
 and i put that aside

3056
02:05:57,679 --> 02:05:58,880
 um as a teenager

3057
02:05:58,880 --> 02:06:01,520
 but then when i was 22

3058
02:06:01,520 --> 02:06:03,040
 and i was reading the

3059
02:06:03,040 --> 02:06:04,159
 um

3060
02:06:04,159 --> 02:06:08,239
 no it was excuse me i was 70 it was 1979 excuse me 1979

3061
02:06:08,239 --> 02:06:09,360
 i was reading

3062
02:06:09,360 --> 02:06:12,960
 so i was at that time i was 22. i was reading

3063
02:06:12,960 --> 02:06:14,480
 the september issue of scientific american

3064
02:06:14,480 --> 02:06:16,480
 which is all about the brain

3065
02:06:16,480 --> 02:06:18,560
 and then the final essay

3066
02:06:18,560 --> 02:06:22,239
 was by francis crick who of dna fame

3067
02:06:22,239 --> 02:06:25,440
 and he had taken his interest to studying the brain now

3068
02:06:25,440 --> 02:06:27,440
 and he said you know

3069
02:06:27,440 --> 02:06:31,679
 there's something wrong here he says we got all this data

3070
02:06:31,679 --> 02:06:35,280
 oh this fact this is 1979 all these facts about the brain tons

3071
02:06:35,280 --> 02:06:37,520
 and tons of facts about the brain

3072
02:06:37,520 --> 02:06:39,040
 do we need more facts

3073
02:06:39,040 --> 02:06:41,040
 or do we just need to think about a way of rearranging

3074
02:06:41,040 --> 02:06:44,719
 the facts we have maybe we're just not thinking about the problem correctly

3075
02:06:44,719 --> 02:06:45,920
 you know

3076
02:06:45,920 --> 02:06:50,159
 because he says this shouldn't be it shouldn't be like this you know

3077
02:06:50,159 --> 02:06:52,639
 so i read that and i said wow

3078
02:06:52,639 --> 02:06:53,920
 i said

3079
02:06:53,920 --> 02:06:56,880
 i don't have to become like an experimental neuroscientist

3080
02:06:56,880 --> 02:06:59,840
 i could just look at all those facts

3081
02:06:59,840 --> 02:07:01,760
 and try to and become a theoretician

3082
02:07:01,760 --> 02:07:03,599
 and try to figure it out

3083
02:07:03,599 --> 02:07:04,800
 and i said that

3084
02:07:04,800 --> 02:07:06,960
 i felt like it was something i would be good at

3085
02:07:06,960 --> 02:07:08,719
 i said i wouldn't be a good experimentalist

3086
02:07:08,719 --> 02:07:10,480
 i don't have the patience for it

3087
02:07:10,480 --> 02:07:12,320
 but i'm a good thinker

3088
02:07:12,320 --> 02:07:13,760
 and i love puzzles

3089
02:07:13,760 --> 02:07:14,719
 and this is like the biggest

3090
02:07:14,719 --> 02:07:16,159
 puzzle in the world it's the biggest

3091
02:07:16,159 --> 02:07:17,440
 puzzle of all time

3092
02:07:17,440 --> 02:07:20,079
 and i got all the puzzle pieces in front of me

3093
02:07:20,079 --> 02:07:21,440
 damn that was exciting

3094
02:07:21,440 --> 02:07:27,760
 and there's something obviously you can't convert it towards it just kind of sparked this passion

3095
02:07:27,760 --> 02:07:31,040
 and i have that a few times in my life just something

3096
02:07:31,040 --> 02:07:31,920
 um

3097
02:07:31,920 --> 02:07:35,840
 yeah just just like you it grabs you

3098
02:07:35,840 --> 02:07:40,000
 yeah i thought it was something that was both important that i could make a contribution to

3099
02:07:40,000 --> 02:07:40,320
 yeah

3100
02:07:40,320 --> 02:07:41,679
 and so all of a sudden it felt like

3101
02:07:41,679 --> 02:07:43,119
 oh it gave me purpose in life

3102
02:07:43,119 --> 02:07:43,599
 yeah

3103
02:07:43,599 --> 02:07:44,400
 you know i honestly

3104
02:07:44,400 --> 02:07:46,000
 don't think it has to be as big

3105
02:07:46,000 --> 02:07:47,679
 as one of those four questions

3106
02:07:47,679 --> 02:07:51,360
 no no i think you can find those things in in the smallest

3107
02:07:51,360 --> 02:07:53,199
 oh absolutely i'm with

3108
02:07:53,199 --> 02:07:57,040
 david foster wallace said like the key to life is to be unborable i'm

3109
02:07:57,040 --> 02:07:59,040
 i think i think it's very

3110
02:07:59,040 --> 02:08:03,119
 possible to find that intensity of joy in the smallest absolutely

3111
02:08:03,119 --> 02:08:04,639
 i'm just you asked me my story

3112
02:08:04,639 --> 02:08:07,280
 yeah yeah i'm actually speaking to the audience

3113
02:08:07,280 --> 02:08:08,960
 yeah it doesn't have to be those four

3114
02:08:08,960 --> 02:08:10,400
 you happen to get excited

3115
02:08:10,400 --> 02:08:13,440
 by one of the bigger questions of

3116
02:08:13,440 --> 02:08:14,320
 in the universe

3117
02:08:14,320 --> 02:08:17,199
 but but that even the smallest things

3118
02:08:17,199 --> 02:08:18,320
 and watching the olympics

3119
02:08:18,320 --> 02:08:24,560
 now just just giving yourself life giving your life over to the study

3120
02:08:24,560 --> 02:08:27,520
 and the mastery of a particular sport is fascinating

3121
02:08:27,520 --> 02:08:28,000
 and

3122
02:08:28,000 --> 02:08:30,880
 and if if it sparks joy

3123
02:08:30,880 --> 02:08:33,679
 and passion you're able to in the case of the olympics

3124
02:08:33,679 --> 02:08:36,480
 basically suffer for like a couple of decades to achieve

3125
02:08:36,480 --> 02:08:38,719
 i mean you can find joint passion just being a parent

3126
02:08:38,719 --> 02:08:39,199
 i mean

3127
02:08:39,199 --> 02:08:39,760
 yeah

3128
02:08:39,760 --> 02:08:41,360
 yeah the the parenting one is funny

3129
02:08:41,360 --> 02:08:43,599
 so i always not always

3130
02:08:43,599 --> 02:08:45,360
 but for a long time wanted kids

3131
02:08:45,360 --> 02:08:46,400
 and get married

3132
02:08:46,400 --> 02:08:49,599
 and stuff and especially that has to do with the fact that

3133
02:08:49,599 --> 02:08:51,679
 i've seen a lot of people

3134
02:08:51,679 --> 02:08:53,440
 that i respect

3135
02:08:53,440 --> 02:08:56,320
 get a whole other level of joy

3136
02:08:56,320 --> 02:08:57,360
 from kids

3137
02:08:57,360 --> 02:08:58,880
 and you know

3138
02:08:58,880 --> 02:09:00,400
 at first is like

3139
02:09:00,400 --> 02:09:02,719
 your thinking is well

3140
02:09:02,719 --> 02:09:05,040
 like i don't have enough time in the day

3141
02:09:05,040 --> 02:09:07,280
 right if i have this passion

3142
02:09:07,280 --> 02:09:08,480
 which is true

3143
02:09:08,480 --> 02:09:09,280
 yes

3144
02:09:09,280 --> 02:09:11,360
 but like if i want to solve intelligence

3145
02:09:11,360 --> 02:09:14,079
 how is this kids situation gonna help me

3146
02:09:14,079 --> 02:09:16,000
 but then you realize

3147
02:09:16,000 --> 02:09:22,000
 that you know like you said the things that sparks joy

3148
02:09:22,000 --> 02:09:24,639
 and it's very possible that kids

3149
02:09:24,639 --> 02:09:26,079
 can provide even a greater

3150
02:09:26,079 --> 02:09:29,840
 or deeper more meaningful joy than those bigger questions

3151
02:09:29,840 --> 02:09:31,840
 yeah when they they enrich each other

3152
02:09:31,840 --> 02:09:36,480
 and that that seemed like um obviously when i was younger it's probably a counter-intuitive notion

3153
02:09:36,480 --> 02:09:38,560
 because there's only so many hours in the day

3154
02:09:38,560 --> 02:09:40,159
 but then life is finite

3155
02:09:40,159 --> 02:09:44,159
 and you have to pick the things that give give you joy

3156
02:09:44,159 --> 02:09:44,719
 yeah

3157
02:09:44,719 --> 02:09:49,840
 but you know also you understand you you can be patient too i mean it's finite

3158
02:09:49,840 --> 02:09:52,960
 but we do have you know whatever 50 years or so it's not so long

3159
02:09:52,960 --> 02:09:53,360
 yeah

3160
02:09:53,360 --> 02:09:53,920
 so

3161
02:09:53,920 --> 02:09:54,960
 so in my case

3162
02:09:54,960 --> 02:09:55,920
 you know in my case

3163
02:09:55,920 --> 02:09:58,480
 i had to give up on my dream of the neuroscience

3164
02:09:58,480 --> 02:10:00,560
 because i i was a graduate student at berkeley

3165
02:10:00,560 --> 02:10:02,800
 and they told me i couldn't do this and i couldn't get funded

3166
02:10:02,800 --> 02:10:03,760
 and you know

3167
02:10:03,760 --> 02:10:04,560
 and

3168
02:10:04,560 --> 02:10:06,560
 and so i went back in

3169
02:10:06,560 --> 02:10:09,119
 and went back in the computing industry for a number of years

3170
02:10:09,119 --> 02:10:11,280
 i thought it would be four but it turned out to be more

3171
02:10:11,280 --> 02:10:13,440
 but i said but i said i'll come back

3172
02:10:13,440 --> 02:10:14,320
 you know i definitely

3173
02:10:14,320 --> 02:10:16,400
 i'm definitely gonna come back i know i'm gonna do this computer

3174
02:10:16,400 --> 02:10:17,440
 stuff for a while but i'm definitely

3175
02:10:17,440 --> 02:10:19,280
 coming back everyone knows that

3176
02:10:19,280 --> 02:10:20,560
 and it's they moved like raising

3177
02:10:20,560 --> 02:10:21,840
 kids well yeah you still

3178
02:10:21,840 --> 02:10:24,480
 you have to spend a lot of time with your kids it's fun enjoyable

3179
02:10:24,480 --> 02:10:25,119
 um

3180
02:10:25,119 --> 02:10:28,000
 but that doesn't mean you have to give up on other dreams

3181
02:10:28,000 --> 02:10:28,880
 it just means that you

3182
02:10:28,880 --> 02:10:33,840
 may have to wait a week or two to work on that next idea well

3183
02:10:33,840 --> 02:10:36,400
 you talked about the

3184
02:10:36,400 --> 02:10:40,800
 the the darker side of me disappointing sides of human nature that we're

3185
02:10:40,800 --> 02:10:41,760
 hoping to overcome

3186
02:10:41,760 --> 02:10:46,800
 so that we don't destroy ourselves i tend to put a lot of value in um

3187
02:10:46,800 --> 02:10:52,800
 the broad general concept of love of the human capacity to

3188
02:10:52,800 --> 02:10:55,360
 um of compassion

3189
02:10:55,360 --> 02:11:01,280
 towards each other of just kindness whatever that longing of like just the human human to human connection

3190
02:11:01,280 --> 02:11:05,119
 yeah it connects back to our initial discussion i tend to

3191
02:11:05,119 --> 02:11:07,360
 see a lot of value in this collective intelligence

3192
02:11:07,360 --> 02:11:10,639
 aspect i think some of the magic of human civilization

3193
02:11:10,639 --> 02:11:14,719
 happens when there's a party is not as fun when it you're alone

3194
02:11:14,719 --> 02:11:18,960
 yeah i totally agree with you on these issues do you think

3195
02:11:18,960 --> 02:11:22,480
 from a neurocortex perspective

3196
02:11:22,480 --> 02:11:25,199
 what role does love play in the human condition

3197
02:11:25,199 --> 02:11:28,320
 well those are two separate things from a new project

3198
02:11:28,320 --> 02:11:32,320
 i don't think it doesn't impact our thinking about human about the neocortex

3199
02:11:32,320 --> 02:11:35,040
 from a human condition point of view i think it's core

3200
02:11:35,040 --> 02:11:36,400
 um

3201
02:11:36,400 --> 02:11:39,280
 i mean we get

3202
02:11:39,280 --> 02:11:41,119
 so much pleasure out of loving people

3203
02:11:41,119 --> 02:11:42,880
 and helping people

3204
02:11:42,880 --> 02:11:44,320
 um

3205
02:11:44,320 --> 02:11:44,960
 so

3206
02:11:44,960 --> 02:11:46,400
 you know i can i'll rack

3207
02:11:46,400 --> 02:11:47,280
 it up to old brain

3208
02:11:47,280 --> 02:11:50,320
 stuff and maybe you can throw it under the the bust of evolution

3209
02:11:50,320 --> 02:11:50,880
 if you want

3210
02:11:50,880 --> 02:11:52,159
 um

3211
02:11:52,159 --> 02:11:53,040
 that's fine

3212
02:11:53,040 --> 02:11:58,320
 um it doesn't impact how i think about how we model the world

3213
02:11:58,320 --> 02:12:00,800
 but from a humanity point of view i think it's essential

3214
02:12:00,800 --> 02:12:03,520
 well i tend to give it to the new brain

3215
02:12:03,520 --> 02:12:09,840
 and also i tend to think that some of aspects of that need to be engineered into ai systems

3216
02:12:09,840 --> 02:12:12,320
 both in their

3217
02:12:12,320 --> 02:12:16,079
 ability to have compassion for other humans

3218
02:12:16,079 --> 02:12:20,480
 and their ability to maximize

3219
02:12:20,480 --> 02:12:22,639
 love in the world between humans

3220
02:12:22,639 --> 02:12:24,960
 so i'm more thinking about the social network

3221
02:12:24,960 --> 02:12:28,159
 so like whenever there's a deep integration between ai systems

3222
02:12:28,159 --> 02:12:28,880
 and humans

3223
02:12:28,880 --> 02:12:30,400
 so specific applications

3224
02:12:30,400 --> 02:12:32,079
 where it's ai

3225
02:12:32,079 --> 02:12:35,119
 and humans i think that's something that

3226
02:12:35,119 --> 02:12:38,880
 often not talked about in terms of um

3227
02:12:38,880 --> 02:12:40,079
 metrics

3228
02:12:40,079 --> 02:12:41,760
 over which you

3229
02:12:41,760 --> 02:12:44,480
 try to maximize

3230
02:12:44,480 --> 02:12:50,000
 like which metric to maximize in a system it seems like one of the most powerful

3231
02:12:50,000 --> 02:12:54,560
 things in societies is the capacity

3232
02:12:54,560 --> 02:12:58,400
 to work it's fascinating i think it's it's a great way of thinking about it

3233
02:12:58,400 --> 02:13:00,079
 you know i have

3234
02:13:00,079 --> 02:13:01,840
 i have been thinking more of these fundamental

3235
02:13:01,840 --> 02:13:05,679
 mechanisms in the brain as opposed to the social interaction between

3236
02:13:05,679 --> 02:13:06,639
 the interaction between humans

3237
02:13:06,639 --> 02:13:07,920
 and ai systems in the future

3238
02:13:07,920 --> 02:13:08,800
 which is

3239
02:13:08,800 --> 02:13:11,199
 and i think if you think about that you're absolutely right

3240
02:13:11,199 --> 02:13:12,239
 um

3241
02:13:12,239 --> 02:13:16,400
 but that's that's a complex system i can have intelligent systems that don't have that component

3242
02:13:16,400 --> 02:13:18,960
 but they're not interacting with people you know they're just running something

3243
02:13:18,960 --> 02:13:20,719
 or building a building someplace

3244
02:13:20,719 --> 02:13:22,239
 or something i don't know

3245
02:13:22,239 --> 02:13:22,960
 um

3246
02:13:22,960 --> 02:13:24,960
 but if you think about interacting with humans

3247
02:13:24,960 --> 02:13:26,480
 yeah it's it's gonna

3248
02:13:26,480 --> 02:13:27,840
 and then but it has to be engineered

3249
02:13:27,840 --> 02:13:30,800
 in there i don't think it's gonna appear on its own

3250
02:13:30,800 --> 02:13:32,400
 that's a good question i

3251
02:13:32,400 --> 02:13:34,960
 yeah well we could

3252
02:13:34,960 --> 02:13:41,599
 in terms of uh from a reinforcement learning perspective

3253
02:13:41,599 --> 02:13:45,040
 whether the darker sides of human nature

3254
02:13:45,040 --> 02:13:48,079
 or the better angels of our nature win out

3255
02:13:48,079 --> 02:13:51,599
 yeah statistically speaking i don't know i tend to be optimistic

3256
02:13:51,599 --> 02:13:53,840
 and hope that love wins out in the end

3257
02:13:53,840 --> 02:13:56,960
 um you've done a lot of incredible stuff

3258
02:13:56,960 --> 02:14:06,400
 and your book is driving towards this fourth question that you started with on the nature of intelligence

3259
02:14:06,400 --> 02:14:08,880
 what do you hope your legacy

3260
02:14:08,880 --> 02:14:13,199
 for people reading a hundred years from now

3261
02:14:13,199 --> 02:14:14,880
 how do you hope they remember your work

3262
02:14:14,880 --> 02:14:17,280
 how do you hope they remember this book

3263
02:14:17,280 --> 02:14:19,679
 well i think as an entrepreneur

3264
02:14:19,679 --> 02:14:20,639
 or scientist

3265
02:14:20,639 --> 02:14:24,480
 or any human who's trying to accomplish some things

3266
02:14:24,480 --> 02:14:26,800
 i have a view that

3267
02:14:26,800 --> 02:14:30,480
 really all you can do is accelerate the inevitable

3268
02:14:30,480 --> 02:14:31,199
 um

3269
02:14:31,199 --> 02:14:32,800
 yeah it's like you know

3270
02:14:32,800 --> 02:14:33,760
 if we didn't figure out

3271
02:14:33,760 --> 02:14:34,719
 if we didn't study the brain

3272
02:14:34,719 --> 02:14:35,679
 someone else would study the brain

3273
02:14:35,679 --> 02:14:37,119
 if you know if elon just

3274
02:14:37,119 --> 02:14:39,520
 didn't make electric cars someone else would do it eventually

3275
02:14:39,520 --> 02:14:41,119
 and if you know if thomas anderson

3276
02:14:41,119 --> 02:14:44,079
 didn't invent a light bulb we wouldn't be using candles today

3277
02:14:44,079 --> 02:14:45,199
 so

3278
02:14:45,199 --> 02:14:48,880
 what you can do as an individual is you can accelerate

3279
02:14:48,880 --> 02:14:50,800
 something that's beneficial

3280
02:14:50,800 --> 02:14:54,639
 and make it happen sooner than whatever that's that's really it that's all you can do

3281
02:14:54,639 --> 02:14:58,960
 um you can't create a new reality that it wasn't gonna happen

3282
02:14:58,960 --> 02:14:59,679
 um

3283
02:14:59,679 --> 02:15:02,159
 so from that perspective

3284
02:15:02,159 --> 02:15:06,960
 um i would hope that our work not just me but our work in general

3285
02:15:06,960 --> 02:15:09,119
 um people would look back and said

3286
02:15:09,119 --> 02:15:12,400
 hey they really helped make this better future happen sooner

3287
02:15:12,400 --> 02:15:14,159
 um they

3288
02:15:14,159 --> 02:15:16,320
 you know they helped us understand

3289
02:15:16,320 --> 02:15:18,079
 the nature of false beliefs sooner than

3290
02:15:18,079 --> 02:15:20,239
 we met up they made it now we're so happy

3291
02:15:20,239 --> 02:15:21,280
 that we have these intelligent machines

3292
02:15:21,280 --> 02:15:22,719
 doing these things helping us

3293
02:15:22,719 --> 02:15:25,599
 that that maybe that solved the climate change problem

3294
02:15:25,599 --> 02:15:28,000
 and they made it happen sooner

3295
02:15:28,000 --> 02:15:32,719
 so i think that's the best i would hope for some would say those guys just

3296
02:15:32,719 --> 02:15:35,679
 moved the needle forward a little bit in time

3297
02:15:35,679 --> 02:15:41,360
 well i do it it feels like the progress of human civilization is not

3298
02:15:41,360 --> 02:15:44,159
 is there's a lot of trajectories

3299
02:15:44,159 --> 02:15:44,560
 and

3300
02:15:44,560 --> 02:15:48,480
 if you have individuals that accelerate

3301
02:15:48,480 --> 02:15:51,920
 towards one direction that helps steer human civilization

3302
02:15:51,920 --> 02:15:55,920
 so i think in this long stretch of time all

3303
02:15:55,920 --> 02:15:57,679
 all trajectories will be traveled

3304
02:15:57,679 --> 02:16:00,800
 but i think it's nice for this particular civilization

3305
02:16:00,800 --> 02:16:01,679
 on earth to travel

3306
02:16:01,679 --> 02:16:04,400
 down one that's not yeah well i think you're right i mean look we have the

3307
02:16:04,400 --> 02:16:06,800
 take the whole period of you know world war ii nazism

3308
02:16:06,800 --> 02:16:09,520
 or something like that well that was a bad sidestep right

3309
02:16:09,520 --> 02:16:11,199
 went over there for a while

3310
02:16:11,199 --> 02:16:14,000
 but you know there is the optimistic view about life that

3311
02:16:14,000 --> 02:16:16,639
 um that ultimately it does converge

3312
02:16:16,639 --> 02:16:22,159
 in a positive way it progresses ultimately even if we have years of darkness

3313
02:16:22,159 --> 02:16:22,880
 um

3314
02:16:22,880 --> 02:16:24,079
 so

3315
02:16:24,079 --> 02:16:24,400
 yeah

3316
02:16:24,400 --> 02:16:26,079
 so i think you can perhaps

3317
02:16:26,079 --> 02:16:31,760
 that's accelerating the positive it could also mean eliminating some bad missteps along the way too

3318
02:16:31,760 --> 02:16:32,558
 um

3319
02:16:32,558 --> 02:16:33,280
 but

3320
02:16:33,280 --> 02:16:34,000
 but i i'm

3321
02:16:34,000 --> 02:16:38,478
 an optimistic in that way i was like you know despite we talked about the end of civilization

3322
02:16:38,478 --> 02:16:42,000
 you know i i think we're gonna live for a long time i hope we are

3323
02:16:42,000 --> 02:16:42,478
 um

3324
02:16:42,478 --> 02:16:45,200
 i think our society in the future is gonna be better we're gonna have less discord

3325
02:16:45,200 --> 02:16:46,398
 we're gonna have less people killing

3326
02:16:46,398 --> 02:16:47,519
 each other you know we'll solve

3327
02:16:47,519 --> 02:16:48,718
 you know we'll make the

3328
02:16:48,718 --> 02:16:52,879
 they'll live in some sort of way that's compatible with the carrying capacity of the earth

3329
02:16:52,879 --> 02:16:56,000
 um i'm optimistic these things will happen

3330
02:16:56,000 --> 02:16:58,558
 and all we can do is try to get there sooner

3331
02:16:58,558 --> 02:17:04,160
 and at the very least if we do destroy ourselves we'll have a few satellites

3332
02:17:04,638 --> 02:17:08,478
 i will that will tell alien civilization that we were once

3333
02:17:08,478 --> 02:17:13,439
 or maybe our future you know future inhabitants of earth you know imagine

3334
02:17:13,439 --> 02:17:14,000
 you know

3335
02:17:14,000 --> 02:17:16,879
 the planet of the apes scenario you know we kill ourselves in a you know million

3336
02:17:16,879 --> 02:17:19,040
 years from now or billion years from now there's another species

3337
02:17:19,040 --> 02:17:20,160
 on the planet curious

3338
02:17:20,160 --> 02:17:21,679
 creatures were once here

3339
02:17:21,679 --> 02:17:22,080
 yeah

3340
02:17:22,080 --> 02:17:24,398
 um jeff thank you so much for your work

3341
02:17:24,398 --> 02:17:24,718
 and

3342
02:17:24,718 --> 02:17:25,120
 um

3343
02:17:25,120 --> 02:17:27,439
 thank you so much for talking to me once again

3344
02:17:27,439 --> 02:17:30,080
 well it's great i love what you do i love your podcast

3345
02:17:30,080 --> 02:17:34,240
 you have the most interesting people me aside

3346
02:17:34,240 --> 02:17:35,760
 so

3347
02:17:35,760 --> 02:17:38,080
 it's a real service i think you do for

3348
02:17:38,080 --> 02:17:42,959
 a very broader sense for humanity i think thanks jeff all right pleasure

3349
02:17:42,959 --> 02:17:45,599
 thanks for listening to this conversation with jeff hawkins

3350
02:17:45,599 --> 02:17:47,920
 and thank you to codeacademy

3351
02:17:47,920 --> 02:17:51,439
 bio optimizers expressvpn asleep

3352
02:17:51,439 --> 02:17:56,638
 and blinkist check them out in the description to support this podcast

3353
02:17:56,638 --> 02:18:01,040
 and now let me leave you with some words from albert camus

3354
02:18:01,040 --> 02:18:05,599
 an intellectual is someone whose mind watches itself

3355
02:18:05,599 --> 02:18:06,638
 i like this

3356
02:18:06,638 --> 02:18:09,679
 because i'm happy to be both haves the watcher

3357
02:18:09,679 --> 02:18:11,040
 and the watched

3358
02:18:11,040 --> 02:18:13,040
 can they be brought together

3359
02:18:13,040 --> 02:18:17,280
 this is a practical question we must try to answer

3360
02:18:17,280 --> 02:18:18,160
 thank you for listening

3361
02:18:18,160 --> 02:18:22,840
 and hope to see you next

3362
02:18:22,840 --> 02:18:25,840
 time

3363
02:18:28,718 --> 02:18:28,718
 you

