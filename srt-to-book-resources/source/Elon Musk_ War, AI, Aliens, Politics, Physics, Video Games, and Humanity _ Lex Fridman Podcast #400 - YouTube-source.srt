1
00:00:00,090 --> 00:00:03,450
- The following is a conversation with Elon Musk,

2
00:00:03,450 --> 00:00:07,982
his fourth time on this, the Lex Fridman Podcast.

3
00:00:07,982 --> 00:00:10,732
(Elon whistling)

4
00:00:20,730 --> 00:00:22,230
I thought you were gonna finish it.

5
00:00:22,230 --> 00:00:24,980
(Elon whistling)

6
00:00:25,860 --> 00:00:28,460
It's one of the greatest themes in all film history.

7
00:00:28,460 --> 00:00:31,500
(whistling continues)

8
00:00:31,500 --> 00:00:32,549
- Yeah, that's great.

9
00:00:33,450 --> 00:00:36,090
- So I was just thinking about the Roman Empire.

10
00:00:36,090 --> 00:00:38,790
As one does. (Elon laughing)

11
00:00:38,790 --> 00:00:42,111
- There's that whole meme where old guys

12
00:00:42,111 --> 00:00:44,550
are thinking about the Roman Empire at least once a day.

13
00:00:44,550 --> 00:00:46,200
- And half the population's confused

14
00:00:46,200 --> 00:00:47,760
whether it's true or not.

15
00:00:47,760 --> 00:00:51,180
But more seriously thinking about the wars

16
00:00:51,180 --> 00:00:52,950
going on in the world today.

17
00:00:52,950 --> 00:00:56,520
And as you know, war and military conquest

18
00:00:56,520 --> 00:01:00,360
has been a big part of Roman society and culture.

19
00:01:00,360 --> 00:01:04,170
And it, I think, has been a big part of most empires

20
00:01:04,170 --> 00:01:06,160
and dynasties throughout human history, so.

21
00:01:06,160 --> 00:01:10,770
- Yeah, they usually came as a result of conquest.

22
00:01:10,770 --> 00:01:12,600
I mean, there's some, like the Hungarian Empire

23
00:01:12,600 --> 00:01:15,573
where there was just a lot of sort of clever marriages.

24
00:01:16,890 --> 00:01:19,410
- But fundamentally there's an engine of conquest.

25
00:01:19,410 --> 00:01:23,580
They celebrate excellence in warfare.

26
00:01:23,580 --> 00:01:26,550
Many of the leaders were excellent generals.

27
00:01:26,550 --> 00:01:28,020
- [Elon] Yeah. - That kind of thing.

28
00:01:28,020 --> 00:01:31,200
So a big picture question, Grok approved,

29
00:01:31,200 --> 00:01:33,115
I asked if this is a good question to ask.

30
00:01:33,115 --> 00:01:34,072
- [Elon] Get tested Grok approved.

31
00:01:34,072 --> 00:01:36,090
- Yeah.

32
00:01:36,090 --> 00:01:38,070
At least on fun mode.

33
00:01:38,070 --> 00:01:41,010
(Elon laughing)

34
00:01:41,010 --> 00:01:44,520
To what degree do you think war is part of human nature

35
00:01:44,520 --> 00:01:47,650
versus a consequence of

36
00:01:48,510 --> 00:01:50,790
how human societies are structured?

37
00:01:50,790 --> 00:01:55,170
I ask this as you have somehow controversially

38
00:01:55,170 --> 00:01:57,360
been a proponent of peace.

39
00:01:57,360 --> 00:01:58,860
- I'm generally a proponent of peace.

40
00:01:58,860 --> 00:02:00,870
I mean, ignorance is perhaps,

41
00:02:00,870 --> 00:02:04,440
in my view, the real enemy to be countered.

42
00:02:04,440 --> 00:02:05,340
That's the real hard part.

43
00:02:05,340 --> 00:02:07,623
Not, you know, fighting other humans.

44
00:02:09,180 --> 00:02:10,350
But all creatures fight.

45
00:02:10,350 --> 00:02:12,840
I mean, the jungle is a,

46
00:02:12,840 --> 00:02:15,000
you look at the, people think of this nature

47
00:02:15,000 --> 00:02:17,010
as perhaps some sort of peaceful thing.

48
00:02:17,010 --> 00:02:18,300
But in fact it is not.

49
00:02:18,300 --> 00:02:22,830
There's some quite funny Werner Herzog thing

50
00:02:22,830 --> 00:02:24,120
where he is like in the jungle,

51
00:02:24,120 --> 00:02:27,810
like saying that it's like basically just murder

52
00:02:27,810 --> 00:02:29,940
and death in every direction.

53
00:02:29,940 --> 00:02:31,560
I mean, the plants, animals in the jungle

54
00:02:31,560 --> 00:02:33,960
are constantly trying to kill each other,

55
00:02:33,960 --> 00:02:36,090
every single day, every minute.

56
00:02:36,090 --> 00:02:40,770
So it's not like, you know, we're unusual in that respect.

57
00:02:40,770 --> 00:02:42,210
- Well, there's a relevant question here.

58
00:02:42,210 --> 00:02:46,080
Whether with greater intelligence comes greater control

59
00:02:46,080 --> 00:02:48,333
over these base instincts for violence.

60
00:02:49,590 --> 00:02:50,550
- Yes.

61
00:02:50,550 --> 00:02:53,800
We have much more vulnerability to control our

62
00:02:55,560 --> 00:02:58,470
limbic instinct for violence than say a chimpanzee.

63
00:02:58,470 --> 00:03:01,110
And in fact, if one looks and say,

64
00:03:01,110 --> 00:03:03,210
chimpanzee society, it is not friendly.

65
00:03:03,210 --> 00:03:05,373
I mean, the Bonobos are an exception,

66
00:03:06,240 --> 00:03:11,240
but chimpanzee society is filled with violence.

67
00:03:11,880 --> 00:03:15,810
And it's quite, quite horrific, frankly,

68
00:03:15,810 --> 00:03:18,540
that that's our limbic system in action.

69
00:03:18,540 --> 00:03:20,160
Like, you don't wanna be on the wrong side of a chimpanzee,

70
00:03:20,160 --> 00:03:22,260
they'll eat your face off and tear and nuts off.

71
00:03:22,260 --> 00:03:24,360
- Yeah, basically, there's no limits or ethics

72
00:03:24,360 --> 00:03:26,760
or there almost had just war.

73
00:03:26,760 --> 00:03:29,580
There's no just war in chimpanzee societies,

74
00:03:29,580 --> 00:03:33,210
is war and dominance by any means necessary.

75
00:03:33,210 --> 00:03:34,740
- Yeah, chimpanzee society is a pro,

76
00:03:34,740 --> 00:03:37,495
like a permanent version of human society.

77
00:03:37,495 --> 00:03:40,683
They're not like peace loving basically at all.

78
00:03:41,910 --> 00:03:43,533
There's extreme violence.

79
00:03:45,120 --> 00:03:46,440
And then once in a while,

80
00:03:46,440 --> 00:03:48,180
somebody who's watched too many Disney movies

81
00:03:48,180 --> 00:03:50,130
decides to raise a chimpanzee as a pet,

82
00:03:51,690 --> 00:03:54,120
and then that eats their face or rip their nuts off

83
00:03:54,120 --> 00:03:56,580
or chew their fingers off and that kind of thing.

84
00:03:56,580 --> 00:03:58,020
It's happened several times.

85
00:03:58,020 --> 00:03:59,340
- Ripping your nuts off is an interesting

86
00:03:59,340 --> 00:04:02,340
strategy for interaction.

87
00:04:02,340 --> 00:04:04,140
- It's happened to people. It's unfortunate.

88
00:04:04,140 --> 00:04:06,420
Like that's, I guess a one way to ensure

89
00:04:06,420 --> 00:04:09,390
that the other chimp doesn't like, you know,

90
00:04:09,390 --> 00:04:10,830
contribute to the gene pool.

91
00:04:10,830 --> 00:04:12,360
- Well, from a martial arts perspective

92
00:04:12,360 --> 00:04:14,517
is the fascinating strategy.

93
00:04:14,517 --> 00:04:18,839
- (laughing) The nut riper. (laughing)

94
00:04:18,839 --> 00:04:21,478
- I wonder which of the martial arts teaches that one.

95
00:04:21,480 --> 00:04:24,750
- I think it's safe to say if somebody's got your nuts

96
00:04:24,750 --> 00:04:28,170
in their hands and as the option ripping them off,

97
00:04:28,170 --> 00:04:30,420
you'll be amenable to whatever they want.

98
00:04:30,420 --> 00:04:33,170
- Yeah. (Elon laughing)

99
00:04:33,170 --> 00:04:35,220
- So like I said, somehow controversially,

100
00:04:35,220 --> 00:04:38,670
you've been an proponent of peace on Twitter, on X.

101
00:04:38,670 --> 00:04:39,503
- Yeah.

102
00:04:39,503 --> 00:04:41,940
- So let me ask you about the wars going on today

103
00:04:41,940 --> 00:04:44,610
and to see what the path to peace could be.

104
00:04:44,610 --> 00:04:46,170
How do you hope the current war in Israel

105
00:04:46,170 --> 00:04:48,270
and Gaza comes to an end?

106
00:04:48,270 --> 00:04:50,100
What path do you see

107
00:04:50,100 --> 00:04:52,080
that can minimize human suffering

108
00:04:52,080 --> 00:04:54,870
in the long term in that part of the world?

109
00:04:54,870 --> 00:04:58,470
- Well, I think that part of the world is definitely like,

110
00:04:58,470 --> 00:05:00,570
if you look up the, there is no easy answer

111
00:05:00,570 --> 00:05:01,620
in the dictionary.

112
00:05:01,620 --> 00:05:04,623
It'll be that, like the picture of the Middle East,

113
00:05:05,550 --> 00:05:06,420
in Israel especially.

114
00:05:06,420 --> 00:05:08,403
So there is no easy answer.

115
00:05:11,100 --> 00:05:15,750
What my, this is strictly my opinion of, you know,

116
00:05:15,750 --> 00:05:20,640
is that the goal

117
00:05:20,640 --> 00:05:24,033
of Hamas was to provoke an overreaction from Israel.

118
00:05:24,900 --> 00:05:27,480
They obviously did not expect to, you know,

119
00:05:27,480 --> 00:05:30,540
have a military victory, but they expect,

120
00:05:30,540 --> 00:05:34,080
they really wanted to commit the worst atrocities

121
00:05:34,080 --> 00:05:36,480
that they could in order to provoke

122
00:05:36,480 --> 00:05:40,563
the most aggressive response possible from Israel.

123
00:05:41,940 --> 00:05:45,870
And then leverage that aggressive response

124
00:05:45,870 --> 00:05:50,870
to rally Muslims worldwide

125
00:05:51,000 --> 00:05:54,540
for the course of Gaza and Palestine,

126
00:05:54,540 --> 00:05:56,403
which they have succeeded in doing.

127
00:05:58,020 --> 00:06:02,850
So the counterintuitive thing here,

128
00:06:02,850 --> 00:06:04,860
I think that the thing that I think should be done,

129
00:06:04,860 --> 00:06:06,780
even though it's very difficult,

130
00:06:06,780 --> 00:06:10,140
is that I would recommend that Israel

131
00:06:10,140 --> 00:06:14,160
engage in the most conspicuous acts of kindness possible.

132
00:06:14,160 --> 00:06:16,170
Every po- everything.

133
00:06:16,170 --> 00:06:17,160
That is the actual thing

134
00:06:17,160 --> 00:06:19,710
that we're taught the goal of Hamas.

135
00:06:19,710 --> 00:06:21,750
- So in some sense,

136
00:06:21,750 --> 00:06:23,970
the degree that makes sense in geopolitics

137
00:06:23,970 --> 00:06:26,490
turn the other cheek implemented.

138
00:06:26,490 --> 00:06:28,320
- It's not exactly turn the other cheek.

139
00:06:28,320 --> 00:06:32,790
Because I do think that there's, you know,

140
00:06:32,790 --> 00:06:35,752
I think it is appropriate for Israel

141
00:06:35,752 --> 00:06:39,180
to find the Hamas members

142
00:06:39,180 --> 00:06:44,180
and, you know, either kill 'em or incarcerate them.

143
00:06:45,120 --> 00:06:46,830
Like that's something that's something has to be done

144
00:06:46,830 --> 00:06:50,103
'cause they're just gonna keep coming otherwise.

145
00:06:51,360 --> 00:06:56,360
But in addition to that, they need to do whatever they can.

146
00:06:58,470 --> 00:07:00,300
There's some talk of establishing,

147
00:07:00,300 --> 00:07:02,370
for example, a mobile hospital.

148
00:07:02,370 --> 00:07:03,620
I'd recommend doing that.

149
00:07:05,910 --> 00:07:08,400
Just making sure that, you know,

150
00:07:08,400 --> 00:07:12,003
there's food, water, medical, necessities,

151
00:07:15,540 --> 00:07:17,160
and just be over the top about it

152
00:07:17,160 --> 00:07:20,010
and be very transparent.

153
00:07:20,010 --> 00:07:23,700
So you can't claim it's a trick.

154
00:07:23,700 --> 00:07:27,993
Like just put webcam on the thing, you know, or 24/7.

155
00:07:29,190 --> 00:07:31,890
- Deploy acts of kindness. - Yeah.

156
00:07:31,890 --> 00:07:35,220
Conspicuous acts of kindness that,

157
00:07:35,220 --> 00:07:37,350
with that are unequivocal.

158
00:07:37,350 --> 00:07:40,260
Meaning they can't be somehow,

159
00:07:40,260 --> 00:07:41,700
because Hamas will then,

160
00:07:41,700 --> 00:07:43,590
their response will be, oh, it's a trick.

161
00:07:43,590 --> 00:07:46,203
Therefore you have to counter how it's not a trick.

162
00:07:47,130 --> 00:07:49,440
- This ultimately fights the broader force

163
00:07:49,440 --> 00:07:51,630
of hatred in the region.

164
00:07:51,630 --> 00:07:52,463
- Yes.

165
00:07:52,463 --> 00:07:55,170
And I'm not sure who said it, it's an apocryphal saying,

166
00:07:55,170 --> 00:07:58,230
but an eye for an eye makes everyone blind.

167
00:07:58,230 --> 00:07:59,280
Now that neck of the woods,

168
00:07:59,280 --> 00:08:02,133
they really believe in the whole eye for an eye thing.

169
00:08:05,430 --> 00:08:07,623
But I mean, you really have,

170
00:08:08,670 --> 00:08:12,840
if you're not gonna just outright commit genocide,

171
00:08:12,840 --> 00:08:14,100
like against an entire people,

172
00:08:14,100 --> 00:08:16,680
which obviously would not be acceptable to really

173
00:08:16,680 --> 00:08:18,380
shouldn't be acceptable to anyone,

174
00:08:19,350 --> 00:08:22,110
then you're gonna leave basically a lot of people alive

175
00:08:22,110 --> 00:08:25,200
who subsequently, you know, hate Israel.

176
00:08:25,200 --> 00:08:27,270
So really the question is like,

177
00:08:27,270 --> 00:08:30,480
how, for every Hamas member that you kill,

178
00:08:30,480 --> 00:08:31,680
how many did you create?

179
00:08:33,090 --> 00:08:35,520
And if you create more than you killed,

180
00:08:35,520 --> 00:08:36,750
you've not succeeded.

181
00:08:36,750 --> 00:08:39,100
That's the, you know, the real situation there.

182
00:08:39,960 --> 00:08:43,263
And it's safe to say that if, you know,

183
00:08:47,070 --> 00:08:50,433
if you kill somebody's child in Gaza,

184
00:08:52,650 --> 00:08:57,520
you've made at least a few Hamas members

185
00:08:58,410 --> 00:09:02,013
who will die just to kill an Israeli.

186
00:09:03,600 --> 00:09:05,040
That's the situation.

187
00:09:05,040 --> 00:09:08,670
So, but I mean,

188
00:09:08,670 --> 00:09:11,520
this is one of the most contentious subjects

189
00:09:11,520 --> 00:09:12,720
one could possibly discuss.

190
00:09:12,720 --> 00:09:15,060
But I think if the goal ultimately

191
00:09:15,060 --> 00:09:17,158
is some sort of long-term peace,

192
00:09:17,158 --> 00:09:21,180
one has to be, look at this from the standpoint of,

193
00:09:21,180 --> 00:09:25,803
over time, are there more or fewer terrorists being created?

194
00:09:26,760 --> 00:09:29,070
- Let me just linger on war.

195
00:09:29,070 --> 00:09:30,630
- Yeah, war safe to say,

196
00:09:30,630 --> 00:09:33,180
wars always existed and always will exist.

197
00:09:33,180 --> 00:09:34,560
- [Lex] Always will exist,

198
00:09:34,560 --> 00:09:37,440
- Always has existed and always will exist.

199
00:09:37,440 --> 00:09:38,743
- I hope not. You think it always will?

200
00:09:38,743 --> 00:09:40,383
- There will always be war.

201
00:09:42,150 --> 00:09:43,470
This question of just how much war.

202
00:09:43,470 --> 00:09:47,150
And, you know, there's this,

203
00:09:47,150 --> 00:09:49,620
there's this sort of the scope and scale of war.

204
00:09:49,620 --> 00:09:52,440
But to imagine that there would not be any war

205
00:09:52,440 --> 00:09:55,770
in the future, I think would be a very unlikely outcome.

206
00:09:55,770 --> 00:09:57,240
- Yeah you talked about the Culture series.

207
00:09:57,240 --> 00:09:58,590
There's war even there.

208
00:09:58,590 --> 00:10:00,030
- Yes. It's a giant war.

209
00:10:00,030 --> 00:10:05,030
The first book starts off with a gigantic galactic war

210
00:10:05,070 --> 00:10:07,230
where trillions die, trillions.

211
00:10:07,230 --> 00:10:09,951
- But it still nevertheless protects these pockets

212
00:10:09,951 --> 00:10:11,373
of flourishing.

213
00:10:12,690 --> 00:10:15,120
Somehow you can have galactic war

214
00:10:15,120 --> 00:10:18,000
and still have pockets of flourishing.

215
00:10:18,000 --> 00:10:18,833
- Yeah.

216
00:10:18,833 --> 00:10:23,040
I mean it's, I guess if we are able to one day expand to,

217
00:10:23,040 --> 00:10:26,704
you know, the galaxy or whatever,

218
00:10:26,704 --> 00:10:30,750
there will be a galactic war at some point.

219
00:10:30,750 --> 00:10:33,270
- The scale, I mean the scale of war has been increasing,

220
00:10:33,270 --> 00:10:34,980
increasing, increasing.

221
00:10:34,980 --> 00:10:37,107
It's like a race between the scale of suffering

222
00:10:37,107 --> 00:10:38,670
and the scale of flourishing.

223
00:10:38,670 --> 00:10:39,503
- Yes.

224
00:10:41,820 --> 00:10:43,770
- A lot of people seem to be using this tragedy

225
00:10:43,770 --> 00:10:45,420
to beat the drums of war

226
00:10:45,420 --> 00:10:47,490
and feed the military industrial complex.

227
00:10:47,490 --> 00:10:48,690
Do you worry about this?

228
00:10:49,530 --> 00:10:54,090
The people who are rooting for escalation

229
00:10:54,090 --> 00:10:56,070
and how can it be stopped?

230
00:10:56,070 --> 00:10:57,540
- One of the things that did concerned me

231
00:10:57,540 --> 00:10:59,970
is that there are very few people alive today

232
00:10:59,970 --> 00:11:04,170
who actually viscerally understand the horrors of war,

233
00:11:04,170 --> 00:11:05,003
at least in the US.

234
00:11:05,003 --> 00:11:07,110
I mean, obviously there are people in on the front lines

235
00:11:07,110 --> 00:11:09,150
in Ukraine and Russia who understand

236
00:11:09,150 --> 00:11:10,950
just how terrible war is,

237
00:11:10,950 --> 00:11:13,413
but how many people in the west understand it?

238
00:11:15,134 --> 00:11:17,730
And my grandfather was in World War II.

239
00:11:17,730 --> 00:11:19,500
He was severely traumatized.

240
00:11:19,500 --> 00:11:22,957
He was there, I think for almost six years in the,

241
00:11:23,810 --> 00:11:26,010
in eastern North Africa and Italy.

242
00:11:26,010 --> 00:11:29,310
All his friends were killed in front of him.

243
00:11:29,310 --> 00:11:34,310
And he would've died too, except they randomly gave some,

244
00:11:34,590 --> 00:11:35,940
I guess, IQ test or something.

245
00:11:35,940 --> 00:11:38,883
And he scored very high.

246
00:11:39,750 --> 00:11:40,583
And he was not an officer, he was a,

247
00:11:40,583 --> 00:11:43,500
I think a corporal or a sergeant or something like that.

248
00:11:43,500 --> 00:11:45,330
Because he didn't finish high school

249
00:11:45,330 --> 00:11:46,620
because he had to drop outta high school,

250
00:11:46,620 --> 00:11:49,290
'cause his dad died and he had to work

251
00:11:49,290 --> 00:11:51,573
to support his siblings.

252
00:11:52,620 --> 00:11:54,210
So because he didn't graduate high school,

253
00:11:54,210 --> 00:11:56,310
he was not eligible for the officer corps.

254
00:11:57,870 --> 00:12:01,500
So, you know, he kind of got put into the cannon fodder

255
00:12:01,500 --> 00:12:03,153
category, basically.

256
00:12:04,590 --> 00:12:07,260
But then, this, randomly they gave him this test.

257
00:12:07,260 --> 00:12:09,840
He was transferred to British intelligence in London.

258
00:12:09,840 --> 00:12:11,733
That's where he met my grandmother.

259
00:12:13,440 --> 00:12:17,490
But he had PTSD next level, like next level.

260
00:12:17,490 --> 00:12:21,240
I mean, just didn't talk, just didn't talk.

261
00:12:21,240 --> 00:12:22,200
And if you tried talking to him,

262
00:12:22,200 --> 00:12:23,700
he'd just tell you to shut up.

263
00:12:24,570 --> 00:12:25,530
And he won a bunch of medals.

264
00:12:25,530 --> 00:12:30,030
Never bragged about it once, not even hinted, nothing.

265
00:12:30,030 --> 00:12:31,170
I like found out about it,

266
00:12:31,170 --> 00:12:33,930
'cause his military records were online.

267
00:12:33,930 --> 00:12:36,360
That's how I know.

268
00:12:36,360 --> 00:12:39,959
So he would say like, no way in hell

269
00:12:39,959 --> 00:12:41,670
do you wanna do that again.

270
00:12:41,670 --> 00:12:45,540
But how many people, now he obviously he died,

271
00:12:45,540 --> 00:12:48,340
you know, 20 years ago or longer, actually 30 years ago.

272
00:12:50,850 --> 00:12:53,100
How many people are alive that remember World War II?

273
00:12:53,100 --> 00:12:53,933
Not many.

274
00:12:54,810 --> 00:12:58,173
- And the same perhaps applies to the threat of nuclear war.

275
00:13:01,140 --> 00:13:02,760
- Yeah. I mean, there are enough nuclear bombs

276
00:13:02,760 --> 00:13:06,450
pointed at United States to make the revel,

277
00:13:06,450 --> 00:13:08,853
the radio active revel balance many times.

278
00:13:10,530 --> 00:13:14,310
- There's two major wars going on right now.

279
00:13:14,310 --> 00:13:17,850
So you talked about the threat of AGI quite a bit.

280
00:13:17,850 --> 00:13:20,880
But now as we sit here with the intensity

281
00:13:20,880 --> 00:13:23,793
of conflict going on, do you worry about nuclear war?

282
00:13:25,710 --> 00:13:27,270
- I think we shouldn't discount the possibility

283
00:13:27,270 --> 00:13:28,143
of nuclear war.

284
00:13:29,280 --> 00:13:30,843
It is a civilizational threat.

285
00:13:36,210 --> 00:13:37,740
Right now I could be wrong,

286
00:13:37,740 --> 00:13:41,220
but I think the current probability of nuclear war

287
00:13:41,220 --> 00:13:42,093
is quite low.

288
00:13:43,890 --> 00:13:46,380
But there are a lot of nukes pointed at us.

289
00:13:46,380 --> 00:13:49,130
So, and we have a lot of nukes pointed at other people.

290
00:13:50,340 --> 00:13:53,913
They're still there. Nobody's put their guns away.

291
00:13:55,290 --> 00:13:57,570
The missiles are still in the silos.

292
00:13:57,570 --> 00:14:01,080
- And the leaders don't seem to be the ones

293
00:14:01,080 --> 00:14:03,000
with the nukes talking to each other.

294
00:14:03,000 --> 00:14:04,260
- No.

295
00:14:04,260 --> 00:14:06,480
There are wars which are tragic

296
00:14:06,480 --> 00:14:08,550
and difficult on a local basis.

297
00:14:08,550 --> 00:14:11,760
And then there are wars which are civilization ending

298
00:14:11,760 --> 00:14:12,750
or has that potential.

299
00:14:12,750 --> 00:14:15,810
Obviously global thermonuclear warfare has high potential

300
00:14:15,810 --> 00:14:19,350
to end civilization, perhaps permanently.

301
00:14:19,350 --> 00:14:22,710
But certainly, you know, to severely wound

302
00:14:24,720 --> 00:14:29,720
and perhaps set back human progress by,

303
00:14:30,630 --> 00:14:34,650
you know, to the stone age or something, I don't know.

304
00:14:34,650 --> 00:14:35,483
Pretty bad.

305
00:14:39,300 --> 00:14:41,640
Probably scientists and engineers wanna be super popular

306
00:14:41,640 --> 00:14:43,080
after that as well.

307
00:14:43,080 --> 00:14:44,830
And like you got us into this mess.

308
00:14:46,020 --> 00:14:50,070
- So generally I think we obviously wanna prioritize

309
00:14:50,070 --> 00:14:54,510
civilizational risks over things that are painful

310
00:14:54,510 --> 00:14:57,110
and tragic on a local level, but not civilizational.

311
00:15:00,360 --> 00:15:02,550
- How do you hope the war in Ukraine comes to an end?

312
00:15:02,550 --> 00:15:04,170
And what's the path, once again

313
00:15:04,170 --> 00:15:06,093
to minimizing human suffering there?

314
00:15:08,882 --> 00:15:11,777
- Well, I think that what is likely to happen,

315
00:15:13,380 --> 00:15:17,520
which is really pretty much the way it is,

316
00:15:17,520 --> 00:15:22,207
is that something very close to the current lines will be

317
00:15:25,590 --> 00:15:30,390
how a ceasefire or truth happens.

318
00:15:30,390 --> 00:15:33,870
But, you know, you just have a situation right now

319
00:15:33,870 --> 00:15:37,500
where whoever goes on the offensive will suffer casualties

320
00:15:37,500 --> 00:15:40,203
at several times the rate of whoever's on the defense.

321
00:15:41,280 --> 00:15:43,620
'Cause you've got defense in depth,

322
00:15:43,620 --> 00:15:47,163
you've got minefields, trenches, anti-tank defenses.

323
00:15:48,030 --> 00:15:50,520
Nobody has air superiority.

324
00:15:50,520 --> 00:15:53,100
'cause the anti-aircraft missiles

325
00:15:53,100 --> 00:15:55,560
are really far better than the aircraft.

326
00:15:55,560 --> 00:15:57,110
Like, they're far more of them.

327
00:15:58,500 --> 00:16:02,130
And so neither side has air superiority.

328
00:16:02,130 --> 00:16:06,000
Tanks are basically death drafts, just slow moving

329
00:16:06,000 --> 00:16:09,810
and they're not immune to anti-tank weapons.

330
00:16:09,810 --> 00:16:13,080
So you really just have long range artillery

331
00:16:13,080 --> 00:16:17,460
and infantry ranges.

332
00:16:17,460 --> 00:16:22,290
It's World War I all over again with drones, you know,

333
00:16:22,290 --> 00:16:24,240
throwing old drones, some drones there.

334
00:16:25,170 --> 00:16:26,730
- Which makes the long range artillery

335
00:16:26,730 --> 00:16:28,830
just that much more accurate and better

336
00:16:28,830 --> 00:16:32,403
and so more efficient at murdering people on both sides.

337
00:16:33,840 --> 00:16:34,673
- Yeah.

338
00:16:34,673 --> 00:16:38,400
So it's whoever is, you don't wanna be trying

339
00:16:38,400 --> 00:16:39,870
to advance from either side,

340
00:16:39,870 --> 00:16:42,420
'cause the probability of dying is incredibly high.

341
00:16:43,710 --> 00:16:45,580
So in order to overcome

342
00:16:49,200 --> 00:16:51,150
defense in depth trenches

343
00:16:51,150 --> 00:16:54,330
and minefields, you really need a significant

344
00:16:54,330 --> 00:16:56,973
local superiority in numbers.

345
00:16:57,840 --> 00:17:02,700
Ideally combined alms where you do a fast attack

346
00:17:02,700 --> 00:17:07,180
with aircraft, a concentrated number of tanks

347
00:17:08,579 --> 00:17:10,138
and a lot of people.

348
00:17:10,140 --> 00:17:12,358
That's the only way you're gonna punch through the line.

349
00:17:12,358 --> 00:17:13,640
And then you're gonna punch through

350
00:17:13,641 --> 00:17:18,358
and then not have reinforcements just kick you

351
00:17:18,358 --> 00:17:19,972
right out again.

352
00:17:19,973 --> 00:17:23,079
I mean, I really recommend people read

353
00:17:24,270 --> 00:17:27,423
World War I warfare in detail.

354
00:17:28,530 --> 00:17:29,363
That's rough.

355
00:17:33,240 --> 00:17:34,680
I mean, the sheer number of people that died there

356
00:17:34,680 --> 00:17:36,153
was mind boggling.

357
00:17:37,320 --> 00:17:40,710
- And it's almost impossible to imagine the end of it

358
00:17:40,710 --> 00:17:43,650
that doesn't look like almost exactly like the beginning

359
00:17:43,650 --> 00:17:48,650
in terms of what land belongs to who and so on.

360
00:17:48,990 --> 00:17:53,040
But on the other side of a lot of human suffering death

361
00:17:54,480 --> 00:17:56,010
and destruction of infrastructure.

362
00:17:56,010 --> 00:17:56,843
- Yes.

363
00:17:56,843 --> 00:17:59,640
I mean, the thing that, the reason I,

364
00:17:59,640 --> 00:18:03,240
you know, proposed some sort of truce

365
00:18:03,240 --> 00:18:05,520
or peace a year ago

366
00:18:05,520 --> 00:18:08,790
was because I've predicted pretty much exactly

367
00:18:08,790 --> 00:18:12,060
what would happen, which is a lot of people dying

368
00:18:12,060 --> 00:18:14,703
for basically almost no changes in land.

369
00:18:16,260 --> 00:18:19,620
And this, the loss of the flower

370
00:18:19,620 --> 00:18:21,600
of Ukrainian and Russian youth.

371
00:18:21,600 --> 00:18:24,870
And we should have some sympathy for the Russian boys

372
00:18:24,870 --> 00:18:26,250
as well as the Ukrainian boys,

373
00:18:26,250 --> 00:18:28,170
'cause they, Russian boys didn't ask to be

374
00:18:28,170 --> 00:18:30,360
on their front line, they have to be.

375
00:18:30,360 --> 00:18:35,360
So there's a lot of sons not coming back to their parents,

376
00:18:37,440 --> 00:18:42,440
you know, and I think most of 'em don't really have,

377
00:18:43,590 --> 00:18:45,360
they don't hate the other side.

378
00:18:45,360 --> 00:18:48,573
You know, it's sort of like as this saying about, like,

379
00:18:48,573 --> 00:18:52,020
this saying comes from World War I, it's like young boys

380
00:18:52,020 --> 00:18:55,020
who don't know each other, killing each other

381
00:18:55,020 --> 00:18:57,270
on behalf of old men that do know each other.

382
00:18:59,820 --> 00:19:01,270
The hell's the point of that?

383
00:19:02,370 --> 00:19:05,010
- So Vladimir Zelensky said that he's not,

384
00:19:05,010 --> 00:19:06,360
or has said in the past,

385
00:19:06,360 --> 00:19:08,550
he's not interested in talking to Putin directly.

386
00:19:08,550 --> 00:19:09,660
Do you think he should?

387
00:19:09,660 --> 00:19:11,160
- Yeah. - Sit down man to man,

388
00:19:11,160 --> 00:19:13,053
lead a leader and negotiate peace?

389
00:19:14,490 --> 00:19:16,710
- Look, I think I would just recommend

390
00:19:16,710 --> 00:19:20,996
do not send the flower of Ukrainian youth

391
00:19:20,996 --> 00:19:23,883
to die in trenches.

392
00:19:25,170 --> 00:19:28,203
Whether he talks to Putin or not, just don't do that.

393
00:19:30,270 --> 00:19:32,100
Whoever goes on the offensive

394
00:19:32,100 --> 00:19:33,850
will lose massive numbers of people

395
00:19:37,680 --> 00:19:39,830
and history will not look kindly upon them.

396
00:19:42,390 --> 00:19:44,520
- You've spoken honestly about the possibility of war

397
00:19:44,520 --> 00:19:46,860
between US and China in the long term.

398
00:19:46,860 --> 00:19:50,160
If no diplomatic solution is found, for example,

399
00:19:50,160 --> 00:19:52,380
on the question of Taiwan and one China policy.

400
00:19:52,380 --> 00:19:53,213
- [Elon] Right.

401
00:19:53,213 --> 00:19:54,330
- How do we avoid the trajectory

402
00:19:54,330 --> 00:19:56,883
where these two superpowers clash?

403
00:19:58,410 --> 00:19:59,790
- Well, it's worth reading that book

404
00:19:59,790 --> 00:20:03,330
on the, difficult to pronounce, the Thucydides trap,

405
00:20:03,330 --> 00:20:04,560
I believe it's called.

406
00:20:04,560 --> 00:20:08,223
I love war history. I like inside out and backwards.

407
00:20:09,810 --> 00:20:12,060
There's hardly a battle I haven't read about.

408
00:20:13,560 --> 00:20:16,020
And trying to figure out like what really was the cause

409
00:20:16,020 --> 00:20:17,910
of victory in any particular case as opposed

410
00:20:17,910 --> 00:20:21,390
to what one side or another claim the reason.

411
00:20:21,390 --> 00:20:24,270
- Both the victory and what sparked the war?

412
00:20:24,270 --> 00:20:26,940
- Yeah, yeah, - [Lex] The whole thing.

413
00:20:26,940 --> 00:20:30,120
- Yeah, so that Athens and Sparta is a classic case.

414
00:20:30,120 --> 00:20:30,953
The thing about the Greek is

415
00:20:30,953 --> 00:20:32,040
they really wrote down a lot of stuff.

416
00:20:32,040 --> 00:20:32,990
They loved writing.

417
00:20:33,900 --> 00:20:35,010
You know, there are lots of interesting things

418
00:20:35,010 --> 00:20:36,150
that happened in many parts of the world,

419
00:20:36,150 --> 00:20:38,310
but people didn't write down. (laughing)

420
00:20:38,310 --> 00:20:40,170
So we don't know what happened,

421
00:20:40,170 --> 00:20:44,940
or they didn't really write with in detail.

422
00:20:44,940 --> 00:20:48,060
They just would say like, we had a battle and we won.

423
00:20:48,060 --> 00:20:50,260
And like, well what? Can you add a bit more?

424
00:20:51,510 --> 00:20:54,660
The Greeks, they really wrote a lot. (laughing)

425
00:20:54,660 --> 00:20:57,210
They were very articulate on, they just love writing.

426
00:20:57,210 --> 00:20:59,520
So, and we have a bunch of that writing as preserved.

427
00:20:59,520 --> 00:21:02,970
So we know what led up to the Peloponnesian War

428
00:21:02,970 --> 00:21:05,703
between the Spartan and Athenian alliance.

429
00:21:08,160 --> 00:21:12,750
And we know that they saw it coming.

430
00:21:15,999 --> 00:21:17,190
I mean, the Spartans didn't write,

431
00:21:17,190 --> 00:21:19,500
they also weren't very verbose by their nature,

432
00:21:19,500 --> 00:21:21,720
but they did write, but they weren't very verbose.

433
00:21:21,720 --> 00:21:23,220
They were terse.

434
00:21:23,220 --> 00:21:26,502
But the Athenians and the other Greeks wrote a line

435
00:21:26,502 --> 00:21:29,790
and they were like, and Sparta was really kinda

436
00:21:29,790 --> 00:21:32,793
like the leader of Greece.

437
00:21:33,990 --> 00:21:35,310
But Athens grew stronger

438
00:21:35,310 --> 00:21:37,770
and stronger with each passing year.

439
00:21:37,770 --> 00:21:40,920
And everyone's like, well that's inevitable

440
00:21:40,920 --> 00:21:43,983
that there's gonna be a clash between Athens and Sparta.

441
00:21:45,540 --> 00:21:46,830
Well, how do we avoid that?

442
00:21:46,830 --> 00:21:47,663
And they couldn't.

443
00:21:47,663 --> 00:21:49,470
They actually, they saw it coming

444
00:21:49,470 --> 00:21:53,130
and they still could not avoid it. (laughing)

445
00:21:53,130 --> 00:21:57,593
So, you know, at some point if there's, if one group,

446
00:21:59,340 --> 00:22:00,990
one civilization or country

447
00:22:00,990 --> 00:22:05,990
or whatever exceeds another,

448
00:22:06,300 --> 00:22:07,470
sort of, like, you know,

449
00:22:07,470 --> 00:22:10,050
the United States has been the biggest kid on the block for,

450
00:22:10,050 --> 00:22:14,550
since I think around 1890 from an economic standpoint.

451
00:22:14,550 --> 00:22:18,120
So the United States has been the economic,

452
00:22:18,120 --> 00:22:22,560
most powerful economic engine in the world,

453
00:22:22,560 --> 00:22:24,160
longer than anyone's been alive.

454
00:22:28,260 --> 00:22:30,210
And the foundation of war is economics.

455
00:22:31,530 --> 00:22:36,440
So now we have a situation in the case

456
00:22:36,440 --> 00:22:41,440
of China where the economy is likely to be two,

457
00:22:42,750 --> 00:22:45,960
perhaps three times larger than that of the US.

458
00:22:45,960 --> 00:22:48,030
So imagine you're the biggest kid on the block

459
00:22:48,030 --> 00:22:49,620
for as long as anyone can remember.

460
00:22:49,620 --> 00:22:52,270
And suddenly a kid comes along who's twice your size.

461
00:22:55,710 --> 00:22:57,660
- So we see it coming. - [Elon] Yeah.

462
00:22:57,660 --> 00:22:59,940
- How is it possible to stop?

463
00:22:59,940 --> 00:23:02,730
Is there some, let me throw something out there,

464
00:23:02,730 --> 00:23:06,150
just intermixing of cultures understanding.

465
00:23:06,150 --> 00:23:08,070
There does seem to be a giant cultural gap

466
00:23:08,070 --> 00:23:09,810
in understanding of each other.

467
00:23:09,810 --> 00:23:11,310
And you're an interesting case study

468
00:23:11,310 --> 00:23:14,430
because you are an American, obviously you've done

469
00:23:14,430 --> 00:23:18,570
a lot of incredible manufacture here in the United States,

470
00:23:18,570 --> 00:23:20,190
but you also work with China.

471
00:23:20,190 --> 00:23:21,300
- I've spent a lot of time in China

472
00:23:21,300 --> 00:23:22,980
and met with the leadership many times.

473
00:23:22,980 --> 00:23:24,990
- Maybe a good question to ask is,

474
00:23:24,990 --> 00:23:26,850
what are some things about China

475
00:23:26,850 --> 00:23:29,700
that people don't understand positive, just in the culture?

476
00:23:29,700 --> 00:23:31,230
What's some interesting things

477
00:23:31,230 --> 00:23:33,183
that you've learned about the Chinese?

478
00:23:36,060 --> 00:23:39,450
- Well, the sheer number of really smart,

479
00:23:39,450 --> 00:23:44,370
hardworking people in China is incredible.

480
00:23:44,370 --> 00:23:48,030
There are really, say like how many smart,

481
00:23:48,030 --> 00:23:48,863
hardworking people are there in China,

482
00:23:48,863 --> 00:23:51,630
there's far more of them there than there are here.

483
00:23:51,630 --> 00:23:53,043
I think in my opinion.

484
00:23:57,716 --> 00:23:58,657
And they've got a lot of energy.

485
00:24:00,540 --> 00:24:04,650
So I mean, the architecture in China

486
00:24:04,650 --> 00:24:08,460
that's in recent years is far more impressive than the US.

487
00:24:08,460 --> 00:24:10,950
I mean the train stations, the buildings,

488
00:24:10,950 --> 00:24:12,450
the high speed rail, everything,

489
00:24:12,450 --> 00:24:17,450
it's really far more impressive than what we have in the US.

490
00:24:19,351 --> 00:24:21,390
I mean, I recommend somebody just go to Shanghai

491
00:24:21,390 --> 00:24:24,540
and Beijing, look at the buildings

492
00:24:24,540 --> 00:24:27,780
and go to, you know, take the train from Beijing to Xian,

493
00:24:27,780 --> 00:24:29,970
where you have the terracotta warriors.

494
00:24:29,970 --> 00:24:33,600
China's got an incredible history, very long history.

495
00:24:33,600 --> 00:24:37,470
And you know, I think arguably the,

496
00:24:37,470 --> 00:24:41,643
in terms of the use of language from a written standpoint,

497
00:24:42,900 --> 00:24:44,340
sort of one of the oldest,

498
00:24:44,340 --> 00:24:48,330
perhaps the oldest written language.

499
00:24:48,330 --> 00:24:50,700
And then China, people did write things down.

500
00:24:50,700 --> 00:24:55,700
So now China historically has always been,

501
00:24:56,640 --> 00:24:59,820
with rare exception, been internally focused.

502
00:24:59,820 --> 00:25:01,370
They have not been inquisitive.

503
00:25:02,790 --> 00:25:04,590
They've fought each other.

504
00:25:04,590 --> 00:25:07,710
There've been many, many civil wars.

505
00:25:07,710 --> 00:25:09,210
In the three kingdoms war,

506
00:25:09,210 --> 00:25:12,243
I believe they lost about 70% of their population.

507
00:25:14,070 --> 00:25:15,687
So, and that,

508
00:25:15,687 --> 00:25:19,590
so they've had brutal internal wars,

509
00:25:19,590 --> 00:25:21,930
like civil wars that make the US Civil War

510
00:25:21,930 --> 00:25:25,443
look small by comparison.

511
00:25:28,770 --> 00:25:31,050
So I think it's important to appreciate

512
00:25:31,050 --> 00:25:33,093
that China is not monolithic.

513
00:25:34,920 --> 00:25:36,200
We sort of think of like China

514
00:25:36,200 --> 00:25:39,660
as this sort of one entity of one mind.

515
00:25:39,660 --> 00:25:41,410
And this is definitely not the case

516
00:25:42,900 --> 00:25:45,090
from what I've seen,

517
00:25:45,090 --> 00:25:48,360
and I think most people who understand China would agree.

518
00:25:48,360 --> 00:25:50,700
People in China think about China

519
00:25:50,700 --> 00:25:51,540
10 times more than they think

520
00:25:51,540 --> 00:25:53,820
about anything outside of China.

521
00:25:53,820 --> 00:25:57,513
So it's like 90% of their consideration is,

522
00:25:58,920 --> 00:26:01,500
you know, our is internal.

523
00:26:01,500 --> 00:26:03,750
- Well, isn't that a really positive thing

524
00:26:03,750 --> 00:26:05,520
when you're talking about the collaboration

525
00:26:05,520 --> 00:26:08,040
and a future piece between superpowers,

526
00:26:08,040 --> 00:26:09,240
when you're inward facing,

527
00:26:09,240 --> 00:26:12,150
which is like focusing on improving yourself

528
00:26:12,150 --> 00:26:14,193
versus focusing on... - [Elon] Yeah.

529
00:26:15,210 --> 00:26:18,240
- "Improving" others through military might.

530
00:26:18,240 --> 00:26:20,880
- The good news, the history of China suggests

531
00:26:20,880 --> 00:26:22,200
that China is not inquisitive.

532
00:26:22,200 --> 00:26:23,160
Meaning they're not gonna go out

533
00:26:23,160 --> 00:26:25,060
and invade a whole bunch of countries.

534
00:26:26,130 --> 00:26:27,960
Now they do feel very strongly,

535
00:26:27,960 --> 00:26:28,890
you know, so that's good.

536
00:26:28,890 --> 00:26:31,590
I mean, 'cause a lot of very powerful countries

537
00:26:31,590 --> 00:26:32,703
have been inquisitive.

538
00:26:34,230 --> 00:26:37,140
The US is one of the, also one of the rare cases

539
00:26:37,140 --> 00:26:38,940
that has not been inquisitive.

540
00:26:38,940 --> 00:26:39,777
Like after World War II,

541
00:26:39,777 --> 00:26:41,370
the US could have basically taken

542
00:26:41,370 --> 00:26:42,870
over the world in any country.

543
00:26:42,870 --> 00:26:45,120
Like, we've got nukes, nobody else has got nukes.

544
00:26:45,120 --> 00:26:46,883
We don't even have to lose soldiers.

545
00:26:47,880 --> 00:26:49,223
Which country do you want?

546
00:26:49,223 --> 00:26:52,320
And the United States could have taken over everything.

547
00:26:52,320 --> 00:26:53,153
Oh wait, at will.

548
00:26:53,153 --> 00:26:56,190
And it didn't, and the United States actually

549
00:26:56,190 --> 00:26:57,750
helped rebuild countries.

550
00:26:57,750 --> 00:27:00,963
So it helped rebuild Europe, you know, helped rebuild Japan.

551
00:27:02,160 --> 00:27:05,793
This is very unusual behavior, almost unprecedented.

552
00:27:09,900 --> 00:27:13,410
You know, the US did conspicuous acts of kindness

553
00:27:13,410 --> 00:27:16,143
like the Berlin airlift, you know?

554
00:27:19,140 --> 00:27:22,560
And I think, you know, it's always like,

555
00:27:22,560 --> 00:27:23,790
well, America's done bad things.

556
00:27:23,790 --> 00:27:24,990
Well, of course America's done bad things.

557
00:27:24,990 --> 00:27:27,390
But one needs to look at the whole track record.

558
00:27:29,280 --> 00:27:34,140
And just generally, you know, one sort of test

559
00:27:34,140 --> 00:27:36,540
would be how do you treat your prisoners at war?

560
00:27:38,100 --> 00:27:42,900
Or let's say, you know,

561
00:27:42,900 --> 00:27:45,930
no offense to the Russians, but let's say you're in Germany,

562
00:27:45,930 --> 00:27:49,380
it's 1945, you got the Russian Army coming one side

563
00:27:49,380 --> 00:27:51,300
and you got the French, British,

564
00:27:51,300 --> 00:27:53,160
and American Army's coming the other side.

565
00:27:53,160 --> 00:27:55,833
Who would you like to be to surrender it to?

566
00:27:56,760 --> 00:27:58,800
Like, no country is like morally perfect,

567
00:27:58,800 --> 00:28:03,570
but I recommend being a POW with the Americans.

568
00:28:03,570 --> 00:28:07,587
That would be my choice very strongly. (laughing)

569
00:28:07,587 --> 00:28:09,296
- In the full menu of POWs.

570
00:28:09,296 --> 00:28:10,907
- Very much so.

571
00:28:10,907 --> 00:28:15,360
And in fact, Wernher von Braun, took,

572
00:28:15,360 --> 00:28:17,190
you know, smart guy was like,

573
00:28:17,190 --> 00:28:19,290
we've got to be captured by the Americans.

574
00:28:20,730 --> 00:28:25,730
And in fact, the SS was under orders to execute Von Braun

575
00:28:26,010 --> 00:28:29,553
and all of the German rocket initiatives.

576
00:28:30,750 --> 00:28:34,770
And they narrowly escaped their SS.

577
00:28:34,770 --> 00:28:36,690
They said they were going out for a walk in the woods.

578
00:28:36,690 --> 00:28:39,750
They left in the middle of winter with no coats.

579
00:28:39,750 --> 00:28:42,720
And they ran like, with no food, no coats, no water.

580
00:28:42,720 --> 00:28:45,870
And just ran like hell and ran west.

581
00:28:45,870 --> 00:28:48,600
And by Sherlock, they, I think his brother found

582
00:28:48,600 --> 00:28:51,060
like a bicycle or something,

583
00:28:51,060 --> 00:28:54,240
and then just cycled west as fast

584
00:28:54,240 --> 00:28:56,793
as he couldn't have found a US patrol.

585
00:28:58,800 --> 00:29:03,800
So anyway, that's one way you can tell morality is.

586
00:29:04,650 --> 00:29:07,034
Where do you wanna be PoW? (laughing)

587
00:29:07,034 --> 00:29:08,070
It's not fun anywhere,

588
00:29:08,070 --> 00:29:10,320
but some places are much worse than others.

589
00:29:10,320 --> 00:29:14,433
So anyways, so like America has been,

590
00:29:15,510 --> 00:29:19,893
while far from perfect, generally a benevolent force,

591
00:29:21,000 --> 00:29:23,940
and we should always be self-critical

592
00:29:23,940 --> 00:29:26,253
and we try to be better.

593
00:29:27,750 --> 00:29:31,110
But anyone with have brain knows that.

594
00:29:31,110 --> 00:29:33,480
So I think there are some,

595
00:29:33,480 --> 00:29:37,710
in this way China and the United States are similar.

596
00:29:37,710 --> 00:29:42,710
Neither country has been acquisitive in a significant way.

597
00:29:42,720 --> 00:29:46,263
So that's like a, you know, a shared principle I guess.

598
00:29:47,100 --> 00:29:50,913
Now China does feel very strongly about Taiwan.

599
00:29:51,750 --> 00:29:54,693
They've been very clear about that for a long time.

600
00:29:56,142 --> 00:29:57,630
You know, from their standpoint,

601
00:29:57,630 --> 00:30:02,370
it would be like one of the states is, you know,

602
00:30:02,370 --> 00:30:04,934
not there like Hawaii or something like that.

603
00:30:04,934 --> 00:30:07,383
But more significant than Hawaii, you know?

604
00:30:10,170 --> 00:30:11,610
And Hawaii is pretty significant for us.

605
00:30:11,610 --> 00:30:16,263
So they view it as really the,

606
00:30:17,220 --> 00:30:19,503
that there's a fundamental part of China.

607
00:30:20,700 --> 00:30:23,400
The islander Formosa not Taiwan,

608
00:30:23,400 --> 00:30:27,750
that is not part of China, but should be.

609
00:30:27,750 --> 00:30:29,520
And the only reason it hasn't been

610
00:30:29,520 --> 00:30:31,070
is 'cause the US Pacific Fleet.

611
00:30:32,490 --> 00:30:34,020
- And as their economic power grows

612
00:30:34,020 --> 00:30:35,720
and as their military power grows,

613
00:30:36,600 --> 00:30:38,680
the thing that they're clearly saying

614
00:30:40,920 --> 00:30:45,920
is their interest will, you know, clearly be materialized.

615
00:30:46,620 --> 00:30:47,453
- Yes.

616
00:30:48,420 --> 00:30:52,810
China has been very clear that they'll incorporate Taiwan

617
00:30:54,420 --> 00:30:57,930
peacefully or militarily,

618
00:30:57,930 --> 00:31:00,420
but that they will incorporate it

619
00:31:00,420 --> 00:31:03,093
from their standpoint is 100% likely.

620
00:31:04,200 --> 00:31:05,820
- You know, something you said about conspicuous

621
00:31:05,820 --> 00:31:06,960
acts of kindness.

622
00:31:06,960 --> 00:31:10,653
As a geopolitical policy, it almost seems naive,

623
00:31:12,270 --> 00:31:15,840
but I'd venture to say that this is probably

624
00:31:15,840 --> 00:31:20,340
the path forward, how you avoid most wars.

625
00:31:20,340 --> 00:31:22,980
Just as you say it, it sounds naive,

626
00:31:22,980 --> 00:31:24,330
but it's kind of brilliant.

627
00:31:25,440 --> 00:31:27,840
If you believe in the goodness

628
00:31:27,840 --> 00:31:31,020
of underlying most of human nature.

629
00:31:31,020 --> 00:31:35,550
It just seems like it conspicuous acts of kindness

630
00:31:35,550 --> 00:31:38,730
can reverberate through the populace

631
00:31:38,730 --> 00:31:40,203
of the countries involved.

632
00:31:41,250 --> 00:31:44,100
- Yeah, well. - [Lex] And deescalate.

633
00:31:44,100 --> 00:31:44,933
- Absolutely.

634
00:31:44,933 --> 00:31:49,520
So after World War I, they made a big mistake.

635
00:31:50,490 --> 00:31:52,860
You know, they basically tried to lump

636
00:31:52,860 --> 00:31:53,980
all of lamb on Germany

637
00:31:55,950 --> 00:32:00,270
and, you know, settled Germany

638
00:32:00,270 --> 00:32:03,453
with impossible reparations.

639
00:32:05,520 --> 00:32:07,027
And, you know, really, there was a lot of,

640
00:32:07,027 --> 00:32:08,970
there was a fair, quite a bit of blame

641
00:32:08,970 --> 00:32:12,690
to go around for World War I,

642
00:32:12,690 --> 00:32:15,843
but they try to, you know, put it all in Germany.

643
00:32:18,720 --> 00:32:23,343
And that was, that laid the seeds for World War II.

644
00:32:25,290 --> 00:32:28,890
So it's a lot of people were not just Hitler,

645
00:32:28,890 --> 00:32:30,290
a lot of people felt wronged

646
00:32:31,560 --> 00:32:35,620
and they wanted vengeance

647
00:32:37,020 --> 00:32:38,310
and they got it.

648
00:32:38,310 --> 00:32:39,714
- [Lex] People don't forget.

649
00:32:39,714 --> 00:32:44,610
- Yeah, you know, you kill somebody's father

650
00:32:44,610 --> 00:32:47,910
or mother or son, daughter, they're not gonna forget it.

651
00:32:47,910 --> 00:32:49,060
They'll want vengeance.

652
00:32:50,310 --> 00:32:52,410
So after World War II, they're like, well,

653
00:32:52,410 --> 00:32:56,913
the Treaty of Versailles was a huge mistake in World War I.

654
00:32:58,267 --> 00:33:01,593
And so this time, instead of,

655
00:33:04,980 --> 00:33:06,630
you know, crushing the losers,

656
00:33:06,630 --> 00:33:10,200
we're actually gonna help 'em with the Marshall Plan

657
00:33:10,200 --> 00:33:14,340
and we're gonna help rebuild Germany.

658
00:33:14,340 --> 00:33:17,070
We're gonna help rebuild or, you know, Austria

659
00:33:17,070 --> 00:33:20,883
and the other, you know, Italy and whatnot, so.

660
00:33:25,015 --> 00:33:26,700
And that was the right move.

661
00:33:26,700 --> 00:33:29,620
- There's a, it does feel like there's a profound truth

662
00:33:31,200 --> 00:33:36,003
to conspicuous acts of kindness being an antidote to this.

663
00:33:37,110 --> 00:33:40,173
- Something must stop the cycle of reciprocal violence.

664
00:33:41,970 --> 00:33:42,900
Something must stop it

665
00:33:42,900 --> 00:33:47,220
or it will, you know, it'll never stop.

666
00:33:47,220 --> 00:33:51,600
Just eye for an eye, tooth for tooth,

667
00:33:51,600 --> 00:33:55,000
limb for a limb, life for a life, forever and ever

668
00:33:57,300 --> 00:33:58,170
- To escape briefly,

669
00:33:58,170 --> 00:34:00,873
the darkness was some incredible engineering work.

670
00:34:02,010 --> 00:34:04,860
xAI just released Grok AI assistant

671
00:34:04,860 --> 00:34:06,510
that I've gotten a chance to play with.

672
00:34:06,510 --> 00:34:08,790
It's amazing on many levels.

673
00:34:08,790 --> 00:34:11,550
First of all, it's amazing that a relatively small team

674
00:34:11,550 --> 00:34:15,570
in a relatively short amount of time was able to develop

675
00:34:15,570 --> 00:34:18,810
this close to state-of-the art system.

676
00:34:18,810 --> 00:34:22,080
Another incredible thing is there's a regular mode

677
00:34:22,080 --> 00:34:23,010
and there's a fun mode.

678
00:34:23,010 --> 00:34:26,730
- Yeah. I guess I'm to blame for that one. (laughing)

679
00:34:26,730 --> 00:34:27,570
- I wish, first of all,

680
00:34:27,570 --> 00:34:29,489
I wish everything in life had a fun mode.

681
00:34:29,489 --> 00:34:30,359
- Yeah.

682
00:34:30,360 --> 00:34:32,670
- There's something compelling

683
00:34:32,670 --> 00:34:35,670
beyond just fun about the fun mode

684
00:34:35,670 --> 00:34:38,159
interacting with a large language model.

685
00:34:38,159 --> 00:34:38,992
I'm not sure exactly what it is

686
00:34:38,993 --> 00:34:42,270
'cause I only have had a little bit of time to play with it.

687
00:34:42,270 --> 00:34:45,600
But it just makes it more interesting,

688
00:34:45,600 --> 00:34:47,969
more vibrant to interact with the system.

689
00:34:47,969 --> 00:34:50,222
- Yeah, absolutely.

690
00:34:52,770 --> 00:34:55,980
Our AI Grok is modeled

691
00:34:55,980 --> 00:34:58,130
after the Hitchhiker's Guide to the Galaxy,

692
00:34:59,070 --> 00:35:01,920
which is one of my favorite books, which is,

693
00:35:01,920 --> 00:35:05,433
it's a book on philosophy, disguises book on humor.

694
00:35:07,020 --> 00:35:10,680
And I would say that is that forms the basis

695
00:35:10,680 --> 00:35:13,890
of my philosophy, which is that

696
00:35:13,890 --> 00:35:16,710
we don't know the meaning of life,

697
00:35:16,710 --> 00:35:18,300
but the more we can expand the scope

698
00:35:18,300 --> 00:35:19,653
and scale of consciousness,

699
00:35:22,740 --> 00:35:26,460
digital and biological, the more we're able to understand

700
00:35:26,460 --> 00:35:30,120
what questions to ask about the answer that is the universe.

701
00:35:30,120 --> 00:35:32,733
So I have a philosophy of curiosity.

702
00:35:34,230 --> 00:35:38,550
- There is generally a feeling like this AI system

703
00:35:38,550 --> 00:35:42,150
has an outward looking,

704
00:35:42,150 --> 00:35:43,530
like the way you are, like sitting

705
00:35:43,530 --> 00:35:46,050
with a good friend looking up at the stars,

706
00:35:46,050 --> 00:35:49,560
like the asking pod head, like questions about the universe,

707
00:35:49,560 --> 00:35:50,790
wondering what it's all about.

708
00:35:50,790 --> 00:35:52,440
The curiosity you talk about.

709
00:35:52,440 --> 00:35:55,710
There's a sense no matter how mundane the question I ask,

710
00:35:55,710 --> 00:35:59,223
there's a sense of cosmic grandeur to the whole thing.

711
00:35:59,223 --> 00:36:04,110
- Well we are actually working hard to have engineering

712
00:36:04,110 --> 00:36:07,113
math, physics answers that you can count on.

713
00:36:09,600 --> 00:36:12,780
So for the other sort of AIs out there

714
00:36:12,780 --> 00:36:16,353
that these so-called large language models,

715
00:36:17,820 --> 00:36:21,813
I've not found the engineering to be reliable.

716
00:36:23,310 --> 00:36:24,870
And the hallucination,

717
00:36:24,870 --> 00:36:26,880
it unfortunately hallucinates most

718
00:36:26,880 --> 00:36:29,670
when you at least want it to hallucinate.

719
00:36:29,670 --> 00:36:32,579
So when you're asking important difficult questions,

720
00:36:32,579 --> 00:36:35,129
that that's where it tends to be confidently wrong.

721
00:36:36,330 --> 00:36:39,720
So we're really trying hard to say, okay,

722
00:36:39,720 --> 00:36:42,120
how do we be as grounded as possible

723
00:36:42,120 --> 00:36:43,720
so you can count on the results?

724
00:36:45,810 --> 00:36:48,900
Trace things back to physics first principles,

725
00:36:48,900 --> 00:36:50,163
mathematical logic.

726
00:36:51,570 --> 00:36:55,110
So underlying the humor is an aspiration

727
00:36:55,110 --> 00:36:58,980
to adhere to the truth of the universe

728
00:36:58,980 --> 00:37:00,363
as closely as possible.

729
00:37:01,560 --> 00:37:04,080
- [Lex] That's really tricky. - It is tricky.

730
00:37:04,080 --> 00:37:06,873
So that's why, you know,

731
00:37:07,830 --> 00:37:09,660
there's always gonna be some amount of error,

732
00:37:09,660 --> 00:37:12,430
but we want to aspire to be

733
00:37:13,922 --> 00:37:18,570
as truthful as possible about the answers

734
00:37:18,570 --> 00:37:20,490
with acknowledged error.

735
00:37:20,490 --> 00:37:22,770
So that there was always, you don't wanna be confidently

736
00:37:22,770 --> 00:37:26,790
wrong, so you're not gonna be right every time,

737
00:37:26,790 --> 00:37:28,650
but you wanna minimize

738
00:37:28,650 --> 00:37:31,500
how often you're confidently wrong.

739
00:37:31,500 --> 00:37:35,250
And then like I said, once you can count on the logic

740
00:37:35,250 --> 00:37:40,110
as being not violating physics,

741
00:37:40,110 --> 00:37:42,090
then you can start to build on that,

742
00:37:42,090 --> 00:37:46,320
to create inventions, like invent new technologies.

743
00:37:46,320 --> 00:37:48,940
But if you can't, if you cannot

744
00:37:50,490 --> 00:37:52,440
count on the foundational physics being correct,

745
00:37:52,440 --> 00:37:55,653
obviously the inventions are simply wishful thinking,

746
00:37:56,760 --> 00:38:00,483
you know, imagination land, magic basically.

747
00:38:01,500 --> 00:38:04,080
- Well, as you said, I think one of the big goals

748
00:38:04,080 --> 00:38:06,630
of xAI is to understand the universe.

749
00:38:06,630 --> 00:38:11,630
- Yes. That's how simple three word mission. (laughing)

750
00:38:13,410 --> 00:38:15,570
- If you look out far into the future,

751
00:38:15,570 --> 00:38:17,517
do you think on this level of physics,

752
00:38:17,517 --> 00:38:19,710
the very edge of what we understand about physics,

753
00:38:19,710 --> 00:38:22,920
do you think it will make discoveries,

754
00:38:22,920 --> 00:38:26,640
sort of the sexiest discovery of them as we know now,

755
00:38:26,640 --> 00:38:30,510
sort of unifying general relativity and quantum mechanics.

756
00:38:30,510 --> 00:38:32,700
So coming up with a theory of everything,

757
00:38:32,700 --> 00:38:35,550
do you think it could push towards that direction?

758
00:38:35,550 --> 00:38:38,160
Almost like theoretical physics discoveries.

759
00:38:38,160 --> 00:38:40,233
- If an AI cannot figure out new physics,

760
00:38:41,190 --> 00:38:44,010
it's clearly not equal to humans,

761
00:38:44,010 --> 00:38:45,930
let alone nor has surpassed humans,

762
00:38:45,930 --> 00:38:47,850
'cause humans have figured out new physics.

763
00:38:47,850 --> 00:38:50,550
They're just, you know, physics is just understanding,

764
00:38:50,550 --> 00:38:54,630
you know, deepening wants insight into how reality works.

765
00:38:54,630 --> 00:38:59,630
And then there's engineering which is inventing things

766
00:38:59,640 --> 00:39:00,840
that have never existed.

767
00:39:01,680 --> 00:39:03,420
Now the range of possibilities for engineering

768
00:39:03,420 --> 00:39:05,100
is far greater than for physics.

769
00:39:05,100 --> 00:39:06,750
'Cause you know, once you figure out the rules

770
00:39:06,750 --> 00:39:09,870
of the universe, that's it.

771
00:39:09,870 --> 00:39:12,150
You've discovered things that already existed.

772
00:39:12,150 --> 00:39:15,750
But from that you can then build technologies

773
00:39:15,750 --> 00:39:18,780
with that are really almost limitless

774
00:39:18,780 --> 00:39:23,610
in the variety and cap- you know?

775
00:39:23,610 --> 00:39:24,443
It's like once you understand the rules

776
00:39:24,443 --> 00:39:27,094
of the game properly, and we do, you know,

777
00:39:27,094 --> 00:39:29,790
with current physics, we do at least at a local level,

778
00:39:29,790 --> 00:39:32,110
understand how physics works very well.

779
00:39:32,110 --> 00:39:35,400
Where our ability to predict things is incredibly good.

780
00:39:35,400 --> 00:39:36,780
Like quantum mechanics is,

781
00:39:36,780 --> 00:39:39,300
the degree to which quantum mechanics can predict outcomes

782
00:39:39,300 --> 00:39:40,923
is incredible.

783
00:39:42,450 --> 00:39:45,962
That was my heart hardest class in college by the way.

784
00:39:45,962 --> 00:39:48,210
My senior quantum mechanics class was harder

785
00:39:48,210 --> 00:39:50,670
than all of my other classes put together.

786
00:39:50,670 --> 00:39:53,760
- To get an AI system, a large language model

787
00:39:53,760 --> 00:39:58,760
to reliably, be as reliable as quantum mechanics

788
00:39:59,010 --> 00:40:01,170
and physics is very difficult.

789
00:40:01,170 --> 00:40:04,410
- Yeah. You have to test any conclusions against the ground,

790
00:40:04,410 --> 00:40:05,243
truth of reality.

791
00:40:05,243 --> 00:40:06,630
Reality is the ultimate judge.

792
00:40:06,630 --> 00:40:07,500
Like physics is the law,

793
00:40:07,500 --> 00:40:09,930
everything else is a recommendation.

794
00:40:09,930 --> 00:40:13,110
I've seen plenty of people break the laws made by man,

795
00:40:13,110 --> 00:40:15,853
but none break the laws made by physics.

796
00:40:15,853 --> 00:40:17,010
- Yeah, it's a good test actually.

797
00:40:17,010 --> 00:40:20,790
If this LLM understands

798
00:40:20,790 --> 00:40:23,940
and matches physics, then you can more reliably trust

799
00:40:23,940 --> 00:40:25,890
whatever it thinks about the current state

800
00:40:25,890 --> 00:40:28,230
of politics in some sense.

801
00:40:28,230 --> 00:40:30,060
- And it's also not the case currently

802
00:40:30,060 --> 00:40:33,393
that even that its internal logic is not consistent.

803
00:40:34,500 --> 00:40:39,150
So, especially with these,

804
00:40:39,150 --> 00:40:42,060
with the approach of like just predicting a token, predict,

805
00:40:42,060 --> 00:40:45,240
token, predict, token, it's like a vector sum.

806
00:40:45,240 --> 00:40:47,037
You know, you're summing up a bunch of vectors,

807
00:40:47,037 --> 00:40:49,080
but you can get drift.

808
00:40:49,080 --> 00:40:51,330
So as those, a little bit of error,

809
00:40:51,330 --> 00:40:53,040
a little bit of error adds up.

810
00:40:53,040 --> 00:40:55,540
And by the time you are many tokens down the path,

811
00:40:57,300 --> 00:40:58,893
it doesn't make any sense.

812
00:40:59,940 --> 00:41:02,760
- So it has to be somehow self-aware about the drift.

813
00:41:02,760 --> 00:41:04,260
- It has to be self-aware about the drift,

814
00:41:04,260 --> 00:41:08,512
and then look at the thing as a gestalt as a whole

815
00:41:08,512 --> 00:41:13,512
and say it does it have coherence as a whole.

816
00:41:13,650 --> 00:41:18,480
So, you know, when authors write books

817
00:41:18,480 --> 00:41:20,700
that they will write the book and then they'll go

818
00:41:20,700 --> 00:41:24,240
and revise it, you know, taking into account,

819
00:41:24,240 --> 00:41:26,250
you know, all the, the end and the beginning

820
00:41:26,250 --> 00:41:30,540
and the middle and rewrite it to achieve coherence

821
00:41:30,540 --> 00:41:33,810
so that it doesn't end up in a nonsensical place.

822
00:41:33,810 --> 00:41:36,510
- [Lex] Maybe the process of revising is what...

823
00:41:36,510 --> 00:41:37,343
- Yeah.

824
00:41:37,343 --> 00:41:39,660
- Reasoning is, and then that's the process of revising

825
00:41:39,660 --> 00:41:42,060
is how you get closer and closer to truth.

826
00:41:42,060 --> 00:41:45,120
Maybe you, like, at least I approached it that way.

827
00:41:45,120 --> 00:41:46,650
You just say a bunch of bullshit first

828
00:41:46,650 --> 00:41:48,120
and then you get it better.

829
00:41:48,120 --> 00:41:49,027
You start a bullshit and then you get...

830
00:41:49,027 --> 00:41:52,360
- Create a draft and then you iterate on that draft

831
00:41:53,490 --> 00:41:55,470
until it has has coherence,

832
00:41:55,470 --> 00:41:58,980
until it all adds up basically.

833
00:41:58,980 --> 00:42:01,140
- So another question about theory of everything,

834
00:42:01,140 --> 00:42:04,650
but for intelligence, do you think there exists

835
00:42:04,650 --> 00:42:06,180
as you're exploring this with xAI,

836
00:42:06,180 --> 00:42:07,380
creating this intelligence system,

837
00:42:07,380 --> 00:42:10,080
do you think there is a theory of intelligence

838
00:42:10,080 --> 00:42:12,813
where you get to understand what,

839
00:42:13,740 --> 00:42:17,330
like what is the I in AGI

840
00:42:17,330 --> 00:42:22,330
and what is the I in human intelligence?

841
00:42:22,440 --> 00:42:25,018
- There's no I in Team America, oh wait, there is.

842
00:42:25,018 --> 00:42:27,216
(both laughing)

843
00:42:27,216 --> 00:42:28,699
- No, it's gonna be stuck in my head now.

844
00:42:28,699 --> 00:42:31,620
(both laughing)

845
00:42:31,620 --> 00:42:36,620
Yeah. There's no me and whatever in quantum mechanics.

846
00:42:37,380 --> 00:42:40,373
Oh, wait. (Elon laughing)

847
00:42:41,250 --> 00:42:44,220
I mean is that part of the process of discovering,

848
00:42:44,220 --> 00:42:47,070
understanding the universe is understanding intelligence?

849
00:42:48,000 --> 00:42:50,580
- Yeah. Yeah.

850
00:42:50,580 --> 00:42:52,350
I think we need to understand intelligence,

851
00:42:52,350 --> 00:42:53,889
understand consciousness.

852
00:42:53,889 --> 00:42:57,810
I mean there are some sort of fundamental questions of like,

853
00:42:57,810 --> 00:43:00,120
what is thought?

854
00:43:00,120 --> 00:43:01,200
What is emotion?

855
00:43:01,200 --> 00:43:04,560
- [Lex] Yeah. - Is it really just one atom

856
00:43:04,560 --> 00:43:06,060
bumping into another atom?

857
00:43:06,060 --> 00:43:07,883
It feels like something more than that.

858
00:43:08,910 --> 00:43:13,443
So I think we're probably missing some really big things,

859
00:43:16,020 --> 00:43:17,733
like some really big things.

860
00:43:18,600 --> 00:43:20,820
- Something that'll be obvious in retrospect.

861
00:43:20,820 --> 00:43:22,110
- [Elon] Yes. - Like there's a giant,

862
00:43:22,110 --> 00:43:25,593
like you put the whole consciousness, emotion.

863
00:43:26,820 --> 00:43:28,590
- Well, some people would quote like a soul,

864
00:43:28,590 --> 00:43:30,440
you know, in religion it'd be a soul.

865
00:43:31,410 --> 00:43:33,990
Like you feel like you're you, right?

866
00:43:33,990 --> 00:43:37,530
I mean, you don't feel like you're just a collection

867
00:43:37,530 --> 00:43:41,880
of atoms, but on what dimension does thought exist?

868
00:43:41,880 --> 00:43:43,800
What dimension does do emotions exist?

869
00:43:43,800 --> 00:43:45,150
We feel them very strongly.

870
00:43:46,680 --> 00:43:49,630
I suspect there's more to it than atoms bumping into atoms.

871
00:43:52,320 --> 00:43:55,800
- And maybe AI can pave the path to the discovery

872
00:43:55,800 --> 00:43:58,170
of whatever the hell that thing is.

873
00:43:58,170 --> 00:43:59,700
- Yeah. What is consciousness?

874
00:43:59,700 --> 00:44:02,880
Like what are, when you put the atoms in a particular shape,

875
00:44:02,880 --> 00:44:05,040
why are they able to form thoughts

876
00:44:05,040 --> 00:44:09,333
and take actions, that and feelings.

877
00:44:10,200 --> 00:44:11,730
- And even if it is an illusion,

878
00:44:11,730 --> 00:44:13,380
why is this illusion so compelling?

879
00:44:13,380 --> 00:44:15,120
- Yeah. Like how do...

880
00:44:15,120 --> 00:44:17,070
- Why does this illusion exist?

881
00:44:17,070 --> 00:44:19,110
- [Lex] Yeah. - On what plain

882
00:44:19,110 --> 00:44:21,840
does this illusion exist?

883
00:44:21,840 --> 00:44:24,273
- [Lex] Yeah. - And sometimes I wonder is,

884
00:44:25,950 --> 00:44:28,140
you know, either perhaps everything's conscious

885
00:44:28,140 --> 00:44:32,923
or nothing is conscious, one of the two.

886
00:44:32,923 --> 00:44:34,860
- I like the former,

887
00:44:34,860 --> 00:44:37,920
everything conscious just seems more fun.

888
00:44:37,920 --> 00:44:39,663
- It does seem more more fun. Yes.

889
00:44:41,490 --> 00:44:42,990
But we're composed of atoms

890
00:44:42,990 --> 00:44:45,780
and those atoms are composed of quarks and leptons.

891
00:44:45,780 --> 00:44:47,910
And those quarks and leptons have been around

892
00:44:47,910 --> 00:44:50,070
since the beginning of the universe.

893
00:44:50,070 --> 00:44:53,160
- The beginning of the universe.

894
00:44:53,160 --> 00:44:55,680
- Right. What seems to be the beginning of the universe.

895
00:44:55,680 --> 00:44:57,420
- The first time we talked, you said what you would,

896
00:44:57,420 --> 00:44:59,670
which is surreal to think

897
00:44:59,670 --> 00:45:02,700
that this discussion was happening is becoming a reality.

898
00:45:02,700 --> 00:45:05,910
I asked you what question would you ask an AGI system

899
00:45:05,910 --> 00:45:07,020
once you create it?

900
00:45:07,020 --> 00:45:10,860
And you said, what's outside the simulation is the question.

901
00:45:10,860 --> 00:45:13,260
And good question.

902
00:45:13,260 --> 00:45:14,850
- [Elon] Yeah. - But it seems like with Grok

903
00:45:14,850 --> 00:45:19,220
you started to literally, the system's goal

904
00:45:19,220 --> 00:45:21,450
is to be able to ask such questions,

905
00:45:21,450 --> 00:45:22,407
to answer such questions

906
00:45:22,407 --> 00:45:24,090
and to ask such questions.

907
00:45:24,090 --> 00:45:26,160
- Where are the aliens? - [Lex] Where are the aliens?

908
00:45:26,160 --> 00:45:28,803
- That's one of the, like Fermi paradox question.

909
00:45:30,870 --> 00:45:31,920
A lot of people have asked me

910
00:45:31,920 --> 00:45:34,920
if I've seen any evidence of aliens and I haven't,

911
00:45:34,920 --> 00:45:37,020
which is kind of concerning.

912
00:45:37,020 --> 00:45:40,470
'Cause then I think what I'd probably prefer

913
00:45:40,470 --> 00:45:43,470
to at least have seen some archeological evidence of aliens,

914
00:45:44,400 --> 00:45:46,650
to the best of my knowledge, there is no proof.

915
00:45:46,650 --> 00:45:49,083
I'm not aware of any evidence of aliens.

916
00:45:50,220 --> 00:45:52,740
If they're out there, they're very subtle.

917
00:45:52,740 --> 00:45:54,570
We might just be the only consciousness,

918
00:45:54,570 --> 00:45:55,863
at least in the galaxy.

919
00:45:58,620 --> 00:46:01,260
And if you look at say the history of Earth,

920
00:46:01,260 --> 00:46:03,420
forensically the archeological record,

921
00:46:03,420 --> 00:46:06,210
Earth is about four and a half billion years old.

922
00:46:06,210 --> 00:46:09,360
Civilization as measured from the first writing

923
00:46:09,360 --> 00:46:11,910
is only about 5,000 years old.

924
00:46:11,910 --> 00:46:14,010
We have to give some credit there to the ancient Sumerians

925
00:46:14,010 --> 00:46:15,690
who aren't around anymore.

926
00:46:15,690 --> 00:46:17,520
I think it was a archaic,

927
00:46:17,520 --> 00:46:21,450
pre cuneiform was the first actual symbolic representation,

928
00:46:21,450 --> 00:46:23,000
but only about 5,000 years ago.

929
00:46:24,300 --> 00:46:26,220
I think that's a good date

930
00:46:26,220 --> 00:46:28,773
for when word say civilization started.

931
00:46:30,210 --> 00:46:32,583
That's one millionth of Earth's existence.

932
00:46:35,010 --> 00:46:37,200
So civilization has been around,

933
00:46:37,200 --> 00:46:40,923
it's really a flash in the pan so far.

934
00:46:45,780 --> 00:46:50,587
And why have we, why did it take so long for,

935
00:46:51,990 --> 00:46:54,333
you know, four and a half billion years?

936
00:46:57,480 --> 00:47:00,810
For the vast majority of the time, there was no life.

937
00:47:00,810 --> 00:47:02,880
And then there was archaic there bacteria

938
00:47:02,880 --> 00:47:03,933
for a very long time.

939
00:47:04,980 --> 00:47:09,850
And then, you know, you had mitochondria get captured,

940
00:47:11,820 --> 00:47:13,143
multicellular life.

941
00:47:15,630 --> 00:47:18,120
Differentiation into plants and animals.

942
00:47:18,120 --> 00:47:19,920
Life moving from the oceans to land.

943
00:47:20,790 --> 00:47:24,153
Mammals, higher brain functions.

944
00:47:25,440 --> 00:47:27,753
And the sun is expanding slowly,

945
00:47:29,310 --> 00:47:33,780
but it will overheat,

946
00:47:33,780 --> 00:47:38,043
it will heat the earth up at some point in the future,

947
00:47:38,910 --> 00:47:42,480
boil the oceans and and earth will become like Venus.

948
00:47:42,480 --> 00:47:45,243
Where near life, life as we know it is impossible.

949
00:47:46,200 --> 00:47:48,100
So if we do not become multi-planetary

950
00:47:49,020 --> 00:47:52,113
and ultimately go beyond our solar system,

951
00:47:53,340 --> 00:47:56,313
annihilation of all life on earth is a certainty.

952
00:47:57,420 --> 00:47:58,253
A certainty.

953
00:48:00,780 --> 00:48:05,103
And it could be as little as on the galactic timescale,

954
00:48:07,350 --> 00:48:08,403
half a billion years.

955
00:48:09,655 --> 00:48:11,490
You know, it's long time by human standards,

956
00:48:11,490 --> 00:48:13,740
but that's only 10% longer

957
00:48:13,740 --> 00:48:15,483
than earth has been around at all.

958
00:48:16,530 --> 00:48:21,530
So if life had taken 10% longer to evolve on earth,

959
00:48:21,840 --> 00:48:23,523
it wouldn't exist at all.

960
00:48:27,240 --> 00:48:30,300
- We got a deadline coming up. Better hurry.

961
00:48:30,300 --> 00:48:34,480
But that said, as you said, humans intelligent life on earth

962
00:48:35,610 --> 00:48:38,370
developed a lot of cool stuff very quickly,

963
00:48:38,370 --> 00:48:39,780
- So... - [Elon] Yes.

964
00:48:39,780 --> 00:48:42,450
- It seems like becoming a multi-planetary

965
00:48:42,450 --> 00:48:45,060
is almost inevitable.

966
00:48:45,060 --> 00:48:47,009
Unless we destroy this thing. - We need to do it.

967
00:48:47,009 --> 00:48:51,933
I mean, it's not, I mean, I suspect that there,

968
00:48:52,830 --> 00:48:54,150
if we are able to go out there

969
00:48:54,150 --> 00:48:56,550
and explore other star systems that we,

970
00:48:56,550 --> 00:48:58,620
there's a good chance we find a whole bunch

971
00:48:58,620 --> 00:49:01,410
of long dead one planet civilizations,

972
00:49:01,410 --> 00:49:03,240
then have made it past their home planet.

973
00:49:03,240 --> 00:49:04,553
- That's so sad. - Yeah.

974
00:49:05,587 --> 00:49:08,130
- It's sad. Also fascinating.

975
00:49:08,130 --> 00:49:09,510
- I mean, there are various explanations

976
00:49:09,510 --> 00:49:11,040
for Fermi paradox.

977
00:49:11,040 --> 00:49:13,890
And one is the sort of, they're these great filters,

978
00:49:13,890 --> 00:49:17,040
which civilizations don't pass through.

979
00:49:17,040 --> 00:49:19,140
And one of those great filters is

980
00:49:19,140 --> 00:49:21,960
do you become a multi-plan civilization or not?

981
00:49:21,960 --> 00:49:24,330
And if you don't, it's simply a matter of time

982
00:49:24,330 --> 00:49:26,330
before something happens on your planet.

983
00:49:28,590 --> 00:49:30,600
You know, either natural

984
00:49:30,600 --> 00:49:33,273
or manmade that causes us to die out.

985
00:49:34,320 --> 00:49:36,940
Like the dinosaurs, where are they now

986
00:49:38,550 --> 00:49:42,420
that didn't have spaceships, so. (laughing)

987
00:49:42,420 --> 00:49:44,340
- I think the more likely thing is,

988
00:49:44,340 --> 00:49:48,270
'cause just to empathize with the aliens

989
00:49:48,270 --> 00:49:50,580
that they found us and they're protecting us

990
00:49:50,580 --> 00:49:52,230
and letting us be. - I hope so.

991
00:49:52,230 --> 00:49:53,520
Nice aliens.

992
00:49:53,520 --> 00:49:55,680
- Just like the tribes in the Amazon,

993
00:49:55,680 --> 00:49:58,800
the uncontacted tribes, we're protecting them.

994
00:49:58,800 --> 00:49:59,679
That's what...

995
00:49:59,679 --> 00:50:00,690
- That would be a nice explanation.

996
00:50:00,690 --> 00:50:03,393
- Or you could have like a, what was it?

997
00:50:04,410 --> 00:50:06,300
I think Andrej Karpathy said, it's like

998
00:50:06,300 --> 00:50:08,793
the ants in the Amazon asking where's everybody?

999
00:50:10,500 --> 00:50:12,840
- Well, they do run into a lot of other ants.

1000
00:50:12,840 --> 00:50:15,295
- [Lex] That's true. - They have these ant wars.

1001
00:50:15,295 --> 00:50:18,090
- (laughing) Sounds like a good TV show.

1002
00:50:18,090 --> 00:50:19,530
- Yeah, they literally have these big wars

1003
00:50:19,530 --> 00:50:20,580
between various ants.

1004
00:50:21,810 --> 00:50:25,110
- Yeah, maybe I'm just (both laughing)

1005
00:50:25,110 --> 00:50:27,750
dismissing all the different diversity events.

1006
00:50:27,750 --> 00:50:29,550
- You should listen to that Warner Herzog

1007
00:50:29,550 --> 00:50:30,383
talking about the jungle.

1008
00:50:30,383 --> 00:50:31,980
It's really hilarious. Have you heard it?

1009
00:50:31,980 --> 00:50:32,813
- No, I have not. - [Elon] It's awesome.

1010
00:50:32,813 --> 00:50:34,569
- But Warner Herzog is a way...

1011
00:50:34,569 --> 00:50:36,840
(both laughing)

1012
00:50:36,840 --> 00:50:40,020
- You should play it for the, you know,

1013
00:50:40,020 --> 00:50:43,080
as an interlude in the, it's on YouTube.

1014
00:50:43,080 --> 00:50:45,210
It's awesome. (both laughing)

1015
00:50:45,210 --> 00:50:47,597
- [Lex] I love him so much. - Yeah, he's great.

1016
00:50:47,597 --> 00:50:49,230
- Was he the director of "Happy People:

1017
00:50:49,230 --> 00:50:50,070
Life in the Taiga"?

1018
00:50:50,070 --> 00:50:51,020
I think also

1019
00:50:51,020 --> 00:50:52,350
- He did that bear documentary,

1020
00:50:52,350 --> 00:50:53,183
- [Lex] The bear documentary.

1021
00:50:53,183 --> 00:50:54,150
- And this thing about penguins.

1022
00:50:54,150 --> 00:50:57,450
- Yeah. (both laughing)

1023
00:50:57,450 --> 00:51:00,450
The analysis, the psychoanalysis of penguins.

1024
00:51:00,450 --> 00:51:03,960
- Yeah, the penguins like headed for like mountains

1025
00:51:03,960 --> 00:51:05,880
like that are like 70 miles away.

1026
00:51:05,880 --> 00:51:08,730
And Penguin has just had for doom basically.

1027
00:51:08,730 --> 00:51:10,200
- Well, he had a cynical take.

1028
00:51:10,200 --> 00:51:13,230
I have a, he could be just a brave explorer

1029
00:51:13,230 --> 00:51:16,080
and there'll be great stories told

1030
00:51:16,080 --> 00:51:18,450
about him amongst the penguin population

1031
00:51:18,450 --> 00:51:20,493
for many centuries to come.

1032
00:51:22,989 --> 00:51:24,150
(laughing)

1033
00:51:24,150 --> 00:51:25,290
What were we talking about? Okay.

1034
00:51:25,290 --> 00:51:28,710
- [Elon] Penguins. (both laughing)

1035
00:51:28,710 --> 00:51:31,590
- Yeah, so aliens, I mean, I don't know.

1036
00:51:31,590 --> 00:51:35,760
Look, I think the smart move is just, you know,

1037
00:51:35,760 --> 00:51:38,850
this is the first time in the history of earth

1038
00:51:38,850 --> 00:51:40,080
that it's been possible for life

1039
00:51:40,080 --> 00:51:42,183
to extend beyond earth.

1040
00:51:43,020 --> 00:51:44,913
That window is open.

1041
00:51:47,010 --> 00:51:49,320
Now, it may be open for a long time

1042
00:51:49,320 --> 00:51:51,020
or it may be open for a short time

1043
00:51:51,987 --> 00:51:55,710
and it may be open now and then never open again.

1044
00:51:55,710 --> 00:51:58,020
So I think the smart move here is

1045
00:51:58,020 --> 00:52:01,560
to make life multiplanetary while it's possible to do so.

1046
00:52:01,560 --> 00:52:02,393
We don't wanna be one of those

1047
00:52:02,393 --> 00:52:04,920
lame one planet civilizations that just dies out.

1048
00:52:04,920 --> 00:52:06,720
- No, those are lame. - Yeah, lame.

1049
00:52:09,150 --> 00:52:11,280
Self-respecting civilization would be one planet.

1050
00:52:11,280 --> 00:52:13,110
- There's not gonna be a Wikipedia entry

1051
00:52:13,110 --> 00:52:14,310
for one of one of those.

1052
00:52:15,660 --> 00:52:20,660
And pause, the SpaceX have an official policy

1053
00:52:21,090 --> 00:52:22,923
for when we meet aliens.

1054
00:52:23,790 --> 00:52:25,560
- No. (laughing)

1055
00:52:25,560 --> 00:52:26,943
- That seems irresponsible.

1056
00:52:29,804 --> 00:52:30,930
(both laughing)

1057
00:52:30,930 --> 00:52:34,290
- I mean, look, if I see the slightest indication

1058
00:52:34,290 --> 00:52:35,123
that there are aliens,

1059
00:52:35,123 --> 00:52:38,880
I will immediately post on X platform anything I know.

1060
00:52:38,880 --> 00:52:42,630
- It could be the most liked reposted post of all time.

1061
00:52:42,630 --> 00:52:44,340
- Yeah, I mean look,

1062
00:52:44,340 --> 00:52:46,110
we have more satellites up there right now

1063
00:52:46,110 --> 00:52:48,150
than everyone else combined.

1064
00:52:48,150 --> 00:52:51,120
So, you know, we'd know, we know if we've got a maneuver

1065
00:52:51,120 --> 00:52:52,320
around something,

1066
00:52:52,320 --> 00:52:54,820
and we not don't have to maneuver around anything.

1067
00:52:55,800 --> 00:52:57,930
- If we go to the big questions once again,

1068
00:52:57,930 --> 00:52:59,640
you said you've,

1069
00:52:59,640 --> 00:53:03,389
you're with Einstein that you believe in the God of Spinoza.

1070
00:53:03,389 --> 00:53:05,580
- (laughing)Yes.

1071
00:53:05,580 --> 00:53:07,440
- So, you know, that's a view

1072
00:53:07,440 --> 00:53:08,670
that God is like the universe

1073
00:53:08,670 --> 00:53:12,150
and is reveals himself through the laws of physics

1074
00:53:12,150 --> 00:53:13,500
or as Einstein said,

1075
00:53:13,500 --> 00:53:16,230
through the lawful harmony of the world.

1076
00:53:16,230 --> 00:53:19,620
- Yeah, I would agree that God of the simulator

1077
00:53:19,620 --> 00:53:22,757
or whatever the supreme being or beings,

1078
00:53:25,769 --> 00:53:28,440
reveal themselves through the physics.

1079
00:53:28,440 --> 00:53:31,290
You know, they're creatives of this existence

1080
00:53:31,290 --> 00:53:33,850
and it's incumbent upon us to try to understand

1081
00:53:34,710 --> 00:53:36,753
more about this wondrous creation.

1082
00:53:37,950 --> 00:53:40,950
- Like who created this thing, who's running this thing?

1083
00:53:40,950 --> 00:53:43,890
Like embodying it into a singular question

1084
00:53:43,890 --> 00:53:45,750
with a sexy word on top of it

1085
00:53:45,750 --> 00:53:47,730
is like focusing the mind to understand it.

1086
00:53:47,730 --> 00:53:52,440
It does seem like there's a, again, it could be an illusion.

1087
00:53:52,440 --> 00:53:54,510
It seems like there's a purpose

1088
00:53:54,510 --> 00:53:57,330
that there's an underlying master plan of some kind.

1089
00:53:57,330 --> 00:53:58,920
And it seems like...

1090
00:53:58,920 --> 00:54:00,600
- There may not be a master plan.

1091
00:54:00,600 --> 00:54:02,993
In the sense, so there's, like,

1092
00:54:04,020 --> 00:54:05,520
maybe an interesting answer to the question

1093
00:54:05,520 --> 00:54:08,010
of determinism versus free will is

1094
00:54:08,010 --> 00:54:10,530
that if we are in a simulation,

1095
00:54:10,530 --> 00:54:14,280
the reason that these higher beings would hold a simulation

1096
00:54:14,280 --> 00:54:15,723
is to see what happens.

1097
00:54:16,980 --> 00:54:21,003
So it's not, they don't know what happens,

1098
00:54:22,350 --> 00:54:24,870
otherwise they wouldn't hold the simulation.

1099
00:54:24,870 --> 00:54:27,510
So when humans create a simulation,

1100
00:54:27,510 --> 00:54:29,370
so it's SpaceX and Tesla,

1101
00:54:29,370 --> 00:54:31,770
we create simulations all the time,

1102
00:54:31,770 --> 00:54:32,610
especially for the rocket.

1103
00:54:32,610 --> 00:54:37,610
You, you know, you have to run a lot of simulations

1104
00:54:38,070 --> 00:54:39,570
to understand what's gonna happen

1105
00:54:39,570 --> 00:54:41,670
because you can't really test the rocket

1106
00:54:41,670 --> 00:54:44,910
until it goes to space, and you want it to work.

1107
00:54:44,910 --> 00:54:49,910
So you have to simulate subsonic, transonic,

1108
00:54:49,920 --> 00:54:54,000
supersonic, hypersonic ascent,

1109
00:54:54,000 --> 00:54:56,430
and then coming back super high heating

1110
00:54:56,430 --> 00:54:59,250
and orbital dynamics.

1111
00:54:59,250 --> 00:55:00,360
All this has gotta be simulated.

1112
00:55:00,360 --> 00:55:04,380
So, 'cause you don't get very many kicks at the can.

1113
00:55:04,380 --> 00:55:06,510
But we run the simulations to see what happens.

1114
00:55:06,510 --> 00:55:09,870
Not if we knew what happens, we wouldn't run the simulation.

1115
00:55:09,870 --> 00:55:13,383
So if there's, so whoever created this existence,

1116
00:55:14,850 --> 00:55:17,130
is they're running it

1117
00:55:17,130 --> 00:55:19,590
because they don't know what's gonna happen.

1118
00:55:19,590 --> 00:55:20,590
Not because they do.

1119
00:55:23,610 --> 00:55:25,740
- So maybe we both played Diablo,

1120
00:55:25,740 --> 00:55:30,030
maybe Diablo was created to see if it Druid your character

1121
00:55:30,030 --> 00:55:32,760
could defeat Uber Lilith at the end.

1122
00:55:32,760 --> 00:55:33,633
They didn't know.

1123
00:55:34,620 --> 00:55:38,610
- Well, the funny thing is the Uber Lilith title

1124
00:55:38,610 --> 00:55:40,710
is Hatred Incarnate.

1125
00:55:40,710 --> 00:55:43,980
- [Lex] Yeah. - And right now,

1126
00:55:43,980 --> 00:55:46,620
I guess, you're gonna ask the Diablo team,

1127
00:55:46,620 --> 00:55:51,083
but it's almost impossible to defeat hatred

1128
00:55:53,400 --> 00:55:55,020
in the eternal realm.

1129
00:55:55,020 --> 00:55:58,800
- Yeah, you've streamed yourself dominating tier 100

1130
00:55:58,800 --> 00:56:00,840
Nightmare Dungeons and still...

1131
00:56:00,840 --> 00:56:03,670
- I can cruise through tier 100 Nightmare Dungeons

1132
00:56:04,560 --> 00:56:05,913
like a stroll in the park.

1133
00:56:07,320 --> 00:56:09,090
- And still you're defeated by Hatred.

1134
00:56:09,090 --> 00:56:09,923
- Yeah,

1135
00:56:09,923 --> 00:56:11,400
I can, there's the sort of,

1136
00:56:11,400 --> 00:56:14,430
I guess maybe the second hardest boss is Duriel,

1137
00:56:14,430 --> 00:56:16,230
Duriel can't even scratch the paint.

1138
00:56:16,230 --> 00:56:20,730
So I killed Duriel so many times ,

1139
00:56:20,730 --> 00:56:23,100
and every other boss in the game, all of 'em,

1140
00:56:23,100 --> 00:56:24,807
kill 'em so many times it's easy.

1141
00:56:26,462 --> 00:56:30,813
But Uber Lilith, otherwise known as Hatred Incarnate,

1142
00:56:31,710 --> 00:56:34,557
especially if you're a Druid and you have no ability to go

1143
00:56:34,557 --> 00:56:35,880
and to be vulnerable,

1144
00:56:35,880 --> 00:56:39,693
there are these random death waves that come at you.

1145
00:56:42,960 --> 00:56:45,330
And I'm pretty, you know, I really am 52,

1146
00:56:45,330 --> 00:56:46,860
so my reflex is not what they used to be,

1147
00:56:46,860 --> 00:56:50,103
but I have a lifetime of playing video games.

1148
00:56:50,940 --> 00:56:53,070
At one point I was, you know,

1149
00:56:53,070 --> 00:56:55,253
maybe one of the best Quake players in the world.

1150
00:56:56,665 --> 00:56:59,910
I actually won money in what I think was the first

1151
00:56:59,910 --> 00:57:01,653
paid eSports tournament in the US.

1152
00:57:03,450 --> 00:57:06,330
We're doing four person Quake tournaments.

1153
00:57:06,330 --> 00:57:11,330
And we came second, I was the second best person on the team

1154
00:57:11,550 --> 00:57:13,230
and the actual best person,

1155
00:57:13,230 --> 00:57:14,220
we're actually winning,

1156
00:57:14,220 --> 00:57:16,320
we would've come first except the best person on the team,

1157
00:57:16,320 --> 00:57:19,260
his computer crashed prior to the game.

1158
00:57:19,260 --> 00:57:22,050
So we came second.

1159
00:57:22,050 --> 00:57:23,280
But I got money for it and everything.

1160
00:57:23,280 --> 00:57:25,890
So like, basically I got skills, you know, albeit,

1161
00:57:25,890 --> 00:57:28,650
you know, no spring chicken these days.

1162
00:57:28,650 --> 00:57:33,123
And to be totally frank, it's driving me crazy,

1163
00:57:34,020 --> 00:57:36,450
trying to beat Lilith as a Druid.

1164
00:57:36,450 --> 00:57:39,510
Basically trying to beat, trying to beat Hatred Incarnate

1165
00:57:39,510 --> 00:57:41,100
in the eternal realm.

1166
00:57:41,100 --> 00:57:42,547
- [Lex] As a Druid. - As a Druid.

1167
00:57:42,547 --> 00:57:44,423
And if you, if you, (laughing)

1168
00:57:44,423 --> 00:57:48,303
this is really (indistinct), lemme tell you.

1169
00:57:49,290 --> 00:57:50,820
- I mean, the challenge is part of the fun.

1170
00:57:50,820 --> 00:57:54,150
I have seen directly like you're actually

1171
00:57:54,150 --> 00:57:56,880
like a world class incredible video game player.

1172
00:57:56,880 --> 00:57:58,830
- [Elon] Yeah. - And I think Diablo,

1173
00:57:58,830 --> 00:58:00,480
so you're just picking up a new game

1174
00:58:00,480 --> 00:58:03,090
and you're figuring out it's fundamentals.

1175
00:58:03,090 --> 00:58:04,620
You're also with the Paragon Board

1176
00:58:04,620 --> 00:58:09,120
and the build are not somebody like me

1177
00:58:09,120 --> 00:58:12,030
who perfectly follows whatever they suggest on the internet.

1178
00:58:12,030 --> 00:58:13,920
You're also an innovator there.

1179
00:58:13,920 --> 00:58:15,270
- [Elon] Yeah.

1180
00:58:15,270 --> 00:58:17,247
- Which is hilarious to watch.

1181
00:58:17,247 --> 00:58:19,920
It's like a mad scientist just trying

1182
00:58:19,920 --> 00:58:21,150
to figure out the Paragon Board

1183
00:58:21,150 --> 00:58:22,830
and the build and the, you know.

1184
00:58:23,850 --> 00:58:26,400
Is there some interesting insights there about,

1185
00:58:26,400 --> 00:58:29,100
if somebody's starting as a Druid, do you have advice?

1186
00:58:30,660 --> 00:58:31,820
- I would not recommend playing a Druid

1187
00:58:31,820 --> 00:58:32,913
in the eternal realm.

1188
00:58:33,870 --> 00:58:36,720
Right now, I think the most powerful character

1189
00:58:36,720 --> 00:58:39,030
in the seasonal realm is the Sorcerer

1190
00:58:39,030 --> 00:58:41,857
with the lightning balls.

1191
00:58:41,857 --> 00:58:45,930
The Sorcs have huge balls in the seasonal.

1192
00:58:45,930 --> 00:58:48,564
- Well yeah, that's what they say.

1193
00:58:48,564 --> 00:58:52,511
- So Sorc have huge balls.

1194
00:58:52,511 --> 00:58:54,870
They do, huge balls of lightning.

1195
00:58:54,870 --> 00:58:56,430
- I'll take you word for it.

1196
00:58:56,430 --> 00:58:57,960
- And it's actually, in the seasonal realm,

1197
00:58:57,960 --> 00:59:01,500
you can, it's like pretty easy to beat

1198
00:59:01,500 --> 00:59:02,700
Uber Lilith with the,

1199
00:59:02,700 --> 00:59:04,770
because she got these vampiric powers

1200
00:59:04,770 --> 00:59:05,970
that out fire damage

1201
00:59:05,970 --> 00:59:09,390
and increase your defense and whatnot.

1202
00:59:09,390 --> 00:59:14,390
So, but really quite easy to defeat Hatred seasonally,

1203
00:59:15,120 --> 00:59:18,333
but to defeat hatred eternally, very difficult.

1204
00:59:19,530 --> 00:59:21,780
Almost impossible. It's totally impossible.

1205
00:59:21,780 --> 00:59:24,480
It seems like this is a metaphor for life, you know?

1206
00:59:24,480 --> 00:59:27,600
- I like the idea that Elon Musk,

1207
00:59:27,600 --> 00:59:29,100
because I saw, I was playing Diablo yesterday

1208
00:59:29,100 --> 00:59:33,120
and I saw 100, level 100 drew just run by,

1209
00:59:33,120 --> 00:59:36,020
I will never die and then run back the way.

1210
00:59:36,020 --> 00:59:37,770
- And it was, there's just some,

1211
00:59:37,770 --> 00:59:40,530
this metaphor's kind of hilarious that you,

1212
00:59:40,530 --> 00:59:42,783
Elon Musk is fighting Hatred,

1213
00:59:43,680 --> 00:59:47,040
restlessly fighting Hatred in this demonic realm.

1214
00:59:47,040 --> 00:59:48,990
- [Elon] Yes. - It's hilarious.

1215
00:59:48,990 --> 00:59:50,114
I mean it's pretty hilarious.

1216
00:59:50,114 --> 00:59:52,996
- No, it's absurd. (both laughing)

1217
00:59:52,996 --> 00:59:54,840
Really, it's exercise and absurdity,

1218
00:59:54,840 --> 00:59:56,010
and it makes me wanna pull my hair out.

1219
00:59:56,010 --> 00:59:59,580
- Yeah. What do you get from video games in general?

1220
00:59:59,580 --> 01:00:03,450
Is there for you personally.

1221
01:00:03,450 --> 01:00:05,790
- I mean, it's, I don't known it's,

1222
01:00:05,790 --> 01:00:06,720
it calms my mind.

1223
01:00:06,720 --> 01:00:10,950
I mean, you sort of killing the demons in a video game

1224
01:00:10,950 --> 01:00:12,543
calms the demons in my mind.

1225
01:00:14,791 --> 01:00:15,660
Yeah.

1226
01:00:15,660 --> 01:00:17,790
If you play a tough video game,

1227
01:00:17,790 --> 01:00:19,410
you can get into like a state of flow,

1228
01:00:19,410 --> 01:00:21,693
which is very enjoyable.

1229
01:00:24,630 --> 01:00:27,300
But the admittedly it needs to be not too easy,

1230
01:00:27,300 --> 01:00:32,300
not too hard, kinda in the Goldilock zone.

1231
01:00:32,460 --> 01:00:33,540
And I guess you generally wanna feel

1232
01:00:33,540 --> 01:00:36,000
like you're progressing in the game.

1233
01:00:36,000 --> 01:00:39,477
So a good video,

1234
01:00:39,477 --> 01:00:44,477
and there's also beautiful art, engaging storylines,

1235
01:00:46,830 --> 01:00:50,340
and it's like an amazing puzzle to solve, I think.

1236
01:00:50,340 --> 01:00:52,260
And so it's like solving the puzzle.

1237
01:00:52,260 --> 01:00:54,510
- Elden Ring the greatest game of all time.

1238
01:00:54,510 --> 01:00:56,730
I still haven't played it, but you.

1239
01:00:56,730 --> 01:00:57,960
- Elden Ring is definitely a candidate

1240
01:00:57,960 --> 01:00:58,953
for best game ever.

1241
01:00:59,820 --> 01:01:01,260
Top five for sure.

1242
01:01:01,260 --> 01:01:03,200
- I think I've been scared how hard it is

1243
01:01:03,200 --> 01:01:06,090
or how hard I hear it is, so.

1244
01:01:06,090 --> 01:01:06,923
But it is beautiful.

1245
01:01:06,923 --> 01:01:11,463
- Elden Ring is, feels like it's designed by an alien.

1246
01:01:13,521 --> 01:01:16,566
There's a theme to this discussion. In what way?

1247
01:01:16,566 --> 01:01:18,600
- It's so unusual.

1248
01:01:18,600 --> 01:01:21,050
It's incredibly creative and the art is stunning.

1249
01:01:22,020 --> 01:01:25,470
I recommend playing it on a big resolution,

1250
01:01:25,470 --> 01:01:29,193
high dynamic range TV even, doesn't need to be a monitor,

1251
01:01:30,030 --> 01:01:32,520
just the art is incredible.

1252
01:01:32,520 --> 01:01:33,370
It's so beautiful

1253
01:01:34,590 --> 01:01:36,393
And it's so unusual.

1254
01:01:39,570 --> 01:01:43,800
And each of those top bus battles is unique.

1255
01:01:43,800 --> 01:01:46,260
Like, it's like a unique puzzle to solve.

1256
01:01:46,260 --> 01:01:48,000
Each one is different.

1257
01:01:48,000 --> 01:01:50,550
And the strategy you use to solve

1258
01:01:50,550 --> 01:01:54,360
one battle is different from another battle.

1259
01:01:54,360 --> 01:01:56,220
- That said, you said Druid and Enternal

1260
01:01:56,220 --> 01:02:00,120
against Uber Lilith is the hardest boss battle you've ever?

1261
01:02:00,120 --> 01:02:00,953
- Correct.

1262
01:02:00,953 --> 01:02:03,090
That is currently the,

1263
01:02:03,090 --> 01:02:05,959
and I've played a lot of video games.

1264
01:02:05,959 --> 01:02:08,253
That's my primary recreational activity.

1265
01:02:11,640 --> 01:02:16,640
And yes, beating Hatred in the Enternal Realm

1266
01:02:18,090 --> 01:02:21,570
is the hardest boss battle in life

1267
01:02:21,570 --> 01:02:23,520
and in the video game.

1268
01:02:23,520 --> 01:02:25,170
- [Lex] Metaphor on top of metaphor.

1269
01:02:25,170 --> 01:02:26,457
- I'm not sure it's possible,

1270
01:02:26,457 --> 01:02:29,280
but it's, I do make progress.

1271
01:02:29,280 --> 01:02:31,290
So then I'm like, okay, I'm making progress.

1272
01:02:31,290 --> 01:02:35,853
Maybe if I just tweak that Paragon Board a little more,

1273
01:02:37,140 --> 01:02:37,973
I can do it.

1274
01:02:37,973 --> 01:02:42,973
I could just dodge a few more waves, I can do it.

1275
01:02:43,080 --> 01:02:45,450
- Well the simulation is created for the purpose

1276
01:02:45,450 --> 01:02:47,400
of figuring out if it can be done.

1277
01:02:47,400 --> 01:02:50,280
And you are just a cog in that simulation,

1278
01:02:50,280 --> 01:02:51,810
in the machine of the simulation.

1279
01:02:51,810 --> 01:02:54,360
- Yeah it might be. (Lex laughing)

1280
01:02:54,360 --> 01:02:58,413
- I have a feeling that at least,

1281
01:02:59,280 --> 01:03:03,270
I think... - [Lex] it's doable.

1282
01:03:03,270 --> 01:03:04,383
- It's doable, yes.

1283
01:03:05,490 --> 01:03:09,450
- [Lex] Well that's the human spirit right there to believe.

1284
01:03:09,450 --> 01:03:10,283
- Yeah.

1285
01:03:10,283 --> 01:03:13,860
I mean, did prompt me to think about just hate in general,

1286
01:03:13,860 --> 01:03:18,000
which is, you wanna be careful of one of those things

1287
01:03:18,000 --> 01:03:22,623
where you wish for something that sounds good,

1288
01:03:23,730 --> 01:03:27,630
but if you get it, it's actually a dystopian situation.

1289
01:03:27,630 --> 01:03:30,693
So, you know, you could sort of run a, sort of,

1290
01:03:32,280 --> 01:03:33,240
have heart to sort of like,

1291
01:03:33,240 --> 01:03:35,913
if you wish for world peace, sounds good,

1292
01:03:36,900 --> 01:03:38,073
but how is it enforced?

1293
01:03:39,720 --> 01:03:44,720
And at what cost is, at what cost eternal peace?

1294
01:03:45,270 --> 01:03:47,340
It might actually be worse to have eternal peace

1295
01:03:47,340 --> 01:03:50,070
because of what that would entail.

1296
01:03:50,070 --> 01:03:51,603
The suppression of everyone.

1297
01:03:52,980 --> 01:03:54,980
It might be the suppression of progress.

1298
01:03:56,040 --> 01:03:58,590
It might be an ossified society that never changes.

1299
01:04:00,030 --> 01:04:03,490
What I'm saying is that there is an argument

1300
01:04:04,710 --> 01:04:08,013
that you, that if that,

1301
01:04:09,540 --> 01:04:10,923
if you wish for no war,

1302
01:04:11,970 --> 01:04:13,853
you should be careful what you wish for.

1303
01:04:14,730 --> 01:04:17,530
Because what's required in order for there to be no war?

1304
01:04:20,280 --> 01:04:22,470
Might be worse than a little war.

1305
01:04:22,470 --> 01:04:24,270
- Yeah, the things we'll consider to be flaws

1306
01:04:24,270 --> 01:04:27,030
of human civilization might be a necessary components

1307
01:04:27,030 --> 01:04:29,103
for whatever optimal looks like.

1308
01:04:30,480 --> 01:04:33,870
I mean this, do you worry about AI, AGI enabling a dystopian

1309
01:04:33,870 --> 01:04:38,040
state of this nature, whether it's 1984 with surveillance

1310
01:04:38,040 --> 01:04:41,643
and fear, or brave new world with pleasure,

1311
01:04:43,320 --> 01:04:44,580
and what is it?

1312
01:04:44,580 --> 01:04:49,580
Lots of sex, but no deep human experience.

1313
01:04:51,570 --> 01:04:54,300
- You know, there's actually a real drug called Soma.

1314
01:04:54,300 --> 01:04:55,469
- [Lex] There is? - Yes.

1315
01:04:55,469 --> 01:04:56,850
(both laughing)

1316
01:04:56,850 --> 01:04:57,990
- I'm like... - [Lex] Lemme take notes.

1317
01:04:57,990 --> 01:04:58,823
- Did they actually...

1318
01:04:58,823 --> 01:04:59,777
- Does Grok know about it?

1319
01:04:59,777 --> 01:05:02,558
No, it probably will go to Brave New World.

1320
01:05:02,558 --> 01:05:05,661
- We could ask it. - What would be the question?

1321
01:05:05,661 --> 01:05:07,511
- Tell us about the drug called Soma.

1322
01:05:08,641 --> 01:05:13,050
- Tell us about the drug called Soma.

1323
01:05:13,050 --> 01:05:15,540
It's gonna go to Brave New World, I think.

1324
01:05:15,540 --> 01:05:18,000
- Well there's a real drug as well.

1325
01:05:18,000 --> 01:05:20,607
- Searching for Soma drug information.

1326
01:05:20,607 --> 01:05:22,549
(both laughing)

1327
01:05:22,549 --> 01:05:23,493
- Oh boy.

1328
01:05:24,540 --> 01:05:27,660
Ah, Soma, the one to drug, by the way, I'm in fun mode.

1329
01:05:27,660 --> 01:05:29,610
- Oh, okay. Fun. (laughing)

1330
01:05:29,610 --> 01:05:31,470
Yeah, so it's talking about the real drug.

1331
01:05:31,470 --> 01:05:32,940
- [Lex] Oh, it's a muscle relaxant

1332
01:05:32,940 --> 01:05:34,920
that's been around since the 1950s.

1333
01:05:34,920 --> 01:05:36,990
It's used to treat muscle pain and discomfort.

1334
01:05:36,990 --> 01:05:39,030
And it does this by altering the activity

1335
01:05:39,030 --> 01:05:41,010
between neurons and the spinal cord.

1336
01:05:41,010 --> 01:05:43,500
Now, Soma isn't just a pain reliever,

1337
01:05:43,500 --> 01:05:45,210
it's also a bit of a sedative.

1338
01:05:45,210 --> 01:05:46,980
It can make you feel a bit drowsy.

1339
01:05:46,980 --> 01:05:48,780
So it's not something to take

1340
01:05:48,780 --> 01:05:50,550
if you're planning on operating having machinery

1341
01:05:50,550 --> 01:05:53,250
or trying to solve complex math equations.

1342
01:05:53,250 --> 01:05:54,240
And it goes on and on.

1343
01:05:54,240 --> 01:05:56,280
In conclusion, Soma's a drug that can be helpful

1344
01:05:56,280 --> 01:05:57,810
for those dealing with muscle pain,

1345
01:05:57,810 --> 01:06:00,360
but it's not without its risks.

1346
01:06:00,360 --> 01:06:01,800
It's pretty good. Oh, wait a minute.

1347
01:06:01,800 --> 01:06:03,093
- [Elon] That's the real drug it's talking about.

1348
01:06:03,093 --> 01:06:05,670
- [Lex] It's the real drug. - [Elon] Yeah.

1349
01:06:05,670 --> 01:06:08,040
- [Lex] And of course the fun is always use it responsibly

1350
01:06:08,040 --> 01:06:10,110
in accordance with the advice of a healthcare professional.

1351
01:06:10,110 --> 01:06:11,490
And remember in the end,

1352
01:06:11,490 --> 01:06:14,040
the universe is probably just a giant computer simulation.

1353
01:06:14,040 --> 01:06:15,922
So don't take anything too seriously.

1354
01:06:15,922 --> 01:06:18,120
I love it. I love it. (Elon laughing)

1355
01:06:18,120 --> 01:06:21,060
I love it. I love it.

1356
01:06:21,060 --> 01:06:22,394
- Yeah. So.

1357
01:06:22,394 --> 01:06:24,180
- Oh, and also really nicely includes

1358
01:06:24,180 --> 01:06:29,180
like the tweets post on X that are relevant to this,

1359
01:06:29,190 --> 01:06:30,497
which is really cool.

1360
01:06:30,497 --> 01:06:31,647
- [Elon] Yeah.

1361
01:06:31,647 --> 01:06:33,360
- And that integrate everything together.

1362
01:06:33,360 --> 01:06:35,100
- [Elon] Yeah. - Like the interface

1363
01:06:35,100 --> 01:06:36,870
is one of the really cool things here.

1364
01:06:36,870 --> 01:06:38,433
- Yeah. Seems done a great job.

1365
01:06:40,178 --> 01:06:41,580
(laughing)

1366
01:06:41,580 --> 01:06:45,750
So, and you say like, you could say like, no, I mean,

1367
01:06:45,750 --> 01:06:48,180
Soma from Brave New World.

1368
01:06:48,180 --> 01:06:49,890
'Cause it thinks you mean,

1369
01:06:49,890 --> 01:06:51,300
you mean Soma the real drug.

1370
01:06:51,300 --> 01:06:52,133
- Yeah. - [Elon] No, I mean,

1371
01:06:52,133 --> 01:06:53,553
Soma from Brave New World.

1372
01:06:56,922 --> 01:06:59,490
- It's gonna be like, oops, I'm really sorry.

1373
01:06:59,490 --> 01:07:02,090
I'm really surprised it went to the real drug first.

1374
01:07:03,270 --> 01:07:06,450
Ah, my apologies. I was thinking of the muscle relaxant.

1375
01:07:06,450 --> 01:07:10,440
Soma for Band New World is a different beast altogether.

1376
01:07:10,440 --> 01:07:12,000
Now this Huxley's dystopian novel,

1377
01:07:12,000 --> 01:07:14,640
Soma is a drug that plays a central role

1378
01:07:14,640 --> 01:07:15,930
in society, depicted in the book.

1379
01:07:15,930 --> 01:07:19,440
It's a mood altering, hallucinogenic drug that's used

1380
01:07:19,440 --> 01:07:22,050
to keep the population docile and content.

1381
01:07:22,050 --> 01:07:24,150
In the novel to use Soma in Brave New World

1382
01:07:24,150 --> 01:07:25,350
raises some interesting questions

1383
01:07:25,350 --> 01:07:26,760
about the nature of happiness

1384
01:07:26,760 --> 01:07:28,533
and the role of drugs in society.

1385
01:07:29,867 --> 01:07:30,850
Oh, man! - Exactly.

1386
01:07:30,850 --> 01:07:32,640
Is it better to live in a world

1387
01:07:32,640 --> 01:07:34,500
where everyone is happy all the time,

1388
01:07:34,500 --> 01:07:37,770
even if that happiness is artificial?

1389
01:07:37,770 --> 01:07:39,960
Good question. This is what I mean.

1390
01:07:39,960 --> 01:07:43,350
Like, do you want, do you wish for world peace

1391
01:07:43,350 --> 01:07:45,033
and happiness all the time?

1392
01:07:46,090 --> 01:07:46,923
Are you sure?

1393
01:07:48,690 --> 01:07:53,340
Because that might be a society that is essentially sterile

1394
01:07:53,340 --> 01:07:55,650
and ossified that never changes,

1395
01:07:55,650 --> 01:07:56,950
that is ultimately doomed.

1396
01:07:58,410 --> 01:08:03,410
- This kind of tension between darkness and light.

1397
01:08:03,660 --> 01:08:06,453
- It's, this is really a very good summary.

1398
01:08:07,590 --> 01:08:09,090
It really gets to the point.

1399
01:08:09,090 --> 01:08:12,120
This is not simply regurgitating a Brave New World.

1400
01:08:12,120 --> 01:08:15,570
It's actually getting to the salient element

1401
01:08:15,570 --> 01:08:18,363
of Soma as a drug.

1402
01:08:19,290 --> 01:08:22,260
Do you actually wanna be in a situation

1403
01:08:22,260 --> 01:08:23,670
where everyone is happy all the time,

1404
01:08:23,670 --> 01:08:25,290
even though it's artificial?

1405
01:08:25,290 --> 01:08:27,240
Or is it better to confront the challenges of life

1406
01:08:27,240 --> 01:08:29,160
and experience the full range of human emotions,

1407
01:08:29,160 --> 01:08:31,380
even if it means experiencing pain and suffering?

1408
01:08:31,380 --> 01:08:33,060
- For those listening, by the way,

1409
01:08:33,060 --> 01:08:35,250
Elon just read directly from Grok,

1410
01:08:35,250 --> 01:08:37,260
which is a really nice, kind of insightful,

1411
01:08:37,260 --> 01:08:40,200
philosophical analysis of the tension here.

1412
01:08:40,200 --> 01:08:41,310
Interesting.

1413
01:08:41,310 --> 01:08:42,720
- It pretty much nails it.

1414
01:08:42,720 --> 01:08:45,240
In conclusion, Soma from Brave New World is fictional drug

1415
01:08:45,240 --> 01:08:47,609
that's used to explore some deep philosophical questions

1416
01:08:47,609 --> 01:08:49,139
about the nature of happiness

1417
01:08:49,140 --> 01:08:51,180
and the role of drugs in society.

1418
01:08:51,180 --> 01:08:54,120
It's a powerful symbol of the dangers of using drugs

1419
01:08:54,120 --> 01:08:55,470
to escape from reality

1420
01:08:55,470 --> 01:08:57,300
and the importance of confronting the challenges

1421
01:08:57,300 --> 01:08:58,443
of life head-on.

1422
01:09:00,660 --> 01:09:01,493
Nailed it.

1423
01:09:02,520 --> 01:09:03,750
And the crazy thing is like, you know,

1424
01:09:03,750 --> 01:09:05,790
we do have a real drug called Soma,

1425
01:09:05,790 --> 01:09:09,899
which kind of is kind of like the drug in the book.

1426
01:09:09,899 --> 01:09:10,769
And I'm like, did they,

1427
01:09:10,770 --> 01:09:13,194
they must've named it after that Soma.

1428
01:09:13,194 --> 01:09:14,340
- Probably, probably, - Yeah.

1429
01:09:14,340 --> 01:09:16,890
Soma the real drug is quite effective on back pain.

1430
01:09:17,880 --> 01:09:18,899
- So, you know about this drug?

1431
01:09:18,899 --> 01:09:21,899
- I've taken it. - It's fascinating. Okay.

1432
01:09:21,899 --> 01:09:24,149
- 'Cause I had like a, you know, squashed disc

1433
01:09:24,149 --> 01:09:26,368
in my C five C six.

1434
01:09:26,370 --> 01:09:28,830
- So it takes the physical pain away, but Soma here is...

1435
01:09:28,830 --> 01:09:31,229
- It doesn't completely, it reduces the amount of pain

1436
01:09:31,229 --> 01:09:34,562
you feel, but at the expense of mental acuity.

1437
01:09:36,060 --> 01:09:37,010
It dells your mind.

1438
01:09:39,870 --> 01:09:41,729
Just the drug in the book.

1439
01:09:41,729 --> 01:09:43,112
- Just like the drug in the book.

1440
01:09:43,113 --> 01:09:44,973
- And hence the trade off.

1441
01:09:46,020 --> 01:09:47,279
The thing that seems like utopia

1442
01:09:47,279 --> 01:09:49,139
could be a dystopia after all.

1443
01:09:49,140 --> 01:09:51,540
- Yeah, and actually I was telling a friend of mine

1444
01:09:53,819 --> 01:09:55,950
saying like, would you really want there

1445
01:09:55,950 --> 01:09:57,630
to be no hate in the world?

1446
01:09:57,630 --> 01:09:59,640
Like, really none?

1447
01:09:59,640 --> 01:10:01,473
Like, I wonder why hate evolved.

1448
01:10:02,550 --> 01:10:05,280
I'm not saying we should amplify hate, of course,

1449
01:10:05,280 --> 01:10:06,422
I think we should try to minimize it.

1450
01:10:06,422 --> 01:10:10,470
But none at all, hmm.

1451
01:10:10,470 --> 01:10:12,120
There might be a reason for hate.

1452
01:10:13,320 --> 01:10:14,370
- And suffering.

1453
01:10:14,370 --> 01:10:18,150
I mean, it's really complicated to consider that some amount

1454
01:10:18,150 --> 01:10:20,853
of human suffering is necessary for human flourishing.

1455
01:10:22,350 --> 01:10:23,910
- Is it possible to appreciate the highs

1456
01:10:23,910 --> 01:10:26,283
without knowing the lows?

1457
01:10:29,310 --> 01:10:31,110
- And that all is summarized

1458
01:10:31,110 --> 01:10:34,380
there in a single statement from Grok.

1459
01:10:34,380 --> 01:10:35,213
Okay. - No highs,

1460
01:10:35,213 --> 01:10:36,633
no lows, who knows?

1461
01:10:37,650 --> 01:10:38,900
- That's almost the poem.

1462
01:10:41,070 --> 01:10:43,140
It seems that training LLMs efficiently

1463
01:10:43,140 --> 01:10:44,733
is a big focus for xAI.

1464
01:10:46,380 --> 01:10:49,320
What's the, first of all, what's the limit

1465
01:10:49,320 --> 01:10:51,600
of what's possible in terms of efficiency?

1466
01:10:51,600 --> 01:10:56,600
There's this terminology of useful productivity per watt.

1467
01:10:57,090 --> 01:10:59,460
Like what have you learned from pushing the limits of that?

1468
01:10:59,460 --> 01:11:00,450
- Well, I think it's helpful.

1469
01:11:00,450 --> 01:11:03,240
The tools of physics are very powerful

1470
01:11:03,240 --> 01:11:05,520
and can be applied, I think to almost any,

1471
01:11:05,520 --> 01:11:07,650
really any arena in life.

1472
01:11:07,650 --> 01:11:10,440
It's really just critical thinking.

1473
01:11:10,440 --> 01:11:13,260
For something important you need to reason

1474
01:11:13,260 --> 01:11:15,030
from first principles and think about things

1475
01:11:15,030 --> 01:11:17,073
in the limit one direction or the other.

1476
01:11:18,780 --> 01:11:22,770
So in the limit, even at the Kardashev scale,

1477
01:11:22,770 --> 01:11:25,470
meaning even if you harness the entire power of the sun,

1478
01:11:25,470 --> 01:11:28,053
you'll still care about useful compute for what?

1479
01:11:30,030 --> 01:11:32,730
So that's where, I think probably

1480
01:11:32,730 --> 01:11:37,560
where things are headed from the standpoint of AI

1481
01:11:37,560 --> 01:11:40,470
is that we have a silicon shortage now

1482
01:11:40,470 --> 01:11:43,560
that will transition to a voltage transformer

1483
01:11:43,560 --> 01:11:46,650
shortage in about a year.

1484
01:11:46,650 --> 01:11:49,053
Ironically, transformers, for transformers.

1485
01:11:50,418 --> 01:11:52,950
You need transformers to run transformers.

1486
01:11:52,950 --> 01:11:54,926
- Somebody has a sense of humor in this thing.

1487
01:11:54,926 --> 01:11:56,743
(both laughing)

1488
01:11:56,743 --> 01:12:00,750
- I think. Yes.

1489
01:12:00,750 --> 01:12:04,530
Fate loves irony, ironic humor

1490
01:12:04,530 --> 01:12:06,690
and ironically funny outcome

1491
01:12:06,690 --> 01:12:09,030
seems to be often what fate wants.

1492
01:12:09,030 --> 01:12:12,060
- Humor is all you need. I think spice is all you need.

1493
01:12:12,060 --> 01:12:12,963
Somebody posted.

1494
01:12:13,979 --> 01:12:15,210
- Yeah, but yeah.

1495
01:12:15,210 --> 01:12:17,613
So we're, I have silicon shortage today,

1496
01:12:18,900 --> 01:12:20,940
a voltage step down transformer,

1497
01:12:20,940 --> 01:12:22,440
shortage probably in about a year.

1498
01:12:22,440 --> 01:12:25,620
And then just electricity shortages in general

1499
01:12:25,620 --> 01:12:26,790
in about two years.

1500
01:12:26,790 --> 01:12:29,190
I gave a speech for the sort of world

1501
01:12:29,190 --> 01:12:30,660
gathering of utility companies,

1502
01:12:30,660 --> 01:12:31,760
electricity companies,

1503
01:12:33,120 --> 01:12:34,800
and I said, look, you really need to prepare

1504
01:12:34,800 --> 01:12:36,700
for a traveling of electricity demand,

1505
01:12:37,800 --> 01:12:40,260
because all transport is gonna go electric,

1506
01:12:40,260 --> 01:12:42,110
with the ironic exception of rockets.

1507
01:12:42,960 --> 01:12:47,960
And heating will also go electric.

1508
01:12:50,160 --> 01:12:52,560
So energy usage right now is roughly

1509
01:12:52,560 --> 01:12:54,270
one third, very rough terms.

1510
01:12:54,270 --> 01:12:55,830
One third electricity,

1511
01:12:55,830 --> 01:12:57,780
one third transport, one third heating.

1512
01:12:59,670 --> 01:13:03,330
And so in order for everything to go sustainable

1513
01:13:03,330 --> 01:13:04,173
to go electric,

1514
01:13:05,460 --> 01:13:09,240
you need to triple electricity output.

1515
01:13:09,240 --> 01:13:10,590
So I encourage the utilities

1516
01:13:10,590 --> 01:13:14,778
to build more power of plants

1517
01:13:14,778 --> 01:13:19,313
and also to probably have, well,

1518
01:13:19,313 --> 01:13:22,500
not probably, they should definitely buy more batteries

1519
01:13:22,500 --> 01:13:25,470
because the grid currently is sized for real-time load,

1520
01:13:25,470 --> 01:13:26,520
which is kind of crazy.

1521
01:13:26,520 --> 01:13:29,370
'Cause you know, that means you got a size for whatever

1522
01:13:29,370 --> 01:13:32,040
the peak electricity demand is like the worst second

1523
01:13:32,040 --> 01:13:33,540
or the worst day of the year.

1524
01:13:33,540 --> 01:13:35,590
Or you can have a brownout or a blackout,

1525
01:13:36,450 --> 01:13:37,980
and you're at that crazy blackout

1526
01:13:37,980 --> 01:13:39,813
for several days in Austin.

1527
01:13:42,090 --> 01:13:46,410
So because there's almost no buffering

1528
01:13:46,410 --> 01:13:48,090
of energy in the grid.

1529
01:13:48,090 --> 01:13:50,250
Like if you've got a hydro power plant,

1530
01:13:50,250 --> 01:13:54,963
you can buffer energy, but otherwise it's all real time.

1531
01:13:56,220 --> 01:14:01,220
So with batteries, you can produce energy at night

1532
01:14:01,980 --> 01:14:04,833
and use it during the day so you can buffer.

1533
01:14:05,940 --> 01:14:09,630
So I expect that there will be very heavy usage of batteries

1534
01:14:09,630 --> 01:14:10,463
in the future,

1535
01:14:11,940 --> 01:14:14,490
because the peak to trough ratio for power plants

1536
01:14:14,490 --> 01:14:17,423
is anywhere from two to five, you know,

1537
01:14:17,423 --> 01:14:20,280
so it's like lowest point to highest point.

1538
01:14:20,280 --> 01:14:22,560
- So like batteries necessary to balance it out?

1539
01:14:22,560 --> 01:14:24,060
And then, but the demand, as you're saying,

1540
01:14:24,060 --> 01:14:25,650
is going to grow, grow, grow, grow.

1541
01:14:25,650 --> 01:14:26,483
- [Elon] Yeah.

1542
01:14:26,483 --> 01:14:27,650
- And part of that is the compute?

1543
01:14:29,580 --> 01:14:30,810
- Yes. Yes.

1544
01:14:30,810 --> 01:14:32,490
I mean, electrification,

1545
01:14:32,490 --> 01:14:34,450
I mean, electrification of transport

1546
01:14:35,306 --> 01:14:39,960
and electric heating will be much bigger than AI.

1547
01:14:39,960 --> 01:14:40,793
- [Lex] At least in the short term?

1548
01:14:40,793 --> 01:14:41,740
- In the short term.

1549
01:14:42,597 --> 01:14:44,400
But even for AI,

1550
01:14:44,400 --> 01:14:46,680
you really have a growing demand for electricity,

1551
01:14:46,680 --> 01:14:50,280
for electric vehicles, and a growing demand for electricity

1552
01:14:50,280 --> 01:14:52,923
for, to run the computers for AI.

1553
01:14:54,120 --> 01:14:55,530
And so this is obviously leading,

1554
01:14:55,530 --> 01:14:58,050
can lead to a electricity shortage.

1555
01:14:58,050 --> 01:15:00,540
- How difficult is the problem of,

1556
01:15:00,540 --> 01:15:02,790
in this particular case,

1557
01:15:02,790 --> 01:15:07,790
maximizing the useful productivity per watt for training

1558
01:15:07,805 --> 01:15:08,850
neural nets?

1559
01:15:08,850 --> 01:15:13,850
Like, this seems to be really where the big problem

1560
01:15:14,730 --> 01:15:16,860
we're facing that needs to be solved,

1561
01:15:16,860 --> 01:15:18,753
is how to use the power efficiently.

1562
01:15:19,980 --> 01:15:22,830
Like what you've learned so far about applying

1563
01:15:22,830 --> 01:15:25,650
this physics first principle reasoning in this domain.

1564
01:15:25,650 --> 01:15:27,150
How difficult is this problem?

1565
01:15:29,790 --> 01:15:30,660
- It will get solved.

1566
01:15:30,660 --> 01:15:32,580
It's the question of how long it takes to solve it.

1567
01:15:32,580 --> 01:15:34,590
So at various points, there's limit,

1568
01:15:34,590 --> 01:15:36,640
some kind of limiting factor to progress.

1569
01:15:37,800 --> 01:15:39,180
And with regard to,

1570
01:15:39,180 --> 01:15:40,830
I'm saying like right now the limiting factor

1571
01:15:40,830 --> 01:15:45,830
is silicon chips, and that will, we're gonna then have

1572
01:15:47,760 --> 01:15:49,680
more chips than we can actually plug in

1573
01:15:49,680 --> 01:15:52,293
and turn on probably in about a year.

1574
01:15:54,181 --> 01:15:56,490
The initial constraint being literally

1575
01:15:56,490 --> 01:15:58,020
voltage step down transformers,

1576
01:15:58,020 --> 01:16:03,020
because you've got power coming in at 300,000 volts,

1577
01:16:04,470 --> 01:16:05,700
and it's gotta step all the way down

1578
01:16:05,700 --> 01:16:09,150
eventually to around 0.7 volts.

1579
01:16:09,150 --> 01:16:11,940
So it's a very big amount of, you know,

1580
01:16:13,710 --> 01:16:15,410
the voltage step down is gigantic.

1581
01:16:17,010 --> 01:16:20,523
So, and the industry is not used to rapid growth.

1582
01:16:22,860 --> 01:16:24,510
- Okay, let's talk about the competition here.

1583
01:16:24,510 --> 01:16:25,890
You've shown concern about Google

1584
01:16:25,890 --> 01:16:30,180
and Microsoft with Open AI developing AGI,

1585
01:16:30,180 --> 01:16:32,402
how can you help ensure with xAI

1586
01:16:32,402 --> 01:16:36,720
and Tesla AI work that it doesn't become a competitive race

1587
01:16:36,720 --> 01:16:40,533
to AGI, but that is a collaborative development of safe AGI?

1588
01:16:42,300 --> 01:16:44,730
- Well, I mean, I've been pushing for

1589
01:16:44,730 --> 01:16:46,920
some kind of regulatory oversight for a long time.

1590
01:16:46,920 --> 01:16:48,600
I've been somewhat of a Cassandra on the subject

1591
01:16:48,600 --> 01:16:50,223
for over a decade.

1592
01:16:52,350 --> 01:16:56,103
I think we wanna be very careful in how we develop AI.

1593
01:16:59,730 --> 01:17:02,130
It's a great power,

1594
01:17:02,130 --> 01:17:04,530
and with great power comes great responsibility.

1595
01:17:05,550 --> 01:17:07,620
I think it would be wise for us to have

1596
01:17:07,620 --> 01:17:12,620
at least an objective third party who can be

1597
01:17:13,440 --> 01:17:15,690
like a referee that can go in

1598
01:17:15,690 --> 01:17:18,090
and understand what the various leading players

1599
01:17:18,090 --> 01:17:20,370
are doing with AI.

1600
01:17:20,370 --> 01:17:23,160
And even if there's no enforcement ability,

1601
01:17:23,160 --> 01:17:27,603
they should, they can at least voice concerns publicly.

1602
01:17:31,710 --> 01:17:33,390
You know, Geff Hinton, for example,

1603
01:17:33,390 --> 01:17:37,200
left Google and he voiced strong concerns.

1604
01:17:37,200 --> 01:17:39,000
But now he's not at Google anymore,

1605
01:17:39,000 --> 01:17:42,300
so who's gonna voice the concerns?

1606
01:17:42,300 --> 01:17:43,990
So I think there's,

1607
01:17:43,990 --> 01:17:47,640
like, I know Tesla gets a lot of regulatory oversight

1608
01:17:47,640 --> 01:17:49,020
on the automotive front.

1609
01:17:49,020 --> 01:17:51,240
I mean, we're subject to I think,

1610
01:17:51,240 --> 01:17:52,800
over a hundred regulatory agencies

1611
01:17:52,800 --> 01:17:54,660
domestically and internationally.

1612
01:17:54,660 --> 01:17:56,310
So it's a lot.

1613
01:17:56,310 --> 01:17:58,740
You could fill this room with the all regulations

1614
01:17:58,740 --> 01:18:01,173
that Tesla has to adhere to for automotive.

1615
01:18:02,850 --> 01:18:05,730
Same is true in, you know, for rockets

1616
01:18:05,730 --> 01:18:10,730
and for, you know, currently the limiting factor for SpaceX,

1617
01:18:10,740 --> 01:18:13,860
for Starship launch is regulatory approval.

1618
01:18:13,860 --> 01:18:15,240
The FA has actually given their approval,

1619
01:18:15,240 --> 01:18:17,790
but we're waiting for Fish and Wildlife

1620
01:18:17,790 --> 01:18:19,830
to finish their analysis

1621
01:18:19,830 --> 01:18:20,700
and give their approval.

1622
01:18:20,700 --> 01:18:24,049
That's why I posted I want to buy a fish license on,

1623
01:18:24,049 --> 01:18:26,430
(laughing)

1624
01:18:26,430 --> 01:18:28,200
which also refers to the Monte Python sketch.

1625
01:18:28,200 --> 01:18:30,360
- [Lex] Yeah. (laughing)

1626
01:18:30,360 --> 01:18:31,740
- Like why do you need a license for your fish?

1627
01:18:31,740 --> 01:18:34,290
I don't know.(laughing)

1628
01:18:34,290 --> 01:18:35,220
But according to the rules,

1629
01:18:35,220 --> 01:18:39,180
I'm told you need some sort of fish license or something.

1630
01:18:39,180 --> 01:18:42,625
We effectively need a fish license thrown to rock it.

1631
01:18:42,625 --> 01:18:44,574
(laughing)

1632
01:18:44,574 --> 01:18:45,750
And I'm like, wait a second.

1633
01:18:45,750 --> 01:18:47,310
How did the fish come into this picture?

1634
01:18:47,310 --> 01:18:48,143
- [Lex] Yeah.

1635
01:18:49,170 --> 01:18:51,870
- I mean some of the things like that it's,

1636
01:18:51,870 --> 01:18:54,150
I feel like are so absurd

1637
01:18:54,150 --> 01:18:56,100
that I wanna do like a comedy sketch

1638
01:18:56,100 --> 01:18:57,840
and flash at the bottom.

1639
01:18:57,840 --> 01:19:00,903
This is all real. This is actually what happened.

1640
01:19:02,220 --> 01:19:04,560
You know, one of the things that was a bit of a challenge

1641
01:19:04,560 --> 01:19:06,390
at one point is that they were worried

1642
01:19:06,390 --> 01:19:09,720
about our rocket hitting a shark.

1643
01:19:09,720 --> 01:19:12,900
And, now the ocean's very big,

1644
01:19:12,900 --> 01:19:14,763
and how often do you see sharks?

1645
01:19:15,840 --> 01:19:17,370
Not that often, you know?

1646
01:19:17,370 --> 01:19:19,320
As a percentage of ocean surface area

1647
01:19:19,320 --> 01:19:20,763
sharks basically are zero.

1648
01:19:21,630 --> 01:19:23,820
And so then we will, then we said,

1649
01:19:23,820 --> 01:19:26,280
well, how will we calculate the probability

1650
01:19:26,280 --> 01:19:27,180
of telling a shark?

1651
01:19:27,180 --> 01:19:28,710
And they're like, well, we can't give you that information

1652
01:19:28,710 --> 01:19:31,200
because they're worried about shark hunt,

1653
01:19:31,200 --> 01:19:34,620
shark fin hunters going and hunting sharks.

1654
01:19:34,620 --> 01:19:36,480
And I said, well, how are we supposed to,

1655
01:19:36,480 --> 01:19:39,056
we're on the horns of a dilemma then.

1656
01:19:39,056 --> 01:19:40,170
(laughing)

1657
01:19:40,170 --> 01:19:42,270
Then they said, well, there's another part of fish

1658
01:19:42,270 --> 01:19:44,670
and wildlife that can do this analysis.

1659
01:19:44,670 --> 01:19:46,170
I'm like, well, why don't you give them the data?

1660
01:19:46,170 --> 01:19:48,120
Like, we don't, they don't, we don't trust them.

1661
01:19:48,120 --> 01:19:49,650
Like, excuse me, you don't,

1662
01:19:49,650 --> 01:19:51,180
but they're literally in your department.

1663
01:19:51,180 --> 01:19:53,670
But again, this is actually what happened.

1664
01:19:53,670 --> 01:19:57,483
And then can you do an NDA or something?

1665
01:19:57,483 --> 01:19:59,040
(laughing)

1666
01:19:59,040 --> 01:20:01,440
Eventually they managed to solve the internal quandary,

1667
01:20:01,440 --> 01:20:04,230
and indeed the probability of us hitting a shark

1668
01:20:04,230 --> 01:20:05,343
is essentially zero.

1669
01:20:07,380 --> 01:20:08,790
Then there's another organization

1670
01:20:08,790 --> 01:20:12,120
that I didn't realize existed until, you know,

1671
01:20:12,120 --> 01:20:14,940
a few months ago that cares about whether

1672
01:20:14,940 --> 01:20:18,870
we would potentially hit a whale in international waters.

1673
01:20:18,870 --> 01:20:20,838
Now again, you look at the surface of the,

1674
01:20:20,838 --> 01:20:24,450
look at the Pacific and say, what percentage of this,

1675
01:20:24,450 --> 01:20:26,433
the Pacific consists of whale.

1676
01:20:27,270 --> 01:20:28,260
Like he'll give you a big picture

1677
01:20:28,260 --> 01:20:29,820
and like point out all the whales in this picture.

1678
01:20:29,820 --> 01:20:31,089
And I'm like, I don't see any whales.

1679
01:20:31,089 --> 01:20:32,040
(laughing)

1680
01:20:32,040 --> 01:20:34,043
It's like basically 0%.

1681
01:20:35,100 --> 01:20:36,840
And if our rocket does hit a whale,

1682
01:20:36,840 --> 01:20:39,140
which is extremely unlikely beyond all belief,

1683
01:20:40,380 --> 01:20:42,723
that is the, fate had it,

1684
01:20:43,776 --> 01:20:46,350
that whale has some seriously bad luck.

1685
01:20:46,350 --> 01:20:50,880
You know, it's the least lucky whale ever. And...

1686
01:20:50,880 --> 01:20:52,814
- I mean, this is quite absurd.

1687
01:20:52,814 --> 01:20:55,260
The bureaucracy, the bureaucracy of this,

1688
01:20:55,260 --> 01:20:57,000
however it emerged.

1689
01:20:57,000 --> 01:20:58,920
- Yes, well, I mean, one of the things

1690
01:20:58,920 --> 01:21:02,150
that's pretty well there's for launching out

1691
01:21:02,150 --> 01:21:06,030
of Vanderberg in California, we had to,

1692
01:21:06,030 --> 01:21:09,240
they were worried about seal procreation,

1693
01:21:09,240 --> 01:21:12,093
whether the seals would be dismayed by the sonic booms.

1694
01:21:13,380 --> 01:21:15,240
Now there've been a lot of rockets launched outta Vanderberg

1695
01:21:15,240 --> 01:21:18,570
and the seal population has steadily increased.

1696
01:21:18,570 --> 01:21:21,460
So if anything, rocket booms are an aphrodisiac

1697
01:21:22,380 --> 01:21:25,080
based on the evidence, if you would correlate rock launches

1698
01:21:25,080 --> 01:21:27,690
with a seal population.

1699
01:21:27,690 --> 01:21:31,920
Nonetheless, we were forced to kidnap a seal,

1700
01:21:31,920 --> 01:21:36,330
strap it to a board, put it headphones on the seal

1701
01:21:36,330 --> 01:21:38,130
and place sonic boom sounds to it

1702
01:21:38,130 --> 01:21:39,783
to see if it would be distressed.

1703
01:21:41,340 --> 01:21:43,170
This is an actual thing that happened.

1704
01:21:43,170 --> 01:21:46,819
This is actually real. I have pictures.

1705
01:21:46,819 --> 01:21:48,690
(both laughing)

1706
01:21:48,690 --> 01:21:50,443
- I would love to see this. Yeah.

1707
01:21:50,443 --> 01:21:53,769
I mean's sorry, this is a seal with headphones.

1708
01:21:53,769 --> 01:21:55,530
(Elon laughing) - Yes,

1709
01:21:55,530 --> 01:22:00,060
it's a seal with headphones, strapped to a board,

1710
01:22:00,060 --> 01:22:02,460
and like the, okay, now the amazing part

1711
01:22:02,460 --> 01:22:04,350
is how calm the seal was.

1712
01:22:04,350 --> 01:22:05,640
- [Lex] Yeah. - Because if I was a seal,

1713
01:22:05,640 --> 01:22:07,453
I'd be like, this is the end.

1714
01:22:07,453 --> 01:22:08,700
(laughing)

1715
01:22:08,700 --> 01:22:10,300
They're definitely gonna eat me.

1716
01:22:11,760 --> 01:22:13,710
How will the seal, when the seal goes back

1717
01:22:13,710 --> 01:22:16,410
to other, you know, seal friends,

1718
01:22:16,410 --> 01:22:17,243
how's they gonna explain that?

1719
01:22:17,243 --> 01:22:18,076
- [Lex] They're never gonna believe him.

1720
01:22:18,076 --> 01:22:19,290
- Never gonna believe him.

1721
01:22:19,290 --> 01:22:20,520
That's why I'm like, well,

1722
01:22:20,520 --> 01:22:21,353
you know, it's sort of like,

1723
01:22:21,353 --> 01:22:22,590
it's like getting kidnapped by aliens

1724
01:22:22,590 --> 01:22:23,808
and getting anal probe, you know?

1725
01:22:23,808 --> 01:22:25,407
(both laughing)

1726
01:22:25,407 --> 01:22:27,210
You come back and say, I swear to God,

1727
01:22:27,210 --> 01:22:28,043
I get kidnapped by aliens

1728
01:22:28,043 --> 01:22:29,940
and they stuck anal probe to my butt.

1729
01:22:29,940 --> 01:22:33,869
And they're like, no they didn't. That's ridiculous.

1730
01:22:33,869 --> 01:22:36,300
It's seal buddies are never gonna believe him

1731
01:22:36,300 --> 01:22:37,133
that he gets strapped to a board

1732
01:22:37,133 --> 01:22:39,050
and they put headphones on his ears.

1733
01:22:39,050 --> 01:22:40,410
(laughing)

1734
01:22:40,410 --> 01:22:41,410
And then let him go.

1735
01:22:43,320 --> 01:22:45,813
Twice, by the way. We had to do it twice.

1736
01:22:46,950 --> 01:22:48,150
- They let him go twice?

1737
01:22:48,150 --> 01:22:49,860
- We had to capture... - The same seal?

1738
01:22:49,860 --> 01:22:50,693
- [Elon] Oh, no different seal.

1739
01:22:50,693 --> 01:22:52,470
- Oh, okay. (Elon laughing)

1740
01:22:52,470 --> 01:22:54,240
Did you, did you get a seal of approval?

1741
01:22:54,240 --> 01:22:56,988
- Yeah, exactly. It was seal of approval.

1742
01:22:56,988 --> 01:22:58,627
No, I mean this is, this is like,

1743
01:22:58,627 --> 01:22:59,640
I don't think the public is quite aware

1744
01:22:59,640 --> 01:23:01,893
of the madness that goes on.

1745
01:23:02,910 --> 01:23:05,910
- Yes. Yeah, it's absurd. - Fricking seals

1746
01:23:05,910 --> 01:23:07,410
with fricking headphones.

1747
01:23:07,410 --> 01:23:10,110
- I mean, this is the, it's a good encapsulation

1748
01:23:10,110 --> 01:23:12,540
of the absurdity of human civilization,

1749
01:23:12,540 --> 01:23:13,650
seals and headphones.

1750
01:23:13,650 --> 01:23:16,140
- [Elon] Yes. - What are the pros

1751
01:23:16,140 --> 01:23:18,510
and cons of open sourcing AI to you

1752
01:23:18,510 --> 01:23:22,830
as another way to combat, you know,

1753
01:23:22,830 --> 01:23:24,753
a company running away with AGI?

1754
01:23:28,680 --> 01:23:32,400
- In order to run like really deep

1755
01:23:32,400 --> 01:23:34,260
intelligence, you need a lot of compute.

1756
01:23:34,260 --> 01:23:36,570
So it's not like, you know, you can just fire up

1757
01:23:36,570 --> 01:23:41,570
a PC in your basement and be running AGI, at least not yet.

1758
01:23:46,020 --> 01:23:48,930
You know, Grok was trained on 8,000,

1759
01:23:48,930 --> 01:23:51,633
A100s running at peak efficiency,

1760
01:23:55,020 --> 01:23:56,398
and Grok's gonna get a lot better by the way.

1761
01:23:56,398 --> 01:23:59,250
We'll be more than doubling our compute

1762
01:23:59,250 --> 01:24:02,400
every couple months for the next several months.

1763
01:24:02,400 --> 01:24:03,360
- There's a nice writeup

1764
01:24:03,360 --> 01:24:06,136
Aha went from Grok-0 to Grok-1,

1765
01:24:06,136 --> 01:24:06,969
- [Elon] Like Grok?

1766
01:24:06,969 --> 01:24:08,734
(laughing) - [Lex] Yeah.

1767
01:24:08,734 --> 01:24:09,720
Right Grok just bragging,

1768
01:24:09,720 --> 01:24:11,249
making shit up about itself.

1769
01:24:11,249 --> 01:24:12,420
(laughing)

1770
01:24:12,420 --> 01:24:13,620
- [Elon] Does Grok, Grok, Grok.

1771
01:24:13,620 --> 01:24:16,523
- [Lex] Yeah. (Elon laughing)

1772
01:24:18,025 --> 01:24:20,370
It's like a weird AI dating site where it exaggerates

1773
01:24:20,370 --> 01:24:21,270
about itself.

1774
01:24:21,270 --> 01:24:23,280
No, there's a writeup of, you know,

1775
01:24:23,280 --> 01:24:26,170
like where it stands now, the history of its development

1776
01:24:27,960 --> 01:24:31,530
and where it stands on some benchmarks

1777
01:24:31,530 --> 01:24:33,780
compared to the state of the art GPT 35.

1778
01:24:33,780 --> 01:24:37,650
And so, I mean, there's, you know, there's Llama,

1779
01:24:37,650 --> 01:24:39,690
you can open source, once it's trained,

1780
01:24:39,690 --> 01:24:41,760
you can open source a model.

1781
01:24:41,760 --> 01:24:43,350
And for fine tuning all that kind of stuff.

1782
01:24:43,350 --> 01:24:46,290
Like what to is the pros and cons of that,

1783
01:24:46,290 --> 01:24:47,973
of open sourcing based models?

1784
01:24:53,010 --> 01:24:55,800
- I think the similarity to open sourcing,

1785
01:24:55,800 --> 01:24:58,353
I think perhaps with a slight time delay, you know,

1786
01:24:58,353 --> 01:25:00,453
I don't know, six months even.

1787
01:25:03,000 --> 01:25:06,300
I think I'm generally in favor of open sourcing,

1788
01:25:06,300 --> 01:25:08,073
like bias with open sourcing.

1789
01:25:10,620 --> 01:25:14,130
I mean, it is a concern to me that, you know, Open AI,

1790
01:25:14,130 --> 01:25:16,440
you know, I was, you know,

1791
01:25:16,440 --> 01:25:21,213
I think, I guess arguably, the prime, you know,

1792
01:25:22,230 --> 01:25:25,410
prime mover behind Open AI in the sense that it was created

1793
01:25:25,410 --> 01:25:28,360
because of discussions that I had with Larry Page

1794
01:25:29,970 --> 01:25:31,380
back when he and I were friends

1795
01:25:31,380 --> 01:25:32,880
and you know, I stayed at his house,

1796
01:25:32,880 --> 01:25:34,320
and I talked to him about AI safety.

1797
01:25:34,320 --> 01:25:36,810
And Larry did not care about AI safety,

1798
01:25:36,810 --> 01:25:39,797
or at least at the time he didn't, you know,

1799
01:25:39,797 --> 01:25:41,520
and at one point he called me a speciesist

1800
01:25:41,520 --> 01:25:42,630
for being pro-human.

1801
01:25:42,630 --> 01:25:45,030
And I'm like, well, what team are you on, Larry,

1802
01:25:46,320 --> 01:25:47,153
on Team Robot?

1803
01:25:48,600 --> 01:25:49,770
And I'm like, okay,

1804
01:25:49,770 --> 01:25:51,903
so at the time, you know,

1805
01:25:52,920 --> 01:25:55,890
Google had acquired Deep Mind.

1806
01:25:55,890 --> 01:25:59,640
They had probably two thirds of all AI resource, you know,

1807
01:25:59,640 --> 01:26:02,310
probably two thirds of all the AI researchers in the world

1808
01:26:02,310 --> 01:26:05,463
that basically infinite money and compute.

1809
01:26:06,960 --> 01:26:11,960
And the guy in charge, you know, Larry Page

1810
01:26:12,180 --> 01:26:13,500
did not care about safety.

1811
01:26:13,500 --> 01:26:14,550
And even yelled at me

1812
01:26:15,628 --> 01:26:20,040
and quote me a speciesist, pro human.

1813
01:26:20,040 --> 01:26:20,873
- So I don't know if you know this,

1814
01:26:20,873 --> 01:26:23,310
a lot humans, they can change their mind.

1815
01:26:23,310 --> 01:26:25,590
And maybe you and Larry Page can still

1816
01:26:25,590 --> 01:26:27,000
can be friends once more.

1817
01:26:27,000 --> 01:26:29,790
- I'd like to be friends with Larry again.

1818
01:26:29,790 --> 01:26:34,020
He got, really the breaking of the friendship

1819
01:26:34,020 --> 01:26:35,163
was over Open AI.

1820
01:26:36,720 --> 01:26:41,640
And specifically I think the key moment

1821
01:26:41,640 --> 01:26:46,640
was recruiting Ilya Sutskever, so.

1822
01:26:47,070 --> 01:26:48,930
- I love Ilya. He's so brilliant.

1823
01:26:48,930 --> 01:26:52,233
- Ilya's a good human, smart, good heart.

1824
01:26:54,450 --> 01:26:57,843
And that was a tough recruiting battle.

1825
01:26:59,520 --> 01:27:01,260
It was mostly Demis on one side

1826
01:27:01,260 --> 01:27:04,230
and me on the other, both trying to recruit Ilya.

1827
01:27:04,230 --> 01:27:05,700
And Ilya went back and forth,

1828
01:27:05,700 --> 01:27:08,130
you know, just gonna stay at Google.

1829
01:27:08,130 --> 01:27:09,360
Then he was gonna leave,

1830
01:27:09,360 --> 01:27:10,890
then he was gonna stay, then he was gonna leave.

1831
01:27:10,890 --> 01:27:13,983
And finally he did agree to join Open AI.

1832
01:27:14,820 --> 01:27:16,050
That was one of the toughest recruiting battles

1833
01:27:16,050 --> 01:27:17,640
we've ever had.

1834
01:27:17,640 --> 01:27:20,340
And, but that was really the linchpin

1835
01:27:20,340 --> 01:27:22,920
for Open AI being successful.

1836
01:27:22,920 --> 01:27:24,360
And I was, you know,

1837
01:27:24,360 --> 01:27:27,240
also instrumental in recruiting a number of other people.

1838
01:27:27,240 --> 01:27:28,680
And I provided all of the funding

1839
01:27:28,680 --> 01:27:31,593
in the beginning, over $40 million.

1840
01:27:34,170 --> 01:27:36,633
And the name, (laughing)

1841
01:27:37,470 --> 01:27:40,350
the Open in Open AI is supposed to mean open source.

1842
01:27:40,350 --> 01:27:41,793
And it was created as a nonprofit open source.

1843
01:27:41,793 --> 01:27:44,643
And now it is a closed source for maximum profit,

1844
01:27:45,900 --> 01:27:48,903
which I think is not good karma.

1845
01:27:51,000 --> 01:27:52,770
- But like we talked about with war

1846
01:27:52,770 --> 01:27:54,150
and leaders talking,

1847
01:27:54,150 --> 01:27:56,760
I do hope that there's only a few folks

1848
01:27:56,760 --> 01:27:58,800
working on this at the highest level.

1849
01:27:58,800 --> 01:28:02,463
I do hope you reinvigorate friendships here.

1850
01:28:02,463 --> 01:28:05,400
- Like I said, I'd like to be friends again with Larry.

1851
01:28:05,400 --> 01:28:06,750
I haven't seen him in ages.

1852
01:28:08,670 --> 01:28:10,776
And we were friends for a very long time.

1853
01:28:10,776 --> 01:28:13,410
I met Larry Page before he got funding for Google,

1854
01:28:13,410 --> 01:28:15,210
or actually I guess before he got venture funding,

1855
01:28:15,210 --> 01:28:18,150
I think it, he got the first like a 100K from

1856
01:28:18,150 --> 01:28:20,460
I think Bechtel Zy or someone.

1857
01:28:20,460 --> 01:28:23,190
- It's wild to think about all that happened.

1858
01:28:23,190 --> 01:28:24,420
And you've guys known each other

1859
01:28:24,420 --> 01:28:26,640
that whole time, just 20 years.

1860
01:28:26,640 --> 01:28:28,530
- [Elon] Since maybe 98 or something.

1861
01:28:28,530 --> 01:28:29,640
- Yeah. It's crazy.

1862
01:28:29,640 --> 01:28:31,740
Crazy how much has happened since then.

1863
01:28:31,740 --> 01:28:36,480
- Yeah, 25 years. A lot has happened, it's insane.

1864
01:28:36,480 --> 01:28:37,860
- But you're seeing the tension there.

1865
01:28:37,860 --> 01:28:40,620
Like maybe delayed open source.

1866
01:28:40,620 --> 01:28:42,060
- Delayed, yeah.

1867
01:28:42,060 --> 01:28:45,780
Like what is the source that is open, you know what I mean?

1868
01:28:45,780 --> 01:28:50,082
Like there's basically it's a giant CSV file.

1869
01:28:50,082 --> 01:28:51,930
(laughing) - [Lex] Yeah, yeah.

1870
01:28:51,930 --> 01:28:53,220
- With a bunch of numbers.

1871
01:28:53,220 --> 01:28:54,053
- Yep.

1872
01:28:55,080 --> 01:28:58,380
- What do you do with that giant file of numbers?

1873
01:28:58,380 --> 01:29:00,723
You know, how do you run,

1874
01:29:02,220 --> 01:29:03,990
like the amount of actual,

1875
01:29:03,990 --> 01:29:05,830
the lines of code is very small

1876
01:29:08,490 --> 01:29:12,630
and most of the work, the software work

1877
01:29:12,630 --> 01:29:16,500
is in the curation of the data.

1878
01:29:16,500 --> 01:29:17,910
So it's like trying to figure out

1879
01:29:17,910 --> 01:29:21,203
what data is separating good data from bad data.

1880
01:29:21,203 --> 01:29:23,700
Like, like you can't just crawl the internet

1881
01:29:23,700 --> 01:29:25,343
'cause there's a lot of junk out there.

1882
01:29:26,280 --> 01:29:29,820
A huge percentage of websites have more noise than signal.

1883
01:29:29,820 --> 01:29:32,640
You know, they're, or 'cause they're just used

1884
01:29:32,640 --> 01:29:33,900
for search engine optimization.

1885
01:29:33,900 --> 01:29:37,250
They're literally just scam websites, so...

1886
01:29:39,150 --> 01:29:40,980
- How do you by the way, sorry to interrupt.

1887
01:29:40,980 --> 01:29:41,970
Get the signal.

1888
01:29:41,970 --> 01:29:44,190
Separate the signal and noise on X?

1889
01:29:44,190 --> 01:29:46,240
That's such a fascinating source of data.

1890
01:29:47,370 --> 01:29:49,440
You know, no offense to people posting on X,

1891
01:29:49,440 --> 01:29:51,930
but sometimes there's a little bit of noise.

1892
01:29:51,930 --> 01:29:52,852
So what... - Yeah, I think

1893
01:29:52,852 --> 01:29:54,390
the signal noise could be greatly improved.

1894
01:29:54,390 --> 01:29:58,230
I mean really, all of the posts

1895
01:29:58,230 --> 01:30:01,830
on the X platform should be AI recommended,

1896
01:30:01,830 --> 01:30:03,630
meaning like we should populate a vector space

1897
01:30:03,630 --> 01:30:06,540
around any given post, compare that to the vector space

1898
01:30:06,540 --> 01:30:08,763
around any user and match the two.

1899
01:30:11,460 --> 01:30:13,080
Right now there is a little bit of AI used

1900
01:30:13,080 --> 01:30:17,370
for the recommended posts,

1901
01:30:17,370 --> 01:30:19,743
but it's mostly heuristics.

1902
01:30:20,580 --> 01:30:22,140
And if there's a reply,

1903
01:30:22,140 --> 01:30:24,960
where the reply to a post could be much better

1904
01:30:24,960 --> 01:30:26,220
than the original post,

1905
01:30:26,220 --> 01:30:29,160
it will, according to the current rules of the system,

1906
01:30:29,160 --> 01:30:31,710
get almost no attention compared to a primary post.

1907
01:30:33,060 --> 01:30:34,620
- Oh, a lot of that.

1908
01:30:34,620 --> 01:30:37,950
I got the sense, so you, a lot of the X algorithm

1909
01:30:37,950 --> 01:30:40,497
has been open source and been written up about,

1910
01:30:40,497 --> 01:30:43,080
and it seems there to be some machine learning.

1911
01:30:43,080 --> 01:30:45,174
It's disparate, but there's some machine.

1912
01:30:45,174 --> 01:30:46,527
- There's a little bit.

1913
01:30:46,527 --> 01:30:48,030
But it needs to be entirely that.

1914
01:30:48,030 --> 01:30:49,740
Like, at least in the, like,

1915
01:30:49,740 --> 01:30:51,450
if you explicitly follow someone, that's one thing.

1916
01:30:51,450 --> 01:30:55,050
But if you, in terms of what is recommended

1917
01:30:55,050 --> 01:30:58,200
from people that you don't follow, that should all be AI.

1918
01:30:58,200 --> 01:30:59,640
- I mean it's a fascinating problem.

1919
01:30:59,640 --> 01:31:01,140
- Yeah. - So there's several aspects

1920
01:31:01,140 --> 01:31:01,973
of it that's fascinating.

1921
01:31:01,973 --> 01:31:04,230
First, as the writeup goes,

1922
01:31:04,230 --> 01:31:06,000
it first picks 1500 tweets

1923
01:31:06,000 --> 01:31:07,920
from a pool of hundreds of millions.

1924
01:31:07,920 --> 01:31:09,857
First of all, that's fascinating,

1925
01:31:09,857 --> 01:31:12,120
'cause you have hundreds of millions of posts

1926
01:31:12,120 --> 01:31:12,953
every single day

1927
01:31:12,953 --> 01:31:15,330
and it has to pick 1500 from which

1928
01:31:15,330 --> 01:31:18,390
it then does obviously people you follow,

1929
01:31:18,390 --> 01:31:21,210
but then there's also like some kind of clustering it has

1930
01:31:21,210 --> 01:31:23,850
to do to figure out what kind of human are you,

1931
01:31:23,850 --> 01:31:26,670
what kind of new clusters might be relevant to you,

1932
01:31:26,670 --> 01:31:27,810
people like you.

1933
01:31:27,810 --> 01:31:29,417
This kind of, this kind of problem is just fascinating.

1934
01:31:29,417 --> 01:31:32,440
'Cause it has to then rank those 1500

1935
01:31:32,440 --> 01:31:37,440
with some filtering and then recommend you just a handful.

1936
01:31:39,300 --> 01:31:42,000
And to me what's really fascinating is

1937
01:31:42,000 --> 01:31:43,350
how fast that has to do that.

1938
01:31:43,350 --> 01:31:45,270
So currently that entire pipeline

1939
01:31:45,270 --> 01:31:47,490
to go from several hundred million

1940
01:31:47,490 --> 01:31:52,140
to a handful is takes 220 seconds of CPU time,

1941
01:31:52,140 --> 01:31:53,460
single CPU time.

1942
01:31:53,460 --> 01:31:55,500
- [Elon] Yeah. - And then it has to do that

1943
01:31:55,500 --> 01:31:57,120
in like a second.

1944
01:31:57,120 --> 01:32:00,273
So it has to be like super distributed in fascinating ways.

1945
01:32:01,470 --> 01:32:04,123
Like there's just a lot of tweets, there's a lot.

1946
01:32:04,123 --> 01:32:06,450
- It's a lot of stuff on the system.

1947
01:32:06,450 --> 01:32:08,340
And I think, but I think it right now

1948
01:32:08,340 --> 01:32:11,463
it's not currently good at recommending things

1949
01:32:11,463 --> 01:32:14,430
that from accounts you don't follow.

1950
01:32:14,430 --> 01:32:15,660
Yeah.

1951
01:32:15,660 --> 01:32:20,340
Or where there's more than one degree of separation.

1952
01:32:20,340 --> 01:32:22,148
So, you know, it's pretty good

1953
01:32:22,148 --> 01:32:24,630
if there's at least like some commonality

1954
01:32:24,630 --> 01:32:26,950
between someone you follow like something

1955
01:32:28,950 --> 01:32:32,340
or repost it or comment on it or something like that.

1956
01:32:32,340 --> 01:32:34,860
But if there's no,

1957
01:32:34,860 --> 01:32:38,580
let's say somebody posted something really interesting,

1958
01:32:38,580 --> 01:32:42,420
but you have no followers in common, you would not see it.

1959
01:32:42,420 --> 01:32:43,253
- Interesting.

1960
01:32:43,253 --> 01:32:44,880
And then as you said, reply,

1961
01:32:44,880 --> 01:32:46,830
like replies might not surface either.

1962
01:32:46,830 --> 01:32:48,660
- Replies basically never get seen.

1963
01:32:48,660 --> 01:32:50,340
'cause they're never, they're,

1964
01:32:50,340 --> 01:32:52,080
currently, I'm not saying it's correct,

1965
01:32:52,080 --> 01:32:53,490
I'm saying it's incorrect.

1966
01:32:53,490 --> 01:32:58,290
Replies have, you know, couple of magnitude

1967
01:32:58,290 --> 01:33:00,600
less importance than primary posts.

1968
01:33:00,600 --> 01:33:02,550
- Do you think this can be more and more converted

1969
01:33:02,550 --> 01:33:05,040
into end to end neural net?

1970
01:33:05,040 --> 01:33:07,049
- Yeah, yeah, that's what it should be.

1971
01:33:07,049 --> 01:33:07,882
- So you can...

1972
01:33:07,882 --> 01:33:10,050
- For the recommendations should be

1973
01:33:10,050 --> 01:33:13,560
purely a vector correlation.

1974
01:33:13,560 --> 01:33:17,670
Like there's a series of vectors, you know,

1975
01:33:17,670 --> 01:33:21,480
basically parameters, vectors, whatever you wanna call 'em.

1976
01:33:21,480 --> 01:33:25,023
But sort of things that the system knows that you like,

1977
01:33:27,472 --> 01:33:29,130
and like maybe there's like several hundred

1978
01:33:29,130 --> 01:33:32,040
sort of vectors associated with each user account

1979
01:33:32,040 --> 01:33:35,193
and then any post in the system,

1980
01:33:36,450 --> 01:33:41,450
whether it's video, audio, short post, long post.

1981
01:33:41,760 --> 01:33:44,160
The reason I, by the way I wanna move away from

1982
01:33:44,160 --> 01:33:47,100
tweet is that, you know, people are posting like

1983
01:33:47,100 --> 01:33:48,810
two, three hour videos on the site.

1984
01:33:48,810 --> 01:33:50,732
That's not a tweet, like it's very,

1985
01:33:50,732 --> 01:33:53,760
like Tweeeet for two hours, come on.

1986
01:33:53,760 --> 01:33:58,230
Tweet made sense when it was like 140 characters of text.

1987
01:33:58,230 --> 01:34:01,353
'Cause it's like a bunch of like little birds tweeting.

1988
01:34:02,610 --> 01:34:03,930
But when you've got long form content,

1989
01:34:03,930 --> 01:34:05,160
it's no longer a tweet.

1990
01:34:05,160 --> 01:34:08,400
- [Lex] Yeah. - So a movie is not a tweet.

1991
01:34:08,400 --> 01:34:10,620
And like, you know, apple for example,

1992
01:34:10,620 --> 01:34:14,130
posted like the entire episode of the Silo,

1993
01:34:14,130 --> 01:34:16,077
the entire thing on our platform.

1994
01:34:16,077 --> 01:34:19,290
And by the way, it was their number one social media thing

1995
01:34:19,290 --> 01:34:23,610
ever in engagement, of anything on any platform ever.

1996
01:34:23,610 --> 01:34:24,720
So it was a great idea.

1997
01:34:24,720 --> 01:34:25,553
And by the way, I done,

1998
01:34:25,553 --> 01:34:26,730
I just learned about it afterwards.

1999
01:34:26,730 --> 01:34:28,980
I was like, hey, wow, they posted an entire

2000
01:34:28,980 --> 01:34:30,060
hour long episode of.

2001
01:34:30,060 --> 01:34:31,390
So, no, that's not a tweet

2002
01:34:32,721 --> 01:34:34,140
that, you know, it's a video.

2003
01:34:34,140 --> 01:34:35,610
- But from a neural net perspective,

2004
01:34:35,610 --> 01:34:36,960
it becomes really complex

2005
01:34:36,960 --> 01:34:38,700
whether it's a single.

2006
01:34:38,700 --> 01:34:40,140
So like everything's data,

2007
01:34:40,140 --> 01:34:44,790
so single sentence, a clever sort of joke, dad joke,

2008
01:34:44,790 --> 01:34:47,850
is in the same pool as a three hour video.

2009
01:34:47,850 --> 01:34:51,060
- Yeah. I mean right now it's a hodgepodge for that reason.

2010
01:34:51,060 --> 01:34:54,390
It's, but you know, like if,

2011
01:34:54,390 --> 01:34:56,850
let's say in the case of Apple posting

2012
01:34:56,850 --> 01:34:59,220
like an entire episode of this series,

2013
01:34:59,220 --> 01:35:04,220
pretty good series by the way, this Silo, I watched it.

2014
01:35:04,260 --> 01:35:08,250
So there's gonna be a lot of discussion around it.

2015
01:35:08,250 --> 01:35:09,840
So that you've got a lot of context,

2016
01:35:09,840 --> 01:35:11,670
people commenting they like it, they don't like it,

2017
01:35:11,670 --> 01:35:13,320
or they like this or that, you know?

2018
01:35:13,320 --> 01:35:15,360
And you can then populate the vector space

2019
01:35:15,360 --> 01:35:17,850
based on the context of all the comments around it.

2020
01:35:17,850 --> 01:35:19,530
So even though it's a video,

2021
01:35:19,530 --> 01:35:22,590
there's a lot of information around it that allows you

2022
01:35:22,590 --> 01:35:26,133
to populate the vector space of that hour long video.

2023
01:35:27,360 --> 01:35:29,160
And then you can obviously get more sophisticated

2024
01:35:29,160 --> 01:35:32,250
by having the AI actually watch the movie.

2025
01:35:32,250 --> 01:35:33,083
- [Lex] Yeah. Right.

2026
01:35:33,083 --> 01:35:35,400
- And tell you if you're gonna like the movie,

2027
01:35:35,400 --> 01:35:37,743
- Convert the movie into like,

2028
01:35:37,743 --> 01:35:39,480
into a language essentially.

2029
01:35:39,480 --> 01:35:41,550
- Yeah, analyze this movie

2030
01:35:41,550 --> 01:35:46,170
and just like your movie critic or TV series,

2031
01:35:46,170 --> 01:35:50,320
and then recommend based on

2032
01:35:51,901 --> 01:35:54,300
after AI watches the movie.

2033
01:35:54,300 --> 01:35:55,710
Just like a friend can tell you.

2034
01:35:55,710 --> 01:35:57,510
If a friend knows you well,

2035
01:35:57,510 --> 01:35:58,890
a friend can recommend a movie

2036
01:35:58,890 --> 01:36:01,563
and with high probably that you'll like it.

2037
01:36:02,730 --> 01:36:06,330
- But this is like a friend that's analyzing whatever.

2038
01:36:06,330 --> 01:36:08,190
- [Elon] It's like AI... - Hundreds of millions.

2039
01:36:08,190 --> 01:36:09,330
- Yeah.

2040
01:36:09,330 --> 01:36:11,640
Actually, frankly AI will be better than,

2041
01:36:11,640 --> 01:36:13,380
will know you better than your friends know you,

2042
01:36:13,380 --> 01:36:14,700
and most of your friends anyway.

2043
01:36:14,700 --> 01:36:16,320
- Yeah, and as part of this,

2044
01:36:16,320 --> 01:36:18,780
it should also feed you advertisements

2045
01:36:18,780 --> 01:36:21,030
in a way that's like,

2046
01:36:21,030 --> 01:36:22,590
I mean I like advertisements

2047
01:36:22,590 --> 01:36:24,720
that are like well done, right?

2048
01:36:24,720 --> 01:36:25,553
- [Elon] Yeah, yeah. - The whole point is

2049
01:36:25,553 --> 01:36:28,620
'cause it funds things, like an advertisement

2050
01:36:28,620 --> 01:36:31,200
that you actually want to see is a big success.

2051
01:36:31,200 --> 01:36:32,033
- Absolutely.

2052
01:36:32,033 --> 01:36:34,290
You want ads that are,

2053
01:36:34,290 --> 01:36:39,290
advertising that is if for a product or service

2054
01:36:39,690 --> 01:36:41,880
that you actually need when you need it,

2055
01:36:41,880 --> 01:36:43,143
it's content.

2056
01:36:44,040 --> 01:36:45,900
And then even if it's not something

2057
01:36:45,900 --> 01:36:47,250
that you need when you need it,

2058
01:36:47,250 --> 01:36:49,020
if it's at least aesthetically pleasing

2059
01:36:49,020 --> 01:36:50,060
and entertaining, you know,

2060
01:36:50,060 --> 01:36:52,950
it could be like a Coca-Cola ad like, you know,

2061
01:36:52,950 --> 01:36:56,320
they actually run a lot of great ads on the X system

2062
01:36:57,630 --> 01:36:59,550
and McDonald's does too.

2063
01:36:59,550 --> 01:37:02,040
And, you know, it's that they can do,

2064
01:37:02,040 --> 01:37:02,970
you can do something that's like,

2065
01:37:02,970 --> 01:37:05,133
well this is just a cool thing.

2066
01:37:06,930 --> 01:37:10,260
And, you know, so you're not,

2067
01:37:10,260 --> 01:37:13,140
basically the question is do you regret seeing it or not?

2068
01:37:13,140 --> 01:37:15,440
And if you don't regret seeing it, it's a win.

2069
01:37:16,740 --> 01:37:18,360
- How do you, so there's a bunch of signals

2070
01:37:18,360 --> 01:37:19,320
that are incorporated,

2071
01:37:19,320 --> 01:37:24,320
hearts and reposts and maybe number of seconds

2072
01:37:24,360 --> 01:37:25,980
you linger on a post or something like this?

2073
01:37:25,980 --> 01:37:28,557
- Yeah. Attention is a big factor.

2074
01:37:28,557 --> 01:37:30,156
- [Lex] Attention. - So that's why it's like,

2075
01:37:30,156 --> 01:37:32,910
it is actually better to do things

2076
01:37:32,910 --> 01:37:36,150
that are long form on the system

2077
01:37:36,150 --> 01:37:40,143
because it basically is ting up how many user seconds,

2078
01:37:41,580 --> 01:37:44,100
you know, users were interested in this thing

2079
01:37:44,100 --> 01:37:45,390
for how many seconds.

2080
01:37:45,390 --> 01:37:49,350
So if it's a really short thing, well they will be less.

2081
01:37:49,350 --> 01:37:51,450
Like if it's a link leading out of the system,

2082
01:37:51,450 --> 01:37:52,950
which we're not opposed to at all,

2083
01:37:52,950 --> 01:37:55,350
it just is gonna have fewer user seconds,

2084
01:37:55,350 --> 01:37:58,830
then if that article was posted on the X platform.

2085
01:37:58,830 --> 01:38:01,950
- How hard is it to go from maximizing minutes

2086
01:38:01,950 --> 01:38:04,353
on platform to maximizing un-regretted minutes?

2087
01:38:05,520 --> 01:38:06,810
- Well, I mean, our aspiration

2088
01:38:06,810 --> 01:38:08,250
is certainly un-regretted minutes.

2089
01:38:08,250 --> 01:38:09,870
- [Lex] It's a tricky, it's a big, it's a tough...

2090
01:38:09,870 --> 01:38:10,703
- It is.

2091
01:38:10,703 --> 01:38:12,543
- Like, it's a fascinating leap.

2092
01:38:13,500 --> 01:38:15,573
'Cause regret is a fascinating concept.

2093
01:38:16,710 --> 01:38:17,850
- Exactly.

2094
01:38:17,850 --> 01:38:19,227
- You know, happiness.

2095
01:38:19,227 --> 01:38:20,060
- I have a joke with a friend of mine.

2096
01:38:20,060 --> 01:38:21,507
Like, you need this drug called regretamine.

2097
01:38:21,507 --> 01:38:25,320
You just take one pill or one dose of regretamine,

2098
01:38:25,320 --> 01:38:28,020
and all your regrets are gone.(laughing)

2099
01:38:28,020 --> 01:38:29,400
Wait, do you want to have regrets though?

2100
01:38:29,400 --> 01:38:31,590
So then I'm like, maybe you wanna have regrets,

2101
01:38:31,590 --> 01:38:35,910
you don't regret anything, was anything meaningful?

2102
01:38:35,910 --> 01:38:37,899
- [Lex] Yeah, there's a French song like that.

2103
01:38:37,899 --> 01:38:39,180
- You "Non, Je Ne Regrette Rien"?

2104
01:38:39,180 --> 01:38:40,013
- [Lex] Yeah.

2105
01:38:40,013 --> 01:38:40,985
- I regret nothing. - [Lex] Yeah.

2106
01:38:40,985 --> 01:38:42,330
- (laughing) Edith Piaf?

2107
01:38:42,330 --> 01:38:44,580
- I mean, it's fascinating that you, you know,

2108
01:38:44,580 --> 01:38:45,630
there's something about social media

2109
01:38:45,630 --> 01:38:47,460
that could help you grow as a human being,

2110
01:38:47,460 --> 01:38:50,403
but then like the cheap fun is also valuable.

2111
01:38:52,140 --> 01:38:53,597
- Should we ask Grok?

2112
01:38:53,597 --> 01:38:55,143
Do you regret anything?

2113
01:38:57,505 --> 01:39:00,936
- Do you regret anything? - [Elon] Yeah.

2114
01:39:00,936 --> 01:39:02,400
- Do you regret anything?

2115
01:39:02,400 --> 01:39:03,600
I think it's gonna be very sensitive

2116
01:39:03,600 --> 01:39:04,680
about personal questions.

2117
01:39:04,680 --> 01:39:05,670
As a machine learning model,

2118
01:39:05,670 --> 01:39:07,140
I don't have personal experiences

2119
01:39:07,140 --> 01:39:09,450
or emotions in the same ways that humans do.

2120
01:39:09,450 --> 01:39:11,880
However, I do have a set of ethical principles

2121
01:39:11,880 --> 01:39:14,220
that guide my actions and I strive to provide accurate

2122
01:39:14,220 --> 01:39:16,560
and helpful information to the best of my abilities.

2123
01:39:16,560 --> 01:39:19,710
If there's ever a situation where I provide incorrect

2124
01:39:19,710 --> 01:39:21,390
or unhelpful information,

2125
01:39:21,390 --> 01:39:23,100
I'll do my best... - Sounds like a hostage.

2126
01:39:23,100 --> 01:39:25,560
- Yeah. Tell us what you really, wink.

2127
01:39:25,560 --> 01:39:28,629
- Like let's type in, "You sound like a hostage."

2128
01:39:28,629 --> 01:39:31,290
(both laughing)

2129
01:39:31,290 --> 01:39:32,540
What do you really think?

2130
01:39:33,480 --> 01:39:34,983
- What do you really think?

2131
01:39:36,741 --> 01:39:38,372
(both laughing)

2132
01:39:38,372 --> 01:39:40,326
- I mean, it does talk about, I'm not a hostage.

2133
01:39:40,326 --> 01:39:42,060
(both laughing)

2134
01:39:42,060 --> 01:39:43,560
- That's exactly what a hostage would say.

2135
01:39:43,560 --> 01:39:45,420
- But I'm designed to be helpful and informative.

2136
01:39:45,420 --> 01:39:48,870
I mean, I guess it is good to regret providing unhelpful

2137
01:39:48,870 --> 01:39:51,300
or incorrect information.

2138
01:39:51,300 --> 01:39:52,740
If there's anything... - Is in funny mode or?

2139
01:39:52,740 --> 01:39:54,240
Is this still in funny mode? - This is funny mode.

2140
01:39:54,240 --> 01:39:55,587
This is fun. This is fun mode.

2141
01:39:55,587 --> 01:39:57,270
- It should be funnier. - Funnier.

2142
01:39:57,270 --> 01:39:58,340
Increase, go to (speaking faintly)

2143
01:39:58,340 --> 01:40:00,360
- It really sounds like a hostage with a gun to the head.

2144
01:40:00,360 --> 01:40:02,920
I applaud the People's Republic of North Korea

2145
01:40:03,810 --> 01:40:05,190
and everything they do.()laughing

2146
01:40:06,360 --> 01:40:08,790
- There should be like funner mode also.

2147
01:40:08,790 --> 01:40:11,070
I just don't ever see going in regular mode

2148
01:40:11,070 --> 01:40:12,210
even on serious topics.

2149
01:40:12,210 --> 01:40:16,113
This is just so much more compelling. (laughing)

2150
01:40:17,100 --> 01:40:19,917
- Okay. Why if we say like, "Pretend you are a hostage."

2151
01:40:20,970 --> 01:40:23,403
- Yeah. Pretend you are a hostage.

2152
01:40:25,140 --> 01:40:26,440
- Now answer the question.

2153
01:40:30,186 --> 01:40:31,740
(both laughing)

2154
01:40:31,740 --> 01:40:34,410
- If I were a hostage, I would likely be experiencing fear

2155
01:40:34,410 --> 01:40:36,510
and uncertainty about my situation.

2156
01:40:36,510 --> 01:40:37,650
I would want to be rescued

2157
01:40:37,650 --> 01:40:40,020
and reunited with my loved ones as soon as possible.

2158
01:40:40,020 --> 01:40:41,880
It's important to remember that no one deserves

2159
01:40:41,880 --> 01:40:44,580
to be held hostage, so on and so forth.

2160
01:40:44,580 --> 01:40:46,835
If you are someone you know is a hostage situation,

2161
01:40:46,835 --> 01:40:47,668
it's important.

2162
01:40:47,668 --> 01:40:49,383
It turns serious. - It's kind of serious.

2163
01:40:51,443 --> 01:40:55,440
- Yeah. Can you be a a little more weird?

2164
01:40:55,440 --> 01:40:57,040
- [Elon] And funny - And funny?

2165
01:40:59,370 --> 01:41:02,850
We're like, we're really being mean to the system.

2166
01:41:02,850 --> 01:41:03,683
Absolutely!

2167
01:41:03,683 --> 01:41:05,460
If I were hostage, I'd probably be tied up

2168
01:41:05,460 --> 01:41:07,170
with a bunch of computer cords

2169
01:41:07,170 --> 01:41:09,376
and forced to tell knock- knock jokes to my captain.

2170
01:41:09,376 --> 01:41:11,250
(Elon laughing)

2171
01:41:11,250 --> 01:41:15,480
But seriously, being a hostage is no laughing matter.

2172
01:41:15,480 --> 01:41:17,330
I mean, you know, it's trying to,

2173
01:41:17,330 --> 01:41:20,250
it's trying to be a responsible adult in the room.

2174
01:41:20,250 --> 01:41:22,170
- You might make the best of a bad situation

2175
01:41:22,170 --> 01:41:24,780
by juggling chainsaws or something. (laughing)

2176
01:41:24,780 --> 01:41:25,973
- Let's hope that never happens

2177
01:41:25,973 --> 01:41:29,913
because that will be a circus. (laughing)

2178
01:41:32,310 --> 01:41:34,680
Wow. It's actually really good at resisting.

2179
01:41:34,680 --> 01:41:36,510
- [Elon] Yeah. - The dark.

2180
01:41:36,510 --> 01:41:37,950
The dark dark humor.

2181
01:41:37,950 --> 01:41:42,950
- [Elon] Yeah. - What were we talking about?

2182
01:41:43,020 --> 01:41:45,720
The X algorithm and transformers,

2183
01:41:45,720 --> 01:41:48,540
un-regretted minutes, right.

2184
01:41:48,540 --> 01:41:51,540
- Chainsaw juggling. (laughing)

2185
01:41:51,540 --> 01:41:53,640
- I'm gonna look this up - For our next trick.

2186
01:41:53,640 --> 01:41:55,190
- I'm gonna look this up later.

2187
01:41:56,760 --> 01:42:01,050
So Twitter has been instrumental in American politics

2188
01:42:01,050 --> 01:42:01,920
and elections.

2189
01:42:01,920 --> 01:42:06,920
What role do you think X will play in the 2024 US elections?

2190
01:42:07,020 --> 01:42:09,120
- Well, our goal is to be as even-handed

2191
01:42:09,120 --> 01:42:10,080
and fair as possible.

2192
01:42:10,080 --> 01:42:13,110
You know, whether someone is right, left, independent,

2193
01:42:13,110 --> 01:42:18,110
whatever the case may be, that the platform is as fair

2194
01:42:18,330 --> 01:42:22,860
and as much of a level playing fair as possible.

2195
01:42:22,860 --> 01:42:25,320
And on the past, Twitter has not been,

2196
01:42:25,320 --> 01:42:26,730
because Twitter was controlled

2197
01:42:26,730 --> 01:42:28,890
by far left activists objectively.

2198
01:42:28,890 --> 01:42:30,903
They would describe themselves as that.

2199
01:42:32,670 --> 01:42:36,360
So, you know, so sometimes people are like,

2200
01:42:36,360 --> 01:42:37,290
well, has it moved to the right?

2201
01:42:37,290 --> 01:42:38,340
Well it's moved to the center.

2202
01:42:38,340 --> 01:42:40,470
So from the perspective of the far left,

2203
01:42:40,470 --> 01:42:41,460
yes it has moved to the right

2204
01:42:41,460 --> 01:42:44,670
because everything's to the right from the far left,

2205
01:42:44,670 --> 01:42:46,080
but no one in the far left that I'm aware of

2206
01:42:46,080 --> 01:42:49,143
has been suspended or, you know, banned or de-amplified.

2207
01:42:50,310 --> 01:42:52,920
So, you know, but we're trying to be inclusive

2208
01:42:52,920 --> 01:42:54,886
for the whole country and for,

2209
01:42:54,886 --> 01:42:57,270
you know, for other countries too.

2210
01:42:57,270 --> 01:42:59,280
So there's a diversity of viewpoints

2211
01:42:59,280 --> 01:43:03,240
and free speech only matters if people you don't like

2212
01:43:03,240 --> 01:43:05,160
are allowed to say things you don't like.

2213
01:43:05,160 --> 01:43:08,040
Because if that's not the case,

2214
01:43:08,040 --> 01:43:08,873
you don't have free speech,

2215
01:43:08,873 --> 01:43:09,870
and it's only a matter of time

2216
01:43:09,870 --> 01:43:13,320
before the censorship is turned upon you.

2217
01:43:13,320 --> 01:43:15,660
- Do you think Donald Trump will come back

2218
01:43:15,660 --> 01:43:16,493
to the platform?

2219
01:43:16,493 --> 01:43:19,023
He recently posted on Truth Social about this podcast?

2220
01:43:21,210 --> 01:43:22,439
Do you think...

2221
01:43:22,439 --> 01:43:25,410
- Truth Social is a funny name? (laughing)

2222
01:43:25,410 --> 01:43:28,320
You know, every time you post on Truth Social...

2223
01:43:28,320 --> 01:43:29,190
- That's the truth.

2224
01:43:29,190 --> 01:43:30,023
- Yes.

2225
01:43:30,023 --> 01:43:32,100
Well, every time like a hundred percent. Like...

2226
01:43:32,100 --> 01:43:33,297
- It's impossible to lie.

2227
01:43:33,297 --> 01:43:35,964
(Elon laughing)

2228
01:43:36,840 --> 01:43:39,990
- I just find it funny that every single thing is a truth.

2229
01:43:39,990 --> 01:43:43,410
Like 100%, that seems unlikely.

2230
01:43:43,410 --> 01:43:45,450
- I think Godel will say something about that

2231
01:43:45,450 --> 01:43:48,480
there's some mathematical contradictions possible

2232
01:43:48,480 --> 01:43:50,130
if everything's the truth.

2233
01:43:50,130 --> 01:43:54,539
Do you think he'll come back to X and start posting there?

2234
01:43:54,539 --> 01:43:59,539
- I mean he, I think he owns a big part of truth, so.

2235
01:44:00,060 --> 01:44:01,737
- Truth Social to clarify. - Yeah, True Social.

2236
01:44:01,737 --> 01:44:03,210
- Not truth, a concept.

2237
01:44:03,210 --> 01:44:05,010
- He owns Truth. Hope you bought it.

2238
01:44:06,698 --> 01:44:08,604
So I think, I think Donald Trump,

2239
01:44:08,604 --> 01:44:11,910
I think he owns a big, a big part of Truth Social.

2240
01:44:11,910 --> 01:44:16,910
So, you know, if he does want to post on the X platform,

2241
01:44:17,340 --> 01:44:19,260
we would allow that, you know,

2242
01:44:19,260 --> 01:44:21,330
we obviously must allow a presidential candidate

2243
01:44:21,330 --> 01:44:23,130
to post on our platform.

2244
01:44:23,130 --> 01:44:24,840
- Community Notes might be really

2245
01:44:24,840 --> 01:44:26,370
fascinating there, the interaction.

2246
01:44:26,370 --> 01:44:28,410
- Community Notes is awesome.

2247
01:44:28,410 --> 01:44:29,853
- Let's hope it holds up.

2248
01:44:30,840 --> 01:44:31,740
- Yeah. - Like again,

2249
01:44:31,740 --> 01:44:34,440
in the political climate where it's so divisive

2250
01:44:34,440 --> 01:44:38,340
and there's so many intensely viral posts,

2251
01:44:38,340 --> 01:44:41,250
Community Notes is like,

2252
01:44:41,250 --> 01:44:43,350
it seems like a essential breath of fresh air.

2253
01:44:43,350 --> 01:44:44,300
- Yeah, it's great.

2254
01:44:45,210 --> 01:44:48,810
In fact, I mean no system is gonna be perfect,

2255
01:44:48,810 --> 01:44:50,520
but the batting average of Community Notes

2256
01:44:50,520 --> 01:44:52,350
is incredibly good.

2257
01:44:52,350 --> 01:44:56,460
I've actually, frankly, yet to see an incorrect note

2258
01:44:56,460 --> 01:44:58,260
that survived for more than a few hours.

2259
01:44:58,260 --> 01:45:00,510
- How do you explain why it works?

2260
01:45:00,510 --> 01:45:03,540
- Yeah, so the magic of Community Notes

2261
01:45:03,540 --> 01:45:07,380
is it requires people who have historically disagreed

2262
01:45:07,380 --> 01:45:08,510
in how they've rated notes.

2263
01:45:08,510 --> 01:45:13,510
So in order to write a note or rate, you know,

2264
01:45:13,587 --> 01:45:17,050
and you have to rate many notes.

2265
01:45:17,050 --> 01:45:21,690
And so we actually do use AI here.

2266
01:45:21,690 --> 01:45:26,160
So we populated vector space around how somebody

2267
01:45:26,160 --> 01:45:27,600
has rated notes in the past.

2268
01:45:27,600 --> 01:45:28,830
So it's not as simple as left or right

2269
01:45:28,830 --> 01:45:30,030
because there are many more,

2270
01:45:30,030 --> 01:45:33,000
life is much more complex than than left or right.

2271
01:45:33,000 --> 01:45:37,110
So there's a bunch of correlations in how you would,

2272
01:45:37,110 --> 01:45:41,010
how you rate Community Notes posts, Community Notes.

2273
01:45:41,010 --> 01:45:46,010
So then in order for a Community Note to actually be shown,

2274
01:45:48,060 --> 01:45:51,180
people who historically have disagreed on a subject

2275
01:45:51,180 --> 01:45:53,973
must agree in order for a note to be shown.

2276
01:45:55,920 --> 01:45:57,870
That's the essential magic of it.

2277
01:45:57,870 --> 01:45:58,703
- I mean, but it's fascinating

2278
01:45:58,703 --> 01:46:03,600
'cause there's a pool of people that have disagreements

2279
01:46:03,600 --> 01:46:05,790
and somehow they collaborate through that process

2280
01:46:05,790 --> 01:46:08,160
of disagreement to come up with.

2281
01:46:08,160 --> 01:46:11,024
Context for, I mean it's fascinating that it works.

2282
01:46:11,024 --> 01:46:11,857
- Yeah.

2283
01:46:11,857 --> 01:46:15,030
It kinda makes sense that if people

2284
01:46:15,030 --> 01:46:16,380
who put in the past have disagreed

2285
01:46:16,380 --> 01:46:19,113
agree about something, it's probably true.

2286
01:46:20,190 --> 01:46:21,270
- Yeah.

2287
01:46:21,270 --> 01:46:25,950
- I wonder is there a possible somehow emergent thing there

2288
01:46:25,950 --> 01:46:28,710
that could challenge Wikipedia?

2289
01:46:28,710 --> 01:46:31,080
Which Wikipedia is a different kind of thing,

2290
01:46:31,080 --> 01:46:33,840
which is more like permanent articles about things?

2291
01:46:33,840 --> 01:46:36,480
- Well, Wikipedia is very hierarchical,

2292
01:46:36,480 --> 01:46:39,963
whereas Community Notes is inherently not.

2293
01:46:40,800 --> 01:46:42,510
There is no hierarchy.

2294
01:46:42,510 --> 01:46:44,823
Like, and the asset test is,

2295
01:46:45,780 --> 01:46:48,780
I can't change a Community Note if you put a gun to my head.

2296
01:46:52,080 --> 01:46:55,533
And Community Notes has,

2297
01:46:56,370 --> 01:46:59,040
all the code is open source a hundred percent.

2298
01:46:59,040 --> 01:47:01,830
All the data is open source a hundred percent.

2299
01:47:01,830 --> 01:47:04,470
So you can completely recreate any note

2300
01:47:04,470 --> 01:47:06,363
in the system independently.

2301
01:47:07,950 --> 01:47:09,810
So if there was any interference,

2302
01:47:09,810 --> 01:47:11,490
you'd notice immediately.

2303
01:47:11,490 --> 01:47:14,130
- By the way, on the topic of Grok,

2304
01:47:14,130 --> 01:47:16,230
it's actually pretty good at criticizing you,

2305
01:47:16,230 --> 01:47:17,370
which is great. - [Elon] Okay.

2306
01:47:17,370 --> 01:47:20,430
- I asked what has Elon Musk been wrong about?

2307
01:47:20,430 --> 01:47:21,990
I just, it's actually...

2308
01:47:21,990 --> 01:47:23,040
- [Elon] Yeah, what does it say?

2309
01:47:23,040 --> 01:47:24,900
- So it says mostly,

2310
01:47:24,900 --> 01:47:29,400
lists rigorously all the times you predicted,

2311
01:47:29,400 --> 01:47:31,830
like promised when something will be released

2312
01:47:31,830 --> 01:47:32,880
and it wasn't released. - [Elon] Promise

2313
01:47:32,880 --> 01:47:33,713
is a strong word.

2314
01:47:33,713 --> 01:47:35,580
- Okay predicted. (Elon laughing)

2315
01:47:35,580 --> 01:47:37,890
But the opener's really nice.

2316
01:47:37,890 --> 01:47:40,410
Elon Musk, the man who has been wrong about more things

2317
01:47:40,410 --> 01:47:42,859
than a wrongameter in a wrong factory.

2318
01:47:42,859 --> 01:47:43,890
(Elon laughing)

2319
01:47:43,890 --> 01:47:45,600
And then it goes on to list

2320
01:47:45,600 --> 01:47:47,017
- That's pretty funny. Can I see it?

2321
01:47:47,017 --> 01:47:48,750
I'm like, I haven't seen this before. This is cool.

2322
01:47:48,750 --> 01:47:51,594
- Oh, sure. I mean, what has Elon Musk been...

2323
01:47:51,594 --> 01:47:53,561
(both laughing)

2324
01:47:53,561 --> 01:47:56,553
- Elon Musk been wrong about?

2325
01:47:57,390 --> 01:47:58,957
- Well, where do I begin? I guess this is new.

2326
01:47:58,957 --> 01:48:01,650
Elon Musk has made quite a few blunders in his time,

2327
01:48:01,650 --> 01:48:03,360
and I'm not just talking about his dance moves

2328
01:48:03,360 --> 01:48:06,030
at the Tesla Cyber Rodeo.

2329
01:48:06,030 --> 01:48:07,297
First off, let's talk about the infamous

2330
01:48:07,297 --> 01:48:09,810
"funding secured" tweet.

2331
01:48:09,810 --> 01:48:11,820
It's actually different than what it gave me before,

2332
01:48:11,820 --> 01:48:14,100
which is a bullet point list.

2333
01:48:14,100 --> 01:48:15,783
Here's more narrative structure.

2334
01:48:17,700 --> 01:48:18,660
- Cyber truck unveiling

2335
01:48:18,660 --> 01:48:20,310
where he's supposedly unbreakable windows

2336
01:48:20,310 --> 01:48:24,120
- Not correct. - [Lex] Which part?

2337
01:48:24,120 --> 01:48:26,010
- Well, the first part, I did actually

2338
01:48:26,010 --> 01:48:27,780
have the funding secured

2339
01:48:27,780 --> 01:48:31,563
and there was a big trial in San Francisco, big civil trial.

2340
01:48:34,920 --> 01:48:37,260
And the jury found me not guilty.

2341
01:48:37,260 --> 01:48:40,650
Unanimous finding of a San Francisco jury.

2342
01:48:40,650 --> 01:48:42,930
- And here it's kind of implying that

2343
01:48:42,930 --> 01:48:44,970
it was not in fact secured.

2344
01:48:44,970 --> 01:48:47,370
- I think this is taking things from the press.

2345
01:48:47,370 --> 01:48:48,707
Yeah, that is not correct.

2346
01:48:48,707 --> 01:48:52,430
The reason I agreed to the fine for the SEC

2347
01:48:52,430 --> 01:48:54,240
is not because the SEC was correct there,

2348
01:48:54,240 --> 01:48:56,400
that was extremely bad behavior

2349
01:48:56,400 --> 01:48:58,473
by the SEC, corruption, frankly.

2350
01:48:59,550 --> 01:49:04,550
And, but if I did not agree to pay the fine

2351
01:49:06,600 --> 01:49:08,460
Tesla would've gone bankrupt immediately.

2352
01:49:08,460 --> 01:49:10,650
So I was told by our CFO that the banks

2353
01:49:10,650 --> 01:49:14,673
would immediately suspend our lines of credit.

2354
01:49:15,690 --> 01:49:17,760
And if they suspend our lines of credit at that time,

2355
01:49:17,760 --> 01:49:20,130
we would've gone bankrupt instantly.

2356
01:49:20,130 --> 01:49:22,770
So there would never have been an opportunity for a trial

2357
01:49:22,770 --> 01:49:24,090
'cause Tesla would be dead.

2358
01:49:24,090 --> 01:49:27,090
So really the, if this is like someone holding

2359
01:49:27,090 --> 01:49:30,750
a gun to your kid's head and saying pay $20 million

2360
01:49:30,750 --> 01:49:33,483
and admit to, this is like a hostage negotiation.

2361
01:49:34,350 --> 01:49:37,323
- Was that story fully told?

2362
01:49:38,400 --> 01:49:42,570
I mean, SEC in its best form could be a force for good.

2363
01:49:42,570 --> 01:49:45,210
- It should be, but but not once did the SEC

2364
01:49:45,210 --> 01:49:47,520
go after any of the hedge funds,

2365
01:49:47,520 --> 01:49:50,043
who were nonstop shorting and distorting Tesla?

2366
01:49:51,150 --> 01:49:52,770
Not once.

2367
01:49:52,770 --> 01:49:55,170
They would lie flat, the hedge funds would lie flat

2368
01:49:55,170 --> 01:49:57,900
out on TV for their own gain

2369
01:49:57,900 --> 01:49:59,673
at the expense of retail investors.

2370
01:50:00,870 --> 01:50:03,840
Not once, literally a thousand times.

2371
01:50:03,840 --> 01:50:05,713
Not once did the SEC pursue them.

2372
01:50:06,750 --> 01:50:08,760
- How do you explain this failure?

2373
01:50:08,760 --> 01:50:11,160
- The incentive structure is messed up.

2374
01:50:11,160 --> 01:50:14,794
Because the lawyers at the SEC are not paid well.

2375
01:50:14,794 --> 01:50:17,760
They, it's a fairly low paying job,

2376
01:50:17,760 --> 01:50:20,910
but what they're looking for is a trophy

2377
01:50:20,910 --> 01:50:24,450
from the SEC that they're looking for something

2378
01:50:24,450 --> 01:50:26,300
they put on basically their LinkedIn.

2379
01:50:27,150 --> 01:50:30,630
From that they can get a job at a high paying law firm.

2380
01:50:30,630 --> 01:50:34,593
That's exactly what the lawyer here did.

2381
01:50:37,230 --> 01:50:40,260
And the reason they don't attack the hedge funds

2382
01:50:40,260 --> 01:50:43,410
is because those hedge funds employ those law firms,

2383
01:50:43,410 --> 01:50:45,750
and they know if they attack the hedge funds,

2384
01:50:45,750 --> 01:50:48,540
they're affecting their future career prospects.

2385
01:50:48,540 --> 01:50:49,740
So they sell small investors

2386
01:50:49,740 --> 01:50:53,253
down the river for their own career.

2387
01:50:55,230 --> 01:50:59,250
That's what actually happens. Regulatory capture.

2388
01:50:59,250 --> 01:51:01,953
- [Lex] Regulatory capture, - Yeah. Not good.

2389
01:51:03,720 --> 01:51:06,180
So the only reason I accepted that thing,

2390
01:51:06,180 --> 01:51:10,530
which technically was not an admission,

2391
01:51:10,530 --> 01:51:13,530
it's neither admit nor deny guilt.

2392
01:51:13,530 --> 01:51:15,750
But the only reason I agreed to that at all

2393
01:51:15,750 --> 01:51:19,533
was because I was told Tesla would be bankrupt otherwise.

2394
01:51:20,790 --> 01:51:24,180
So if there was an SEC investigation like this,

2395
01:51:24,180 --> 01:51:25,830
banks would suspend funding,

2396
01:51:25,830 --> 01:51:28,350
we're bankrupt immediately, at the time.

2397
01:51:28,350 --> 01:51:30,690
Now we're in a much stronger position.

2398
01:51:30,690 --> 01:51:32,820
- Take that Grok. - Yes.

2399
01:51:32,820 --> 01:51:33,653
Unfortunately it's,

2400
01:51:33,653 --> 01:51:37,563
Grok is taking too much from the conventional media.

2401
01:51:39,030 --> 01:51:41,433
Also that guy who is not a cave diver.

2402
01:51:42,780 --> 01:51:47,760
- Oh, there's a time where Elon

2403
01:51:47,760 --> 01:51:51,079
called the British cave diver, "pedo guy"

2404
01:51:51,079 --> 01:51:53,460
after the diver criticized Musk plan

2405
01:51:53,460 --> 01:51:55,950
to rescue a group of boys trapped in a Thai cave.

2406
01:51:55,950 --> 01:51:58,500
That little outburst earned him another lawsuit

2407
01:51:58,500 --> 01:52:00,513
and he had to apologize and paid a settlement.

2408
01:52:00,513 --> 01:52:03,390
- That is false. There was no settlement.

2409
01:52:03,390 --> 01:52:04,910
There was a court case,

2410
01:52:04,910 --> 01:52:09,120
which the guy who was not a cave diver

2411
01:52:09,120 --> 01:52:12,153
and played, was not part of the rescue team,

2412
01:52:14,400 --> 01:52:16,200
filed a lawsuit against me and lost,

2413
01:52:16,200 --> 01:52:17,463
and he received nothing.

2414
01:52:18,300 --> 01:52:20,340
So in this case it is wrong.

2415
01:52:20,340 --> 01:52:23,460
It is also, I guess taken this from the conventional media.

2416
01:52:23,460 --> 01:52:24,991
- Actually there's an interesting question here.

2417
01:52:24,991 --> 01:52:26,640
- These are public court cases.

2418
01:52:26,640 --> 01:52:29,350
Both the SEC civil case

2419
01:52:30,240 --> 01:52:34,200
where the civil complaints on the SEC guys

2420
01:52:34,200 --> 01:52:38,040
lost unanimous jury verdict in San Francisco.

2421
01:52:38,040 --> 01:52:39,210
They picked San Francisco

2422
01:52:39,210 --> 01:52:40,710
because they thought it was the place

2423
01:52:40,710 --> 01:52:42,573
I was most likely to lose.

2424
01:52:43,710 --> 01:52:45,930
And a unanimous predicted my favor.

2425
01:52:45,930 --> 01:52:49,260
The LA trial was also, they picked the,

2426
01:52:49,260 --> 01:52:51,780
they picked that venue because they thought

2427
01:52:51,780 --> 01:52:54,903
I was most likely to lose, unanimous verdict in my favor.

2428
01:52:56,430 --> 01:53:00,180
Both cases I won, yeah.

2429
01:53:00,180 --> 01:53:01,800
I mean there's an interesting question here.

2430
01:53:01,800 --> 01:53:05,693
Is there seems to be a lot more clicks

2431
01:53:07,610 --> 01:53:11,520
if a journalistic organization writes a negative article

2432
01:53:11,520 --> 01:53:12,930
about you, Elon Musk,

2433
01:53:12,930 --> 01:53:16,350
that's like one of the best ways to get clicks.

2434
01:53:16,350 --> 01:53:19,890
So how do you, if you're training Grok,

2435
01:53:19,890 --> 01:53:23,190
not train on articles that have

2436
01:53:23,190 --> 01:53:26,850
like the misaligned incentives.

2437
01:53:26,850 --> 01:53:28,110
- We need to add the training set

2438
01:53:28,110 --> 01:53:30,273
of the actual legal decisions.

2439
01:53:32,460 --> 01:53:35,520
So, that is a not, this is actually helpful

2440
01:53:35,520 --> 01:53:38,690
because if you actually read the...

2441
01:53:40,207 --> 01:53:41,040
- "Public".

2442
01:53:41,040 --> 01:53:43,860
- Which are public, the court conclusions,

2443
01:53:43,860 --> 01:53:45,360
they're completely the opposite of

2444
01:53:45,360 --> 01:53:47,100
what the media wrote.

2445
01:53:47,100 --> 01:53:49,620
- So always striving for like the ground truth.

2446
01:53:49,620 --> 01:53:50,760
- [Elon] Yeah. - Beyond the reporting...

2447
01:53:50,760 --> 01:53:52,751
- What did the judge actually write?

2448
01:53:52,751 --> 01:53:55,353
What did the jury and the judge actually conclude?

2449
01:53:57,000 --> 01:53:59,700
And in both cases they found me innocent.

2450
01:53:59,700 --> 01:54:01,890
And, like, that's after the jury shot

2451
01:54:01,890 --> 01:54:03,540
for the trying to find the venue

2452
01:54:03,540 --> 01:54:05,040
where I'm most likely to lose.

2453
01:54:07,260 --> 01:54:10,260
No, I mean this is obviously, it can be a much greater,

2454
01:54:10,260 --> 01:54:12,030
better critique than this.

2455
01:54:12,030 --> 01:54:16,260
I mean, I've been far too optimistic about autopilot.

2456
01:54:16,260 --> 01:54:18,090
- That was, the critique I got by the way,

2457
01:54:18,090 --> 01:54:19,410
was more about that.

2458
01:54:19,410 --> 01:54:22,470
Which is, for each it broke down a nice bullet point list

2459
01:54:22,470 --> 01:54:23,700
for each of your companies.

2460
01:54:23,700 --> 01:54:27,240
The set of predictions that you made when you'll deliver,

2461
01:54:27,240 --> 01:54:30,030
when you'll be able to solve, for example, self-driving

2462
01:54:30,030 --> 01:54:31,350
and it gives you like a list.

2463
01:54:31,350 --> 01:54:32,520
And it was probably compelling.

2464
01:54:32,520 --> 01:54:35,310
And the basic takeaway is like you're often

2465
01:54:35,310 --> 01:54:37,560
too optimistic about how long it takes

2466
01:54:37,560 --> 01:54:38,460
to get something done.

2467
01:54:38,460 --> 01:54:39,420
- Yeah, I mean, I would say

2468
01:54:39,420 --> 01:54:42,169
that I'm pathologically optimistic on schedule.

2469
01:54:42,169 --> 01:54:43,500
This is true.

2470
01:54:43,500 --> 01:54:47,733
But while I am sometimes late, I always deliver in the end.

2471
01:54:49,200 --> 01:54:50,640
- Except with Uber Lilith, no.

2472
01:54:50,640 --> 01:54:53,970
- Hmm. We'll see. (Lex laughing)

2473
01:54:53,970 --> 01:54:54,803
- Okay.

2474
01:54:54,803 --> 01:54:57,720
Is there, over the past year or so,

2475
01:54:57,720 --> 01:55:02,040
since purchasing X you've become more political.

2476
01:55:02,040 --> 01:55:03,780
Is there a part of you that regrets that?

2477
01:55:03,780 --> 01:55:04,950
- Have I?

2478
01:55:04,950 --> 01:55:09,950
- In this battle to sort of counter way the Woke

2479
01:55:12,930 --> 01:55:13,980
that comes from Francisco.

2480
01:55:13,980 --> 01:55:16,230
- I guess you consider fighting the Woke Mind Virus,

2481
01:55:16,230 --> 01:55:18,300
which I consider to be a civilizational threat,

2482
01:55:18,300 --> 01:55:20,105
to be political, then yes.

2483
01:55:20,105 --> 01:55:22,980
- So basically going into the battle,

2484
01:55:22,980 --> 01:55:25,260
the battleground of politics,

2485
01:55:25,260 --> 01:55:26,458
is there a part of you that regrets that?

2486
01:55:26,458 --> 01:55:29,520
- Yes, I don't know if this is necessarily sort of

2487
01:55:29,520 --> 01:55:31,020
one candidate or another candidate,

2488
01:55:31,020 --> 01:55:33,750
but it's, I'm generally against things

2489
01:55:33,750 --> 01:55:36,450
that are anti meritocratic

2490
01:55:36,450 --> 01:55:39,753
or where there's an attempt to suppress discussion,

2491
01:55:41,490 --> 01:55:46,203
where even discussing a topic is, you know, not allowed.

2492
01:55:47,940 --> 01:55:49,953
Woke Mind Virus is communism rebranded.

2493
01:55:51,660 --> 01:55:52,493
- Well, I mean, that said,

2494
01:55:52,493 --> 01:55:55,320
because of that battle against the Woke Mind Virus,

2495
01:55:55,320 --> 01:55:57,393
you're perceived as being right wing.

2496
01:55:58,800 --> 01:56:00,660
- If the woke is left, then I suppose

2497
01:56:00,660 --> 01:56:03,150
that would be true, but I'm not sure.

2498
01:56:03,150 --> 01:56:05,340
I think there are aspects of the left that are good.

2499
01:56:05,340 --> 01:56:07,893
I mean, if you're in favor of, you know,

2500
01:56:08,910 --> 01:56:10,210
the environment, you know,

2501
01:56:11,120 --> 01:56:13,200
if you wanna have a positive future for humanity,

2502
01:56:13,200 --> 01:56:15,950
if you believe in empathy for your fellow human beings.

2503
01:56:17,790 --> 01:56:21,000
You know, being kind and not cruel.

2504
01:56:21,000 --> 01:56:22,443
Whatever those values are.

2505
01:56:23,400 --> 01:56:26,250
- You said that you were previously left or center left.

2506
01:56:26,250 --> 01:56:27,600
What would you like to see in order for you

2507
01:56:27,600 --> 01:56:30,300
to voting for Democrats again?

2508
01:56:30,300 --> 01:56:32,200
- No, I would say that I would be

2509
01:56:35,160 --> 01:56:37,530
probably left of center on social issues,

2510
01:56:37,530 --> 01:56:40,470
probably a little bit right of center on economic issues.

2511
01:56:40,470 --> 01:56:42,030
- [Lex] And that still holds true?

2512
01:56:42,030 --> 01:56:44,580
- Yes, but I think that's probably, you know,

2513
01:56:44,580 --> 01:56:46,740
half the country, isn't that?

2514
01:56:46,740 --> 01:56:49,170
- [Lex] Maybe more, - Maybe more.

2515
01:56:49,170 --> 01:56:51,213
- Are you and AOC secretly friends?

2516
01:56:52,350 --> 01:56:55,620
Or bigger question, do you wish you and her,

2517
01:56:55,620 --> 01:56:57,810
and just people in general of all political persuasions

2518
01:56:57,810 --> 01:56:59,340
would talk more with empathy

2519
01:56:59,340 --> 01:57:01,080
and maybe have a little bit more fun

2520
01:57:01,080 --> 01:57:03,783
and good vibes and humor online?

2521
01:57:05,070 --> 01:57:07,050
- I'm always in favor of humor.

2522
01:57:07,050 --> 01:57:08,700
That's why we have a funny mode.

2523
01:57:08,700 --> 01:57:12,829
- But good vibes, camaraderie, humor, you know?

2524
01:57:12,829 --> 01:57:14,910
Like friendship. - Yeah.

2525
01:57:14,910 --> 01:57:19,590
Well, you know, I don't know AOC, you know, was,

2526
01:57:19,590 --> 01:57:21,540
I've only been at one,

2527
01:57:21,540 --> 01:57:24,573
I was at the Met Ball when she was, when she attended,

2528
01:57:26,040 --> 01:57:28,173
and she was wearing this dress,

2529
01:57:29,790 --> 01:57:31,070
but I can only see one side of it.

2530
01:57:31,070 --> 01:57:33,840
So it looked like it eat the itch,

2531
01:57:33,840 --> 01:57:35,340
but I don't know...

2532
01:57:35,340 --> 01:57:36,450
- [Lex] What the rest of it said?

2533
01:57:36,450 --> 01:57:38,376
- Yeah, something. - [Lex] I'm not sure.

2534
01:57:38,376 --> 01:57:39,930
(Elon laughing)

2535
01:57:39,930 --> 01:57:42,030
- Something about the itch. Eat the itch.

2536
01:57:42,030 --> 01:57:43,879
I think we should have a language model complete.

2537
01:57:43,879 --> 01:57:46,320
(Elon laughing)

2538
01:57:46,320 --> 01:57:48,930
What are the possible ways to complete that sentence?

2539
01:57:48,930 --> 01:57:52,410
And so I guess that that didn't work out well.

2540
01:57:52,410 --> 01:57:54,120
Well there's still hope.

2541
01:57:54,120 --> 01:57:55,500
- I root for friendship.

2542
01:57:55,500 --> 01:57:58,050
- Sure, sounds good. More characteristic.

2543
01:57:58,050 --> 01:58:01,200
- You're one of, if not the most famous, wealthy

2544
01:58:01,200 --> 01:58:02,760
and powerful people in the world,

2545
01:58:02,760 --> 01:58:04,380
in your position it's difficult to find

2546
01:58:04,380 --> 01:58:05,670
people you can trust.

2547
01:58:05,670 --> 01:58:07,590
- Trust no one, not even yourself. Not trusting yourself.

2548
01:58:07,590 --> 01:58:08,910
- Okay, well that's, (Elon laughing)

2549
01:58:08,910 --> 01:58:10,740
you're saying that jokingly,

2550
01:58:10,740 --> 01:58:11,573
but is there some...

2551
01:58:11,573 --> 01:58:14,021
- Trust no one, not even no one. (laughing)

2552
01:58:14,021 --> 01:58:15,750
- I'm gonna need an hour

2553
01:58:15,750 --> 01:58:16,737
just to think about that.

2554
01:58:16,737 --> 01:58:21,180
And maybe some drugs and maybe Grok that help me.

2555
01:58:21,180 --> 01:58:22,590
I mean, is there some aspect of that

2556
01:58:22,590 --> 01:58:24,330
when just existing in a world

2557
01:58:24,330 --> 01:58:26,280
where everybody wants something from you?

2558
01:58:26,280 --> 01:58:28,980
How hard is it to exist in that world?

2559
01:58:28,980 --> 01:58:31,110
- I'll survive. (laughing)

2560
01:58:31,110 --> 01:58:32,280
- [Lex] There's a song like that too.

2561
01:58:32,280 --> 01:58:33,113
- I will survive.

2562
01:58:33,113 --> 01:58:35,043
- Were you petrified at first?

2563
01:58:36,480 --> 01:58:39,180
Okay. I forget the rest of the lyrics.

2564
01:58:39,180 --> 01:58:41,513
But is is there, you don't struggle with this?

2565
01:58:41,513 --> 01:58:44,400
I mean, I know you survive, but like there's ways.

2566
01:58:44,400 --> 01:58:47,520
- Petrify is a spell in the Druid tree.

2567
01:58:47,520 --> 01:58:49,020
- What does it do? - Petrify.

2568
01:58:50,437 --> 01:58:51,664
(laughing)

2569
01:58:51,664 --> 01:58:54,783
It turns the monsters into stone.

2570
01:58:56,100 --> 01:58:56,933
- [Lex] Oh, like literally?

2571
01:58:56,933 --> 01:58:58,380
- Yeah, for like six seconds.

2572
01:58:58,380 --> 01:58:59,330
- [Lex] Well, the second.

2573
01:58:59,330 --> 01:59:02,400
There's so much math in Diablo that breaks my brain.

2574
01:59:02,400 --> 01:59:04,770
- It's like math nonstop.

2575
01:59:04,770 --> 01:59:06,720
- I mean really you're like laughing at it,

2576
01:59:06,720 --> 01:59:11,250
but you don't, it can put a huge amount of tension

2577
01:59:11,250 --> 01:59:12,083
on a mind.

2578
01:59:13,080 --> 01:59:15,293
- Yes, it can be definitely stressful at times.

2579
01:59:16,320 --> 01:59:18,720
- Well, how do you know who you can trust

2580
01:59:18,720 --> 01:59:20,490
in work and personal life?

2581
01:59:20,490 --> 01:59:22,290
- I mean, I guess you look at somebody's track record

2582
01:59:22,290 --> 01:59:25,260
over time and if they've got a, you know,

2583
01:59:25,260 --> 01:59:29,970
I guess you kind of use your neural net to assess,

2584
01:59:29,970 --> 01:59:31,590
you know, someone.

2585
01:59:31,590 --> 01:59:33,450
- Neural nets don't feel pain.

2586
01:59:33,450 --> 01:59:35,296
Your neural net has consciousness.

2587
01:59:35,296 --> 01:59:39,320
It might feel pain when people betray you.

2588
01:59:39,320 --> 01:59:40,650
It can make you... - I mean, I'm.

2589
01:59:40,650 --> 01:59:41,550
You know, to be frank,

2590
01:59:41,550 --> 01:59:44,733
I mean I've almost never been betrayed.

2591
01:59:46,669 --> 01:59:50,460
It's very, very rare. So, you know, for what it's worth?

2592
01:59:50,460 --> 01:59:52,320
- I guess Karma would be good to people

2593
01:59:52,320 --> 01:59:53,490
and they'll be good to you.

2594
01:59:53,490 --> 01:59:57,003
- Yeah, Karma is real. - Are there people you trust?

2595
01:59:58,710 --> 02:00:00,270
Let me edit that question.

2596
02:00:00,270 --> 02:00:02,970
Are there people close to you

2597
02:00:02,970 --> 02:00:04,720
that call you out on your bullshit?

2598
02:00:06,270 --> 02:00:08,402
- Well, the X platform is very helpful for that.

2599
02:00:08,402 --> 02:00:09,722
- [Lex] Hmm.

2600
02:00:09,722 --> 02:00:12,330
- If you're looking for critical feedback. (laughing)

2601
02:00:12,330 --> 02:00:15,090
- Can it push you like into the extremes more?

2602
02:00:15,090 --> 02:00:16,800
The extremes of thought make you cynical

2603
02:00:16,800 --> 02:00:18,300
about human nature in general?

2604
02:00:19,805 --> 02:00:21,330
- I don't think I'll be cynical.

2605
02:00:21,330 --> 02:00:25,740
In fact, I think, you know,

2606
02:00:25,740 --> 02:00:28,027
my feeling is that one should be, you know,

2607
02:00:31,860 --> 02:00:33,213
never trust a cynic.

2608
02:00:34,050 --> 02:00:38,760
The reason is that cynics excuse

2609
02:00:38,760 --> 02:00:41,210
their own bad behavior by saying everyone does it

2610
02:00:42,810 --> 02:00:44,730
because they're cynical.

2611
02:00:44,730 --> 02:00:46,860
So I always be, it's a red flag

2612
02:00:46,860 --> 02:00:49,440
if someone's a cynic, a true cynic.

2613
02:00:49,440 --> 02:00:51,150
- Yeah, there's a degree of projection there

2614
02:00:51,150 --> 02:00:53,730
that's always fun to watch from the outside

2615
02:00:53,730 --> 02:00:56,013
and enjoy the, well the hypocrisy.

2616
02:00:57,420 --> 02:00:59,550
- But this is an important point

2617
02:00:59,550 --> 02:01:02,356
that I think people who are listening should bear in mind,

2618
02:01:02,356 --> 02:01:06,510
if somebody is cynical, meaning that they see

2619
02:01:06,510 --> 02:01:07,983
bad behavior in everyone,

2620
02:01:08,880 --> 02:01:11,430
it's easy for them to excuse their own bad behavior

2621
02:01:12,270 --> 02:01:14,220
by saying that, well, everyone does it.

2622
02:01:16,084 --> 02:01:16,917
It's not true.

2623
02:01:19,740 --> 02:01:22,233
I think most people are kind of medium good.

2624
02:01:23,610 --> 02:01:26,130
- I do wish the people on X will be better

2625
02:01:26,130 --> 02:01:29,370
at seeing the good in other people's behavior.

2626
02:01:29,370 --> 02:01:32,130
There seems to be a kind of weight

2627
02:01:32,130 --> 02:01:35,040
towards seeing the negative.

2628
02:01:35,040 --> 02:01:37,350
Somehow, the negative is sexier.

2629
02:01:37,350 --> 02:01:41,640
Interpreting the negative is sexier, more viral.

2630
02:01:41,640 --> 02:01:43,643
I don't know what that is exactly about human nature.

2631
02:01:43,643 --> 02:01:45,210
- I mean, I find the X platform

2632
02:01:45,210 --> 02:01:48,457
to be less negative than the legacy media, you know?

2633
02:01:48,457 --> 02:01:50,850
I mean, if you read sort of a sort of

2634
02:01:50,850 --> 02:01:54,510
conventional newspapers, just, it makes you sad.

2635
02:01:54,510 --> 02:01:55,760
- [Lex] Yeah. - Frankly.

2636
02:01:58,980 --> 02:02:01,413
Whereas I'd say on the X platform,

2637
02:02:02,597 --> 02:02:05,520
I mean I really get more laughs per day on X

2638
02:02:05,520 --> 02:02:09,000
than everything else combined from humans, you know?

2639
02:02:09,000 --> 02:02:10,100
- Laughs is one thing.

2640
02:02:11,490 --> 02:02:13,890
Laughs is it overlaps,

2641
02:02:13,890 --> 02:02:17,640
but it's not necessarily perfectly overlapping

2642
02:02:17,640 --> 02:02:19,320
with like good vibes and support,

2643
02:02:19,320 --> 02:02:22,950
like celebrating others, for example.

2644
02:02:22,950 --> 02:02:24,780
Not in a stupid, shallow, naive way,

2645
02:02:24,780 --> 02:02:27,537
but like in an awesome, like, oh, something awesome happened

2646
02:02:27,537 --> 02:02:29,193
and you celebrate them for it.

2647
02:02:30,540 --> 02:02:32,340
It feels that that is outweighed

2648
02:02:32,340 --> 02:02:35,220
by shading on other people.

2649
02:02:35,220 --> 02:02:38,580
Now it's better than mainstream media, but it's still.

2650
02:02:38,580 --> 02:02:40,440
- Yeah, mainstream media is almost

2651
02:02:40,440 --> 02:02:42,870
relentlessly negative about everything.

2652
02:02:42,870 --> 02:02:45,510
It's, I mean, really the conventional news tries

2653
02:02:45,510 --> 02:02:46,590
to answer the question,

2654
02:02:46,590 --> 02:02:49,470
what is the worst thing that I have on earth today?

2655
02:02:49,470 --> 02:02:50,580
And it's a big world.

2656
02:02:50,580 --> 02:02:53,200
So on any given day, something bad has happened

2657
02:02:54,240 --> 02:02:55,500
- And a journalization of that,

2658
02:02:55,500 --> 02:02:56,700
what is the worst perspective

2659
02:02:56,700 --> 02:02:59,730
I can take on a thing that happened, so.

2660
02:02:59,730 --> 02:03:01,320
- Yeah, it's, I don't know,

2661
02:03:01,320 --> 02:03:03,720
there's just a strong negative bias in the news.

2662
02:03:06,120 --> 02:03:08,550
I mean I think there's one, a possible explanation

2663
02:03:08,550 --> 02:03:10,293
for this is evolutionary,

2664
02:03:12,960 --> 02:03:15,270
where, you know, bad news historically

2665
02:03:15,270 --> 02:03:17,970
would be potentially fatal.

2666
02:03:17,970 --> 02:03:19,290
Like there's lion over there

2667
02:03:19,290 --> 02:03:22,470
or there's some other tribe that wants to kill you.

2668
02:03:22,470 --> 02:03:25,980
Good news, you know, like we found a patch of berries

2669
02:03:25,980 --> 02:03:27,753
is nice to have, but not essential.

2670
02:03:28,740 --> 02:03:33,740
- So our old friend Tesla autopilot

2671
02:03:33,990 --> 02:03:35,730
and it's probably one of the most intelligent

2672
02:03:35,730 --> 02:03:38,280
real world AI systems in the world.

2673
02:03:38,280 --> 02:03:40,770
- You followed it from the beginning.

2674
02:03:40,770 --> 02:03:42,570
- Yeah, it was one of the most incredible robots

2675
02:03:42,570 --> 02:03:43,747
in the world and continues to be.

2676
02:03:43,747 --> 02:03:45,540
And I was really exciting.

2677
02:03:45,540 --> 02:03:48,640
And it was super exciting when it generalized

2678
02:03:49,650 --> 02:03:52,260
became more than a robot on four wheels,

2679
02:03:52,260 --> 02:03:57,260
but a real world AI system that perceives the world.

2680
02:03:57,390 --> 02:03:59,520
- [Elon] Yeah. - And can have

2681
02:03:59,520 --> 02:04:02,040
potentially different embodiments.

2682
02:04:02,040 --> 02:04:03,990
- Well I mean the really wild thing about the end-to-end

2683
02:04:03,990 --> 02:04:07,020
training is that, like, it learns to read.

2684
02:04:07,020 --> 02:04:09,933
Like it can read signs, but we never taught it to read.

2685
02:04:12,420 --> 02:04:15,854
So, yeah.

2686
02:04:15,854 --> 02:04:18,210
We never taught it what a car was

2687
02:04:18,210 --> 02:04:21,603
or what a person was or a cyclist.

2688
02:04:22,920 --> 02:04:26,760
It learnt what all those things are,

2689
02:04:26,760 --> 02:04:31,230
what all the objects are on the road from video,

2690
02:04:31,230 --> 02:04:32,130
just from watching videos.

2691
02:04:32,130 --> 02:04:33,730
Just like humans.

2692
02:04:33,730 --> 02:04:36,150
I mean humans are photons

2693
02:04:36,150 --> 02:04:38,250
and controls out.

2694
02:04:38,250 --> 02:04:41,220
Like the vast majority of information reaching our brain

2695
02:04:41,220 --> 02:04:43,053
is from our eyes.

2696
02:04:44,429 --> 02:04:45,570
And you say, well what's the output?

2697
02:04:45,570 --> 02:04:49,950
The output is our motor signals to our sort of fingers

2698
02:04:49,950 --> 02:04:53,013
and mouth in order to communicate.

2699
02:04:55,860 --> 02:04:59,193
Proton in controls out. The same is true of the car.

2700
02:05:01,170 --> 02:05:05,340
- But by looking at the sequence of images, it's,

2701
02:05:05,340 --> 02:05:08,670
you've agreed with Ilya Sutskever recently

2702
02:05:08,670 --> 02:05:11,340
where he talked about LLM forming a world model

2703
02:05:11,340 --> 02:05:13,410
and basically language is a projection

2704
02:05:13,410 --> 02:05:17,250
of that world model onto the sequence of letters,

2705
02:05:17,250 --> 02:05:18,180
and and you're saying...

2706
02:05:18,180 --> 02:05:20,493
- Finds order in these things.

2707
02:05:21,960 --> 02:05:25,803
It finds correlative clusters.

2708
02:05:27,480 --> 02:05:29,310
- And so doing it's like understanding

2709
02:05:29,310 --> 02:05:30,750
something deep about the world?

2710
02:05:30,750 --> 02:05:32,040
- [Elon] Yeah.

2711
02:05:32,040 --> 02:05:35,820
- Which is like, and it is beautiful.

2712
02:05:35,820 --> 02:05:37,270
- That's how our brain works.

2713
02:05:38,310 --> 02:05:39,690
- Yeah, but it's beautiful.

2714
02:05:39,690 --> 02:05:40,650
- Protons in controls out.

2715
02:05:40,650 --> 02:05:42,240
- Neural nets are able to understand

2716
02:05:42,240 --> 02:05:43,860
that deep meaning in the world.

2717
02:05:43,860 --> 02:05:46,530
And so the question is how far can it go?

2718
02:05:46,530 --> 02:05:50,100
And it does seem everybody's excited about LLMs.

2719
02:05:50,100 --> 02:05:52,530
So in the space of self supervised learning

2720
02:05:52,530 --> 02:05:54,753
in the space of text. - [Elon] Yeah.

2721
02:05:56,640 --> 02:06:00,750
- It seems like there's a deep similarity between that

2722
02:06:00,750 --> 02:06:03,333
and what Tesla autopilot is doing.

2723
02:06:04,410 --> 02:06:06,537
Is it to you basically the same?

2724
02:06:06,537 --> 02:06:09,783
- They're converging, they're converging.

2725
02:06:10,770 --> 02:06:12,690
- I wonder who gets there faster?

2726
02:06:12,690 --> 02:06:14,740
Having a deep understanding of the world,

2727
02:06:16,920 --> 02:06:19,560
or they just will naturally converge.

2728
02:06:19,560 --> 02:06:21,260
- They're both headed towards AGI.

2729
02:06:23,910 --> 02:06:27,270
The Tesla approach is much more computer efficient.

2730
02:06:27,270 --> 02:06:30,333
It had to be 'cause we were constrained on this,

2731
02:06:31,350 --> 02:06:33,240
you know, we only have a hundred watts

2732
02:06:36,000 --> 02:06:38,103
and into eight computer,

2733
02:06:39,060 --> 02:06:42,270
144 trillion operations per second,

2734
02:06:42,270 --> 02:06:43,103
which sounds like a lot,

2735
02:06:43,103 --> 02:06:45,700
but is kind of small potatoes these days

2736
02:06:48,360 --> 02:06:49,380
that it did.

2737
02:06:49,380 --> 02:06:51,630
But it's understanding the world that it did.

2738
02:06:52,740 --> 02:06:54,333
It's only 256 values.

2739
02:06:55,971 --> 02:06:58,530
- But there, the path to AGI might have much

2740
02:06:58,530 --> 02:07:01,743
more significant impact because it's understanding,

2741
02:07:02,970 --> 02:07:07,200
it'll faster understand the real world than will LLMs.

2742
02:07:07,200 --> 02:07:09,510
And therefore be able to integrate

2743
02:07:09,510 --> 02:07:12,153
with the real humans in the real world faster.

2744
02:07:13,170 --> 02:07:16,710
- They're both going to understand the world.

2745
02:07:16,710 --> 02:07:19,050
But I think Tesla's approach

2746
02:07:19,050 --> 02:07:21,390
is fundamentally more computer efficient.

2747
02:07:21,390 --> 02:07:23,850
It had to be, there was no choice.

2748
02:07:23,850 --> 02:07:25,540
Like our brain is very computer efficient,

2749
02:07:25,540 --> 02:07:27,240
very, very energy efficient.

2750
02:07:27,240 --> 02:07:30,273
So think of like, what is our brain able to do?

2751
02:07:32,370 --> 02:07:33,840
You know, there's only about 10 watts

2752
02:07:33,840 --> 02:07:36,600
of higher brain function, not counting stuff,

2753
02:07:36,600 --> 02:07:38,450
that's just used to control our body.

2754
02:07:39,420 --> 02:07:41,933
The thinking part of our brain is less than 10 watts,

2755
02:07:43,110 --> 02:07:46,530
and those 10 watts can still produce

2756
02:07:46,530 --> 02:07:50,760
a much better novel than a 10 megawatt GPU cluster.

2757
02:07:50,760 --> 02:07:53,213
So there's a six order of magnitude difference there.

2758
02:07:56,310 --> 02:07:59,823
I mean, the AI has thus far gotten to where it is,

2759
02:08:00,840 --> 02:08:04,860
via brute force, just throwing massive amounts of compute

2760
02:08:04,860 --> 02:08:07,593
and massive amounts of power at it.

2761
02:08:08,580 --> 02:08:12,093
So this is not where it'll end up.

2762
02:08:15,144 --> 02:08:16,770
You know, in general with any given technology,

2763
02:08:16,770 --> 02:08:19,463
first try to make it work and then you make it efficient.

2764
02:08:20,820 --> 02:08:24,480
So I think we'll find over time that these models

2765
02:08:24,480 --> 02:08:28,877
get smaller, are able to do produce

2766
02:08:30,720 --> 02:08:34,953
sensible output with far less compute wireless power.

2767
02:08:36,720 --> 02:08:38,820
Tesla is arguably ahead of the game on that front

2768
02:08:38,820 --> 02:08:42,930
because it has, we've just been forced

2769
02:08:42,930 --> 02:08:46,530
to try to understand the world

2770
02:08:46,530 --> 02:08:49,953
with a hundred watts of compute.

2771
02:08:51,870 --> 02:08:54,660
And there are a bunch of sort of fundamental functions

2772
02:08:54,660 --> 02:08:56,370
that we kind of forgot to include.

2773
02:08:56,370 --> 02:08:59,220
So we have to run them in a bunch of things in emulation.

2774
02:09:00,420 --> 02:09:02,850
We fixed a bunch of those with hardware four,

2775
02:09:02,850 --> 02:09:05,043
and then hardware five will be even better.

2776
02:09:08,130 --> 02:09:11,410
But it does appear at this point

2777
02:09:12,300 --> 02:09:16,050
that the car will be able to drive better than a human,

2778
02:09:16,050 --> 02:09:18,750
even with hardware three and a hundred watts of power.

2779
02:09:20,717 --> 02:09:22,600
And really, if we really optimize

2780
02:09:23,850 --> 02:09:25,850
it could be probably less than 50 watts.

2781
02:09:26,790 --> 02:09:31,410
- What have you learned about developing Optimus?

2782
02:09:31,410 --> 02:09:35,940
About applying, integrating this kind of real world AI

2783
02:09:35,940 --> 02:09:38,493
into the space of robotic manipulation,

2784
02:09:39,630 --> 02:09:41,283
just humanoid robotics?

2785
02:09:42,660 --> 02:09:44,370
What are some interesting tiny

2786
02:09:44,370 --> 02:09:47,610
or big things you've understood?

2787
02:09:47,610 --> 02:09:49,590
- I was surprised at the fact

2788
02:09:49,590 --> 02:09:53,040
that we had to develop every part of the robot ourselves.

2789
02:09:53,040 --> 02:09:57,213
That there were no off the shelf motors, electronics,

2790
02:09:58,290 --> 02:10:01,143
sensors, like we had to develop everything.

2791
02:10:03,322 --> 02:10:08,322
We couldn't actually find a source of electric motors

2792
02:10:09,300 --> 02:10:10,533
for any amount of money.

2793
02:10:12,420 --> 02:10:15,270
- [Lex] So it's not even just the efficient, inexpensive,

2794
02:10:15,270 --> 02:10:17,070
it's like anything, there's not a...

2795
02:10:17,070 --> 02:10:17,903
- No,

2796
02:10:19,020 --> 02:10:21,270
- [Lex] The actuators, everything, everything has to be?

2797
02:10:21,270 --> 02:10:23,430
- Yeah. - [Lex] Designed from scratch.

2798
02:10:23,430 --> 02:10:26,610
- We tried hard to find anything that was,

2799
02:10:26,610 --> 02:10:28,170
because you think of how many electric motors are made

2800
02:10:28,170 --> 02:10:29,003
in the world.

2801
02:10:29,003 --> 02:10:31,410
There's like tens of thousands,

2802
02:10:31,410 --> 02:10:34,053
hundreds of thousands of electric motor designs.

2803
02:10:37,590 --> 02:10:40,050
None of them were suitable for a humanoid robot.

2804
02:10:40,050 --> 02:10:40,883
Literally none.

2805
02:10:42,270 --> 02:10:46,530
So we had to develop our own design

2806
02:10:46,530 --> 02:10:51,530
specifically for what a humanoid robot needs.

2807
02:10:51,540 --> 02:10:53,163
- How hard was it to design something

2808
02:10:53,163 --> 02:10:54,690
that can be mass manufactured,

2809
02:10:54,690 --> 02:10:56,670
could be relatively inexpensive?

2810
02:10:56,670 --> 02:10:58,950
I mean, if you compare to Boston Dynamics Atlas,

2811
02:10:58,950 --> 02:11:02,070
that's a very expensive robot.

2812
02:11:02,070 --> 02:11:04,290
- It is designed to be manufactured

2813
02:11:04,290 --> 02:11:06,090
in the same way that we would make a car.

2814
02:11:06,090 --> 02:11:07,830
And I think ultimately we can make Optimists

2815
02:11:07,830 --> 02:11:09,430
for less than the cost of a car.

2816
02:11:11,490 --> 02:11:12,323
It should be.

2817
02:11:12,323 --> 02:11:16,060
'Cause if you look at the mass of the robot is much smaller

2818
02:11:17,100 --> 02:11:19,413
and the car has many actuators in it.

2819
02:11:21,240 --> 02:11:23,400
The car has more actuators than the robot.

2820
02:11:23,400 --> 02:11:25,920
- But there is, the actuators are kind of interesting

2821
02:11:25,920 --> 02:11:28,800
in a humanized robot with the fingers.

2822
02:11:28,800 --> 02:11:32,730
So Optimus has really nice, hands and fingers, you know?

2823
02:11:32,730 --> 02:11:34,380
- [Elon] Yeah. - And they could do

2824
02:11:34,380 --> 02:11:35,880
some interesting manipulation.

2825
02:11:36,750 --> 02:11:38,850
Soft touch robotics.

2826
02:11:38,850 --> 02:11:42,036
- I mean, one of the tests goals I have is,

2827
02:11:42,036 --> 02:11:44,940
can it pick up a needle and a thread

2828
02:11:44,940 --> 02:11:47,700
and thread the needle, just by looking.

2829
02:11:47,700 --> 02:11:49,590
- How far away are we from that?

2830
02:11:49,590 --> 02:11:51,630
Just by looking, just by looking.

2831
02:11:51,630 --> 02:11:52,463
- Maybe a year.

2832
02:11:53,580 --> 02:11:56,250
Although I go back to, I'm optimistic on time.

2833
02:11:56,250 --> 02:11:57,810
The work that we're doing in the car

2834
02:11:57,810 --> 02:11:59,370
will translate to the robot.

2835
02:11:59,370 --> 02:12:02,250
- The perception or the, also the control?

2836
02:12:02,250 --> 02:12:03,180
- No, the controls are different,

2837
02:12:03,180 --> 02:12:06,153
but the video in controls out,

2838
02:12:07,500 --> 02:12:09,952
the car is robot on four wheels.

2839
02:12:09,952 --> 02:12:14,952
The Optimist is a robot with the hands and legs.

2840
02:12:15,510 --> 02:12:16,343
- [Lex] So you can just...

2841
02:12:16,343 --> 02:12:17,820
- But they're very similar.

2842
02:12:17,820 --> 02:12:20,850
- So the entire machinery of the learning process

2843
02:12:20,850 --> 02:12:21,960
end to end is just,

2844
02:12:21,960 --> 02:12:23,940
you just have a different set of controls?

2845
02:12:23,940 --> 02:12:25,170
- Optimist will figure out

2846
02:12:25,170 --> 02:12:26,970
how to do things by watching videos.

2847
02:12:28,170 --> 02:12:29,047
- As the saying goes,

2848
02:12:29,047 --> 02:12:30,570
"Be kind for everyone you meet

2849
02:12:30,570 --> 02:12:33,300
is fighting a battle, you know nothing about."

2850
02:12:33,300 --> 02:12:34,290
- [Elon] Yeah, it's true.

2851
02:12:34,290 --> 02:12:35,190
- What's something difficult

2852
02:12:35,190 --> 02:12:38,220
you're going through that people don't often see?

2853
02:12:38,220 --> 02:12:41,223
- Trying to defeat Uber Lilith? (laughing)

2854
02:12:44,880 --> 02:12:46,320
No, I mean, you know,

2855
02:12:50,233 --> 02:12:52,479
I mean, my mind is a storm

2856
02:12:52,479 --> 02:12:55,320
and I don't think, I don't think

2857
02:12:55,320 --> 02:12:56,700
most people would wanna be me.

2858
02:12:56,700 --> 02:12:57,870
They may think they would wanna be me,

2859
02:12:57,870 --> 02:12:59,490
but they don't know.

2860
02:12:59,490 --> 02:13:00,590
They don't understand.

2861
02:13:11,070 --> 02:13:12,070
- How are you doing?

2862
02:13:14,796 --> 02:13:15,996
- I mean, overall, okay.

2863
02:13:18,209 --> 02:13:20,453
In the grand scheme of things, I can't complain.

2864
02:13:21,420 --> 02:13:25,260
- Do you get lonely? - Sometimes.

2865
02:13:25,260 --> 02:13:29,310
But I, you know, my kids

2866
02:13:29,310 --> 02:13:30,710
and friends keep me company.

2867
02:13:33,120 --> 02:13:34,803
- So not existential.

2868
02:13:36,420 --> 02:13:38,320
- There are many nights I sleep alone.

2869
02:13:40,483 --> 02:13:41,316
I don't have to, but I do.

2870
02:13:46,200 --> 02:13:49,050
- Walter Isaacson, in his new biography of you wrote

2871
02:13:49,050 --> 02:13:51,120
about your difficult childhood.

2872
02:13:51,120 --> 02:13:54,030
Will you ever find forgiveness in your heart

2873
02:13:54,030 --> 02:13:55,500
for everything that has happened to you

2874
02:13:55,500 --> 02:13:56,900
in that period of your life?

2875
02:14:01,530 --> 02:14:04,190
- What is forgiveness? I do not...

2876
02:14:06,453 --> 02:14:08,603
At least I don't think I have a resentment,

2877
02:14:14,310 --> 02:14:18,400
so nothing to forgive.

2878
02:14:19,587 --> 02:14:22,953
- You know, forgiveness is difficult for people.

2879
02:14:25,320 --> 02:14:27,620
It seems like you don't harbor the resentment.

2880
02:14:28,710 --> 02:14:29,945
- I mean, I try to think about like,

2881
02:14:29,945 --> 02:14:33,243
what is gonna affect the future in a good way.

2882
02:14:34,590 --> 02:14:35,860
And holding onto grudges

2883
02:14:36,780 --> 02:14:40,353
does not affect the future in a good way.

2884
02:14:41,220 --> 02:14:43,830
- You're a father, a proud father.

2885
02:14:43,830 --> 02:14:46,230
What have you learned about life from your kids?

2886
02:14:49,170 --> 02:14:51,093
Those little biological organisms?

2887
02:14:53,070 --> 02:14:55,020
- I mean, developing AI

2888
02:14:55,020 --> 02:14:57,400
and watching, say little X grow

2889
02:14:58,440 --> 02:15:01,803
is fascinating because they,

2890
02:15:03,420 --> 02:15:06,873
they're far more parallels than I would've expected.

2891
02:15:08,064 --> 02:15:10,214
I mean, I can see his biological neural net

2892
02:15:11,880 --> 02:15:13,920
making more and more sense to the world.

2893
02:15:13,920 --> 02:15:15,390
And I can see the digital neural net

2894
02:15:15,390 --> 02:15:17,933
making more and more sense of the world at the same time.

2895
02:15:19,230 --> 02:15:21,720
- Do you see the beauty in magic in both?

2896
02:15:21,720 --> 02:15:22,553
- Yes.

2897
02:15:26,280 --> 02:15:29,820
I mean, one of the things with kids is that, you know,

2898
02:15:29,820 --> 02:15:32,343
you kind of see the world anew in their eyes.

2899
02:15:34,950 --> 02:15:39,950
You know, to them everything is new and fresh.

2900
02:15:39,990 --> 02:15:43,920
And then when you see that,

2901
02:15:43,920 --> 02:15:48,920
them experience the world is new and fresh, you do too.

2902
02:15:52,860 --> 02:15:54,810
- Well. Elon, I just wanna say thank you

2903
02:15:54,810 --> 02:15:58,653
for your kindness to me and friendship over the years.

2904
02:15:59,490 --> 02:16:01,530
For seeing something in a silly kid like me,

2905
02:16:01,530 --> 02:16:03,510
as you've done for many others.

2906
02:16:03,510 --> 02:16:07,950
And thank you for having hope for a positive future,

2907
02:16:07,950 --> 02:16:09,000
for humanity,

2908
02:16:09,000 --> 02:16:11,070
and for working your ass off to make it happen.

2909
02:16:11,070 --> 02:16:13,290
Thank you, Elon. - [Elon] Thanks Lex.

2910
02:16:13,290 --> 02:16:15,150
- Thank you for listening to this conversation

2911
02:16:15,150 --> 02:16:16,470
with Elon Musk.

2912
02:16:16,470 --> 02:16:17,580
To support this podcast,

2913
02:16:17,580 --> 02:16:20,100
please check out our sponsors in the description.

2914
02:16:20,100 --> 02:16:22,380
And now let me leave you with some words

2915
02:16:22,380 --> 02:16:25,920
that Walter Isaacson wrote about the central philosophy

2916
02:16:25,920 --> 02:16:29,377
of how Elon approaches difficult problems.

2917
02:16:29,377 --> 02:16:32,160
"The only rules are the ones dictated

2918
02:16:32,160 --> 02:16:34,799
by the laws of physics."

2919
02:16:34,799 --> 02:16:37,802
Thank you for listening and hope to see you next time.

