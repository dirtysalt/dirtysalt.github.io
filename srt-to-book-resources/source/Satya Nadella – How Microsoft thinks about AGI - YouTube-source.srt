1
00:00:00,100 --> 00:00:03,420
Maybe after the Industrial Revolution, this is the biggest thing.

2
00:00:03,420 --> 00:00:08,440
But at the same time, I'm a little grounded in the fact that this is still early innings.

3
00:00:08,440 --> 00:00:10,860
If you're a model company, you may have a winner's curse.

4
00:00:10,860 --> 00:00:12,460
You may have done all the hard work

5
00:00:12,460 --> 00:00:20,550
done unbelievable innovation, except it's kind of like one copy away from that being commoditized.

6
00:00:20,550 --> 00:00:27,620
We didn't want to just be a host star for one company and have just a massive book of business with one customer.

7
00:00:27,620 --> 00:00:29,080
That- that's not a business.

8
00:00:29,080 --> 00:00:31,700
You can't build an infrastructure that's optimized for one model.

9
00:00:31,700 --> 00:00:34,620
If you do that, you're one tweak away from some MoE

10
00:00:34,620 --> 00:00:38,600
like, breakthrough that happens when your entire network topology goes out of the window.

11
00:00:38,600 --> 00:00:40,000
Then that's a scary thing.

12
00:00:40,000 --> 00:00:43,160
Our business, which today is an end user tools business

13
00:00:43,160 --> 00:00:47,949
will become essentially an infrastructure business in support of agents doing work.

14
00:00:47,949 --> 00:00:51,460
The thing that you have to think through is not what you do in the next five years

15
00:00:51,460 --> 00:00:54,120
but what do you do for the next 50?

16
00:00:54,120 --> 00:00:59,340
Today, we are interviewing Satya Nadella, we being me and Dilin Patel

17
00:00:59,340 --> 00:01:01,080
who is founder of SemiAnalysis.

18
00:01:01,080 --> 00:01:02,080
Satya, welcome.

19
00:01:02,080 --> 00:01:02,480
Thank you.

20
00:01:02,480 --> 00:01:03,000
It's great.

21
00:01:03,000 --> 00:01:04,739
Thanks for coming over to Atlanta.

22
00:01:04,739 --> 00:01:05,019
Yeah.

23
00:01:05,019 --> 00:01:06,320
Thank you for giving us the tour of

24
00:01:06,320 --> 00:01:07,380
uh, the new facility.

25
00:01:07,380 --> 00:01:08,140
It's been really cool to see.

26
00:01:08,140 --> 00:01:09,720
Absolutely.

27
00:01:09,720 --> 00:01:13,860
Satya and Scott Guthrie, Microsoft's EVP of Cloud and AI

28
00:01:13,860 --> 00:01:16,580
give us a tour of their brand new Fairwater 2 data center

29
00:01:16,580 --> 00:01:19,360
the current most powerful in the world.

30
00:01:19,360 --> 00:01:23,300
We try to 10X the training capacity every 18 to 24 months.

31
00:01:23,300 --> 00:01:25,940
And so this would be effectively a 10X increase

32
00:01:25,940 --> 00:01:28,040
10X from what GPT-5 was trained with.

33
00:01:28,040 --> 00:01:30,700
And so to put it in perspective, the number of optics

34
00:01:30,700 --> 00:01:38,500
the network optics in this building, is almost as much as all of Azure across all our data centers two and a half years ago.

35
00:01:38,500 --> 00:01:41,680
It's kind of, what, five million network connections.

36
00:01:41,680 --> 00:01:46,060
You've got all this bandwidth between different sites in the region and between the two regions.

37
00:01:46,060 --> 00:01:53,740
So is this like a big bet on scaling in the future that you anticipate in the future there's gonna be some huge model that needs to require two whole different regions to train?

38
00:01:53,740 --> 00:01:58,800
Uh- The goal is to be able to kind of aggregate these FLOPs for a large training job

39
00:01:58,800 --> 00:02:02,020
and then put these things together across sites.

40
00:02:02,020 --> 00:02:02,580
Right.

41
00:02:02,580 --> 00:02:06,380
And the reality is, you'll use it for

42
00:02:06,380 --> 00:02:09,240
uh, training  and then you'll use it for data gen

43
00:02:09,240 --> 00:02:11,740
you'll use it for inference in all sort of ways.

44
00:02:11,740 --> 00:02:11,750
Yeah.

45
00:02:11,750 --> 00:02:14,800
It's not like it's going to be used only for one workload forever.

46
00:02:14,800 --> 00:02:18,360
Fairwater 4, which you're going to see under construction nearby- Mm-hmm.

47
00:02:18,360 --> 00:02:18,370
.

48
00:02:18,370 --> 00:02:18,370
..

49
00:02:18,370 --> 00:02:21,020
yeah, will also be on that one peta- petabits network.

50
00:02:21,020 --> 00:02:21,380
Yep.

51
00:02:21,380 --> 00:02:24,080
So that we can actually link the two at a very high rate.

52
00:02:24,080 --> 00:02:27,420
And then basically, we do the AI WAN connecting to Milwaukee

53
00:02:27,420 --> 00:02:29,640
where we have multiple other Fairwaters being built.

54
00:02:29,640 --> 00:02:35,109
Literally, you can see the- the model parallelism and the data parallelism.

55
00:02:35,109 --> 00:02:37,850
And it's kind of built for, um

56
00:02:37,850 --> 00:02:42,020
essentially the training jobs, the pods, the super pods

57
00:02:42,020 --> 00:02:44,400
across this campus.

58
00:02:44,400 --> 00:02:49,680
And then with the WAN, you can go to the Wisconsin data center

59
00:02:49,680 --> 00:02:54,450
and you literally run a training job with all of them getting aggregated.

60
00:02:54,450 --> 00:02:57,840
And what we're seeing right here is this is a cell with no servers in it yet

61
00:02:57,840 --> 00:02:58,680
no racks.

62
00:02:58,680 --> 00:03:00,580
How many, uh, racks are in a cell?

63
00:03:00,580 --> 00:03:03,500
We think about, uh, we don't necessarily share that per se

64
00:03:03,500 --> 00:03:04,109
but- but we- we.

65
00:03:04,109 --> 00:03:04,109
..

66
00:03:04,109 --> 00:03:05,450
Let me- That's the reason I asked.

67
00:03:05,450 --> 00:03:06,930
 No, no, no.

68
00:03:06,930 --> 00:03:08,560
Uh, you'll see upstairs.

69
00:03:08,560 --> 00:03:09,220
I'll start counting.

70
00:03:09,220 --> 00:03:09,269
I'll start counting.

71
00:03:09,269 --> 00:03:10,060
You can start counting.

72
00:03:10,060 --> 00:03:10,780
We'll let you start counting.

73
00:03:10,780 --> 00:03:11,700
How many cells are there in this building?

74
00:03:11,700 --> 00:03:12,950
That part also I can't tell you.

75
00:03:12,950 --> 00:03:16,920
Division is easy, right?

76
00:03:16,920 --> 00:03:21,540
My god, it's kinda loud.

77
00:03:21,540 --> 00:03:24,280
Are you looking at this like, "Now I see where my money is going"?

78
00:03:24,280 --> 00:03:27,300
 It's kind of like, "I run a software company.

79
00:03:27,300 --> 00:03:28,966
Welcome to the software company.

80
00:03:28,966 --> 00:03:33,700
" How big is the design space once you've decided to use GB200s and NVLINK?

81
00:03:33,700 --> 00:03:35,660
How many other decisions are there to be made?

82
00:03:35,660 --> 00:03:43,020
There is coupling from the model architecture to what is the physical plan- Yeah.

83
00:03:43,020 --> 00:03:43,030
.

84
00:03:43,030 --> 00:03:43,030
..

85
00:03:43,030 --> 00:03:44,580
that's optimized.

86
00:03:44,580 --> 00:03:47,080
And it's also scary in that sense, which is

87
00:03:47,080 --> 00:03:49,480
A, there's gonna be a new chip that will come out.

88
00:03:49,480 --> 00:03:49,769
Yeah.

89
00:03:49,769 --> 00:03:52,600
Which obviously, I mean, you take Vera Rubin Ultra.

90
00:03:52,600 --> 00:03:55,800
I mean, that's gonna have power density that's going to be so different

91
00:03:55,800 --> 00:03:58,109
but with cooling requirements that are going to be so different.

92
00:03:58,109 --> 00:03:58,549
Right.

93
00:03:58,549 --> 00:03:58,780
Right?

94
00:03:58,780 --> 00:04:04,120
So you kind of don't want to just build all to one spec.

95
00:04:04,120 --> 00:04:06,820
So that goes back a little bit to I think the dialogue we'll have

96
00:04:06,820 --> 00:04:10,480
which is you want to be scaling- Yeah.

97
00:04:10,480 --> 00:04:10,490
.

98
00:04:10,490 --> 00:04:10,490
..

99
00:04:10,490 --> 00:04:11,380
in time.

100
00:04:11,380 --> 00:04:11,660
Yeah.

101
00:04:11,660 --> 00:04:13,410
As opposed to scale once- Yeah.

102
00:04:13,410 --> 00:04:13,410
.

103
00:04:13,410 --> 00:04:13,410
.

104
00:04:13,410 --> 00:04:14,410
and then be stuck with it.

105
00:04:14,410 --> 00:04:15,140
Yeah.

106
00:04:15,140 --> 00:04:18,200
When you look at all the past technological transitions

107
00:04:18,200 --> 00:04:21,899
whether it be, you know, railroads or the internet or

108
00:04:21,899 --> 00:04:25,180
you know, replaceable parts, industrialization, uh

109
00:04:25,180 --> 00:04:31,930
the cloud, all of these things, each revolution has gotten much faster in the time it goes from technology discover to ramp- Yeah.

110
00:04:31,930 --> 00:04:31,930
.

111
00:04:31,930 --> 00:04:31,930
.

112
00:04:31,930 --> 00:04:33,860
and pervasiveness through the economy.

113
00:04:33,860 --> 00:04:38,220
Many folks who have been on Dark Ashes podcast believe this is sort of the final

114
00:04:38,220 --> 00:04:42,040
uh, technological revolution or transition, and that this time is very

115
00:04:42,040 --> 00:04:43,020
very different.

116
00:04:43,020 --> 00:04:45,020
Um, and at least so far in the markets

117
00:04:45,020 --> 00:04:46,820
it's sort of, you know, in three years

118
00:04:46,820 --> 00:04:51,160
we've already skyrocketed to, you know, hyperscalers are doing $500 billion of CapEx next year

119
00:04:51,160 --> 00:04:56,540
which is a scale that's un- unmatched to prior revolutions in terms of speed.

120
00:04:56,540 --> 00:04:58,780
And the end state seems to be quite different.

121
00:04:58,780 --> 00:04:59,973
How- how do you.

122
00:04:59,973 --> 00:05:00,340
..

123
00:05:00,340 --> 00:05:03,920
Your- your framing of this seems quite different than sort of the

124
00:05:03,920 --> 00:05:05,770
I would say, the AI bro, who is-  .

125
00:05:05,770 --> 00:05:05,770
..

126
00:05:05,770 --> 00:05:08,860
who is quite, um, you know, AGI is coming.

127
00:05:08,860 --> 00:05:11,080
And, you know, I- I'd like to understand that more.

128
00:05:11,080 --> 00:05:18,370
Yeah, I mean, look, I- I start with the excitement that I also feel for maybe after the Industrial Revolution

129
00:05:18,370 --> 00:05:19,760
this is the biggest thing.

130
00:05:19,760 --> 00:05:24,260
Um, and so therefore, I- I- I- I start with that premise.

131
00:05:24,260 --> 00:05:27,760
Uh, but at the same time, I'm a little grounded in the fact that

132
00:05:27,760 --> 00:05:29,780
uh, this is still early innings.

133
00:05:29,780 --> 00:05:31,920
Uh, we built some very useful things.

134
00:05:31,920 --> 00:05:33,660
We're seeing some great properties.

135
00:05:33,660 --> 00:05:36,140
The scaling laws seem to be working.

136
00:05:36,140 --> 00:05:40,220
Um, and I'm optimistic that they'll continue to work

137
00:05:40,220 --> 00:05:40,420
right?

138
00:05:40,420 --> 00:05:42,420
Some of it is, um, you know

139
00:05:42,420 --> 00:05:48,120
it does require real science breakthroughs, but it's also a lot of engineering and what have you.

140
00:05:48,120 --> 00:05:52,160
But that said, I also sort of take the view that

141
00:05:52,160 --> 00:05:55,440
you know, even what has been happening in the last 70 years of computing

142
00:05:55,440 --> 00:05:58,280
uh, has also been a march, uh

143
00:05:58,280 --> 00:06:02,000
that has helped us move, um, you know

144
00:06:02,000 --> 00:06:03,740
with, as I said, you- you know

145
00:06:03,740 --> 00:06:06,351
I- I like one of the things that Raj Reddy.

146
00:06:06,351 --> 00:06:06,562
..

147
00:06:06,562 --> 00:06:06,772
..

148
00:06:06,772 --> 00:06:09,148
. uh, has as a metaphor for what AI is

149
00:06:09,148 --> 00:06:09,488
right?

150
00:06:09,488 --> 00:06:11,618
He's a, he's a Turing Award winner out of

151
00:06:11,618 --> 00:06:14,544
uh, CMU, um, and he's always .

152
00:06:14,544 --> 00:06:14,738
..

153
00:06:14,738 --> 00:06:17,218
And he had this even pre-AGI, uh

154
00:06:17,218 --> 00:06:18,758
but he had this metaphor of, uh

155
00:06:18,758 --> 00:06:22,768
AI should either be a guardian angel or a cognitive amplifier.

156
00:06:22,768 --> 00:06:23,568
I love that.

157
00:06:23,568 --> 00:06:26,448
Uh, it's a simple way to think about what this is.

158
00:06:26,448 --> 00:06:29,508
Ultimately, what is its u- human utility?

159
00:06:29,508 --> 00:06:31,968
It is going to be a cognitive amplifier

160
00:06:31,968 --> 00:06:33,958
uh, and a guardian angel.

161
00:06:33,958 --> 00:06:35,948
And so if I sort of view it that way

162
00:06:35,948 --> 00:06:37,587
I view it as a tool.

163
00:06:37,587 --> 00:06:39,908
But then you can also go very mystical about it and say

164
00:06:39,908 --> 00:06:41,768
"Well, this is, you know, more than a tool.

165
00:06:41,768 --> 00:06:44,492
It does all these things which only humans did so far.

166
00:06:44,492 --> 00:06:47,188
" But that has been the case with many technologies in the past.

167
00:06:47,188 --> 00:06:50,428
Only humans did a lot of things, and then we add tools that did them.

168
00:06:50,428 --> 00:06:50,868
Mm.

169
00:06:50,868 --> 00:06:54,008
I guess, uh, we don't have to get wrapped up in the definition here

170
00:06:54,008 --> 00:06:56,548
but maybe one way to think about it is like may- maybe it takes five years

171
00:06:56,548 --> 00:06:57,888
10 years, 20 years.

172
00:06:57,888 --> 00:07:01,328
At some point, eventually a machine is producing Satya tokens

173
00:07:01,328 --> 00:07:01,908
right?

174
00:07:01,908 --> 00:07:04,308
And the Microsoft board thinks that Satya tokens are worth a lot.

175
00:07:04,308 --> 00:07:06,188
 How much, how much are you wasting of this

176
00:07:06,188 --> 00:07:06,558
uh-  .

177
00:07:06,558 --> 00:07:06,598
..

178
00:07:06,598 --> 00:07:09,108
of, of, like, economic value by interviewing Satya?

179
00:07:09,108 --> 00:07:12,187
 I could not afford the API cost of Satya tokens.

180
00:07:12,187 --> 00:07:15,728
Um, but so, you know, whatever you wanna call it is that

181
00:07:15,728 --> 00:07:17,348
are the Satya tokens a tool or an agent

182
00:07:17,348 --> 00:07:22,848
whatever, um, right now if you have models that cost on the order of dollars or cents per million tokens

183
00:07:22,848 --> 00:07:26,728
there's just an enormous room for expansion, uh

184
00:07:26,728 --> 00:07:30,298
a margin expansion there where Satya to- a million tokens of Satya are

185
00:07:30,298 --> 00:07:31,508
like, worth a lot.

186
00:07:31,508 --> 00:07:34,488
Um, and where does that margin go

187
00:07:34,488 --> 00:07:39,328
and what level of that margin is Microsoft involved in is the question I have?

188
00:07:39,328 --> 00:07:45,158
So I think, um, in, in some sense this goes back again to essentially what's the

189
00:07:45,158 --> 00:07:47,908
uh, economic growth picture gonna really look like.

190
00:07:47,908 --> 00:07:50,688
Um, what's the firm gonna look like?

191
00:07:50,688 --> 00:07:52,088
What's productivity gonna look like?

192
00:07:52,088 --> 00:07:52,098
Yeah.

193
00:07:52,098 --> 00:07:54,188
And that to me is where, again

194
00:07:54,188 --> 00:07:57,788
if the Industrial Revolution created after, whatever

195
00:07:57,788 --> 00:08:01,228
70 years of diffusion is when you started seeing the economic growth

196
00:08:01,228 --> 00:08:01,388
right?

197
00:08:01,388 --> 00:08:01,698
It took .

198
00:08:01,698 --> 00:08:01,718
..

199
00:08:01,718 --> 00:08:04,458
That's the other thing to remember is, um

200
00:08:04,458 --> 00:08:08,138
even if the tech is diffusing fast, uh

201
00:08:08,138 --> 00:08:12,168
this time around, for true economic growth to appear

202
00:08:12,168 --> 00:08:15,147
it has to sort of diffuse to a point where the work

203
00:08:15,147 --> 00:08:17,468
the work artifact and the workflow has to change.

204
00:08:17,468 --> 00:08:19,678
And so that's kinda one place where I think

205
00:08:19,678 --> 00:08:26,127
uh, the change management required for a corporation to truly change I think is something we shouldn't discount.

206
00:08:26,127 --> 00:08:30,788
So, I think going forward, do humans and the tokens they produce

207
00:08:30,788 --> 00:08:33,248
uh, get higher leverage, right?

208
00:08:33,248 --> 00:08:38,048
Uh, whether it's the Dwarkesh or the Dylan tokens of the future.

209
00:08:38,048 --> 00:08:43,388
I mean, think about the amount of technolo- would you be able to run SemiAnalysis or this podcast without technology?

210
00:08:43,388 --> 00:08:44,048
No chance.

211
00:08:44,048 --> 00:08:44,168
Yeah.

212
00:08:44,168 --> 00:08:44,448
Right?

213
00:08:44,448 --> 00:08:47,728
I mean, the f- scale that you would be able to achieve

214
00:08:47,728 --> 00:08:48,788
no chance.

215
00:08:48,788 --> 00:08:50,428
So the question is what's that scale?

216
00:08:50,428 --> 00:08:53,748
Is it gonna be ten x-ed with something that comes through?

217
00:08:53,748 --> 00:08:54,848
Uh, absolutely.

218
00:08:54,848 --> 00:08:58,128
Uh, and therefore with it you'll ramp to some revenue number

219
00:08:58,128 --> 00:09:01,088
or you'll ramp to some audience number or what have you.

220
00:09:01,088 --> 00:09:02,867
And so that I think is what's going to happen

221
00:09:02,867 --> 00:09:03,108
right?

222
00:09:03,108 --> 00:09:03,117
Yeah.

223
00:09:03,117 --> 00:09:05,298
I mean, the, the point is, uh

224
00:09:05,298 --> 00:09:07,408
that s- whatever, what took 70 years

225
00:09:07,408 --> 00:09:11,748
maybe 150 years for the Industrial Revolution may happen in 20 years

226
00:09:11,748 --> 00:09:13,028
25 years.

227
00:09:13,028 --> 00:09:20,988
That's a better way to f- Like, I would love to compress what happened in 200 years of the Industrial Revolution into 20-year period

228
00:09:20,988 --> 00:09:22,108
if you're lucky.

229
00:09:22,108 --> 00:09:22,568
Mm.

230
00:09:22,568 --> 00:09:26,468
So Microsoft historically has been perhaps, you know

231
00:09:26,468 --> 00:09:29,808
the greatest software company, the largest software as a service company.

232
00:09:29,808 --> 00:09:35,348
You know, you've gone through a transition in the past where you used to sell Windows licenses and discs of Windows or Microsoft

233
00:09:35,348 --> 00:09:39,408
and now you sell, you know, subscriptions to 365 or

234
00:09:39,408 --> 00:09:40,098
um .

235
00:09:40,098 --> 00:09:40,598
..

236
00:09:40,598 --> 00:09:42,788
A- as, as we go from sort of

237
00:09:42,788 --> 00:09:45,648
you know, that transition to wh- where your business is today

238
00:09:45,648 --> 00:09:47,988
um, there's also a transition going after that

239
00:09:47,988 --> 00:09:48,608
right?

240
00:09:48,608 --> 00:09:52,768
Uh, software as a service, incredibly low incremental cost per user.

241
00:09:52,768 --> 00:09:55,788
Uh, there's a lot of R&D, there's a lot of customer acquisition cost.

242
00:09:55,788 --> 00:10:02,858
This is why, not Microsoft, but the SaaS companies have m- underperformed massively in the markets because the cogs of AI is just so high.

243
00:10:02,858 --> 00:10:02,878
Yeah.

244
00:10:02,878 --> 00:10:06,048
And that just completely breaks how these business models work.

245
00:10:06,048 --> 00:10:07,478
H- how do you as a, as

246
00:10:07,478 --> 00:10:10,698
as a, as perhaps the greatest software company

247
00:10:10,698 --> 00:10:17,008
um, software as a service company transition Microsoft to this new age where cogs matters a lot

248
00:10:17,008 --> 00:10:20,128
um, and, and the incremental cost per users is different

249
00:10:20,128 --> 00:10:20,328
right?

250
00:10:20,328 --> 00:10:23,341
Because right now you're charging, "Hey, it's 20 bucks for Copilot.

251
00:10:23,341 --> 00:10:23,648
" Yeah.

252
00:10:23,648 --> 00:10:24,804
So I think that this is a .

253
00:10:24,804 --> 00:10:24,918
..

254
00:10:24,918 --> 00:10:26,718
 it's a great question because in some sense

255
00:10:26,718 --> 00:10:30,788
the business models themselves, I think the levers are gonna remain similar

256
00:10:30,788 --> 00:10:30,998
right?

257
00:10:30,998 --> 00:10:32,158
Which is if I look at the, the

258
00:10:32,158 --> 00:10:35,328
if, if you look at the menu of models

259
00:10:35,328 --> 00:10:38,248
uh, starting from, like, say, consumer all the way

260
00:10:38,248 --> 00:10:40,308
right, there will be some ad unit

261
00:10:40,308 --> 00:10:46,588
uh, there will be some transaction, there will be some device gross margin for somebody who builds an AI device.

262
00:10:46,588 --> 00:10:50,948
Um, uh, there will be subscriptions, consumer and enterprise.

263
00:10:50,948 --> 00:10:52,627
Uh, and then there'll be consumption, right?

264
00:10:52,627 --> 00:10:54,971
So I still think that that's kinda how .

265
00:10:54,971 --> 00:10:54,978
..

266
00:10:54,978 --> 00:10:56,867
Those are all the meters.

267
00:10:56,867 --> 00:10:58,828
To your point, what is a subscription?

268
00:10:58,828 --> 00:11:02,928
Up to now, people like subscriptions because they can budget for them

269
00:11:02,928 --> 00:11:03,448
right?

270
00:11:03,448 --> 00:11:11,127
They are essentially entitlements to some consumption rights that come encapsulated in a subscription.

271
00:11:11,127 --> 00:11:12,418
So that, I think, is what .

272
00:11:12,418 --> 00:11:12,478
..

273
00:11:12,478 --> 00:11:14,488
In some sense it becomes a pricing decision.

274
00:11:14,488 --> 00:11:19,414
Uh, so how much consumption is en- you are entitled to is .

275
00:11:19,414 --> 00:11:19,468
..

276
00:11:19,468 --> 00:11:21,208
If you look at all the coding subscriptions

277
00:11:21,208 --> 00:11:22,608
that's kinda what they are, right?

278
00:11:22,608 --> 00:11:22,617
Yeah.

279
00:11:22,617 --> 00:11:25,428
And they kinda have the pro tier, the standard tier

280
00:11:25,428 --> 00:11:26,688
and what have you.

281
00:11:26,688 --> 00:11:30,398
And so I think that's how the pricing will ha- uh

282
00:11:30,398 --> 00:11:33,308
you know, and the margin structures will get tiered.

283
00:11:33,308 --> 00:11:35,851
Um, the interesting thing is having .

284
00:11:35,851 --> 00:11:35,858
..

285
00:11:35,858 --> 00:11:40,578
At Microsoft, the good news for us is we kinda are in that business

286
00:11:40,578 --> 00:11:43,048
uh, all, in across all those meters.

287
00:11:43,048 --> 00:11:45,978
In fact, at, at a, as a portfolio level

288
00:11:45,978 --> 00:11:49,728
uh, we pretty much have consumption, subscriptions

289
00:11:49,728 --> 00:11:53,508
uh, to all of the other consumer levers as well.

290
00:11:53,508 --> 00:11:58,948
Um, and then I think time will tell which of these models make sense in what categories.

291
00:11:58,948 --> 00:12:01,367
Um, one thing on the SaaS side

292
00:12:01,367 --> 00:12:04,031
since you brought up, which I think a lot about is .

293
00:12:04,031 --> 00:12:04,038
..

294
00:12:04,038 --> 00:12:07,367
Uh, take Office 365 or Microsoft 365.

295
00:12:07,367 --> 00:12:11,188
I mean, man, having a low ARPU is great because h- here's an interesting thing

296
00:12:11,188 --> 00:12:11,428
right?

297
00:12:11,428 --> 00:12:16,688
During the transition from server to cloud, one of the questions we used to ask ourselves is

298
00:12:16,688 --> 00:12:21,648
"Oh my God, if all we did was just basically move the same users who were using

299
00:12:21,648 --> 00:12:25,388
let's call it, our office licenses and our servers at that time

300
00:12:25,388 --> 00:12:27,839
office servers, right, to the cloud.

301
00:12:27,839 --> 00:12:28,036
".

302
00:12:28,036 --> 00:12:28,234
..

303
00:12:28,234 --> 00:12:32,784
and we had cogs, this is going to basically not only shrink our margins

304
00:12:32,784 --> 00:12:36,864
uh, but we'll be fundamentally a non-profitable or even less profitable company.

305
00:12:36,864 --> 00:12:41,884
Except what happened was the move to the cloud expanded the market like crazy

306
00:12:41,884 --> 00:12:43,404
uh, right?

307
00:12:43,404 --> 00:12:45,184
I mean, we sold a few servers in India

308
00:12:45,184 --> 00:12:46,064
didn't sell much.

309
00:12:46,064 --> 00:12:51,394
Whereas in the cloud, suddenly everybody in India also could afford fractionally buying

310
00:12:51,394 --> 00:12:52,074
uh, servers.

311
00:12:52,074 --> 00:12:52,954
The IT cost.

312
00:12:52,954 --> 00:12:55,094
I mean, in fact the biggest thing I had not realized

313
00:12:55,094 --> 00:13:03,104
for example, was the amount of money people were spending buying storage underneath SharePoint.

314
00:13:03,104 --> 00:13:09,204
In fact, EMC's biggest segment may have been storage servers for SharePoint.

315
00:13:09,204 --> 00:13:13,704
All that sort of dropped in the cloud because nobody had to go buy

316
00:13:13,704 --> 00:13:15,014
in fact it was working capital, I mean

317
00:13:15,014 --> 00:13:17,564
basically it was cash flow out, right?

318
00:13:17,564 --> 00:13:20,774
And so it expanded the market massively.

319
00:13:20,774 --> 00:13:24,144
So this AI thing will be that, right?

320
00:13:24,144 --> 00:13:31,464
So if you take coding, um, lit- what we built with GitHub and VSCode and over whatever

321
00:13:31,464 --> 00:13:36,964
decades, uh, suddenly the coding assistant is that big in one year.

322
00:13:36,964 --> 00:13:41,324
And so that, I think, is what's going to happen as well which is the market expands massively.

323
00:13:41,324 --> 00:13:41,864
Mm.

324
00:13:41,864 --> 00:13:48,264
I guess there's a question of the market will expand but will the parts of the revenue that touch Microsoft expand?

325
00:13:48,264 --> 00:13:51,424
So Copilot is an example where if you look

326
00:13:51,424 --> 00:13:53,664
uh, early this year, I think, uh

327
00:13:53,664 --> 00:13:55,814
I guess according to Dylan's numbers, um

328
00:13:55,814 --> 00:14:00,914
the Copilot revenue, GitHub Copilot revenue, was like 500 million or something like that.

329
00:14:00,914 --> 00:14:03,784
And then, uh, there were like no close competitors.

330
00:14:03,784 --> 00:14:07,484
Whereas now you have Claude Code, Cursor

331
00:14:07,484 --> 00:14:10,334
and Copilot with around similar revenue, around a billion.

332
00:14:10,334 --> 00:14:12,224
And then Codex is catching up around 700

333
00:14:12,224 --> 00:14:13,364
800 million.

334
00:14:13,364 --> 00:14:16,884
And so the question is across all the services that Microsoft has access to

335
00:14:16,884 --> 00:14:19,704
what is the advantage that Microsoft's equivalents of Copilot have?

336
00:14:19,704 --> 00:14:20,144
Yeah.

337
00:14:20,144 --> 00:14:22,024
By the way, I love this chart.

338
00:14:22,024 --> 00:14:24,114
You know, I love this chart for so many reasons.

339
00:14:24,114 --> 00:14:25,844
One is we're still on the top.

340
00:14:25,844 --> 00:14:33,604
  Um, second is all these companies that are listed here are all companies that have been born in the last four

341
00:14:33,604 --> 00:14:34,244
five years.

342
00:14:34,244 --> 00:14:34,624
Yeah.

343
00:14:34,624 --> 00:14:35,004
Yeah.

344
00:14:35,004 --> 00:14:36,664
That to me is the best sign, right?

345
00:14:36,664 --> 00:14:41,264
Which is if you have new competitors, new existential problems when you say man who is it now?

346
00:14:41,264 --> 00:14:42,644
Oh, Claude's going to kill you.

347
00:14:42,644 --> 00:14:43,754
Cursor's going to kill you.

348
00:14:43,754 --> 00:14:44,124
Yeah.

349
00:14:44,124 --> 00:14:45,184
It's not boring, right?

350
00:14:45,184 --> 00:14:45,924
So thank God.

351
00:14:45,924 --> 00:14:48,564
Like that means we are in the right direction.

352
00:14:48,564 --> 00:14:49,684
But this is it, right?

353
00:14:49,684 --> 00:14:55,264
The fact that we went from nothing to this scale is the market expansion.

354
00:14:55,264 --> 00:14:56,924
So this is like the cloud-like stuff.

355
00:14:56,924 --> 00:15:03,944
This, uh, fundamentally this category of coding and AI is probably going to be one of the biggest categories

356
00:15:03,944 --> 00:15:04,164
right?

357
00:15:04,164 --> 00:15:05,824
It is a software factory category.

358
00:15:05,824 --> 00:15:05,853
Yeah.

359
00:15:05,853 --> 00:15:08,244
In fact it may be bigger than knowledge work.

360
00:15:08,244 --> 00:15:08,644
Yeah.

361
00:15:08,644 --> 00:15:11,364
So I kind of want to keep myself open-minded about

362
00:15:11,364 --> 00:15:12,874
I mean, we want to have tough competition.

363
00:15:12,874 --> 00:15:13,834
I think that's your point- Yeah.

364
00:15:13,834 --> 00:15:13,834
.

365
00:15:13,834 --> 00:15:13,834
.

366
00:15:13,834 --> 00:15:15,704
which I think is a great one.

367
00:15:15,704 --> 00:15:18,154
Uh, but man, like I'm glad we have

368
00:15:18,154 --> 00:15:23,973
we parlayed, uh, what we had into this and now we have to compete.

369
00:15:23,973 --> 00:15:26,524
And so in the compete side, uh

370
00:15:26,524 --> 00:15:30,104
even in the last quarter, we just fin- we did our quarterly announcement

371
00:15:30,104 --> 00:15:32,723
I think we grew from 20 to 26 million subs

372
00:15:32,723 --> 00:15:32,904
right?

373
00:15:32,904 --> 00:15:35,064
So I feel good about our sub growth

374
00:15:35,064 --> 00:15:37,723
uh, and where the direction of travel on that is.

375
00:15:37,723 --> 00:15:44,704
But the more interesting thing that has happened is guess where all the repos of all these other guys

376
00:15:44,704 --> 00:15:47,884
uh, who are generating lots and lots of code go to?

377
00:15:47,884 --> 00:15:49,144
They go to GitHub.

378
00:15:49,144 --> 00:15:53,164
So i- GitHub is at an all-time high in terms of repo creation

379
00:15:53,164 --> 00:15:54,864
PRs, everything.

380
00:15:54,864 --> 00:15:58,624
So that, in some sense, we want to keep that open by the way.

381
00:15:58,624 --> 00:16:00,534
That means we want to have that, right?

382
00:16:00,534 --> 00:16:02,654
Because we don't want to conflate that with our own growth

383
00:16:02,654 --> 00:16:02,834
right?

384
00:16:02,834 --> 00:16:07,124
The, interestingly enough, we're getting one developer joining GitHub a second or something.

385
00:16:07,124 --> 00:16:07,133
Mm.

386
00:16:07,133 --> 00:16:08,424
That is the stat I think.

387
00:16:08,424 --> 00:16:12,304
And then 80% of them just fall into some GitHub Copilot

388
00:16:12,304 --> 00:16:14,204
uh, workflow just because there are.

389
00:16:14,204 --> 00:16:17,484
And by the way many of these things will even use some of our coding

390
00:16:17,484 --> 00:16:21,644
uh, code review agents which are by default on just because you can use it.

391
00:16:21,644 --> 00:16:25,084
So we'll have many, many structural shots at this.

392
00:16:25,084 --> 00:16:28,984
The thing that we're also going to do is what we did with Git

393
00:16:28,984 --> 00:16:32,364
Git, the primitives of GitHub whether starting with Git

394
00:16:32,364 --> 00:16:40,484
to issues, to actions, these are powerful lovely things because they kind of are all built around your repo.

395
00:16:40,484 --> 00:16:42,344
So we want to extend that.

396
00:16:42,344 --> 00:16:45,364
At EA- last week at GitHub Universe that's kind of what we did

397
00:16:45,364 --> 00:16:45,543
right?

398
00:16:45,543 --> 00:16:51,364
So we said Agent HQ was the conceptual thing that we said we are going to build out.

399
00:16:51,364 --> 00:16:58,184
This is where, for example, you have a thing called Mission Control and you go to Mission Control and now I can fire off

400
00:16:58,184 --> 00:17:01,164
sometimes I describe it as the cable TV of all these AI agents

401
00:17:01,164 --> 00:17:05,792
because I'll have essentially packaged into one subscription Codex

402
00:17:05,792 --> 00:17:10,184
Claude, um, you know, cognition stuff

403
00:17:10,184 --> 00:17:13,464
anyone's agents, Grok, all of them will be there.

404
00:17:13,464 --> 00:17:18,604
So I get one package and then I can literally go issue a task

405
00:17:18,604 --> 00:17:22,502
steer them so they'll all be working in their independent branches.

406
00:17:22,502 --> 00:17:26,344
Uh, I can monitor them, uh, so I literally have

407
00:17:26,344 --> 00:17:28,844
because I think that's going to be one of the biggest places of innovation

408
00:17:28,844 --> 00:17:29,024
right?

409
00:17:29,024 --> 00:17:32,464
Because right now I want to be able to use multiple agents

410
00:17:32,464 --> 00:17:35,364
I want to be able to then digest the output of the multiple agents

411
00:17:35,364 --> 00:17:47,564
I want to be able to then keep a ha- a handle on my repo so if there's some- some kind of a heads up display that needs to be built and then for me to quickly steer and triage what the coding agents have generated.

412
00:17:47,564 --> 00:17:53,364
That to me between VSCode, GitHub, and all of these new primitives we'll build

413
00:17:53,364 --> 00:17:56,074
uh, as mission control I think, uh

414
00:17:56,074 --> 00:18:00,524
with a control plane observability, I mean think about everyone who is going to deploy all this

415
00:18:00,524 --> 00:18:07,004
will require a whole host of observability of what agent did what at what time to what code base.

416
00:18:07,004 --> 00:18:09,524
So I feel that's the opportunity, uh

417
00:18:09,524 --> 00:18:14,714
and at the end of the day your point is well taken which is we better be competitive and innovate and if we don't

418
00:18:14,714 --> 00:18:20,204
yes, we'll get toppled but I like the chart at least as long as we're on the top even with competition.

419
00:18:20,204 --> 00:18:26,124
The key point here is sort of that GitHub will keep growing irregardless of whose coding agent wins but that

420
00:18:26,124 --> 00:18:27,744
that market only grows at, you know

421
00:18:27,744 --> 00:18:30,134
call it 10, 15, 20% which is way above GDP.

422
00:18:30,134 --> 00:18:41,344
It's a great compounder but these AI coding agents have grown from you know call it $500 million run rate at the end of last year which was basically just GitHub Copilot to now the current run rate across

423
00:18:41,344 --> 00:18:44,684
you know, GitHub Copilot, Claude Code, Cursor

424
00:18:44,684 --> 00:18:48,904
Cognition, Windsurf, Replit, uh, Codex, OpenAI Codex

425
00:18:48,904 --> 00:18:50,424
that's, that's, that's run rating at five

426
00:18:50,424 --> 00:18:51,590
$6 billion now.

427
00:18:51,590 --> 00:18:51,758
..

428
00:18:51,758 --> 00:18:53,981
. um, for the, for the Q4 of

429
00:18:53,981 --> 00:18:54,912
of this year.

430
00:18:54,912 --> 00:18:55,841
That's a 10X, right?

431
00:18:55,841 --> 00:18:57,482
And, and when you look at, hey

432
00:18:57,482 --> 00:18:59,712
what's the TAM of, of software agents?

433
00:18:59,712 --> 00:19:02,852
Is it, is it the $2 trillion of wages you pay people

434
00:19:02,852 --> 00:19:05,872
or is it, is it, is it something beyond that

435
00:19:05,872 --> 00:19:08,582
uh, because every company in the world will now be able to- Absolutely.

436
00:19:08,582 --> 00:19:08,582
.

437
00:19:08,582 --> 00:19:08,582
.

438
00:19:08,582 --> 00:19:10,832
you know, develop software more?

439
00:19:10,832 --> 00:19:13,272
No question Microsoft takes a slice of that

440
00:19:13,272 --> 00:19:18,232
but you've gone from near 100% or certainly way above 50% to

441
00:19:18,232 --> 00:19:21,732
you know, sub 25% market share in just one year.

442
00:19:21,732 --> 00:19:25,512
What is the sort of confidence that people can get that Microsoft will be- No

443
00:19:25,512 --> 00:19:25,542
no, I mean, there's no.

444
00:19:25,542 --> 00:19:25,542
..

445
00:19:25,542 --> 00:19:26,852
Again, I- it goes back a little bit

446
00:19:26,852 --> 00:19:31,752
Dylan, to sort of there's no birthright here that we should have any confidence other than to say

447
00:19:31,752 --> 00:19:33,779
"Hey, we should go innovate.

448
00:19:33,779 --> 00:19:38,272
" And knowing the, the lucky break we have in some sense is that

449
00:19:38,272 --> 00:19:42,272
uh, this category is gonna be a lot bigger than anything we had high share in.

450
00:19:42,272 --> 00:19:43,632
Let's, let me say it that way

451
00:19:43,632 --> 00:19:43,852
right?

452
00:19:43,852 --> 00:19:43,862
Mm-hmm.

453
00:19:43,862 --> 00:19:44,902
In some sense, you could say, well

454
00:19:44,902 --> 00:19:47,172
we kind of had high share in VS Code.

455
00:19:47,172 --> 00:19:50,192
We had high share in the repos for

456
00:19:50,192 --> 00:19:51,152
with GitHub.

457
00:19:51,152 --> 00:19:52,752
Uh, and that was a good market

458
00:19:52,752 --> 00:19:58,172
but the point is even having a decent share in what is a much more expansive market

459
00:19:58,172 --> 00:19:58,372
right?

460
00:19:58,372 --> 00:20:01,012
I mean, you could say we had a high share in client server

461
00:20:01,012 --> 00:20:02,212
server computing.

462
00:20:02,212 --> 00:20:06,272
We are much lower share than that in hyper-scale

463
00:20:06,272 --> 00:20:08,532
but is it a much bigger business?

464
00:20:08,532 --> 00:20:10,092
By orders of magnitude.

465
00:20:10,092 --> 00:20:13,592
So at least there's existence proof that Microsoft is doing okay

466
00:20:13,592 --> 00:20:18,632
uh, even if our share position has not been as strong as it was

467
00:20:18,632 --> 00:20:22,392
uh, as long as the markets we're competing in are creating more value

468
00:20:22,392 --> 00:20:24,212
uh, and there are multiple winners.

469
00:20:24,212 --> 00:20:25,712
Uh, so I think that's the stuff.

470
00:20:25,712 --> 00:20:27,972
But I w- I, I take your point

471
00:20:27,972 --> 00:20:31,212
that ultimately it all means you have to get competitive

472
00:20:31,212 --> 00:20:32,752
so I watch that every quarter.

473
00:20:32,752 --> 00:20:33,989
And so that's why I think we're.

474
00:20:33,989 --> 00:20:34,022
..

475
00:20:34,022 --> 00:20:38,822
I'm very optimistic that, uh, what we're going to do with GitHub HQ and

476
00:20:38,822 --> 00:20:43,932
uh, or Agent HQ, turning GitHub into a place where all these agents come.

477
00:20:43,932 --> 00:20:46,652
Uh, as I said, we'll have multiple shots on goal on there

478
00:20:46,652 --> 00:20:46,852
right?

479
00:20:46,852 --> 00:20:48,312
It need, it need not be that

480
00:20:48,312 --> 00:20:51,032
hey, some of these guys can succeed along with us

481
00:20:51,032 --> 00:20:54,312
uh, and so it n- doesn't need to be just one winner

482
00:20:54,312 --> 00:20:55,932
uh, and one subscription.

483
00:20:55,932 --> 00:20:56,742
Hmm.

484
00:20:56,742 --> 00:20:59,832
I, I guess the reason to focus on this question is that it's not just about GitHub

485
00:20:59,832 --> 00:21:04,772
but fundamentally about Office and all the other software that Microsoft offers

486
00:21:04,772 --> 00:21:07,772
which is that one vision you could have about how AI proceeds is that

487
00:21:07,772 --> 00:21:12,481
look, the models are c- going to keep being hobbled

488
00:21:12,481 --> 00:21:15,592
and you'll need this direct, visible, um

489
00:21:15,592 --> 00:21:17,152
observability all the time.

490
00:21:17,152 --> 00:21:19,871
And another vision is over time, these models can.

491
00:21:19,871 --> 00:21:19,981
..

492
00:21:19,981 --> 00:21:21,672
now they're doing tasks that take two minutes.

493
00:21:21,672 --> 00:21:22,855
In the future, they'll be doing tasks that.

494
00:21:22,855 --> 00:21:22,921
..

495
00:21:22,921 --> 00:21:24,092
Next they're gonna be doing tasks that take 10

496
00:21:24,092 --> 00:21:24,872
30 minutes.

497
00:21:24,872 --> 00:21:27,792
In the future, maybe they're doing days worth of work autonomously

498
00:21:27,792 --> 00:21:33,512
and then the model companies are charging thousands of dollars maybe for access to

499
00:21:33,512 --> 00:21:39,212
uh, really, a coworker, which could use any UI to communicate with their human and

500
00:21:39,212 --> 00:21:41,712
uh, so forth and migrate between platforms.

501
00:21:41,712 --> 00:21:43,472
So w- if we were getting closer to that

502
00:21:43,472 --> 00:21:46,352
why aren't the model companies that are, uh

503
00:21:46,352 --> 00:21:49,672
just getting more and more profitable the ones that are taking all the margin?

504
00:21:49,672 --> 00:21:52,671
Why is the, the place where the scaffolding happens

505
00:21:52,671 --> 00:21:55,092
which becomes less and less relevant as AIs become more capa- capable

506
00:21:55,092 --> 00:21:56,512
gonna be that important?

507
00:21:56,512 --> 00:22:01,242
And that goes to, you know, Office as it exists now versus coworkers that are just doing knowledge work autonomously.

508
00:22:01,242 --> 00:22:01,972
And so- I think that's a great point.

509
00:22:01,972 --> 00:22:02,738
I mean, I think that's a gr-.

510
00:22:02,738 --> 00:22:02,782
..

511
00:22:02,782 --> 00:22:04,832
I mean, for example, I mean, this is where

512
00:22:04,832 --> 00:22:07,632
you know, does all the m- value migrate just to

513
00:22:07,632 --> 00:22:10,252
uh, the model, um, and, uh

514
00:22:10,252 --> 00:22:11,902
or does the mo- you know, the.

515
00:22:11,902 --> 00:22:12,042
..

516
00:22:12,042 --> 00:22:15,152
does it get split between the scaffolding, um

517
00:22:15,152 --> 00:22:17,112
and, uh, the model and what have you?

518
00:22:17,112 --> 00:22:19,332
I, I think that, uh, time will tell

519
00:22:19,332 --> 00:22:23,192
but my, my fundamental point also is the incentive structure gets clear

520
00:22:23,192 --> 00:22:23,412
right?

521
00:22:23,412 --> 00:22:25,033
Which is if you take, um.

522
00:22:25,033 --> 00:22:25,261
..

523
00:22:25,261 --> 00:22:27,232
let's take, uh, let's take information work

524
00:22:27,232 --> 00:22:28,392
or take even coding.

525
00:22:28,392 --> 00:22:33,372
Um, already, in fact, one of the favorite settings I have

526
00:22:33,372 --> 00:22:35,932
uh, in GitHub Copilot is called Auto

527
00:22:35,932 --> 00:22:39,012
um, right, which will just optimize.

528
00:22:39,012 --> 00:22:46,752
In fact, I buy a subscription, the Auto one will start picking and optimizing for what I am asking it to do

529
00:22:46,752 --> 00:22:48,992
uh, and it could even be fully autonomous

530
00:22:48,992 --> 00:22:54,882
and it could sort of arbitrage the tokens available across multiple models to go get a task done.

531
00:22:54,882 --> 00:22:55,692
So if that is the.

532
00:22:55,692 --> 00:22:55,822
..

533
00:22:55,822 --> 00:22:56,744
that, that mean, that.

534
00:22:56,744 --> 00:22:56,942
..

535
00:22:56,942 --> 00:23:00,892
if you take that argument, the commodity there will be models.

536
00:23:00,892 --> 00:23:03,012
Uh, and especially with open source models

537
00:23:03,012 --> 00:23:06,382
you can pick a checkpoint, and you can take a bunch of your data

538
00:23:06,382 --> 00:23:07,622
and you're seeing it, right?

539
00:23:07,622 --> 00:23:11,392
I think all of us will start u- whether it's from Cursor or from Microsoft

540
00:23:11,392 --> 00:23:14,392
uh, we will start seeing some in-house models even

541
00:23:14,392 --> 00:23:15,190
uh, which will.

542
00:23:15,190 --> 00:23:15,262
..

543
00:23:15,262 --> 00:23:18,102
and then you'll offload most of your, uh

544
00:23:18,102 --> 00:23:19,432
tasks to it.

545
00:23:19,432 --> 00:23:23,412
So, I think that one argument is if you win the scaffolding

546
00:23:23,412 --> 00:23:28,232
uh, which today is dealing with all the hobbling problems or the

547
00:23:28,232 --> 00:23:31,352
uh, the jaggedness of these intelligence problems

548
00:23:31,352 --> 00:23:33,072
which you kind of have to.

549
00:23:33,072 --> 00:23:40,852
Um, if you win that, then you will vertically integrate yourself into the model just because you will have the liquidity of the data and what have you

550
00:23:40,852 --> 00:23:43,912
and there are enough and more checkpoints that are gonna be available.

551
00:23:43,912 --> 00:23:44,882
Uh, that's the other thing, right?

552
00:23:44,882 --> 00:23:49,152
So structurally, I think there will always be an open-source model

553
00:23:49,152 --> 00:23:57,652
uh, that will be fairly capable in the world that you could then use as long as you have something that you can use that

554
00:23:57,652 --> 00:23:59,582
uh, with, which is data, uh

555
00:23:59,582 --> 00:24:00,732
and a scaffolding, right?

556
00:24:00,732 --> 00:24:02,382
So I can make the argument that, oh

557
00:24:02,382 --> 00:24:04,792
my God, uh, if you're a model company

558
00:24:04,792 --> 00:24:06,752
you may be, uh, you may have a winner's curse.

559
00:24:06,752 --> 00:24:08,672
You may have done all the hard work

560
00:24:08,672 --> 00:24:14,212
done unbelievable innovation, except it's kind of like one copy

561
00:24:14,212 --> 00:24:22,572
uh, away from that being commoditized, and then the person who has the data for grounding and context engineering

562
00:24:22,572 --> 00:24:27,852
um, and the liquidity of data can then go take that checkpoint and train it.

563
00:24:27,852 --> 00:24:30,372
So, I think the argument can be made both ways.

564
00:24:30,372 --> 00:24:32,592
Un- unpacking sort of what you said, there's two views of the world

565
00:24:32,592 --> 00:24:32,832
right?

566
00:24:32,832 --> 00:24:34,579
One is that models.

567
00:24:34,579 --> 00:24:34,702
..

568
00:24:34,702 --> 00:24:37,562
there's so many different models out there, open source exists.

569
00:24:37,562 --> 00:24:41,602
There will be differences between the models that will drive some level of

570
00:24:41,602 --> 00:24:43,002
you know, who wins and who doesn't

571
00:24:43,002 --> 00:24:45,112
but the scaffolding is what enables you to win.

572
00:24:45,112 --> 00:24:45,272
Yeah.

573
00:24:45,272 --> 00:24:49,732
The other view is that actually models are the key IP

574
00:24:49,732 --> 00:24:50,549
and yes, we're in a very.

575
00:24:50,549 --> 00:24:50,621
..

576
00:24:50,621 --> 00:24:52,672
everyone's in a tight race, and there's some

577
00:24:52,672 --> 00:24:55,348
you know, "Hey, I can use Anthropic or OpenAI

578
00:24:55,348 --> 00:24:56,852
" and you can see this in the revenue charts

579
00:24:56,852 --> 00:24:57,052
right?

580
00:24:57,052 --> 00:25:02,272
Like OpenAI's revenue started skyrocketing once they finally had a code model similar capabilities to Anthropic

581
00:25:02,272 --> 00:25:03,852
although in different ways.

582
00:25:03,852 --> 00:25:04,832
Um-.

583
00:25:04,832 --> 00:25:05,282
..

584
00:25:05,282 --> 00:25:06,492
th- th- there's a view that, like

585
00:25:06,492 --> 00:25:09,692
the model companies are actually the ones that garner all the margin

586
00:25:09,692 --> 00:25:09,952
right?

587
00:25:09,952 --> 00:25:12,212
Because, you know, if you look across this year

588
00:25:12,212 --> 00:25:15,192
at least on Anthropic, their gross margins on inference went from

589
00:25:15,192 --> 00:25:18,032
you know, well below 40% to north of 60

590
00:25:18,032 --> 00:25:18,402
right- Yeah.

591
00:25:18,402 --> 00:25:18,402
.

592
00:25:18,402 --> 00:25:18,402
.

593
00:25:18,402 --> 00:25:19,492
by the end of the year.

594
00:25:19,492 --> 00:25:21,442
Um, the- these- the margins aren't- Yeah.

595
00:25:21,442 --> 00:25:21,442
.

596
00:25:21,442 --> 00:25:21,442
.

597
00:25:21,442 --> 00:25:24,812
expanding there despite, hey, more Chinese open-source models than ever.

598
00:25:24,812 --> 00:25:24,942
Yeah.

599
00:25:24,942 --> 00:25:25,912
Hey, OpenAI's competitive.

600
00:25:25,912 --> 00:25:27,102
Hey, Google's competitive.

601
00:25:27,102 --> 00:25:28,962
Hey, xGrok is now competitive, right?

602
00:25:28,962 --> 00:25:30,882
All these- all these companies are now competitive.

603
00:25:30,882 --> 00:25:35,272
And yet despite this, the margins have expanded at the model layer significantly.

604
00:25:35,272 --> 00:25:35,382
Yeah.

605
00:25:35,382 --> 00:25:37,975
Um, h- h- how do you think about the.

606
00:25:37,975 --> 00:25:38,162
..

607
00:25:38,162 --> 00:25:39,732
It's a gr- it's a great question.

608
00:25:39,732 --> 00:25:44,292
I mean, it- it- I- I think the- the one thing is perhaps a few years ago people were saying

609
00:25:44,292 --> 00:25:47,954
"Oh, I can just wrap a model and build a successful company.

610
00:25:47,954 --> 00:25:53,472
" Uh, and that, I think, is- probably gotten debunked just because the model capabilities

611
00:25:53,472 --> 00:25:53,714
uh.

612
00:25:53,714 --> 00:25:53,822
..

613
00:25:53,822 --> 00:25:56,692
and the tools used in particular.

614
00:25:56,692 --> 00:25:59,472
But the interesting thing is there's no- like when I look at Office 365

615
00:25:59,472 --> 00:26:03,132
let's take even this little thing we built called Excel Agent.

616
00:26:03,132 --> 00:26:04,312
It's interesting, right?

617
00:26:04,312 --> 00:26:07,532
Excel Agent is not a UI-level wrapper.

618
00:26:07,532 --> 00:26:11,492
It's actually a model that is in the middle tier.

619
00:26:11,492 --> 00:26:16,912
Uh, in this case, because we have all the IP from the- the GPT family

620
00:26:16,912 --> 00:26:29,452
uh, we are taking that and putting it into the core middle tier of the Office system to both teach it what it means to natively understand Excel

621
00:26:29,452 --> 00:26:30,852
everything in it.

622
00:26:30,852 --> 00:26:33,652
So it's not just, hey, I just have a pixel-level understanding.

623
00:26:33,652 --> 00:26:37,712
I have a n- full understanding of all the native artifacts of Excel

624
00:26:37,712 --> 00:26:40,142
uh, both when I see it- like because if you think about it

625
00:26:40,142 --> 00:26:42,572
if I'm going to give it some reasoning task

626
00:26:42,572 --> 00:26:45,932
right, I need to even fix the reasoning mistakes I make.

627
00:26:45,932 --> 00:26:48,742
And so that means I need to both not just see the pixels.

628
00:26:48,742 --> 00:26:49,902
I need to be able to see, oh

629
00:26:49,902 --> 00:26:52,502
I got that formula wrong, and I need to understand that.

630
00:26:52,502 --> 00:26:57,512
And then- so to some degree, that's all being done not at the UI wrapper level with some prompt

631
00:26:57,512 --> 00:27:01,652
but it's being done in the middle tier by teaching it all the tools of Excel

632
00:27:01,652 --> 00:27:01,872
right?

633
00:27:01,872 --> 00:27:08,732
So I'm giving it even- essentially a markdown to teach it the skills of what it means to be a sophisticated Excel user.

634
00:27:08,732 --> 00:27:12,672
So it's a weird thing that- it goes back a little bit to AI brain

635
00:27:12,672 --> 00:27:12,852
right?

636
00:27:12,852 --> 00:27:15,852
Which is you're building not just Excel.

637
00:27:15,852 --> 00:27:19,592
You are now business logic in its traditional sense.

638
00:27:19,592 --> 00:27:29,752
You're taking the Excel business logic in the traditional sense and wrapping essentially a cognitive layer to it using this model which knows how to use the tool.

639
00:27:29,752 --> 00:27:29,802
Mm-hmm.

640
00:27:29,802 --> 00:27:35,052
So in some sense, Excel will come with an analyst bundled in and with all the tools used.

641
00:27:35,052 --> 00:27:35,372
Mm-hmm.

642
00:27:35,372 --> 00:27:39,052
That's the type of stuff that'll get built by everybody.

643
00:27:39,052 --> 00:27:41,321
So even for the model companies, they're allowed to compete

644
00:27:41,321 --> 00:27:41,492
right?

645
00:27:41,492 --> 00:27:44,492
So if they price stuff high, uh

646
00:27:44,492 --> 00:27:45,161
guess what?

647
00:27:45,161 --> 00:27:47,292
If I'm a builder of a tool like this

648
00:27:47,292 --> 00:27:48,612
I'll substitute you.

649
00:27:48,612 --> 00:27:52,412
I may use you for a while, and so as long as there's competition

650
00:27:52,412 --> 00:27:53,872
there's always a winner-take-all thing, right?

651
00:27:53,872 --> 00:27:57,772
If there's going to be one model that is better than everybody else with massive distance

652
00:27:57,772 --> 00:27:59,452
yes, that's a winner take all.

653
00:27:59,452 --> 00:28:02,612
As long as there's gonna be competition where there's multiple models

654
00:28:02,612 --> 00:28:06,132
just like hyperscale competition, and there's an open-source check

655
00:28:06,132 --> 00:28:08,702
uh, there is enough room here, uh

656
00:28:08,702 --> 00:28:11,092
to go build value on top of models.

657
00:28:11,092 --> 00:28:11,572
Mm-hmm.

658
00:28:11,572 --> 00:28:14,672
Uh, but at Microsoft, the way I look at it and say is

659
00:28:14,672 --> 00:28:19,932
uh, we are going to be in the hyperscale business which will support multiple models.

660
00:28:19,932 --> 00:28:22,832
We will have access to OpenAI models for

661
00:28:22,832 --> 00:28:26,372
uh, uh, you know, seven more years which we will innovate on top of

662
00:28:26,372 --> 00:28:30,652
so royalty f- uh, essentially, I think of ourselves as having a frontier-class model

663
00:28:30,652 --> 00:28:33,262
uh, that we can use and innovate on with full

664
00:28:33,262 --> 00:28:34,952
uh, flexibility.

665
00:28:34,952 --> 00:28:36,912
And we'll build our own models, uh

666
00:28:36,912 --> 00:28:42,112
with MAI, um, and- and so we will always have a model level.

667
00:28:42,112 --> 00:28:44,532
And then we'll build these, whether it's in security

668
00:28:44,532 --> 00:28:46,912
whether it's in knowledge work, whether it's in coding

669
00:28:46,912 --> 00:28:50,672
or in signs, we will build our own application scaffolding- Mm-hmm.

670
00:28:50,672 --> 00:28:50,682
.

671
00:28:50,682 --> 00:28:50,682
..

672
00:28:50,682 --> 00:28:52,472
which will be model-forward, right?

673
00:28:52,472 --> 00:28:52,502
Mm-hmm.

674
00:28:52,502 --> 00:28:54,632
It won't be a wrapper on a model

675
00:28:54,632 --> 00:28:57,661
but the model will be wrapped into, uh

676
00:28:57,661 --> 00:28:58,772
the application.

677
00:28:58,772 --> 00:29:01,372
I have so many questions about th- the other things you mentioned.

678
00:29:01,372 --> 00:29:02,792
But before we move on to those topics

679
00:29:02,792 --> 00:29:05,322
um, I still wonder whether this is

680
00:29:05,322 --> 00:29:11,992
like, not forward-looking on AI capabilities, where you're imagining models like they exist today

681
00:29:11,992 --> 00:29:13,552
where, yeah, I can- you have this

682
00:29:13,552 --> 00:29:15,232
like- it takes a screenshot of your screen

683
00:29:15,232 --> 00:29:17,852
but it can't, like, look inside each cell and what the formula is.

684
00:29:17,852 --> 00:29:19,252
And I think the better m- mental model here is

685
00:29:19,252 --> 00:29:24,822
like, look, a human- just imagine that these models actually will be able to actually use a computer as well as a human.

686
00:29:24,822 --> 00:29:25,122
100%, yeah.

687
00:29:25,122 --> 00:29:29,252
And a human knowledge worker who is using Excel can look into the formulas

688
00:29:29,252 --> 00:29:36,152
can, you know, use alternative software, can migrate data between Office 365 and another piece of software if the migration is necessary

689
00:29:36,152 --> 00:29:37,012
et cetera.

690
00:29:37,012 --> 00:29:38,772
So what is- That's kind of what I'm saying.

691
00:29:38,772 --> 00:29:40,301
So what- what- But if that's the case

692
00:29:40,301 --> 00:29:42,942
then the integration with Excel doesn't matter that much- No

693
00:29:42,942 --> 00:29:42,942
no, no.

694
00:29:42,942 --> 00:29:42,942
no, no.

695
00:29:42,942 --> 00:29:42,942
no, no.

696
00:29:42,942 --> 00:29:46,422
because then- And- and don't worry about the Excel integration.

697
00:29:46,422 --> 00:29:49,652
After all, Excel was built as a tool for analysts.

698
00:29:49,652 --> 00:29:50,372
Great.

699
00:29:50,372 --> 00:29:56,652
So whoever is this AI that is an analyst should have tools that they can use.

700
00:29:56,652 --> 00:29:57,312
Uh, that they have a computer, right?

701
00:29:57,312 --> 00:29:59,272
That- that- just the way a human can use a computer

702
00:29:59,272 --> 00:29:59,732
that's their tool.

703
00:29:59,732 --> 00:30:01,492
The- the- the- the tool is the computer.

704
00:30:01,492 --> 00:30:01,892
Right.

705
00:30:01,892 --> 00:30:07,792
Right, so that- so all I'm saying is I'm building an analyst as- as essentially an AI agent

706
00:30:07,792 --> 00:30:14,272
uh, which happens to come with a- an a priori knowledge of how to use all of these analytical tools.

707
00:30:14,272 --> 00:30:15,822
Uh, but is- is it something- well

708
00:30:15,822 --> 00:30:18,252
maybe just- just to make sure we're talking about the same thing

709
00:30:18,252 --> 00:30:22,722
um, is it a thing that a hu- like me using Excel as a podcaster.

710
00:30:22,722 --> 00:30:23,022
No, no, no, no.

711
00:30:23,022 --> 00:30:24,044
I'm not proficient in Excel, but like.

712
00:30:24,044 --> 00:30:24,082
..

713
00:30:24,082 --> 00:30:25,482
It'll be an auton- a completely autonomous.

714
00:30:25,482 --> 00:30:31,152
So just imagine I work- like so we should now maybe sort of lay out how I think the future of the company is

715
00:30:31,152 --> 00:30:32,072
right?

716
00:30:32,072 --> 00:30:32,102
Yeah.

717
00:30:32,102 --> 00:30:36,172
Uh, the future of the company would be the tools business which I have a computer.

718
00:30:36,172 --> 00:30:36,322
Yeah.

719
00:30:36,322 --> 00:30:37,792
I use Excel.

720
00:30:37,792 --> 00:30:40,372
And in fact, in the future, I'll even have a copilot.

721
00:30:40,372 --> 00:30:40,502
Right.

722
00:30:40,502 --> 00:30:42,672
Uh, and that copilot will also have agents

723
00:30:42,672 --> 00:30:42,862
right?

724
00:30:42,862 --> 00:30:46,782
That still I am- I- you know, it's still me steering everything.

725
00:30:46,782 --> 00:30:47,072
Yeah.

726
00:30:47,072 --> 00:30:48,152
And everything is coming back.

727
00:30:48,152 --> 00:30:49,392
So that's kind of one world.

728
00:30:49,392 --> 00:30:50,092
Yeah.

729
00:30:50,092 --> 00:30:57,022
Then the second world is the company just literally provisions a computing resource for an AI agent.

730
00:30:57,022 --> 00:30:57,692
Yeah.

731
00:30:57,692 --> 00:30:59,652
And that is working fully autonomously.

732
00:30:59,652 --> 00:31:00,372
Yeah.

733
00:31:00,372 --> 00:31:06,902
That fully autonomous agent will have essentially embodied set of those same tools- Right.

734
00:31:06,902 --> 00:31:06,915
.

735
00:31:06,915 --> 00:31:06,922
..

736
00:31:06,922 --> 00:31:08,912
uh, that are available to it, right?

737
00:31:08,912 --> 00:31:14,172
So this AI tool that comes in also has not just a raw computer

738
00:31:14,172 --> 00:31:19,112
uh, because it's gonna be more token-efficient to use tools to get stuff done.

739
00:31:19,112 --> 00:31:21,412
In fact, I kinda look at it and say our business

740
00:31:21,412 --> 00:31:28,422
which today is an end-user tools business, will become essentially an infrastructure business in support of agents doing work.

741
00:31:28,422 --> 00:31:28,805
Okay.

742
00:31:28,805 --> 00:31:28,923
..

743
00:31:28,923 --> 00:31:30,792
. is another way to think about it

744
00:31:30,792 --> 00:31:31,091
right?

745
00:31:31,091 --> 00:31:33,558
So if one of the things that you'll see us do .

746
00:31:33,558 --> 00:31:33,692
..

747
00:31:33,692 --> 00:31:41,192
In, in, in fact, like, all the stuff we built underneath the M365 still is going to be very relevant.

748
00:31:41,192 --> 00:31:43,252
Uh, you need some place to store it

749
00:31:43,252 --> 00:31:46,831
some place to do archival, some place to do discovery

750
00:31:46,831 --> 00:31:49,952
some place to manage all of these activities

751
00:31:49,952 --> 00:31:51,411
e- even if you're an AI agent.

752
00:31:51,411 --> 00:31:51,992
Mm-hmm.

753
00:31:51,992 --> 00:31:52,488
So that's .

754
00:31:52,488 --> 00:31:52,522
..

755
00:31:52,522 --> 00:31:54,572
So it's kind of a new infrastructure.

756
00:31:54,572 --> 00:31:56,151
S- so just to make sure I understand

757
00:31:56,151 --> 00:32:01,371
you're saying, like, look, theoretically, a future AI that has actual computer use

758
00:32:01,371 --> 00:32:01,761
which is .

759
00:32:01,761 --> 00:32:01,761
..

760
00:32:01,761 --> 00:32:04,022
all these companies are working on, model companies are working on right now

761
00:32:04,022 --> 00:32:08,202
could use, even if it's not partnered with Microsoft or under our umbrella

762
00:32:08,202 --> 00:32:09,891
could use Microsoft software.

763
00:32:09,891 --> 00:32:11,754
But you're saying we're gonna give them .

764
00:32:11,754 --> 00:32:11,962
..

765
00:32:11,962 --> 00:32:13,931
if, if you're working with our infrastructure

766
00:32:13,931 --> 00:32:19,871
we're gonna give you, like, lower-level access that makes it more efficient for you to do the same things you could have otherwise done anyways.

767
00:32:19,871 --> 00:32:20,331
100%.

768
00:32:20,331 --> 00:32:20,341
100%.

769
00:32:20,341 --> 00:32:21,772
I mean, so the entire thing in

770
00:32:21,772 --> 00:32:23,572
in fact, the way th- you know

771
00:32:23,572 --> 00:32:26,671
like, what happened is we had servers

772
00:32:26,671 --> 00:32:30,792
then there was virtualization, and then we had many more servers.

773
00:32:30,792 --> 00:32:32,522
So that's another way to think about this

774
00:32:32,522 --> 00:32:34,002
which is, hey, don't think of this .

775
00:32:34,002 --> 00:32:34,002
..

776
00:32:34,002 --> 00:32:36,111
the tool as the end thing.

777
00:32:36,111 --> 00:32:41,032
What is the entire substrate underneath that tool that humans use?

778
00:32:41,032 --> 00:32:47,032
And that entire substrate is the bootstrap for the AI agent as well because the AI agent needs a computer.

779
00:32:47,032 --> 00:32:47,712
That's kind of one.

780
00:32:47,712 --> 00:32:56,002
Like, you know, so in fact, one of the fascinating things we are seeing a significant amount of growth is all these guys who are doing these o- office artifacts and

781
00:32:56,002 --> 00:33:00,712
and what have you as autonomous agents and so on want to provision Windows 365

782
00:33:00,712 --> 00:33:00,952
right?

783
00:33:00,952 --> 00:33:05,411
They really want to be able to provision a computer for these agents.

784
00:33:05,411 --> 00:33:06,448
Uh, and so .

785
00:33:06,448 --> 00:33:06,482
..

786
00:33:06,482 --> 00:33:12,911
absolutely, and that's where I think we're gonna have essentially an end user computing infrastructure business

787
00:33:12,911 --> 00:33:15,792
which I think is going to just keep growing because guess what?

788
00:33:15,792 --> 00:33:18,032
It's going to grow faster than the number of users.

789
00:33:18,032 --> 00:33:20,272
So in fact, that's kind of one of the other questions people ask me

790
00:33:20,272 --> 00:33:22,323
is, "Hey, what happens to the per-user business?

791
00:33:22,323 --> 00:33:27,131
" At least the early signs may be the way to think about the per-user business is not just per user

792
00:33:27,131 --> 00:33:31,331
it's per agent, and if you sort of say it's per user and per agent

793
00:33:31,331 --> 00:33:35,512
the key is what's the stuff to provision for every agent?

794
00:33:35,512 --> 00:33:36,812
A computer?

795
00:33:36,812 --> 00:33:39,631
Um, a set of security things around it?

796
00:33:39,631 --> 00:33:41,631
An identity around it?

797
00:33:41,631 --> 00:33:44,812
Uh, and all those things, our observability and so on

798
00:33:44,812 --> 00:33:46,812
are the management layers, and that's, I think

799
00:33:46,812 --> 00:33:48,611
all going to get baked into that.

800
00:33:48,611 --> 00:33:51,341
The way to frame it, at least the way I currently think about it

801
00:33:51,341 --> 00:33:52,651
and I'd like to hear your, you know

802
00:33:52,651 --> 00:33:56,681
your view, is that, uh, these model companies are all building environments to- Yep.

803
00:33:56,681 --> 00:33:56,735
.

804
00:33:56,735 --> 00:33:56,742
..

805
00:33:56,742 --> 00:33:59,222
train their models to use Excel- Yep.

806
00:33:59,222 --> 00:33:59,245
.

807
00:33:59,245 --> 00:33:59,292
..

808
00:33:59,292 --> 00:34:01,672
or Amazon shopping or whatever, whatever it is

809
00:34:01,672 --> 00:34:02,692
book flights.

810
00:34:02,692 --> 00:34:08,755
Um, but at the same time, they're also training these models to do migration from .

811
00:34:08,755 --> 00:34:08,761
..

812
00:34:08,761 --> 00:34:11,092
because that, that is probably the most immediate

813
00:34:11,092 --> 00:34:12,382
uh, valuable thing, right?

814
00:34:12,382 --> 00:34:14,871
Converting mainframe-based systems to- Yep.

815
00:34:14,871 --> 00:34:14,893
.

816
00:34:14,893 --> 00:34:14,902
..

817
00:34:14,902 --> 00:34:20,062
standard cloud systems, converting, um, Excel databases into real databases- Yep.

818
00:34:20,062 --> 00:34:20,062
.

819
00:34:20,062 --> 00:34:20,062
.

820
00:34:20,062 --> 00:34:20,991
uh, with SQL.

821
00:34:20,991 --> 00:34:21,152
Yep.

822
00:34:21,152 --> 00:34:21,451
Right?

823
00:34:21,451 --> 00:34:24,732
Or, or converting, um, you know

824
00:34:24,732 --> 00:34:30,442
w- what is done in Word and Excel to something that is more programmatic and more efficient in a classical sense- Absolutely.

825
00:34:30,442 --> 00:34:30,442
.

826
00:34:30,442 --> 00:34:30,442
.

827
00:34:30,442 --> 00:34:32,652
that can actually be done by humans as well.

828
00:34:32,652 --> 00:34:35,531
It's just not cost-effective for the software developer to do that.

829
00:34:35,531 --> 00:34:38,761
That seems to be what everyone is going to do with AI for the next

830
00:34:38,761 --> 00:34:41,462
you know, few years at least to massively drive value.

831
00:34:41,462 --> 00:34:49,072
Um, h- h- how does Microsoft fit into that if the models can utilize the tools themselves to migrate to something?

832
00:34:49,072 --> 00:34:54,112
And yes, Microsoft has, you know, a leadership position in databases and in storage and

833
00:34:54,112 --> 00:34:57,652
and in all these other categories, but the use of

834
00:34:57,652 --> 00:35:05,452
say, a office ecosystem is going to be significantly less just like potentially the use of a mainframe ecosystem could be potentially less.

835
00:35:05,452 --> 00:35:07,872
Now mainframes have grown for the last two decades actually

836
00:35:07,872 --> 00:35:09,112
even though no one talks about them anymore.

837
00:35:09,112 --> 00:35:10,212
They've still grown.

838
00:35:10,212 --> 00:35:11,112
100%.

839
00:35:11,112 --> 00:35:11,801
I agree with that.

840
00:35:11,801 --> 00:35:12,632
How does that, how does that flow forward?

841
00:35:12,632 --> 00:35:12,781
Yeah.

842
00:35:12,781 --> 00:35:14,031
I mean, at the end of the day

843
00:35:14,031 --> 00:35:15,632
this is not about sort of, hey

844
00:35:15,632 --> 00:35:20,152
um, there is going to be a significant amount of time where there's going to be a hybrid world

845
00:35:20,152 --> 00:35:20,352
right?

846
00:35:20,352 --> 00:35:24,872
Because people are gonna be using the tools that are gonna be working with agents that have to use tools

847
00:35:24,872 --> 00:35:27,252
and by the way, they have to communicate with each other.

848
00:35:27,252 --> 00:35:31,011
What's the artifact to generate that then a human needs to see?

849
00:35:31,011 --> 00:35:34,292
So, like, all of these things will be real considerations in any place.

850
00:35:34,292 --> 00:35:35,312
So the outputs, inputs.

851
00:35:35,312 --> 00:35:37,672
So I don't think it'll just be about how I migrate it off

852
00:35:37,672 --> 00:35:37,892
right?

853
00:35:37,892 --> 00:35:40,022
But the bottom line is I have to live in this hybrid world.

854
00:35:40,022 --> 00:35:40,602
So let .

855
00:35:40,602 --> 00:35:40,622
..

856
00:35:40,622 --> 00:35:48,152
but that doesn't fully answer your question because there can be a real new efficient frontier where I stress agents working with agents

857
00:35:48,152 --> 00:35:50,081
uh, and completely optimizing.

858
00:35:50,081 --> 00:35:50,591
Mm-hmm.

859
00:35:50,591 --> 00:35:52,712
And even when agents are working with agents

860
00:35:52,712 --> 00:35:54,652
what are the primitives that are needed?

861
00:35:54,652 --> 00:35:57,212
Uh, do you need a storage system?

862
00:35:57,212 --> 00:36:00,452
Uh, does that storage system need to have e-discovery?

863
00:36:00,452 --> 00:36:03,392
Does that e-discover- uh, do you need to have observability?

864
00:36:03,392 --> 00:36:09,672
Do you need to have an identity system that is going to use multiple models with all having one identity system?

865
00:36:09,672 --> 00:36:16,312
So these are all the core underlying rails we have today for what our office systems or what have you

866
00:36:16,312 --> 00:36:18,841
uh, and that's what I think we will have in the future as well.

867
00:36:18,841 --> 00:36:20,452
You talked about databases, right?

868
00:36:20,452 --> 00:36:21,542
I mean take .

869
00:36:21,542 --> 00:36:21,562
..

870
00:36:21,562 --> 00:36:24,471
you know, man, I would love all of Excel to have a database backend

871
00:36:24,471 --> 00:36:24,672
right?

872
00:36:24,672 --> 00:36:27,442
In fact, I would love for all that to happen immediately.

873
00:36:27,442 --> 00:36:27,962
Mm-hmm.

874
00:36:27,962 --> 00:36:30,272
Uh, and that database is a good database.

875
00:36:30,272 --> 00:36:33,352
I mean, databases in fact will be a big thing that will grow.

876
00:36:33,352 --> 00:36:37,372
Uh, in fact, if I think about all of the office artifacts

877
00:36:37,372 --> 00:36:43,562
uh, being structured better, the ability to do the joins between structured and unstructured better because of the agenting

878
00:36:43,562 --> 00:36:47,402
well, that'll grow the underlying what is infrastructure business.

879
00:36:47,402 --> 00:36:50,551
It happens the consumption of that is all being driven by agents.

880
00:36:50,551 --> 00:36:54,511
You could say all that is just in time generated software by a model company.

881
00:36:54,511 --> 00:36:56,011
That could also be true.

882
00:36:56,011 --> 00:36:56,561
If we .

883
00:36:56,561 --> 00:36:56,582
..

884
00:36:56,582 --> 00:36:58,532
we will be one such model company too.

885
00:36:58,532 --> 00:37:00,474
Uh, and so we will build in .

886
00:37:00,474 --> 00:37:00,482
..

887
00:37:00,482 --> 00:37:07,432
so the competition could be, uh, that we will build a model plus all the infrastructure and provision it

888
00:37:07,432 --> 00:37:10,952
and then there will be competition between a bunch of those folks who can do that.

889
00:37:10,952 --> 00:37:11,572
Hmm.

890
00:37:11,572 --> 00:37:13,172
Um, I guess speaking of model companies

891
00:37:13,172 --> 00:37:15,661
you say, okay, we will also be one of the .

892
00:37:15,661 --> 00:37:15,882
..

893
00:37:15,882 --> 00:37:18,432
not only we'll have the infrastructure, we'll have the model itself.

894
00:37:18,432 --> 00:37:25,761
Right now, Microsoft AI's most recent model that was released two months ago is 36 in Chatbot Arena and there's a q- I mean

895
00:37:25,761 --> 00:37:27,452
you obviously have the IP rights to OpenAI

896
00:37:27,452 --> 00:37:28,472
so there's a question of .

897
00:37:28,472 --> 00:37:28,632
..

898
00:37:28,632 --> 00:37:28,792
..

899
00:37:28,792 --> 00:37:31,682
. first, to the extent you agree w- that l- it seems to be behind

900
00:37:31,682 --> 00:37:32,721
why is that the case?

901
00:37:32,721 --> 00:37:34,932
Especially given the fact that you could, um

902
00:37:34,932 --> 00:37:36,622
you theoretically have the right to just, like

903
00:37:36,622 --> 00:37:40,341
fork OpenAI's mono repo or distill on their models.

904
00:37:40,341 --> 00:37:45,261
Um, y- yeah, es- especially if it's a big part of your strategy that we need to have a leading model company.

905
00:37:45,261 --> 00:37:46,662
Yeah, I mean, f- so first of all

906
00:37:46,662 --> 00:37:50,942
we are g- absolutely going to use the OpenAI models

907
00:37:50,942 --> 00:37:54,381
uh, to the maximum, uh, across all of our products

908
00:37:54,381 --> 00:37:54,662
right?

909
00:37:54,662 --> 00:37:59,982
I mean, that's, I think, the core thing that we're gonna continue to do all the way for the next seven years.

910
00:37:59,982 --> 00:38:02,202
Uh, and not just use it, uh

911
00:38:02,202 --> 00:38:03,542
but then add value to it.

912
00:38:03,542 --> 00:38:06,622
That's kinda w- where the analyst and this Excel agent

913
00:38:06,622 --> 00:38:08,790
and these are all things that we will do where

914
00:38:08,790 --> 00:38:10,682
you know, we'll do r- you know

915
00:38:10,682 --> 00:38:18,741
RL fine-tuning, we'll do some mid-training runs on top of a GPT family where we have unique data assets and build capability.

916
00:38:18,741 --> 00:38:23,922
Um, the MAI model, the way I think we're gonna think about it is the

917
00:38:23,922 --> 00:38:25,881
the good news here, in fact, with the new agreement

918
00:38:25,881 --> 00:38:32,361
is even we can be very, very clear that we're gonna build a world-class superintelligence team and go after it with high ambition.

919
00:38:32,361 --> 00:38:38,122
But th- at the same time, we're also gonna use this time to be smart about how to use both these things.

920
00:38:38,122 --> 00:38:40,062
So that means we will, on one end

921
00:38:40,062 --> 00:38:42,841
be very product-focused or, on the other end

922
00:38:42,841 --> 00:38:44,401
be very research-focused.

923
00:38:44,401 --> 00:38:47,062
In other words, uh, because we have access

924
00:38:47,062 --> 00:38:55,002
aha, to the GPT family, the last thing I don't want to do is use my flops in a way that is just duplicative and doesn't add much value.

925
00:38:55,002 --> 00:38:56,772
So I want to be able to take

926
00:38:56,772 --> 00:39:05,742
uh, the flops that we use to generate a GPT family and maximize its value while my MAI flops are being used for.

927
00:39:05,742 --> 00:39:05,792
..

928
00:39:05,792 --> 00:39:07,772
Let's take the image model that we launched

929
00:39:07,772 --> 00:39:10,732
which I think this launched, uh, is a number nine in the

930
00:39:10,732 --> 00:39:12,202
uh, image arena.

931
00:39:12,202 --> 00:39:13,511
You know, we're using it, you know

932
00:39:13,511 --> 00:39:15,042
both for cost optimization.

933
00:39:15,042 --> 00:39:18,182
It's on Copilot, it's in Bing, and we're gonna use that.

934
00:39:18,182 --> 00:39:20,502
We have a, a audio model in Copilot

935
00:39:20,502 --> 00:39:23,071
which really it's got personality and what have you.

936
00:39:23,071 --> 00:39:24,642
We optimized it for our product.

937
00:39:24,642 --> 00:39:25,952
So we will do those.

938
00:39:25,952 --> 00:39:28,542
Even on the LM arena, we started on the text one

939
00:39:28,542 --> 00:39:30,651
I think it was, it debuted at night 13.

940
00:39:30,651 --> 00:39:33,272
And by the way, it was v- it was done only on

941
00:39:33,272 --> 00:39:35,682
whatever, 15,000, uh, H100s?

942
00:39:35,682 --> 00:39:37,770
And so it was a very small model.

943
00:39:37,770 --> 00:39:38,991
And, uh, so it was, again

944
00:39:38,991 --> 00:39:41,962
to prove out, uh, the core capability

945
00:39:41,962 --> 00:39:44,841
the instruction-following and everything else, which b- you know

946
00:39:44,841 --> 00:39:47,902
we wanted to make sure we can match what was state-of-the-art.

947
00:39:47,902 --> 00:39:49,982
And so that shows us, given scaling laws

948
00:39:49,982 --> 00:39:52,801
what we are capable of doing if it gave more flops to it

949
00:39:52,801 --> 00:39:53,002
right?

950
00:39:53,002 --> 00:39:58,462
So the next thing we will do is an omni model where we will take sort of the work we have done in audio

951
00:39:58,462 --> 00:40:01,281
what we have done in image, and what we have done in text.

952
00:40:01,281 --> 00:40:03,721
That'll be the next pit stop on the MAI side.

953
00:40:03,721 --> 00:40:06,202
So when I think about the MAI roadmap

954
00:40:06,202 --> 00:40:08,741
we're gonna build a first-class superintelligence team.

955
00:40:08,741 --> 00:40:10,602
We are gonna continue to drop and do on

956
00:40:10,602 --> 00:40:12,741
in the open some of these models.

957
00:40:12,741 --> 00:40:17,542
They will either be in our products being used because they're going to be latency-friendly

958
00:40:17,542 --> 00:40:21,261
cogs-friendly, or what have you, or they'll have some special capability.

959
00:40:21,261 --> 00:40:25,562
And we will do real research in order to be ready for some next five

960
00:40:25,562 --> 00:40:28,162
six, seven, eight brea- breakthroughs, uh

961
00:40:28,162 --> 00:40:30,801
that are all needed on this march towards superintelligence.

962
00:40:30,801 --> 00:40:31,531
So I think that's.

963
00:40:31,531 --> 00:40:31,591
..

964
00:40:31,591 --> 00:40:39,381
And while exploiting the advantage we have of having the GPT family that we can work on top of as well.

965
00:40:39,381 --> 00:40:39,841
Mm-hmm.

966
00:40:39,841 --> 00:40:41,881
S- say we roll forward seven years, uh

967
00:40:41,881 --> 00:40:44,051
you no longer have access to OpenAI models.

968
00:40:44,051 --> 00:40:51,241
What does one get confidence, or what does Microsoft do to make sure they are leading or have a leading AI lab

969
00:40:51,241 --> 00:40:51,482
right?

970
00:40:51,482 --> 00:40:54,841
Today, you know, it's, it's all OpenAI has developed many of the breakthroughs

971
00:40:54,841 --> 00:40:59,861
whether it be scaling or reasoning, or Google's developed all the breakthroughs like Transformers.

972
00:40:59,861 --> 00:41:02,321
Uh, but, but it- it is also a big talent game

973
00:41:02,321 --> 00:41:02,582
right?

974
00:41:02,582 --> 00:41:04,522
You know, you've seen Meta spend, you know

975
00:41:04,522 --> 00:41:06,962
north of $20 billion on talent, right?

976
00:41:06,962 --> 00:41:12,202
Uh, you've seen Anthropic pr- uh, poach the entire Blueshift reasoning team from Google last year.

977
00:41:12,202 --> 00:41:16,861
You've seen Meta poach a large reasoning and post-training team from Google more recently.

978
00:41:16,861 --> 00:41:20,071
These, these sorts of talent wars are very capital-intensive.

979
00:41:20,071 --> 00:41:22,202
They're the ones that, you know, arguably

980
00:41:22,202 --> 00:41:24,761
you know, if you're spending $100 billion on infrastructure

981
00:41:24,761 --> 00:41:27,642
you should also spend, you know, X amount of money on

982
00:41:27,642 --> 00:41:32,192
on the people using the infrastructure so that they're more efficiently making these new breakthroughs.

983
00:41:32,192 --> 00:41:34,281
What, what confidence can one get that

984
00:41:34,281 --> 00:41:38,452
you know, hey, Microsoft will have a team that's world-class that can make these breakthroughs?

985
00:41:38,452 --> 00:41:41,421
And, you know, once you decide to turn on the money faucet

986
00:41:41,421 --> 00:41:43,241
you know, you're, you're being a bit capital-efficient right now

987
00:41:43,241 --> 00:41:44,861
which is, which is smart, it seems

988
00:41:44,861 --> 00:41:47,102
uh, to not waste money d- doing duplicative work.

989
00:41:47,102 --> 00:41:49,792
But once you decide you need to, you know

990
00:41:49,792 --> 00:41:51,281
how, how can one say, "Oh, yeah

991
00:41:51,281 --> 00:41:54,261
now you can shoot up to, we're the top five model"?

992
00:41:54,261 --> 00:41:55,372
Well, look, I mean, at the e- eh

993
00:41:55,372 --> 00:41:57,662
the end of the day, we are gonna build a world-class team

994
00:41:57,662 --> 00:42:01,522
and we, uh, already have a world-class team that's beginning to be sort of a sample

995
00:42:01,522 --> 00:42:01,721
right?

996
00:42:01,721 --> 00:42:03,921
With Moustafa coming in, we have Karen

997
00:42:03,921 --> 00:42:07,162
we have Amar Subramanian who did a l- lot of the post-training at Gemini

998
00:42:07,162 --> 00:42:12,582
Tufai, who's at Microsoft, Nando, who did a lot of the multimedia s- work at DeepMind is there.

999
00:42:12,582 --> 00:42:15,602
And so we're gonna build a world-class team.

1000
00:42:15,602 --> 00:42:17,301
And in fact, I think later this week

1001
00:42:17,301 --> 00:42:22,261
even Moustafa published some, you know, a little more clarity on what our lab is going to go do.

1002
00:42:22,261 --> 00:42:24,741
Um, I think the thing that I want

1003
00:42:24,741 --> 00:42:27,712
uh, the world to know, perhaps, uh

1004
00:42:27,712 --> 00:42:32,361
is we are gonna build the infrastructure that'll support multiple models.

1005
00:42:32,361 --> 00:42:34,751
Uh, you know, uh, we.

1006
00:42:34,751 --> 00:42:35,051
..

1007
00:42:35,051 --> 00:42:44,182
Because from a hyperscale perspective, we wanna build the most scaled infrastructure fleet that's capable of supporting all the models the world needs

1008
00:42:44,182 --> 00:42:47,511
whether it's from open source or whether it's obviously from OpenAI and others.

1009
00:42:47,511 --> 00:42:48,848
And so that's kinda one job.

1010
00:42:48,848 --> 00:42:49,072
..

1011
00:42:49,072 --> 00:42:51,354
. second is in our own model capability

1012
00:42:51,354 --> 00:42:54,844
we will absolutely use the OpenAI model in our products

1013
00:42:54,844 --> 00:42:56,683
and we'll start building our own models.

1014
00:42:56,683 --> 00:42:58,624
And we may, like in- in GitHub Copilot

1015
00:42:58,624 --> 00:43:04,494
Anthropic is used, so we will even have other frontier models that are gonna be wrapped into our products as well.

1016
00:43:04,494 --> 00:43:07,514
So, I think that that's kind of how at least each time

1017
00:43:07,514 --> 00:43:13,854
at the end of the day, the eval of the product as it meets a particular task or a job is what matters.

1018
00:43:13,854 --> 00:43:18,414
And we'll sort of back from there into the vertical integration needed

1019
00:43:18,414 --> 00:43:20,454
uh, knowing that as long as you're a service

1020
00:43:20,454 --> 00:43:22,674
you know, you're serving the market well with the product

1021
00:43:22,674 --> 00:43:24,894
you can always cost optimize.

1022
00:43:24,894 --> 00:43:25,594
Mm.

1023
00:43:25,594 --> 00:43:27,414
Th- th- there's a question going forward.

1024
00:43:27,414 --> 00:43:31,154
So right now, we have models that have this distinction between training an inference

1025
00:43:31,154 --> 00:43:33,634
and one could argue that there's, like

1026
00:43:33,634 --> 00:43:36,784
a s- smaller and smaller difference between the different models.

1027
00:43:36,784 --> 00:43:40,254
Um, going forward, if you're really expecting something like human-level intelligence

1028
00:43:40,254 --> 00:43:42,074
humans learn on the job.

1029
00:43:42,074 --> 00:43:43,594
H- you know, if you think about your last 30 years

1030
00:43:43,594 --> 00:43:45,414
wha- what makes Satya tokens so valuable?

1031
00:43:45,414 --> 00:43:48,614
It's the last 30 years of wisdom and experience you've gained at Microsoft.

1032
00:43:48,614 --> 00:43:51,174
Um, and w- we will eventually have models

1033
00:43:51,174 --> 00:43:54,513
if they get to human level, which will have this ability to continuously learn on the job

1034
00:43:54,513 --> 00:43:58,234
and that will drive so much value to the model company that is ahead

1035
00:43:58,234 --> 00:43:59,234
at least in my view.

1036
00:43:59,234 --> 00:44:02,814
Because you have copies of one model broadly deployed through the economy

1037
00:44:02,814 --> 00:44:06,154
learning how to do every single job, and unlike humans

1038
00:44:06,154 --> 00:44:08,754
they can amalgamate their learnings to that model.

1039
00:44:08,754 --> 00:44:12,974
So, there's this sort of continuous learning sort of exponential feedback loop

1040
00:44:12,974 --> 00:44:16,384
um, which almost looks like a sort of intelligence explosion.

1041
00:44:16,384 --> 00:44:22,094
Uh, if that happens and Microsoft isn't the leading model company by that time

1042
00:44:22,094 --> 00:44:25,144
doesn't then the s- uh, you know

1043
00:44:25,144 --> 00:44:26,994
you were saying, well, we substitute one model for another

1044
00:44:26,994 --> 00:44:28,334
et cetera, matter less, 'cause it's just

1045
00:44:28,334 --> 00:44:31,474
like, this one model knows how to do every single job of the economy.

1046
00:44:31,474 --> 00:44:33,234
The other long tail don't.

1047
00:44:33,234 --> 00:44:33,554
Yeah.

1048
00:44:33,554 --> 00:44:42,104
No, I think that your point about if there's one model that is the only model that's most broadly deployed in the world and it sees all the data and it has continuous learning- Yeah.

1049
00:44:42,104 --> 00:44:42,104
.

1050
00:44:42,104 --> 00:44:42,104
.

1051
00:44:42,104 --> 00:44:43,664
that's game, set, match- Yeah.

1052
00:44:43,664 --> 00:44:43,664
.

1053
00:44:43,664 --> 00:44:43,664
.

1054
00:44:43,664 --> 00:44:44,974
and, you know, you're such sharp, right?

1055
00:44:44,974 --> 00:44:49,054
I mean, the- the reality, at least I see

1056
00:44:49,054 --> 00:44:56,714
um, is the world, even today, for all the dominance of any one model

1057
00:44:56,714 --> 00:44:57,714
it's not the case.

1058
00:44:57,714 --> 00:45:00,100
Um, a- is t- take any.

1059
00:45:00,100 --> 00:45:00,244
..

1060
00:45:00,244 --> 00:45:01,714
take coding.

1061
00:45:01,714 --> 00:45:02,794
There's multiple models.

1062
00:45:02,794 --> 00:45:05,594
In fact, every day it's less the case

1063
00:45:05,594 --> 00:45:08,823
where there is not one model that is getting deployed broadly.

1064
00:45:08,823 --> 00:45:11,534
In fact, there's multiple models that are getting deployed.

1065
00:45:11,534 --> 00:45:12,844
It's kind of like databases, right?

1066
00:45:12,844 --> 00:45:14,043
You- it's always the thing is, like

1067
00:45:14,043 --> 00:45:17,244
hey, can one database be the one that just is used everywhere?

1068
00:45:17,244 --> 00:45:18,414
Except it's not.

1069
00:45:18,414 --> 00:45:21,554
Uh, there are multiple types of databases that are getting deployed

1070
00:45:21,554 --> 00:45:23,794
uh, for different use cases.

1071
00:45:23,794 --> 00:45:29,354
So, I think that there is going to be some network effects of continual learning or data

1072
00:45:29,354 --> 00:45:33,064
y- you know, I'll call liquidity, that any one model has.

1073
00:45:33,064 --> 00:45:35,004
Uh, is it gonna happen in all domains?

1074
00:45:35,004 --> 00:45:35,904
I don't think so.

1075
00:45:35,904 --> 00:45:37,584
Is it gonna happen in all GOs?

1076
00:45:37,584 --> 00:45:38,394
I don't think so.

1077
00:45:38,394 --> 00:45:39,994
Is it gonna happen in all segments?

1078
00:45:39,994 --> 00:45:40,594
I don't think so.

1079
00:45:40,594 --> 00:45:42,574
It'll happen in all categories at the same time?

1080
00:45:42,574 --> 00:45:43,154
I don't think so.

1081
00:45:43,154 --> 00:45:46,494
So therefore, I feel like the design space is so large

1082
00:45:46,494 --> 00:45:49,454
uh, that there's plenty of opportunity.

1083
00:45:49,454 --> 00:45:54,274
But your fundamental point is having a capability which is at the infrastructure layer

1084
00:45:54,274 --> 00:45:58,034
model layer, and at the scaffolding layer

1085
00:45:58,034 --> 00:46:02,234
and then to be able to compose these things not just as a vertical stack

1086
00:46:02,234 --> 00:46:05,574
but to be able to compose each thing for what its purpose is

1087
00:46:05,574 --> 00:46:05,714
right?

1088
00:46:05,714 --> 00:46:08,314
You can't build an infrastructure that's optimized for one model.

1089
00:46:08,314 --> 00:46:10,794
If you do that, what if you go fall behind?

1090
00:46:10,794 --> 00:46:14,534
In fact, all the infrastructure you built will be a waste

1091
00:46:14,534 --> 00:46:14,734
right?

1092
00:46:14,734 --> 00:46:21,754
You kind of need to build an infrastructure that's capable of supporting multiple sort of families and lineages of models.

1093
00:46:21,754 --> 00:46:25,634
Otherwise, the capital you put in, which is optimized for one model architecture

1094
00:46:25,634 --> 00:46:33,514
you- that means you're one tweak away from some MOE-like breakthrough that happens with somebody else and your entire network topology goes out of the window.

1095
00:46:33,514 --> 00:46:34,894
Then that's a scary thing, right?

1096
00:46:34,894 --> 00:46:39,644
So therefore, you kind of want the infrastructure to support whatever may come

1097
00:46:39,644 --> 00:46:42,574
in fact, in your own model family and other model families

1098
00:46:42,574 --> 00:46:43,374
and you got to be open.

1099
00:46:43,374 --> 00:46:45,494
If you're- if you're serious about the hyperscale business

1100
00:46:45,494 --> 00:46:47,084
you got to be serious about that, right?

1101
00:46:47,084 --> 00:46:50,734
Um, if you're serious about being a model company

1102
00:46:50,734 --> 00:46:58,094
you've got to basically say, "Hey, what are the ways people can actually do things on top of the model so that I can have an ISV ecosystem?

1103
00:46:58,094 --> 00:47:00,204
" Unless I'm thinking I'll own every category.

1104
00:47:00,204 --> 00:47:01,054
That just can't be.

1105
00:47:01,054 --> 00:47:02,694
Then- then you won't have an API business

1106
00:47:02,694 --> 00:47:05,884
and that by definition will mean you'll never be

1107
00:47:05,884 --> 00:47:09,154
uh, a platform company that's gonna be successfully deployed everywhere

1108
00:47:09,154 --> 00:47:09,374
right?

1109
00:47:09,374 --> 00:47:14,914
So therefore, the industry structure is s- such that it will

1110
00:47:14,914 --> 00:47:19,320
uh, really force people to specialize, and that.

1111
00:47:19,320 --> 00:47:19,403
..

1112
00:47:19,403 --> 00:47:27,374
in that specialization, a company like Microsoft should compete in each layer by its merits

1113
00:47:27,374 --> 00:47:31,094
uh, but not think that this is all about all a road to game

1114
00:47:31,094 --> 00:47:34,274
set, match where I just compose vertically all these layers.

1115
00:47:34,274 --> 00:47:36,894
That's- that just doesn't happen.

1116
00:47:36,894 --> 00:47:42,104
So, according to Dylan's numbers, there's gonna be half a trillion in AI CapEx next year alone

1117
00:47:42,104 --> 00:47:46,344
and labs are already spending billions of dollars to snag top researcher talent.

1118
00:47:46,344 --> 00:47:50,084
But none of that matters if there's not enough high quality data to train on.

1119
00:47:50,084 --> 00:47:57,884
Without the right data, even the most advanced infrastructure and world-class talent won't translate into end value for the user.

1120
00:47:57,884 --> 00:47:59,474
That's where Labobox comes in.

1121
00:47:59,474 --> 00:48:03,354
Labobox produces high quality data at massive scale

1122
00:48:03,354 --> 00:48:06,204
powering any capability that you want your model to have.

1123
00:48:06,204 --> 00:48:15,574
It doesn't matter whether you need a coding agent that needs detailed feedback on multi-hour trajectories or a robotics model that needs thousands of samples on everyday tasks

1124
00:48:15,574 --> 00:48:19,074
or a voice agent that can also perform real world actions for the user

1125
00:48:19,074 --> 00:48:20,394
like booking them a flight.

1126
00:48:20,394 --> 00:48:22,854
To be clear, this isn't just off-the-shelf data.

1127
00:48:22,854 --> 00:48:29,574
Labobox can design and launch a custom production scale data pipeline in 48 hours

1128
00:48:29,574 --> 00:48:33,974
and they can get you tens of thousands of targeted examples in weeks.

1129
00:48:33,974 --> 00:48:36,579
Reach out at labobox.

1130
00:48:36,579 --> 00:48:38,994
com/dwarkesh.

1131
00:48:38,994 --> 00:48:41,548
All right, back to Satya.

1132
00:48:41,548 --> 00:48:47,145
So, last year, Microsoft was o- on path to be the largest infrastructure provider

1133
00:48:47,145 --> 00:48:47,705
uh, by far.

1134
00:48:47,705 --> 00:48:49,386
You were the earliest in '23, so you

1135
00:48:49,386 --> 00:48:52,225
you went out there, you acquired all the resources in terms of leasing data centers

1136
00:48:52,225 --> 00:48:54,486
starting construction, securing power, everything.

1137
00:48:54,486 --> 00:48:58,826
You guys were on pace to beat Amazon in '26 or '27.

1138
00:48:58,826 --> 00:49:01,546
Um, but certainly by '28, you were gonna beat them.

1139
00:49:01,546 --> 00:49:03,346
Um, since then, you, you know

1140
00:49:03,346 --> 00:49:05,866
in, let's call it the second half of last year

1141
00:49:05,866 --> 00:49:11,836
Microsoft did this big pause, right, where they let go of a bunch of leasing sites that they were gonna take

1142
00:49:11,836 --> 00:49:15,366
which then Google, Meta, um, Amazon in some cases

1143
00:49:15,366 --> 00:49:17,806
Oracle, uh, took these sites.

1144
00:49:17,806 --> 00:49:19,446
We're sitting in one of the largest data centers in the world

1145
00:49:19,446 --> 00:49:20,375
so obviously it's not everything.

1146
00:49:20,375 --> 00:49:22,336
You guys are expanding like crazy, uh

1147
00:49:22,336 --> 00:49:24,134
but there are sites that you just stopped working on.

1148
00:49:24,134 --> 00:49:24,586
Hmm.

1149
00:49:24,586 --> 00:49:26,386
Wh- why, why did you do this

1150
00:49:26,386 --> 00:49:26,966
right?

1151
00:49:26,966 --> 00:49:30,308
Yeah, I mean, the fundamental thing we .

1152
00:49:30,308 --> 00:49:30,314
..

1153
00:49:30,314 --> 00:49:34,306
This goes back a little bit to what is the hyperscale business all about

1154
00:49:34,306 --> 00:49:34,526
right?

1155
00:49:34,526 --> 00:49:46,526
Which is one of the key decisions we made was that if you're gonna build out Azure to be fantastic for all sort of stages of AI

1156
00:49:46,526 --> 00:49:49,946
uh, from training to mid-training, to data gen

1157
00:49:49,946 --> 00:49:53,566
to inference, we just need fungibility, uh

1158
00:49:53,566 --> 00:49:54,265
of the fleet.

1159
00:49:54,265 --> 00:50:01,866
Um, and, and so that entire thing caused us not to basically go build a

1160
00:50:01,866 --> 00:50:06,526
a whole lot of capacity with a particular set of generations.

1161
00:50:06,526 --> 00:50:17,046
Uh, because the other thing that you got to realize is having actually for up to now 10Xed every 18 months enough training capacity for the various OpenAI models

1162
00:50:17,046 --> 00:50:22,466
uh, we realized that, um, the key is to stay on that path.

1163
00:50:22,466 --> 00:50:27,145
But the more important thing is to actually have a balance to not just train

1164
00:50:27,145 --> 00:50:30,185
but to be able to serve these models all around the world.

1165
00:50:30,185 --> 00:50:35,236
Because at the end of the day, the rate of monetization is what then will allow us to even keep

1166
00:50:35,236 --> 00:50:35,946
uh, funding.

1167
00:50:35,946 --> 00:50:39,705
And then the infrastructure was going to need us to support

1168
00:50:39,705 --> 00:50:41,725
as I said, multiple models and what have you.

1169
00:50:41,725 --> 00:50:43,725
So once we said that that's the case

1170
00:50:43,725 --> 00:50:46,969
since then, we just course corrected to where .

1171
00:50:46,969 --> 00:50:46,975
..

1172
00:50:46,975 --> 00:50:48,006
the path we are on, right?

1173
00:50:48,006 --> 00:50:52,085
If I look at the path we are on is we are doing a lot more starts now.

1174
00:50:52,085 --> 00:50:55,486
Uh, we are also buying up as managed capacity as we can

1175
00:50:55,486 --> 00:50:57,595
whether it's to build, whether it's to lease

1176
00:50:57,595 --> 00:50:59,606
or even GPUs as a service.

1177
00:50:59,606 --> 00:51:02,725
But we are building it for where we see the demand

1178
00:51:02,725 --> 00:51:05,786
uh, and the serving needs and our training needs.

1179
00:51:05,786 --> 00:51:10,705
And we didn't want to just be a host stop for one company

1180
00:51:10,705 --> 00:51:14,086
uh, and have just a massive book of business with one customer.

1181
00:51:14,086 --> 00:51:15,495
That, that's not a business, right?

1182
00:51:15,495 --> 00:51:16,975
That is sort of, uh, you know

1183
00:51:16,975 --> 00:51:19,455
you should be vertically integrated with that company.

1184
00:51:19,455 --> 00:51:19,875
Yeah.

1185
00:51:19,875 --> 00:51:25,086
Uh, and so given the, the thing that OpenAI was going to be a successful independent company

1186
00:51:25,086 --> 00:51:26,106
which is fantastic, right?

1187
00:51:26,106 --> 00:51:27,546
I think it makes sense, right?

1188
00:51:27,546 --> 00:51:32,915
And even Meta may use third-party capacity, but ultimately they're all going to be first party

1189
00:51:32,915 --> 00:51:36,125
uh, for anyone who has large scale

1190
00:51:36,125 --> 00:51:38,606
they'll be, you know, they'll be a hyperscaler on their own.

1191
00:51:38,606 --> 00:51:44,765
And so to me, was to build out a hyperscale fleet and our own research compute.

1192
00:51:44,765 --> 00:51:47,066
Uh, and that's what the adjustment was.

1193
00:51:47,066 --> 00:51:49,314
Um, you know, and then, and so I feel very

1194
00:51:49,314 --> 00:51:49,826
very good.

1195
00:51:49,826 --> 00:51:56,106
Oh, by the way, the other thing is I didn't want to get stuck with massive scale of one generation.

1196
00:51:56,106 --> 00:51:58,286
I mean, we just saw the, the GB200s.

1197
00:51:58,286 --> 00:52:00,216
I mean, the GB300s are coming, right?

1198
00:52:00,216 --> 00:52:02,326
And by the time I get to Vera Rubin

1199
00:52:02,326 --> 00:52:04,185
Vera Rubin Ultra, guess what?

1200
00:52:04,185 --> 00:52:08,546
The data center is gonna look very different because the power per rack

1201
00:52:08,546 --> 00:52:11,265
power per row is gonna be so different.

1202
00:52:11,265 --> 00:52:13,526
Uh, the cooling requirements are gonna be so different.

1203
00:52:13,526 --> 00:52:21,106
And that, that means I don't want to just go build out like a whole number of gigawatts that are only for a one generation

1204
00:52:21,106 --> 00:52:22,286
one family.

1205
00:52:22,286 --> 00:52:28,145
And so I think the pacing matters and the fungibility and the location matters.

1206
00:52:28,145 --> 00:52:31,886
Uh, the workload diversity matters, customer diversity matters

1207
00:52:31,886 --> 00:52:33,245
and that's what we're building towards.

1208
00:52:33,245 --> 00:52:35,466
The other thing that we've learned a lot is

1209
00:52:35,466 --> 00:52:40,165
um, every AI workload does require not only the AI accelerator

1210
00:52:40,165 --> 00:52:41,986
but it requires a whole lot of other things

1211
00:52:41,986 --> 00:52:42,265
right?

1212
00:52:42,265 --> 00:52:46,205
And in fact, a lot of the margin structure for us will be in those other things.

1213
00:52:46,205 --> 00:53:02,725
And so therefore, we want to build out Azure as being fantastic for the long tail of the workloads because that's the hyperscale business while knowing that we've got to be super competitive starting with the bare metal for the highest end training.

1214
00:53:02,725 --> 00:53:05,606
And, but that can't crowd out the rest of the business

1215
00:53:05,606 --> 00:53:05,805
right?

1216
00:53:05,805 --> 00:53:10,866
Because we're not in the business of just doing five contracts with five customers

1217
00:53:10,866 --> 00:53:12,466
being their bare metal service.

1218
00:53:12,466 --> 00:53:14,846
That's not a, a Microsoft business.

1219
00:53:14,846 --> 00:53:16,165
That may be a business for someone else

1220
00:53:16,165 --> 00:53:17,426
and that's a good thing.

1221
00:53:17,426 --> 00:53:19,705
What we have said is we are in the hyperscale business

1222
00:53:19,705 --> 00:53:21,026
which is at the end of the day

1223
00:53:21,026 --> 00:53:25,725
a long tail business, uh, for AI workloads.

1224
00:53:25,725 --> 00:53:32,346
And in order to do that, we will have some leading bare metal as a service capabilities for a set of models

1225
00:53:32,346 --> 00:53:33,466
including our own.

1226
00:53:33,466 --> 00:53:35,765
Uh, and that I think is the balance you see.

1227
00:53:35,765 --> 00:53:40,116
The, another sort of question that comes around this whole fungibility topic is

1228
00:53:40,116 --> 00:53:41,616
okay, it's not where you want it

1229
00:53:41,616 --> 00:53:41,856
right?

1230
00:53:41,856 --> 00:53:45,716
You would rather have it in a good population center like Atlanta as you're- we're here.

1231
00:53:45,716 --> 00:53:48,366
Um, there, there's, there's also the question of like

1232
00:53:48,366 --> 00:53:52,546
well, how much does that matter if as the horizon of AI tasks grows?

1233
00:53:52,546 --> 00:53:53,406
Well, actually- It's a great question.

1234
00:53:53,406 --> 00:53:53,415
.

1235
00:53:53,415 --> 00:53:53,415
..

1236
00:53:53,415 --> 00:53:56,606
you know, 30 seconds for a reasoning prompt or

1237
00:53:56,606 --> 00:53:59,046
you know, 30 minutes for a deep research or

1238
00:53:59,046 --> 00:54:02,066
you know, it's gonna be hours for software agents at some point

1239
00:54:02,066 --> 00:54:03,875
um, and days and so on and so forth

1240
00:54:03,875 --> 00:54:05,386
the time to human interaction.

1241
00:54:05,386 --> 00:54:06,636
Why does it matter if it's- Yeah.

1242
00:54:06,636 --> 00:54:06,636
.

1243
00:54:06,636 --> 00:54:06,636
.

1244
00:54:06,636 --> 00:54:08,176
if it's- It's a great, it's a great question.

1245
00:54:08,176 --> 00:54:08,375
.

1246
00:54:08,375 --> 00:54:08,395
..

1247
00:54:08,395 --> 00:54:10,006
uh, location A, B, or C?

1248
00:54:10,006 --> 00:54:10,586
That's exactly right.

1249
00:54:10,586 --> 00:54:13,426
So in fact, that's one of the other reasons why we want to think about like

1250
00:54:13,426 --> 00:54:15,786
hey, what does an Azure region look like and what is the

1251
00:54:15,786 --> 00:54:18,125
in fact the networking between Azure regions?

1252
00:54:18,125 --> 00:54:21,426
So this is where, uh, I think as the model capabilities evolve

1253
00:54:21,426 --> 00:54:24,566
and I think the usage of these tokens

1254
00:54:24,566 --> 00:54:29,165
whether it's synchronously or asynchronously evolves, and in fact you don't want to be out of position

1255
00:54:29,165 --> 00:54:29,866
right?

1256
00:54:29,866 --> 00:54:32,125
Then on top of that, by the way

1257
00:54:32,125 --> 00:54:34,026
what are the data residency laws, right?

1258
00:54:34,026 --> 00:54:34,849
What, where do I .

1259
00:54:34,849 --> 00:54:34,856
..

1260
00:54:34,856 --> 00:54:36,685
Like, I mean, the entire EU thing

1261
00:54:36,685 --> 00:54:40,786
uh, for us where we literally had to create an EU data boundary

1262
00:54:40,786 --> 00:54:44,966
uh, basically meant that you can't just round-trip a call to wherever

1263
00:54:44,966 --> 00:54:46,205
even if it's asynchronous.

1264
00:54:46,205 --> 00:54:51,846
And so therefore you need to have maybe regional things that are high density and then the power costs and so on.

1265
00:54:51,846 --> 00:54:57,966
But you're 100% right in bringing up that the topology as we build out

1266
00:54:57,966 --> 00:55:03,305
uh, will have to evolve, one, for tokens per dollar of a watt.

1267
00:55:03,305 --> 00:55:05,506
Uh, what are the economics?

1268
00:55:05,506 --> 00:55:09,145
So, overlay that with what is the usage pattern

1269
00:55:09,145 --> 00:55:11,596
um, usage pattern in terms of synchronous

1270
00:55:11,596 --> 00:55:16,495
asynchronous, but also what is the compute storage because the latencies may matter for certain things.

1271
00:55:16,495 --> 00:55:18,296
Uh, the storage better be there.

1272
00:55:18,296 --> 00:55:22,645
If I have a Cosmos DB close to this for session data or even for an autonomous thing

1273
00:55:22,645 --> 00:55:25,765
then that also has to be somewhere close to it

1274
00:55:25,765 --> 00:55:26,305
and so on.

1275
00:55:26,305 --> 00:55:29,886
So I think that all of those considerations is what will shape

1276
00:55:29,886 --> 00:55:31,665
uh, the hyperscale business.

1277
00:55:31,665 --> 00:55:32,271
Mm-hmm.

1278
00:55:32,271 --> 00:55:34,666
You know, prior to the pause, you were- you were- you're

1279
00:55:34,666 --> 00:55:37,606
you know, versus, you know, what we had forecasted for you by '28

1280
00:55:37,606 --> 00:55:38,986
you were going to be, like, 12

1281
00:55:38,986 --> 00:55:40,236
13 gigawatts.

1282
00:55:40,236 --> 00:55:40,276
Yeah.

1283
00:55:40,276 --> 00:55:42,726
And now we're at, you know, nine and a half or so

1284
00:55:42,726 --> 00:55:42,966
right?

1285
00:55:42,966 --> 00:55:44,806
But, you know, something that's even more relevant

1286
00:55:44,806 --> 00:55:46,816
right, and it's- it's, you know, I just want you to

1287
00:55:46,816 --> 00:55:49,406
like, more concretely state that this is the business you don't want to be in.

1288
00:55:49,406 --> 00:56:00,566
But, like, Oracle's going from like one-fifth your size to bigger than you by end of 2027 and while it's not a Microsoft level quality of return on invested capital

1289
00:56:00,566 --> 00:56:00,986
right?

1290
00:56:00,986 --> 00:56:03,656
They're still making 35% gross margins, right?

1291
00:56:03,656 --> 00:56:07,135
So sort of the question is like does it- is it- isn't it- is it- is it

1292
00:56:07,135 --> 00:56:09,696
you know, hey, it's not Microsoft's business to maybe do this

1293
00:56:09,696 --> 00:56:12,216
but you've created a hyperscaler now- Yeah.

1294
00:56:12,216 --> 00:56:12,216
.

1295
00:56:12,216 --> 00:56:12,216
.

1296
00:56:12,216 --> 00:56:15,116
by refusing this business, by giving away the right of- Look

1297
00:56:15,116 --> 00:56:15,209
I- I- .

1298
00:56:15,209 --> 00:56:15,216
..

1299
00:56:15,216 --> 00:56:16,186
first refusal, et cetera.

1300
00:56:16,186 --> 00:56:16,839
I'm not.

1301
00:56:16,839 --> 00:56:17,036
..

1302
00:56:17,036 --> 00:56:21,906
First of all, I don't, I don't want to take away anything from the success Oracle has had- Yeah.

1303
00:56:21,906 --> 00:56:21,916
.

1304
00:56:21,916 --> 00:56:21,916
..

1305
00:56:21,916 --> 00:56:24,066
uh, in building their business, and I wish them well.

1306
00:56:24,066 --> 00:56:26,566
And so the thing that I think I've answered for you is

1307
00:56:26,566 --> 00:56:29,326
it didn't make sense for us, uh

1308
00:56:29,326 --> 00:56:34,266
to go be a host, uh, for one model company

1309
00:56:34,266 --> 00:56:37,306
uh, with limited time horizon RPO.

1310
00:56:37,306 --> 00:56:37,726
Let's- Yeah.

1311
00:56:37,726 --> 00:56:39,206
Let's just put it that way, right?

1312
00:56:39,206 --> 00:56:42,606
The thing that you have to think through is not what you do in the next five years

1313
00:56:42,606 --> 00:56:45,026
but what do you do for the next 50?

1314
00:56:45,026 --> 00:56:48,926
Uh, because that's kind of what I- we made our set of decisions

1315
00:56:48,926 --> 00:56:53,306
um, I feel very good about our OpenAI partnership and what we're doing.

1316
00:56:53,306 --> 00:56:55,386
We have a decent book, book of business.

1317
00:56:55,386 --> 00:56:57,286
We wish them a lot of success.

1318
00:56:57,286 --> 00:57:00,046
In fact, we are buyers even of Oracle capacity

1319
00:57:00,046 --> 00:57:00,896
we wish them- Yep.

1320
00:57:00,896 --> 00:57:00,896
.

1321
00:57:00,896 --> 00:57:00,896
.

1322
00:57:00,896 --> 00:57:01,676
success.

1323
00:57:01,676 --> 00:57:06,966
But, you know, at this point, I think the industrial logic for what we are trying to do is pretty clear

1324
00:57:06,966 --> 00:57:08,938
which is, it's not about, like, chasing.

1325
00:57:08,938 --> 00:57:09,096
..

1326
00:57:09,096 --> 00:57:10,046
I mean, first of all, I track

1327
00:57:10,046 --> 00:57:11,706
by the way, your, uh, things

1328
00:57:11,706 --> 00:57:14,226
whe- whether it's the AWS or the Google and ours

1329
00:57:14,226 --> 00:57:16,086
which I think is super useful.

1330
00:57:16,086 --> 00:57:19,866
Uh, but doesn't mean I got to chase those.

1331
00:57:19,866 --> 00:57:20,056
Yeah.

1332
00:57:20,056 --> 00:57:22,936
Uh, I have to chase them for not just

1333
00:57:22,936 --> 00:57:26,136
uh, the gross margin that they may represent in a period of time.

1334
00:57:26,136 --> 00:57:33,646
You know, does Mi- what, what is this book of business that Microsoft uniquely can go clear which makes sense for us to clear?

1335
00:57:33,646 --> 00:57:34,606
And that's what we'll do.

1336
00:57:34,606 --> 00:57:35,946
I, I, I guess I have a question

1337
00:57:35,946 --> 00:57:37,646
even stepping back from this, of, okay

1338
00:57:37,646 --> 00:57:40,686
I, I take your point that it's a better business to be in

1339
00:57:40,686 --> 00:57:45,056
all else equal, to have a long tail of customers you can have higher margin from

1340
00:57:45,056 --> 00:57:45,266
right?

1341
00:57:45,266 --> 00:57:49,286
 That when you're serving bare metal to a few labs.

1342
00:57:49,286 --> 00:57:50,226
But then there's a question of, okay

1343
00:57:50,226 --> 00:57:51,626
which way is the industry evolving?

1344
00:57:51,626 --> 00:57:55,546
And so if we believe we're on the path to smarter and smarter AIs

1345
00:57:55,546 --> 00:58:07,446
then why isn't the shape of the industry that the OpenAIs and Anthropics and DeepMinds are the platform which the long tail of enterprises are actually doing business with

1346
00:58:07,446 --> 00:58:09,106
where they need bare metal, but, like

1347
00:58:09,106 --> 00:58:09,906
they are the platform?

1348
00:58:09,906 --> 00:58:13,586
What is the long tail that is directly using Azure

1349
00:58:13,586 --> 00:58:18,846
um, 'cause, you know, you, you want to use the general cognitive core- But those models are gonna be available on Azure

1350
00:58:18,846 --> 00:58:19,046
right?

1351
00:58:19,046 --> 00:58:21,766
So any workload that says, "Hey, I want to use

1352
00:58:21,766 --> 00:58:25,517
um, you know, some open source model and an OpenAI model

1353
00:58:25,517 --> 00:58:27,446
" like, I mean, if you go to Azure Foundry today

1354
00:58:27,446 --> 00:58:31,076
you have all these models that you can provision by PTUs

1355
00:58:31,076 --> 00:58:33,366
get a Cosmos DB, get a SQL DB

1356
00:58:33,366 --> 00:58:35,026
get some storage, get some compute.

1357
00:58:35,026 --> 00:58:36,626
That's what a real workload looks like.

1358
00:58:36,626 --> 00:58:38,136
A real workload is not just, "Hey

1359
00:58:38,136 --> 00:58:40,468
I called in an API call to a model.

1360
00:58:40,468 --> 00:58:45,666
" A real workload needs all of these things to go build an app

1361
00:58:45,666 --> 00:58:47,486
uh, or instantiate an application.

1362
00:58:47,486 --> 00:58:49,386
In fact, the model companies need that

1363
00:58:49,386 --> 00:58:50,576
right, to build anything.

1364
00:58:50,576 --> 00:58:52,779
It's just not like, "I have a token factory.

1365
00:58:52,779 --> 00:58:54,606
" I have to have all of these things.

1366
00:58:54,606 --> 00:58:56,566
That's the hyperscale business.

1367
00:58:56,566 --> 00:58:58,586
Uh, and it's not even any one model

1368
00:58:58,586 --> 00:58:59,836
but all these models.

1369
00:58:59,836 --> 00:59:02,446
And so if you want Grok plus, let's say

1370
00:59:02,446 --> 00:59:05,066
uh, OpenAI plus an open source model

1371
00:59:05,066 --> 00:59:08,826
come to Azure Foundry, provision them, build your application

1372
00:59:08,826 --> 00:59:09,886
here is a database.

1373
00:59:09,886 --> 00:59:11,836
That's kind of what the business is.

1374
00:59:11,836 --> 00:59:23,141
Uh, you, there is a separate business called just selling raw bare metal services to model companies and that's the argument about how much of that business you want to be in and not be in and what is that.

1375
00:59:23,141 --> 00:59:23,196
..

1376
00:59:23,196 --> 00:59:25,306
It's a very different segment of the business

1377
00:59:25,306 --> 00:59:31,066
which, uh, we are in and we also have limits to how much of it is going to crowd out the rest of it.

1378
00:59:31,066 --> 00:59:34,126
Uh, but that's kind of at least the way I look at it.

1379
00:59:34,126 --> 00:59:36,046
So, so there's, there's sort of two questions here

1380
00:59:36,046 --> 00:59:36,246
right?

1381
00:59:36,246 --> 00:59:38,486
Like, why, why couldn't you just do both is one

1382
00:59:38,486 --> 00:59:40,586
and then the other one is, um

1383
00:59:40,586 --> 00:59:46,196
given, you know, our, our estimates on what your capacity is in 2028 is three and a half gigawatts lower

1384
00:59:46,196 --> 00:59:51,136
sure, you could have dedicated that to OpenAI training and inference capacity

1385
00:59:51,136 --> 00:59:53,566
but you could have also dedicated that to

1386
00:59:53,566 --> 00:59:56,816
hey, th- this three and a half gigawatts is actually just running Azure

1387
00:59:56,816 --> 01:00:00,126
it's running Microsoft 365, it's running GitHub Copilot.

1388
01:00:00,126 --> 01:00:00,736
It doesn't actually.

1389
01:00:00,736 --> 01:00:00,796
..

1390
01:00:00,796 --> 01:00:02,876
I could have built it and not given it to OpenAI.

1391
01:00:02,876 --> 01:00:05,406
Or, or I may want to build it in a different location.

1392
01:00:05,406 --> 01:00:06,716
I may want to build it in UAE

1393
01:00:06,716 --> 01:00:07,836
I may want to build it in India

1394
01:00:07,836 --> 01:00:08,916
I may want to build it in Europe

1395
01:00:08,916 --> 01:00:09,076
right?

1396
01:00:09,076 --> 01:00:11,006
So one of the other things is, as I said

1397
01:00:11,006 --> 01:00:13,866
like, where we have real capacity constraints right now are

1398
01:00:13,866 --> 01:00:16,516
given the regulatory needs and the data sovereignty needs

1399
01:00:16,516 --> 01:00:18,356
we got to build all over the world.

1400
01:00:18,356 --> 01:00:21,986
Uh, it's, first of all, state-side capacity is super important and we're going to build everything.

1401
01:00:21,986 --> 01:00:24,886
But one of the things is, when I look out to 2030

1402
01:00:24,886 --> 01:00:31,086
uh, I have a sort of a global view of what is Microsoft shape of business by first party and third party.

1403
01:00:31,086 --> 01:00:40,146
Third party segmented by the Frontier labs and how much they want versus the inference capacity we want to build for multiple models

1404
01:00:40,146 --> 01:00:42,726
um, and our own research compute needs

1405
01:00:42,726 --> 01:00:42,946
right?

1406
01:00:42,946 --> 01:00:46,886
So that's all what's going into my calculus versus saying

1407
01:00:46,886 --> 01:00:50,886
"Hey," uh, I think you're rightfully pointing out the pause

1408
01:00:50,886 --> 01:00:53,566
but the pause was not done because we said

1409
01:00:53,566 --> 01:00:55,857
"Oh my God, we don't want to build that.

1410
01:00:55,857 --> 01:01:01,166
" We realized that, oh, we want to build what we want to build slightly differently

1411
01:01:01,166 --> 01:01:07,086
uh, by both workload type as well as geo type and timing as well.

1412
01:01:07,086 --> 01:01:11,066
Like, we'll keep ramping up our gigawatts and the question is

1413
01:01:11,066 --> 01:01:15,056
at what pace and in what location and in what sort of

1414
01:01:15,056 --> 01:01:16,946
how do I write even the Moore's Law on it

1415
01:01:16,946 --> 01:01:17,136
right?

1416
01:01:17,136 --> 01:01:17,136
Yep.

1417
01:01:17,136 --> 01:01:23,066
Which is, do I really want to overbuild three and a half in '27 or do I want to spread that in '27

1418
01:01:23,066 --> 01:01:24,184
'28, knowing even.

1419
01:01:24,184 --> 01:01:24,336
..

1420
01:01:24,336 --> 01:01:28,486
One of the biggest learnings we had even with NVIDIA is their pace increased

1421
01:01:28,486 --> 01:01:30,316
uh, in terms of their model mi- I mean

1422
01:01:30,316 --> 01:01:31,666
their migrations.

1423
01:01:31,666 --> 01:01:32,227
So that was a-.

1424
01:01:32,227 --> 01:01:32,276
..

1425
01:01:32,276 --> 01:01:33,126
a big factor.

1426
01:01:33,126 --> 01:01:35,586
I didn't want to go get stuck for four years

1427
01:01:35,586 --> 01:01:37,996
five years of depreciation on one, uh

1428
01:01:37,996 --> 01:01:38,886
generation.

1429
01:01:38,886 --> 01:01:41,086
And I wanted to just basically buy like

1430
01:01:41,086 --> 01:01:43,166
in fact, Jensen's a- advice to me was two things.

1431
01:01:43,166 --> 01:01:45,673
One is, "Hey, get on the speed of light execution.

1432
01:01:45,673 --> 01:01:48,786
" That's why I think even the execution in this Atlanta data center

1433
01:01:48,786 --> 01:01:50,186
I mean, like, in 90 days, right?

1434
01:01:50,186 --> 01:01:53,546
Right, between when we get it and do a handoff to a real workload

1435
01:01:53,546 --> 01:01:56,916
that's sort of real speed of light execution on their front.

1436
01:01:56,916 --> 01:01:58,376
And so I wanted to get good on that.

1437
01:01:58,376 --> 01:02:03,526
And then that way, then I'm building this each generation and scaling.

1438
01:02:03,526 --> 01:02:07,850
Uh, and then every five years, then you have a much more balanced.

1439
01:02:07,850 --> 01:02:07,976
..

1440
01:02:07,976 --> 01:02:10,886
So it becomes really literally like a flow

1441
01:02:10,886 --> 01:02:13,756
uh, for a n- large-scale industrial operation like this

1442
01:02:13,756 --> 01:02:21,196
where you suddenly are not lopsided, where you built up a lot in one time and then you take a ma- massive hiatus because you're stuck with all this

1443
01:02:21,196 --> 01:02:23,746
to your point, in one location, which may be great for training

1444
01:02:23,746 --> 01:02:24,886
may not be great for inference.

1445
01:02:24,886 --> 01:02:26,906
Because I can't serve even if it, like

1446
01:02:26,906 --> 01:02:30,866
is all asynchronous, but Europe ain't gonna let me round trip to U- Texas.

1447
01:02:30,866 --> 01:02:32,566
So that's all of the things.

1448
01:02:32,566 --> 01:02:36,006
How do I rationalize this statement with what you've done over the last few weeks?

1449
01:02:36,006 --> 01:02:39,136
You've announced deals with Iris Energy, um

1450
01:02:39,136 --> 01:02:43,856
with Nebious, um, and Lambda Labs, and there's a few more coming as well.

1451
01:02:43,856 --> 01:02:48,766
Uh, you're, you're going out there and securing capacity that you're renting from the neo-clouds

1452
01:02:48,766 --> 01:02:50,706
um, rather than having built it yourself.

1453
01:02:50,706 --> 01:02:54,126
What was the, what was- I think it's f- it's fine for us because we now have it

1454
01:02:54,126 --> 01:02:56,846
you know, when you have line of sight to demand

1455
01:02:56,846 --> 01:02:58,796
which can be so where people are building it

1456
01:02:58,796 --> 01:02:59,406
it's great.

1457
01:02:59,406 --> 01:03:01,766
In fact, we'll even have, I would say

1458
01:03:01,766 --> 01:03:05,646
you know, we will take leases, we will take build-to-suit

1459
01:03:05,646 --> 01:03:09,236
we'll take even GPU-as-a-service where we don't have capacity

1460
01:03:09,236 --> 01:03:11,846
but we need capacity and someone else has that.

1461
01:03:11,846 --> 01:03:17,626
Uh, and by the way, I would even sort of welcome every neo-cloud to just be part of our marketplace.

1462
01:03:17,626 --> 01:03:19,566
Uh, because again, g- guess what?

1463
01:03:19,566 --> 01:03:22,506
If they, if they go bring their capacity into our marketplace

1464
01:03:22,506 --> 01:03:25,326
that customer who comes through Azure will use the neo-cloud

1465
01:03:25,326 --> 01:03:29,966
which is a great win for them, and we'll use compute storage databases

1466
01:03:29,966 --> 01:03:31,166
all the rest from Azure.

1467
01:03:31,166 --> 01:03:34,366
So I'm not at all thinking of this as just a

1468
01:03:34,366 --> 01:03:37,223
you know, "Hey, I should just go gobble up all of that myself.

1469
01:03:37,223 --> 01:03:38,006
" Hmm.

1470
01:03:38,006 --> 01:03:41,006
Um, uh, so you mentioned the co- how

1471
01:03:41,006 --> 01:03:44,046
the, you know, you're depreciating this asset that's five

1472
01:03:44,046 --> 01:03:46,536
six years, and this is the majority of the

1473
01:03:46,536 --> 01:03:49,466
you know, 75% of the TCO of a data center

1474
01:03:49,466 --> 01:03:53,086
and Jensen is taking a 75% margin on that.

1475
01:03:53,086 --> 01:04:01,066
So what all the hyperscalers are trying to do is develop their own accelerator so that they can reduce this overwhelming cost for

1476
01:04:01,066 --> 01:04:03,906
um, uh, equipment to increase their margins.

1477
01:04:03,906 --> 01:04:04,126
Yeah.

1478
01:04:04,126 --> 01:04:05,286
And then, and then like, you know

1479
01:04:05,286 --> 01:04:06,646
when you look at where they are, right?

1480
01:04:06,646 --> 01:04:08,166
Google's way ahead of everyone else, right?

1481
01:04:08,166 --> 01:04:09,546
They've been doing it for the longest.

1482
01:04:09,546 --> 01:04:12,166
They're gonna make something like five to seven million chips

1483
01:04:12,166 --> 01:04:12,486
right?

1484
01:04:12,486 --> 01:04:13,826
Of their own TPUs.

1485
01:04:13,826 --> 01:04:16,066
You look at Amazon, they're trying to make three to five million.

1486
01:04:16,066 --> 01:04:17,455
Uh, but when we look at what

1487
01:04:17,455 --> 01:04:19,766
you know, Microsoft is, is ordering of their own chips

1488
01:04:19,766 --> 01:04:22,386
it's, it's, it's way below that number.

1489
01:04:22,386 --> 01:04:24,706
Um, you've had a program for just as long

1490
01:04:24,706 --> 01:04:26,756
what's going on with your internal chips?

1491
01:04:26,756 --> 01:04:26,756
Yeah.

1492
01:04:26,756 --> 01:04:27,066
That's a good question.

1493
01:04:27,066 --> 01:04:35,986
So, so the couple of things, one is the thing that is the biggest competitor for any new accelerator is kind of even the previous generation of NVIDIA

1494
01:04:35,986 --> 01:04:36,146
right?

1495
01:04:36,146 --> 01:04:39,506
I mean, in a fleet, what I'm going to look at is the overall TCO.

1496
01:04:39,506 --> 01:04:41,526
So the bar I have even for our own

1497
01:04:41,526 --> 01:04:42,856
and which by the way, you know

1498
01:04:42,856 --> 01:04:45,206
just looking at the data for Maia 200

1499
01:04:45,206 --> 01:04:51,566
which looks great, um, e- e- except that one of the things that we learned even on the compute side

1500
01:04:51,566 --> 01:04:51,726
right?

1501
01:04:51,726 --> 01:04:53,086
Which is we had a lot of Intel

1502
01:04:53,086 --> 01:04:55,726
then we introduced AMD, and then we introduced Cobalt.

1503
01:04:55,726 --> 01:04:58,106
And so that's kind of how we scaled it.

1504
01:04:58,106 --> 01:05:07,696
And so we have good, um, sort of existence proof of at least in core compute on how to build your own silicon and then manage a fleet where all three are at play in some balance.

1505
01:05:07,696 --> 01:05:11,136
Uh, because by the way, even Google's buying NVIDIA and so is

1506
01:05:11,136 --> 01:05:11,886
uh, Amazon.

1507
01:05:11,886 --> 01:05:16,306
And it makes sense because NVIDIA is innovating and it's the general-purpose thing.

1508
01:05:16,306 --> 01:05:20,006
All models run on it, uh, and customer demand is there

1509
01:05:20,006 --> 01:05:22,726
because if you build your own vertical thing

1510
01:05:22,726 --> 01:05:24,836
you better have your own model, uh

1511
01:05:24,836 --> 01:05:27,606
which is, you know, either going to use it for training or inference

1512
01:05:27,606 --> 01:05:30,946
and you have to generate your own demand for it or subsidize the demand for it.

1513
01:05:30,946 --> 01:05:33,436
So therefore, you want to, uh, make sure

1514
01:05:33,436 --> 01:05:35,346
um, you scale it appropriately.

1515
01:05:35,346 --> 01:05:37,416
So the way we are going to go do it is

1516
01:05:37,416 --> 01:05:45,576
um, have a closed loop between our own MAI models and our silicon because I feel like that's the re- that

1517
01:05:45,576 --> 01:05:49,486
that's what gives you the birthright to really do your own silicon

1518
01:05:49,486 --> 01:05:49,666
right?

1519
01:05:49,666 --> 01:05:55,686
Where you literally have, uh, designed the microarchitecture with what you're doing

1520
01:05:55,686 --> 01:05:57,796
and then you keep pace with your own models.

1521
01:05:57,796 --> 01:06:03,186
Um, in our case, the good, the good news here is OpenAI has a program

1522
01:06:03,186 --> 01:06:05,056
uh, which we have access to.

1523
01:06:05,056 --> 01:06:10,106
Um, and so therefore, to think that Microsoft is not going to have something that's sca- What level of access do you have to that?

1524
01:06:10,106 --> 01:06:10,906
All of it.

1525
01:06:10,906 --> 01:06:12,106
You just get the IP for all of that?

1526
01:06:12,106 --> 01:06:12,456
Yeah, yeah.

1527
01:06:12,456 --> 01:06:14,846
So the only IP you don't have is a consumer hardware?

1528
01:06:14,846 --> 01:06:15,666
That's it.

1529
01:06:15,666 --> 01:06:16,006
Oh, wow.

1530
01:06:16,006 --> 01:06:16,586
Okay.

1531
01:06:16,586 --> 01:06:17,536
 Yeah.

1532
01:06:17,536 --> 01:06:19,486
Interesting.

1533
01:06:19,486 --> 01:06:20,336
 Yeah.

1534
01:06:20,336 --> 01:06:22,446
Oh, and by the way, we gave them a

1535
01:06:22,446 --> 01:06:24,966
a bunch of IP as well to bootstrap them

1536
01:06:24,966 --> 01:06:25,166
right?

1537
01:06:25,166 --> 01:06:28,033
So this is one of the reasons why they had a mass.

1538
01:06:28,033 --> 01:06:28,116
..

1539
01:06:28,116 --> 01:06:30,736
Because we built all these supercomputers together, uh

1540
01:06:30,736 --> 01:06:33,166
rebuilt it for them, and they, uh

1541
01:06:33,166 --> 01:06:35,086
benefited from it, rightfully so.

1542
01:06:35,086 --> 01:06:38,326
And, uh, and now as they innovate even at the system level

1543
01:06:38,326 --> 01:06:39,866
we get access to all of it.

1544
01:06:39,866 --> 01:06:44,786
Uh, and, uh, we first wants to in- e- want to instantiate what they build

1545
01:06:44,786 --> 01:06:46,946
uh, for them.

1546
01:06:46,946 --> 01:06:48,006
Uh, but then we'll extend it.

1547
01:06:48,006 --> 01:06:49,747
And so to think that we don't have.

1548
01:06:49,747 --> 01:06:49,876
..

1549
01:06:49,876 --> 01:06:51,206
And so if anything, the way I

1550
01:06:51,206 --> 01:06:53,356
I think about to your question is,  uh

1551
01:06:53,356 --> 01:06:57,586
Microsoft wants to be a fantastic, I'll call it

1552
01:06:57,586 --> 01:07:02,106
speed of light execution partner for NVIDIA, because quite frankly

1553
01:07:02,106 --> 01:07:05,046
that fleet, uh, is life itself.

1554
01:07:05,046 --> 01:07:05,893
I'm not worried about.

1555
01:07:05,893 --> 01:07:05,956
..

1556
01:07:05,956 --> 01:07:08,546
I mean, obviously, Jensen's doing super well with his margins

1557
01:07:08,546 --> 01:07:10,666
but the TCO has many dimensions to it

1558
01:07:10,666 --> 01:07:13,086
and I want to be great at that TCO.

1559
01:07:13,086 --> 01:07:18,956
Uh, on top of that, I want to be able to sort of really work with the OpenAI lineage

1560
01:07:18,956 --> 01:07:25,786
uh, and the MAI lineage, and the system design knowing that we have the IP rights on both ends.

1561
01:07:25,786 --> 01:07:26,526
 Hmm.

1562
01:07:26,526 --> 01:07:28,426
Um, uh, sp- speaking of rights, one thing

1563
01:07:28,426 --> 01:07:30,746
you know, you had an interview a couple of days ago

1564
01:07:30,746 --> 01:07:34,946
uh, where you said that we have rights to the

1565
01:07:34,946 --> 01:07:36,486
the, the new agreement you made with OpenAI

1566
01:07:36,486 --> 01:07:39,031
you have rights to, the exclusivity to-.

1567
01:07:39,031 --> 01:07:39,404
..

1568
01:07:39,404 --> 01:07:43,014
the stateless API calls that OpenAI makes.

1569
01:07:43,014 --> 01:07:46,863
And we were sort of confused about if there's any state whatsoever.

1570
01:07:46,863 --> 01:07:53,934
I mean, you were just mentioning a second ago that all these complicated workloads that are coming up are gonna require memory and databases and storage and so forth.

1571
01:07:53,934 --> 01:07:56,204
And is that now not stateless?

1572
01:07:56,204 --> 01:07:57,804
Or ChatGPT is storing stuff, run sessions- No

1573
01:07:57,804 --> 01:07:58,714
but that's the reason why.

1574
01:07:58,714 --> 01:08:02,374
So the, the thing, the business, the strategic decision we made

1575
01:08:02,374 --> 01:08:08,394
and also accommodating for the flexibility OpenAI needed in order to be able to procure compute for.

1576
01:08:08,394 --> 01:08:08,504
..

1577
01:08:08,504 --> 01:08:11,933
Essentially, think of O- OpenAI having, um

1578
01:08:11,933 --> 01:08:14,554
a PasS business and a SaaS business.

1579
01:08:14,554 --> 01:08:18,434
SaaS business is ChatGPT, their PasS business is their API.

1580
01:08:18,434 --> 01:08:18,953
Yeah.

1581
01:08:18,953 --> 01:08:22,194
That API is Azure-exclusive.

1582
01:08:22,194 --> 01:08:25,412
The SaaS business, they can run it anywhere.

1583
01:08:25,412 --> 01:08:28,334
And they can partner with anyone they want to to build SaaS products?

1584
01:08:28,334 --> 01:08:30,354
They, so if they want a partner

1585
01:08:30,354 --> 01:08:33,694
and this partner wants to use a s- a stateless API

1586
01:08:33,694 --> 01:08:36,894
then Azure is the place where they can get the stateless API.

1587
01:08:36,894 --> 01:08:39,493
I- it seems like there's a way for them to make you

1588
01:08:39,493 --> 01:08:41,403
you, you know, build the product together and

1589
01:08:41,403 --> 01:08:41,984
and it's a stateful thing.

1590
01:08:41,984 --> 01:08:44,014
No, even that, they'll have to come to Azure.

1591
01:08:44,014 --> 01:08:44,314
Okay.

1592
01:08:44,314 --> 01:08:45,978
So if it is any partner.

1593
01:08:45,978 --> 01:08:46,124
..

1594
01:08:46,124 --> 01:08:49,054
And so, so fundamentally, you know, so l- again

1595
01:08:49,054 --> 01:08:54,234
this is done in the spirit of, what is it that we valued as part of our partnership?

1596
01:08:54,234 --> 01:08:57,834
And we made sure while at the same time we were good partners to OpenAI

1597
01:08:57,834 --> 01:08:59,444
given all the flexibility they need.

1598
01:08:59,444 --> 01:09:01,814
So, so for example, Salesforce wants to integrate OpenAI.

1599
01:09:01,814 --> 01:09:02,754
It's not through an API.

1600
01:09:02,754 --> 01:09:04,823
They actually work together, train a model together

1601
01:09:04,823 --> 01:09:07,453
deploy it on, let's say, Amazon now.

1602
01:09:07,453 --> 01:09:08,412
Is that, is that allowed?

1603
01:09:08,412 --> 01:09:10,294
Or, uh, or do they have to use your- No

1604
01:09:10,294 --> 01:09:14,514
for any custom agreement like that, they will have to come run it.

1605
01:09:14,514 --> 01:09:17,754
There, there are some few exceptions to US government and so on that we made

1606
01:09:17,754 --> 01:09:19,874
but other than that, they'll have to come to Azure.

1607
01:09:19,874 --> 01:09:23,134
So as Satya explained, as AI agents get more capable

1608
01:09:23,134 --> 01:09:26,234
you're gonna need more and more observability into what they're doing.

1609
01:09:26,234 --> 01:09:28,254
You're gonna need to catch them when they're making mistakes

1610
01:09:28,254 --> 01:09:30,874
you're gonna need high-level summaries of what they're doing

1611
01:09:30,874 --> 01:09:34,314
and you're gonna need a picture of how everything that they're doing fits together.

1612
01:09:34,314 --> 01:09:36,912
This is exactly what CodeRabbit provides.

1613
01:09:36,912 --> 01:09:41,754
You just make a normal pull request and CodeRabbit automatically reviews the PR.

1614
01:09:41,754 --> 01:09:46,153
It generates a summary of changes so you can understand exactly what the PR's author was intending

1615
01:09:46,153 --> 01:09:52,234
and it uses the context from your full code base to provide line-by-line feedback on how things could be improved.

1616
01:09:52,234 --> 01:09:57,034
This is helpful whether you're viewing a PR from a coworker or an agent.

1617
01:09:57,034 --> 01:10:04,094
In either case, CodeRabbit will write up its thoughts and flag any issues so that your teammate or your agent can go fix them.

1618
01:10:04,094 --> 01:10:06,234
I've noticed that when I'm coding with agents

1619
01:10:06,234 --> 01:10:10,614
CodeRabbit catches a lot of mistakes that the models make by default.

1620
01:10:10,614 --> 01:10:15,414
For example, the models have a bad habit of using old versions of libraries.

1621
01:10:15,414 --> 01:10:19,714
So in one session, I watched CodeRabbit catch a call to a

1622
01:10:19,714 --> 01:10:22,754
an old model, figure out what the new version was

1623
01:10:22,754 --> 01:10:24,894
and then suggest that improvement.

1624
01:10:24,894 --> 01:10:26,926
Go to coderabbit.

1625
01:10:26,926 --> 01:10:30,003
ai/thwarkash to learn more.

1626
01:10:30,003 --> 01:10:31,494
Stepping back, a question I have is

1627
01:10:31,494 --> 01:10:32,244
you know, when we were t- uh

1628
01:10:32,244 --> 01:10:34,934
w- walking back and forth, uh, at the factory

1629
01:10:34,934 --> 01:10:36,754
one of the things you were talking about is

1630
01:10:36,754 --> 01:10:39,454
you know, uh, Microsoft, you can think of it as a software business

1631
01:10:39,454 --> 01:10:41,834
but now it's really becoming an industrial business.

1632
01:10:41,834 --> 01:10:45,054
Uh, there's all this capex, there's all this construction.

1633
01:10:45,054 --> 01:10:47,264
And if you just look over the last two y- t- um

1634
01:10:47,264 --> 01:10:49,294
two years, your sort of capex has

1635
01:10:49,294 --> 01:10:50,574
like, tripled.

1636
01:10:50,574 --> 01:10:55,723
And maybe you extrapolate that forward, it just actually just becomes this huge industrial

1637
01:10:55,723 --> 01:10:56,384
uh, explosion.

1638
01:10:56,384 --> 01:10:58,134
U- Other hyperscalers are taking loans, right?

1639
01:10:58,134 --> 01:11:00,734
Meta's, Meta's done a $20 billion loan at Louisiana.

1640
01:11:00,734 --> 01:11:02,594
They've taken, they've done a corporate loan.

1641
01:11:02,594 --> 01:11:05,054
It s- seems clear everyone's free cash flow is going to zero.

1642
01:11:05,054 --> 01:11:07,864
 Um, which is, which is, I'm sure Amy is

1643
01:11:07,864 --> 01:11:09,170
like, gonna beat you up for-  .

1644
01:11:09,170 --> 01:11:09,184
..

1645
01:11:09,184 --> 01:11:10,654
for even, if you even try to do that.

1646
01:11:10,654 --> 01:11:12,934
But, like, uh, what- what- what's happening?

1647
01:11:12,934 --> 01:11:16,854
I mean, I think, uh, I think the structural change

1648
01:11:16,854 --> 01:11:21,014
um, is what you're referencing, which I think is massive

1649
01:11:21,014 --> 01:11:21,174
right?

1650
01:11:21,174 --> 01:11:24,223
Which is, I, I describe it as we are now a

1651
01:11:24,223 --> 01:11:27,494
a capital-intensive business and a knowledge-intensive business.

1652
01:11:27,494 --> 01:11:32,034
And in fact, we have to use our knowledge to increase the ROIC on the capital spent

1653
01:11:32,034 --> 01:11:32,204
right?

1654
01:11:32,204 --> 01:11:33,155
Because that's gonna.

1655
01:11:33,155 --> 01:11:33,283
..

1656
01:11:33,283 --> 01:11:35,374
You know, look, the hardware guys have done a great job

1657
01:11:35,374 --> 01:11:40,034
uh, of marketing the Moore's Law, which I think is unbelievable and it's great.

1658
01:11:40,034 --> 01:11:43,434
But if you even look, I think some of the stats I even did in my earnings call

1659
01:11:43,434 --> 01:11:46,144
which is for a given GPT family, right?

1660
01:11:46,144 --> 01:11:53,734
Uh, the improvement, software improvements of really throughput in terms of tokens per dollar per watt that we're able to get

1661
01:11:53,734 --> 01:11:56,274
uh, y- you know, quarter over quarter

1662
01:11:56,274 --> 01:11:57,974
year over year, is massive.

1663
01:11:57,974 --> 01:11:58,784
Uh, right?

1664
01:11:58,784 --> 01:12:02,034
So it's 5X, 10X, maybe 40X in some of these cases

1665
01:12:02,034 --> 01:12:02,214
right?

1666
01:12:02,214 --> 01:12:04,994
Just because how you can optimize.

1667
01:12:04,994 --> 01:12:07,974
That's s- sort of knowledge intense- Yeah.

1668
01:12:07,974 --> 01:12:07,984
.

1669
01:12:07,984 --> 01:12:07,984
..

1670
01:12:07,984 --> 01:12:11,254
intensity coming to bring out capital efficiency.

1671
01:12:11,254 --> 01:12:14,234
So that, at, at some level, the

1672
01:12:14,234 --> 01:12:15,654
that's what we have to master.

1673
01:12:15,654 --> 01:12:16,314
What does it mean?

1674
01:12:16,314 --> 01:12:18,704
Like, so many people ask me, "What is the difference between

1675
01:12:18,704 --> 01:12:21,854
uh, you know, a classic, old-time host

1676
01:12:21,854 --> 01:12:23,118
uh, and a hyperscaler?

1677
01:12:23,118 --> 01:12:24,654
" It is software.

1678
01:12:24,654 --> 01:12:29,034
So yes, it is capital-intensive, but as long as you have systems

1679
01:12:29,034 --> 01:12:33,374
know-how, software capability to optimize by workload

1680
01:12:33,374 --> 01:12:34,214
by fleet.

1681
01:12:34,214 --> 01:12:37,104
That's why I think when, when we say fungibility

1682
01:12:37,104 --> 01:12:38,724
there's so much software in it.

1683
01:12:38,724 --> 01:12:40,204
It's just not about the fleet, right?

1684
01:12:40,204 --> 01:12:42,634
It's kind of the ability to evict a workload

1685
01:12:42,634 --> 01:12:45,334
uh, you know, and then schedule another workload.

1686
01:12:45,334 --> 01:12:50,574
Can I, like, manage the, that algorithm of scheduling around?

1687
01:12:50,574 --> 01:12:53,834
Uh, that is the type of stuff that we have to be world-class at.

1688
01:12:53,834 --> 01:12:56,804
And so yes, so I think we'll still remain a software company.

1689
01:12:56,804 --> 01:12:57,274
Mm-hmm.

1690
01:12:57,274 --> 01:12:59,324
Uh, but yes, this is a different business.

1691
01:12:59,324 --> 01:13:00,643
Um, and we're gonna manage.

1692
01:13:00,643 --> 01:13:02,354
Look, I think at the end of the day

1693
01:13:02,354 --> 01:13:07,234
uh, the cash flow that Microsoft has allows us to have

1694
01:13:07,234 --> 01:13:10,574
um, both these arms firing on, you know

1695
01:13:10,574 --> 01:13:11,494
uh, well.

1696
01:13:11,494 --> 01:13:12,154
Mm.

1697
01:13:12,154 --> 01:13:13,654
I- it seems like in the short term

1698
01:13:13,654 --> 01:13:17,354
you have more sort of, um, credence on things taking a while

1699
01:13:17,354 --> 01:13:18,334
being more jagged.

1700
01:13:18,334 --> 01:13:19,724
But in the, maybe in the long term

1701
01:13:19,724 --> 01:13:21,484
you think, like, the people who say

1702
01:13:21,484 --> 01:13:23,214
talk about AGI and ASI are correct.

1703
01:13:23,214 --> 01:13:25,514
Like Sam, Sam will be right, but eventually.

1704
01:13:25,514 --> 01:13:30,754
Um, and I, I have a broader question about what makes sense for a hyperscaler to do

1705
01:13:30,754 --> 01:13:35,854
given that you have to invest massively in this thing which depreciates over five years.

1706
01:13:35,854 --> 01:13:37,824
So s- uh, so if you, if you have 20

1707
01:13:37,824 --> 01:13:42,354
40 timelines for the kind of thing that somebody like Sam anticipates in three years

1708
01:13:42,354 --> 01:13:46,874
um, you know, what- what is a reasonable thing for you to do in that world?

1709
01:13:46,874 --> 01:13:49,544
There needs to be an allocation, uh

1710
01:13:49,544 --> 01:13:51,578
to I'll call it research compute.

1711
01:13:51,578 --> 01:13:51,724
..

1712
01:13:51,724 --> 01:13:52,349
Mm-hmm.

1713
01:13:52,349 --> 01:13:52,519
..

1714
01:13:52,519 --> 01:13:56,434
. that needs to be done like you did R&D.

1715
01:13:56,434 --> 01:13:56,754
Yeah.

1716
01:13:56,754 --> 01:13:56,994
Right?

1717
01:13:56,994 --> 01:13:59,114
So, that's the best way to even account for it

1718
01:13:59,114 --> 01:13:59,674
quite frankly.

1719
01:13:59,674 --> 01:14:01,784
We should think of it as just R&D expense.

1720
01:14:01,784 --> 01:14:05,379
And you should say, "Hey, what's the research computing or how do you want to scale it?

1721
01:14:05,379 --> 01:14:06,214
" Yeah.

1722
01:14:06,214 --> 01:14:11,234
Um, and let's even say it's an order of magnitude scale

1723
01:14:11,234 --> 01:14:12,773
um, in some period.

1724
01:14:12,773 --> 01:14:13,454
Pick your thing.

1725
01:14:13,454 --> 01:14:13,514
Yeah.

1726
01:14:13,514 --> 01:14:14,474
Is it two years?

1727
01:14:14,474 --> 01:14:15,774
Is it 16 months?

1728
01:14:15,774 --> 01:14:16,634
What have you, right?

1729
01:14:16,634 --> 01:14:19,474
So, that's sort of one piece, which is kind of

1730
01:14:19,474 --> 01:14:20,654
that's kind of table stakes.

1731
01:14:20,654 --> 01:14:22,434
That's R&D expenses.

1732
01:14:22,434 --> 01:14:24,834
And the rest is all demand driven, right?

1733
01:14:24,834 --> 01:14:27,254
I mean, ultimately you can, you don't have to build ahead of demand

1734
01:14:27,254 --> 01:14:28,824
but you better have a demand, uh

1735
01:14:28,824 --> 01:14:33,414
uh, plan, uh, that doesn't go completely off-kilter.

1736
01:14:33,414 --> 01:14:33,834
Do you buy.

1737
01:14:33,834 --> 01:14:33,924
..

1738
01:14:33,924 --> 01:14:38,544
So, these labs are now projecting revenues of 100 billion in '27

1739
01:14:38,544 --> 01:14:40,834
'28, uh, and they're projecting, you know

1740
01:14:40,834 --> 01:14:42,534
revenue keeps growing at this rate of, like

1741
01:14:42,534 --> 01:14:43,994
3X, 2X a year.

1742
01:14:43,994 --> 01:14:44,180
So there's lo-.

1743
01:14:44,180 --> 01:14:44,244
..

1744
01:14:44,244 --> 01:14:48,534
In the marketplace, right, there's all kinds of incentives right now and

1745
01:14:48,534 --> 01:14:49,794
and rightfully so, right?

1746
01:14:49,794 --> 01:14:54,754
I mean, what, what do you expect an independent lab that is sort of trying to raise money to do

1747
01:14:54,754 --> 01:14:54,934
right?

1748
01:14:54,934 --> 01:15:01,584
They have to put some numbers out there such that they can actually go raise money so that they can pay their bills for compute- Yeah.

1749
01:15:01,584 --> 01:15:01,584
.

1750
01:15:01,584 --> 01:15:01,584
.

1751
01:15:01,584 --> 01:15:02,014
and what have you.

1752
01:15:02,014 --> 01:15:03,634
And it's, and it's good thing.

1753
01:15:03,634 --> 01:15:06,754
I mean, someone's going to take some risk and put it in there

1754
01:15:06,754 --> 01:15:08,184
and they've shown traction.

1755
01:15:08,184 --> 01:15:08,184
Yeah.

1756
01:15:08,184 --> 01:15:13,094
It's not like it's all risk without seeing the fact that they've been performing.

1757
01:15:13,094 --> 01:15:13,104
Yeah.

1758
01:15:13,104 --> 01:15:17,094
Whether it's OpenAI, whether it's Anthropic, so I feel great about what they've done.

1759
01:15:17,094 --> 01:15:19,834
Uh,  and we have massive book of business with these chaps.

1760
01:15:19,834 --> 01:15:19,844
Yeah.

1761
01:15:19,844 --> 01:15:22,014
So, therefore, uh, that's all good.

1762
01:15:22,014 --> 01:15:26,354
But overall, ultimately, there's two simple things.

1763
01:15:26,354 --> 01:15:28,334
One is you got to allocate for R&D.

1764
01:15:28,334 --> 01:15:30,234
You brought up even talent, you got to sp-.

1765
01:15:30,234 --> 01:15:30,384
..

1766
01:15:30,384 --> 01:15:32,114
Like, the talent for AI- Yeah.

1767
01:15:32,114 --> 01:15:32,124
.

1768
01:15:32,124 --> 01:15:32,124
..

1769
01:15:32,124 --> 01:15:33,074
is at a premium.

1770
01:15:33,074 --> 01:15:34,614
You got to spend there.

1771
01:15:34,614 --> 01:15:36,814
You got to spend on compute, so in some sense

1772
01:15:36,814 --> 01:15:40,454
researcher to GPU  ratios have to be high.

1773
01:15:40,454 --> 01:15:45,454
Uh, that is sort of what it takes to be a leading R&D company in this world

1774
01:15:45,454 --> 01:15:48,274
uh, and that's something that needs to scale

1775
01:15:48,274 --> 01:15:54,334
um, and you have to have a balance sheet that allows you to scale that long before it's conventional wisdom and so on.

1776
01:15:54,334 --> 01:15:56,274
So, that's kind of one thing.

1777
01:15:56,274 --> 01:16:01,134
But the other is all about sort of knowing how to forecast.

1778
01:16:01,134 --> 01:16:02,734
A- as we look across the world, right

1779
01:16:02,734 --> 01:16:05,934
America has dominated many tech stacks, right?

1780
01:16:05,934 --> 01:16:09,474
Um, the US owns Windows, right, through Microsoft

1781
01:16:09,474 --> 01:16:11,214
which is deployed even in China, right?

1782
01:16:11,214 --> 01:16:12,854
That's the main operating system.

1783
01:16:12,854 --> 01:16:14,654
Um, of course, there's Linux, which is open source

1784
01:16:14,654 --> 01:16:18,264
but, you know, Windows is deployed everywhere in China on personal computers.

1785
01:16:18,264 --> 01:16:19,994
Um, you look at, you look at Word

1786
01:16:19,994 --> 01:16:21,014
it's, it's deployed everywhere.

1787
01:16:21,014 --> 01:16:23,854
You look at all these various technologies, it's deployed everywhere.

1788
01:16:23,854 --> 01:16:26,094
The thing that is quite unique and, and

1789
01:16:26,094 --> 01:16:28,494
and Microsoft and other companies have grown elsewhere

1790
01:16:28,494 --> 01:16:28,683
right?

1791
01:16:28,683 --> 01:16:31,944
They've built, they're building data centers in Europe and in India and then

1792
01:16:31,944 --> 01:16:32,984
and then all these other, you know

1793
01:16:32,984 --> 01:16:35,554
in Southeast Asia and in LATAM and Africa

1794
01:16:35,554 --> 01:16:36,074
right?

1795
01:16:36,074 --> 01:16:39,044
All of these different places you're building capacity

1796
01:16:39,044 --> 01:16:40,494
but this seems quite different, right?

1797
01:16:40,494 --> 01:16:46,183
You know, t- today the political aspect of technology

1798
01:16:46,183 --> 01:16:46,714
of comput-.

1799
01:16:46,714 --> 01:16:46,804
..

1800
01:16:46,804 --> 01:16:50,074
You know, you know, the, the US administration didn't care about the dot-com bubble

1801
01:16:50,074 --> 01:16:50,714
right?

1802
01:16:50,714 --> 01:16:56,754
Um, it seems like the US administration as well as every other administration around the world cares a lot about AI.

1803
01:16:56,754 --> 01:16:58,085
And the question is, you know, we've.

1804
01:16:58,085 --> 01:16:58,123
..

1805
01:16:58,123 --> 01:16:59,494
we're in a sort of a bipolar world

1806
01:16:59,494 --> 01:17:02,824
at least with US and China, but Europe and

1807
01:17:02,824 --> 01:17:04,864
and India and all these other countries are

1808
01:17:04,864 --> 01:17:07,259
are saying, "No, actually, we're going to have sovereign AI as well.

1809
01:17:07,259 --> 01:17:12,954
" How does Microsoft navigate, you know, the difference of the '90s where it's like there's one country in the world that matters

1810
01:17:12,954 --> 01:17:13,114
right?

1811
01:17:13,114 --> 01:17:13,644
It's America.

1812
01:17:13,644 --> 01:17:14,199
And we do.

1813
01:17:14,199 --> 01:17:14,403
..

1814
01:17:14,403 --> 01:17:17,634
Our companies sell everywhere, and therefore Microsoft benefits massively

1815
01:17:17,634 --> 01:17:19,944
to a world where it is bipolar, where

1816
01:17:19,944 --> 01:17:24,864
hey, Microsoft can't just necessarily have the right to win all of Europe or India or

1817
01:17:24,864 --> 01:17:25,903
you know, Singapore.

1818
01:17:25,903 --> 01:17:27,984
There's actually sovereign AI efforts.

1819
01:17:27,984 --> 01:17:29,354
What, what is your thought process here?

1820
01:17:29,354 --> 01:17:30,334
That's a great- How do you think about this?

1821
01:17:30,334 --> 01:17:32,654
It's, it's, I think, a, a super

1822
01:17:32,654 --> 01:17:35,054
 you know, critical, um, piece

1823
01:17:35,054 --> 01:17:35,924
which is.

1824
01:17:35,924 --> 01:17:36,344
..

1825
01:17:36,344 --> 01:17:48,314
Um, I think that the key, key priority for the US tech sector and the US government is to ensure that we not only do leading innovative work

1826
01:17:48,314 --> 01:17:55,554
but we also collectively build trust around the world on our tech stack

1827
01:17:55,554 --> 01:17:55,764
right?

1828
01:17:55,764 --> 01:17:59,694
Because I always say the United States is just an unbelievable place

1829
01:17:59,694 --> 01:18:01,794
it's just unique in history, right?

1830
01:18:01,794 --> 01:18:05,634
It's 4% of the world's population, 25% of the GDP

1831
01:18:05,634 --> 01:18:10,133
and 50% of the market cap, and I think you should think about those ratios and

1832
01:18:10,133 --> 01:18:11,994
uh, really,  and reflect on it.

1833
01:18:11,994 --> 01:18:18,414
That 50% happens because, quite frankly, the trust the world has in the United States

1834
01:18:18,414 --> 01:18:21,964
whether it's its capital markets or whether it's its technology and

1835
01:18:21,964 --> 01:18:27,574
and its stewardship of what matters at any given time in terms of leading

1836
01:18:27,574 --> 01:18:29,374
uh, sector.

1837
01:18:29,374 --> 01:18:34,354
So, if that is broken, uh, then that's not a good day for the United States.

1838
01:18:34,354 --> 01:18:35,894
And so, if we start with that

1839
01:18:35,894 --> 01:18:38,614
which I think the, you know, President Trump gets

1840
01:18:38,614 --> 01:18:41,994
the White House, David Sachs, everyone, uh

1841
01:18:41,994 --> 01:18:43,814
really, I think gets it.

1842
01:18:43,814 --> 01:18:52,834
Uh, and so therefore, I applaud anything that the United States government and the tech sector jointly does to

1843
01:18:52,834 --> 01:18:59,334
quite frankly, for example, put our own capital at risk collectively as an industry in every part of the world

1844
01:18:59,334 --> 01:18:59,574
right?

1845
01:18:59,574 --> 01:19:07,634
So, I would like, in fact, the USG to take credit for foreign direct investment by American companies all over the world

1846
01:19:07,634 --> 01:19:07,814
right?

1847
01:19:07,814 --> 01:19:13,834
It's kind of like, uh, least talked about but the best marketing  that the United States should be doing is.

1848
01:19:13,834 --> 01:19:17,234
It's not just about all the foreign direct investment coming into the United States

1849
01:19:17,234 --> 01:19:21,953
but the most leading sector, which is these AI factories

1850
01:19:21,953 --> 01:19:24,434
are all being created all over the world by whom?

1851
01:19:24,434 --> 01:19:27,234
By America, uh, and American companies.

1852
01:19:27,234 --> 01:19:31,954
And so you start there, and then you even build other agreements around it

1853
01:19:31,954 --> 01:19:38,814
which are around their continuity, their legitimate sovereignty concerns around whether it's data residency

1854
01:19:38,814 --> 01:19:42,840
whether it's even what happens, um, uh-.

1855
01:19:42,840 --> 01:19:43,034
..

1856
01:19:43,034 --> 01:19:47,314
uh, for them to have real agency and guarantees

1857
01:19:47,314 --> 01:19:49,234
uh, on privacy and so on.

1858
01:19:49,234 --> 01:19:49,680
And so the.

1859
01:19:49,680 --> 01:19:49,744
..

1860
01:19:49,744 --> 01:19:51,694
In fact, our European commitments, I think

1861
01:19:51,694 --> 01:19:52,734
are worth reading, right?

1862
01:19:52,734 --> 01:20:01,354
So we made a series of commitments to Europe on how we will really govern our hyperscale investment there

1863
01:20:01,354 --> 01:20:06,754
uh, such that really European, uh, Union and the European countries have sovereignty.

1864
01:20:06,754 --> 01:20:10,654
We're also building sovereign clouds in, in France and in Germany.

1865
01:20:10,654 --> 01:20:13,954
We have something called Sovereign Services on Azure

1866
01:20:13,954 --> 01:20:19,514
which literally give people key management services along with confidential computing

1867
01:20:19,514 --> 01:20:24,724
including confidential computing in GPUs, which we have done great innovative work with NVIDIA.

1868
01:20:24,724 --> 01:20:26,246
Um, and so I think.

1869
01:20:26,246 --> 01:20:26,324
..

1870
01:20:26,324 --> 01:20:31,624
I feel very, very good about being able to build both technically

1871
01:20:31,624 --> 01:20:36,154
and through policy, this trust in the American tech stack.

1872
01:20:36,154 --> 01:20:36,894
Mm-hmm.

1873
01:20:36,894 --> 01:20:38,954
H- and how do you see this shaking out as

1874
01:20:38,954 --> 01:20:40,394
you know, you do have this, uh

1875
01:20:40,394 --> 01:20:43,474
network effect with continual learning and things on the model level

1876
01:20:43,474 --> 01:20:46,414
maybe you have equivalent things at the hyperscaler level as well

1877
01:20:46,414 --> 01:20:49,334
and do you expect that the countries will say

1878
01:20:49,334 --> 01:20:53,224
"Look, it's clear that one model or a couple models are the best and so we're gonna use them

1879
01:20:53,224 --> 01:20:54,774
but we're gonna have some laws around, well

1880
01:20:54,774 --> 01:20:56,700
the weights have to be hosted in our country.

1881
01:20:56,700 --> 01:20:58,704
" Or do you expect that there will be

1882
01:20:58,704 --> 01:21:00,935
uh, this push to have.

1883
01:21:00,935 --> 01:21:01,184
..

1884
01:21:01,184 --> 01:21:03,174
it has to be a model trained in our country?

1885
01:21:03,174 --> 01:21:05,124
Maybe an analogy here is like people would l- uh

1886
01:21:05,124 --> 01:21:09,224
you know, semiconductors are very important to the economy and people would like to have their sort of sovereign semiconductors

1887
01:21:09,224 --> 01:21:16,474
but, like, TSMC is just better and so semiconductors are so important to the economy that you will just go to Taiwan and buy the semiconductors.

1888
01:21:16,474 --> 01:21:17,314
You have to.

1889
01:21:17,314 --> 01:21:19,686
Will it be like that with AI or is there.

1890
01:21:19,686 --> 01:21:19,764
..

1891
01:21:19,764 --> 01:21:27,674
Um, ultimately, I think what matters is the use of AI in their economy to create economic value

1892
01:21:27,674 --> 01:21:27,874
right?

1893
01:21:27,874 --> 01:21:31,960
I mean, that's the, uh, the diffusion theory which is ultimately.

1894
01:21:31,960 --> 01:21:32,104
..

1895
01:21:32,104 --> 01:21:38,364
it's not the leading sector, but it's the ability to use the leading technology to create your own comparative advantage.

1896
01:21:38,364 --> 01:21:38,624
Yeah.

1897
01:21:38,624 --> 01:21:38,834
Right?

1898
01:21:38,834 --> 01:21:42,434
So that, I think, will fundamentally be the core driver.

1899
01:21:42,434 --> 01:21:45,054
But that said, they will want continuity of that

1900
01:21:45,054 --> 01:21:45,254
right?

1901
01:21:45,254 --> 01:21:49,854
So in some sense, that's one of the reasons why I believe there's always going to be a check

1902
01:21:49,854 --> 01:21:53,114
a little bit, to sort of some of your points on

1903
01:21:53,114 --> 01:21:56,554
hey, can this one model have all the runaway deployment?

1904
01:21:56,554 --> 01:21:59,194
I- that's why open source is always gonna be there.

1905
01:21:59,194 --> 01:22:03,294
There will be, by definition, uh, multiple models.

1906
01:22:03,294 --> 01:22:04,134
That'll be one way.

1907
01:22:04,134 --> 01:22:05,461
Like, it's kind of the, you know.

1908
01:22:05,461 --> 01:22:05,624
..

1909
01:22:05,624 --> 01:22:09,934
that's one way for people to sort of demand continuity and not have concentration risk

1910
01:22:09,934 --> 01:22:11,384
is another way to say it.

1911
01:22:11,384 --> 01:22:11,384
Yeah.

1912
01:22:11,384 --> 01:22:11,754
It is, right?

1913
01:22:11,754 --> 01:22:15,562
Um, and so you say, "Hey, I want multiple models and then I want an open source.

1914
01:22:15,562 --> 01:22:18,774
" So I feel, uh, as long as that's there

1915
01:22:18,774 --> 01:22:24,874
every country will feel like, okay, I don't have to worry about deploying the best model and broadly diffusing

1916
01:22:24,874 --> 01:22:30,164
because I can always take, uh, what is my data and my liquidity and move it

1917
01:22:30,164 --> 01:22:33,634
uh, to another model, whether it's open source or on

1918
01:22:33,634 --> 01:22:35,514
uh, from another country or what have you.

1919
01:22:35,514 --> 01:22:35,724
Mm-hmm.

1920
01:22:35,724 --> 01:22:39,414
So concentration risk, um, and sovereignty, right?

1921
01:22:39,414 --> 01:22:41,314
Which is really agency.

1922
01:22:41,314 --> 01:22:43,894
Those are the two things I think that'll drive the market structure.

1923
01:22:43,894 --> 01:22:47,154
The, the thing about this is that this doesn't exist for semiconductors

1924
01:22:47,154 --> 01:22:47,494
right?

1925
01:22:47,494 --> 01:22:47,524
Exactly.

1926
01:22:47,524 --> 01:22:50,744
You know, all refrigerators, cars have chips made in Taiwan.

1927
01:22:50,744 --> 01:22:52,354
It didn't exist until now.

1928
01:22:52,354 --> 01:22:54,387
Until now, everyone is now.

1929
01:22:54,387 --> 01:22:54,614
..

1930
01:22:54,614 --> 01:22:55,274
like, you know, like- Even, even then

1931
01:22:55,274 --> 01:22:55,414
right?

1932
01:22:55,414 --> 01:22:57,394
America, you know, if Taiwan is cut off

1933
01:22:57,394 --> 01:22:58,654
there is, there are no more cars

1934
01:22:58,654 --> 01:22:59,774
there are no more refrigerators.

1935
01:22:59,774 --> 01:23:04,264
TSMC Arizona is not replacing any real fraction of the production.

1936
01:23:04,264 --> 01:23:04,714
Like, they're.

1937
01:23:04,714 --> 01:23:04,764
..

1938
01:23:04,764 --> 01:23:05,272
it is, it, it.

1939
01:23:05,272 --> 01:23:05,304
..

1940
01:23:05,304 --> 01:23:05,626
they're.

1941
01:23:05,626 --> 01:23:05,704
..

1942
01:23:05,704 --> 01:23:07,474
the sovereignty is a bit of like a

1943
01:23:07,474 --> 01:23:08,494
a scam if you will, right?

1944
01:23:08,494 --> 01:23:09,974
 I mean, it's, it's worthwhile having it

1945
01:23:09,974 --> 01:23:12,018
it's important to have it, but it's not a real.

1946
01:23:12,018 --> 01:23:12,244
..

1947
01:23:12,244 --> 01:23:13,574
it's not real sovereignty, right?

1948
01:23:13,574 --> 01:23:14,614
And we're a global economy.

1949
01:23:14,614 --> 01:23:14,861
We don't.

1950
01:23:14,861 --> 01:23:14,904
..

1951
01:23:14,904 --> 01:23:15,112
we.

1952
01:23:15,112 --> 01:23:15,244
..

1953
01:23:15,244 --> 01:23:17,374
I think it's kind of like Dylan saying

1954
01:23:17,374 --> 01:23:21,134
"Hey, at this point, we've not learned anything about sort of

1955
01:23:21,134 --> 01:23:25,641
uh, res- what resilience means and what one needs to do

1956
01:23:25,641 --> 01:23:26,034
" right?

1957
01:23:26,034 --> 01:23:27,770
So it's kind of.

1958
01:23:27,770 --> 01:23:28,434
..

1959
01:23:28,434 --> 01:23:31,694
Any nation state, including the United States

1960
01:23:31,694 --> 01:23:39,994
at this point, will do what it takes to be more self-sufficient on some of these critical supply chains.

1961
01:23:39,994 --> 01:23:46,334
So I, as a multinational company, have to think about that as a first-class requirement

1962
01:23:46,334 --> 01:23:46,554
right?

1963
01:23:46,554 --> 01:23:55,414
If I don't, then I'm not respecting what is in the sort of policy interests of that country long term

1964
01:23:55,414 --> 01:23:55,734
right?

1965
01:23:55,734 --> 01:23:59,314
And I'm not saying they won't make practical decisions in the short term

1966
01:23:59,314 --> 01:23:59,514
right?

1967
01:23:59,514 --> 01:24:00,094
Absolutely.

1968
01:24:00,094 --> 01:24:02,374
I mean, the globalization can't just be rewound

1969
01:24:02,374 --> 01:24:02,614
right?

1970
01:24:02,614 --> 01:24:05,654
I mean, all these capital investments cannot be made

1971
01:24:05,654 --> 01:24:08,016
uh, in, in a way, at the pace at which.

1972
01:24:08,016 --> 01:24:08,124
..

1973
01:24:08,124 --> 01:24:09,696
But at the same time, you have to kind of.

1974
01:24:09,696 --> 01:24:09,804
..

1975
01:24:09,804 --> 01:24:10,264
Like, if I.

1976
01:24:10,264 --> 01:24:10,374
..

1977
01:24:10,374 --> 01:24:11,254
l- like, think about it, right?

1978
01:24:11,254 --> 01:24:12,974
If somebody showed up in Washington and said

1979
01:24:12,974 --> 01:24:13,914
"Hey, you know, you know what?

1980
01:24:13,914 --> 01:24:16,724
We're not gonna build any semiconductor plants.

1981
01:24:16,724 --> 01:24:18,734
" They're gonna be kicked out of the United States.

1982
01:24:18,734 --> 01:24:21,514
Um, and, and the same thing is gonna be

1983
01:24:21,514 --> 01:24:23,283
uh, true in every other country too.

1984
01:24:23,283 --> 01:24:25,954
Uh, and so therefore, I think we have to

1985
01:24:25,954 --> 01:24:29,954
as companies, respect what the lessons learned are

1986
01:24:29,954 --> 01:24:31,964
um, you know, whether it's, you know

1987
01:24:31,964 --> 01:24:34,524
you could say the pandemic woke us up or whatever.

1988
01:24:34,524 --> 01:24:34,657
But.

1989
01:24:34,657 --> 01:24:34,724
..

1990
01:24:34,724 --> 01:24:38,494
and nevertheless, people are saying, "Look, globalization was fantastic.

1991
01:24:38,494 --> 01:24:42,514
Uh, it helped supply chains be globalized and be super efficient.

1992
01:24:42,514 --> 01:24:45,386
But there's such a thing called resilience and we are happy.

1993
01:24:45,386 --> 01:24:45,504
..

1994
01:24:45,504 --> 01:24:46,949
you know, we want resilience.

1995
01:24:46,949 --> 01:24:50,494
" And so therefore, that feature will get built.

1996
01:24:50,494 --> 01:24:52,574
At what pace I think is the point you're making.

1997
01:24:52,574 --> 01:24:54,634
It can't be like you can't snap your fingers and say

1998
01:24:54,634 --> 01:24:59,364
"All the TSMC plants now are all in Arizona and with all of the capability.

1999
01:24:59,364 --> 01:25:00,534
" They're not going to be.

2000
01:25:00,534 --> 01:25:01,834
But is there a plan?

2001
01:25:01,834 --> 01:25:02,734
There will be a plan.

2002
01:25:02,734 --> 01:25:03,964
And should we respect that?

2003
01:25:03,964 --> 01:25:04,524
Absolutely.

2004
01:25:04,524 --> 01:25:06,981
And so I, I feel that's the world.

2005
01:25:06,981 --> 01:25:07,124
..

2006
01:25:07,124 --> 01:25:13,634
I wanna meet the world where it is and what it wants to do going forward

2007
01:25:13,634 --> 01:25:17,179
as opposed to say, "Hey, we have a point of view that doesn't respect your view.

2008
01:25:17,179 --> 01:25:17,894
" Mm-hmm.

2009
01:25:17,894 --> 01:25:19,594
So j- just to make sure I understand

2010
01:25:19,594 --> 01:25:25,254
th- the idea here is each country will want some kind of data residency

2011
01:25:25,254 --> 01:25:30,514
privacy, et cetera, and Microsoft is especially privileged here because you have relationships with these countries

2012
01:25:30,514 --> 01:25:34,814
you have expertise in setting up these kinds of sovereign data centers

2013
01:25:34,814 --> 01:25:35,719
and.

2014
01:25:35,719 --> 01:25:36,162
..

2015
01:25:36,162 --> 01:25:39,302
therefore, Microsoft is uniquely fit for a world with

2016
01:25:39,302 --> 01:25:42,001
um, more sovereignty requirements?

2017
01:25:42,001 --> 01:25:43,081
Yeah, I mean, like, I, I

2018
01:25:43,081 --> 01:25:46,422
I don't wanna sort of describe it as somehow we are uniquely privileged.

2019
01:25:46,422 --> 01:25:46,852
Yeah.

2020
01:25:46,852 --> 01:25:50,251
Uh, I would just say I think of that as a business requirement- I see.

2021
01:25:50,251 --> 01:25:50,251
.

2022
01:25:50,251 --> 01:25:50,251
.

2023
01:25:50,251 --> 01:25:53,102
that we have been doing all the hard work all these decades- Yeah.

2024
01:25:53,102 --> 01:25:53,112
.

2025
01:25:53,112 --> 01:25:53,112
..

2026
01:25:53,112 --> 01:25:54,112
and we will plan to.

2027
01:25:54,112 --> 01:25:57,142
And so my answer to Dylan's previous question was

2028
01:25:57,142 --> 01:25:59,015
I take these re-.

2029
01:25:59,015 --> 01:25:59,112
..

2030
01:25:59,112 --> 01:26:00,762
you know, whether it's in the United States

2031
01:26:00,762 --> 01:26:03,121
quite frankly, or, or when, you know

2032
01:26:03,121 --> 01:26:06,041
when the White House and the USG says

2033
01:26:06,041 --> 01:26:09,610
"Hey, we want you to allocate more of your

2034
01:26:09,610 --> 01:26:12,822
" I don't know, "wafer starts to, uh

2035
01:26:12,822 --> 01:26:14,929
uh, fabs in the US.

2036
01:26:14,929 --> 01:26:16,162
" We take that seriously.

2037
01:26:16,162 --> 01:26:19,581
Uh, or whether it is data center in the EU boundary

2038
01:26:19,581 --> 01:26:20,602
we take that seriously.

2039
01:26:20,602 --> 01:26:20,652
Yeah.

2040
01:26:20,652 --> 01:26:28,212
So to me, um, ma- respecting what I think are legitimate reasons why countries care about sovereignty- Yeah.

2041
01:26:28,212 --> 01:26:28,212
.

2042
01:26:28,212 --> 01:26:28,212
.

2043
01:26:28,212 --> 01:26:32,562
and building for it as a software and a physical plant is what I

2044
01:26:32,562 --> 01:26:33,652
I would say we are going to do.

2045
01:26:33,652 --> 01:26:33,952
Mm-hmm.

2046
01:26:33,952 --> 01:26:35,392
Uh, a- and as we go to

2047
01:26:35,392 --> 01:26:36,762
like, the bipolar world, right?

2048
01:26:36,762 --> 01:26:38,162
US, China- Yeah.

2049
01:26:38,162 --> 01:26:38,172
.

2050
01:26:38,172 --> 01:26:38,172
..

2051
01:26:38,172 --> 01:26:41,722
um, there is, there is a lot around

2052
01:26:41,722 --> 01:26:43,048
you know, American tech does not.

2053
01:26:43,048 --> 01:26:43,192
..

2054
01:26:43,192 --> 01:26:44,982
you know, it's not just you versus Amazon

2055
01:26:44,982 --> 01:26:46,902
um, or you versus, you know, Anthropic

2056
01:26:46,902 --> 01:26:48,052
or you versus Google.

2057
01:26:48,052 --> 01:26:48,322
Yeah.

2058
01:26:48,322 --> 01:26:51,762
There is a whole host of competi- com- competition.

2059
01:26:51,762 --> 01:26:54,562
How does, how does America rebuild the trust?

2060
01:26:54,562 --> 01:26:54,572
Great point.

2061
01:26:54,572 --> 01:26:56,562
What do you do to rebuild the trust to say

2062
01:26:56,562 --> 01:26:59,814
"Actually, no, American companies will be the main provider for you?

2063
01:26:59,814 --> 01:27:03,952
" Um, and how do you think about competition with up-and-coming Chinese companies

2064
01:27:03,952 --> 01:27:06,102
whether it be, you know, ByteDance and Alibaba

2065
01:27:06,102 --> 01:27:07,382
or DeepSeek and Moonshot?

2066
01:27:07,382 --> 01:27:09,112
And this is ju- just to add to the question

2067
01:27:09,112 --> 01:27:13,581
one concern is, look, we're talking about how AI is becoming this sort of industrial CapEx race

2068
01:27:13,581 --> 01:27:17,822
uh, where you're just rapidly having to build quickly across all those supply chain.

2069
01:27:17,822 --> 01:27:19,882
When you hear that, at least up until now

2070
01:27:19,882 --> 01:27:21,342
you just think about China, right?

2071
01:27:21,342 --> 01:27:23,342
This is, like, their comparative advantage.

2072
01:27:23,342 --> 01:27:23,352
Very much.

2073
01:27:23,352 --> 01:27:27,782
And especially if we're not gonna m- moonshot to ASI next year

2074
01:27:27,782 --> 01:27:28,316
but we.

2075
01:27:28,316 --> 01:27:28,432
..

2076
01:27:28,432 --> 01:27:31,222
it's gonna be this decades of build outs

2077
01:27:31,222 --> 01:27:32,251
and infrastructure- It's a great point.

2078
01:27:32,251 --> 01:27:32,251
.

2079
01:27:32,251 --> 01:27:32,251
.

2080
01:27:32,251 --> 01:27:35,541
and so forth, how do you deal with Chinese competition

2081
01:27:35,541 --> 01:27:36,802
and are they privileged in that world?

2082
01:27:36,802 --> 01:27:37,822
Yeah, so it's a great que-.

2083
01:27:37,822 --> 01:27:37,871
..

2084
01:27:37,871 --> 01:27:47,462
I mean, in fact, you just made the point of why I think trust in American tech is probably the most important feature.

2085
01:27:47,462 --> 01:27:51,081
It's not even the model capability, maybe.

2086
01:27:51,081 --> 01:27:53,342
It is, like, can I trust you

2087
01:27:53,342 --> 01:27:55,041
the company?

2088
01:27:55,041 --> 01:27:59,762
Can I trust you, your country, and its institutions- Mm-hmm.

2089
01:27:59,762 --> 01:27:59,785
.

2090
01:27:59,785 --> 01:27:59,812
..

2091
01:27:59,812 --> 01:28:05,001
to be a long-term supplier may be the thing that wins the world.

2092
01:28:05,001 --> 01:28:06,282
I think it's a good note to end on.

2093
01:28:06,282 --> 01:28:06,642
Yeah.

2094
01:28:06,642 --> 01:28:07,782
Satya, thank you for doing this.

2095
01:28:07,782 --> 01:28:08,922
 Thank you so much.

2096
01:28:08,922 --> 01:28:09,322
Thank you.

2097
01:28:09,322 --> 01:28:09,662
Yes.

2098
01:28:09,662 --> 01:28:09,942
Thanks.

2099
01:28:09,942 --> 01:28:10,882
Such a pleasure.

2100
01:28:10,882 --> 01:28:11,081
Yeah.

2101
01:28:11,081 --> 01:28:12,272
Such a pleasure.

2102
01:28:12,272 --> 01:28:12,802
It's awesome.

2103
01:28:12,802 --> 01:28:14,552
It's like, man, you two guys are

2104
01:28:14,552 --> 01:28:14,791
like-  .

2105
01:28:14,791 --> 01:28:14,791
..

2106
01:28:14,791 --> 01:28:15,922
quite the team.

2107
01:28:15,922 --> 01:28:18,062
  Hey, everybody.

2108
01:28:18,062 --> 01:28:19,702
I hope you enjoyed that episode.

2109
01:28:19,702 --> 01:28:24,942
If you did, the most helpful thing you can do is just share it with other people who you think might enjoy it.

2110
01:28:24,942 --> 01:28:30,822
It's also helpful if you leave a rating or a comment on whatever platform you are listening on.

2111
01:28:30,822 --> 01:28:35,999
If you're interested in sponsoring the podcast, you can reach out at dwarkesh.

2112
01:28:35,999 --> 01:28:38,331
com/advertise.

2113
01:28:38,331 --> 01:28:41,242
Otherwise, I'll see you in the next one.

