1
00:00:00,130 --> 00:00:03,340
- The following is a conversion with Judea Pearl,

2
00:00:03,340 --> 00:00:06,850
professor at UCLA and a winner of the Turing Award,

3
00:00:06,850 --> 00:00:10,474
that's generally recognized as the Nobel Prize of computing.

4
00:00:10,474 --> 00:00:12,520
He's one of the seminal figures

5
00:00:12,520 --> 00:00:14,560
in the field of artificial intelligence,

6
00:00:14,560 --> 00:00:16,760
computer science, and statistics.

7
00:00:16,760 --> 00:00:20,070
He has developed and championed probabilistic approaches

8
00:00:20,070 --> 00:00:22,810
to AI, including Bayesian networks,

9
00:00:22,810 --> 00:00:26,160
and profound ideas in causality in general.

10
00:00:26,160 --> 00:00:29,200
These ideas are important not just to AI,

11
00:00:29,200 --> 00:00:32,372
but to our understanding and practice of science.

12
00:00:32,372 --> 00:00:35,647
But in the field of AI, the idea of causality,

13
00:00:35,647 --> 00:00:38,420
cause and effect, to many,

14
00:00:38,420 --> 00:00:41,020
lie at the core of what is currently missing

15
00:00:41,020 --> 00:00:42,200
and what must be developed

16
00:00:42,200 --> 00:00:45,670
in order to build truly intelligent systems.

17
00:00:45,670 --> 00:00:48,100
For this reason, and many others,

18
00:00:48,100 --> 00:00:50,870
his work is worth returning to often.

19
00:00:50,870 --> 00:00:54,320
I recommend his most recent book called "Book of Why"

20
00:00:54,320 --> 00:00:57,270
that presents key ideas from a lifetime of work

21
00:00:57,270 --> 00:01:00,470
in a way that is accessible to the general public.

22
00:01:00,470 --> 00:01:03,530
This is the "Artificial Intelligence Podcast."

23
00:01:03,530 --> 00:01:05,910
If you enjoy it, subscribe on YouTube,

24
00:01:05,910 --> 00:01:07,880
give it five stars on Apple Podcast,

25
00:01:07,880 --> 00:01:10,410
support on Patreon, or simply connect with me

26
00:01:10,410 --> 00:01:15,370
on Twitter @lexfridman, spelled F-R-I-D-M-A-N.

27
00:01:15,370 --> 00:01:18,240
If you leave a review on Apple Podcasts especially,

28
00:01:18,240 --> 00:01:21,010
but also Castbox, or comment on YouTube,

29
00:01:21,010 --> 00:01:23,420
consider mentioning topics, people, ideas,

30
00:01:23,420 --> 00:01:25,130
questions, quotes in science, tech,

31
00:01:25,130 --> 00:01:27,530
and philosophy, you find interesting,

32
00:01:27,530 --> 00:01:29,610
and I'll read them on this podcast.

33
00:01:29,610 --> 00:01:31,990
I won't call out names, but I love comments

34
00:01:31,990 --> 00:01:33,910
with kindness and thoughtfulness in them,

35
00:01:33,910 --> 00:01:35,800
so I thought I'd share them with you.

36
00:01:35,800 --> 00:01:37,880
Someone on YouTube highlighted a quote

37
00:01:37,880 --> 00:01:40,070
from the conversation with Noam Chomsky

38
00:01:40,070 --> 00:01:42,840
where he said that the significance of your life

39
00:01:42,840 --> 00:01:44,491
is something you create.

40
00:01:44,491 --> 00:01:46,630
I like this line as well.

41
00:01:46,630 --> 00:01:49,509
On most days, the existentialist approach to life

42
00:01:49,509 --> 00:01:52,957
is one I find liberating and fulfilling.

43
00:01:52,957 --> 00:01:55,070
I recently started doing ads

44
00:01:55,070 --> 00:01:56,700
at the end of the introduction.

45
00:01:56,700 --> 00:01:59,410
I'll do one or two minutes after introducing the episode

46
00:01:59,410 --> 00:02:01,140
and never any ads in the middle

47
00:02:01,140 --> 00:02:03,330
that break the flow of the conversation.

48
00:02:03,330 --> 00:02:04,780
I hope that works for you

49
00:02:04,780 --> 00:02:07,753
and doesn't hurt the listening experience.

50
00:02:07,753 --> 00:02:10,239
This show is presented by Cash App,

51
00:02:10,239 --> 00:02:13,100
the number one finance app in the App Store.

52
00:02:13,100 --> 00:02:15,570
I personally use Cash App to send money to friends,

53
00:02:15,570 --> 00:02:17,460
but you can also use it to buy, sell,

54
00:02:17,460 --> 00:02:20,150
and deposit Bitcoin in just seconds.

55
00:02:20,150 --> 00:02:22,830
Cash App also has a new investing feature.

56
00:02:22,830 --> 00:02:25,900
You can buy fractions of a stock, say $1 worth,

57
00:02:25,900 --> 00:02:28,070
no matter what the stock price is.

58
00:02:28,070 --> 00:02:30,760
Broker's services are provided by Cash App Investing,

59
00:02:30,760 --> 00:02:33,795
a subsidiary of Square, a member SIPC.

60
00:02:33,795 --> 00:02:36,650
I'm excited to be working with Cash App

61
00:02:36,650 --> 00:02:39,970
to support one of my favorite organizations called FIRST,

62
00:02:39,970 --> 00:02:43,470
best known for their FIRST Robotics and LEGO competitions.

63
00:02:43,470 --> 00:02:45,940
They educate and inspire hundreds of thousands

64
00:02:45,940 --> 00:02:48,713
of students in over 110 countries,

65
00:02:48,713 --> 00:02:51,790
and have a perfect rating on Charity Navigator,

66
00:02:51,790 --> 00:02:53,770
which means the donated money is used

67
00:02:53,770 --> 00:02:55,607
to the maximum effectiveness.

68
00:02:55,607 --> 00:02:58,730
When you get Cash App from the App Store or Google Play

69
00:02:58,730 --> 00:03:02,070
and use code LexPodcast, you'll get $10

70
00:03:02,070 --> 00:03:05,160
and Cash App will also donate $10 to FIRST.

71
00:03:05,160 --> 00:03:07,600
Which, again, is an organization

72
00:03:07,600 --> 00:03:09,751
that I've personally seen inspire girls and boys

73
00:03:09,751 --> 00:03:12,850
to dream of engineering a better world.

74
00:03:12,850 --> 00:03:16,963
And now, here's my conversation with Judea Pearl.

75
00:03:18,130 --> 00:03:19,760
You mentioned in an interview

76
00:03:19,760 --> 00:03:21,880
that science is not a collection of facts,

77
00:03:21,880 --> 00:03:25,603
but a constant human struggle with the mysteries of nature.

78
00:03:26,440 --> 00:03:27,990
What was the first mystery

79
00:03:27,990 --> 00:03:30,200
that you can recall that hooked you,

80
00:03:30,200 --> 00:03:31,437
that captivated your curiosity?

81
00:03:31,437 --> 00:03:32,650
- Oh, the first mystery.

82
00:03:32,650 --> 00:03:34,175
That's a good one.

83
00:03:34,175 --> 00:03:36,751
Yeah, I remember that.

84
00:03:36,751 --> 00:03:38,529
- [Lex] What was it?

85
00:03:38,529 --> 00:03:40,029
- I had a fever for three days

86
00:03:41,065 --> 00:03:45,862
when I learned about Descartes and a little geometry,

87
00:03:45,862 --> 00:03:49,930
and I found out that you can do all the construction

88
00:03:49,930 --> 00:03:52,375
in geometry using algebra.

89
00:03:52,375 --> 00:03:54,560
And I couldn't get over it.

90
00:03:54,560 --> 00:03:56,612
I simply couldn't get out of bed.

91
00:03:56,612 --> 00:03:58,440
(chuckles)

92
00:03:58,440 --> 00:04:02,503
- What kinda world does analytic geometry unlock?

93
00:04:02,503 --> 00:04:07,503
- Well, it connects algebra with geometry, okay?

94
00:04:07,700 --> 00:04:12,416
So, Descartes has the idea that geometrical construction

95
00:04:12,416 --> 00:04:15,781
and geometrical theorems and assumptions

96
00:04:15,781 --> 00:04:19,610
can be articulated in the language of algebra.

97
00:04:19,610 --> 00:04:24,445
Which means that all the proofs that we did in high school

98
00:04:24,445 --> 00:04:28,660
in trying to prove that the three bisectors meet

99
00:04:28,660 --> 00:04:32,914
at one point, and that the (chuckles)

100
00:04:32,914 --> 00:04:37,914
All this can be proven by shuffling around notation.

101
00:04:38,169 --> 00:04:42,483
That was a traumatic experience.

102
00:04:42,483 --> 00:04:44,510
- (chuckles) Traumatic experience.

103
00:04:44,510 --> 00:04:45,810
- [Judea] For me, it was, it was, I'm telling you, right?

104
00:04:45,810 --> 00:04:47,020
- So it's the connection

105
00:04:47,020 --> 00:04:49,170
between the different mathematical disciplines,

106
00:04:49,170 --> 00:04:50,677
that they all

107
00:04:50,677 --> 00:04:52,542
- They're not even two different languages.

108
00:04:52,542 --> 00:04:54,114
- Languages. - Yeah.

109
00:04:54,114 --> 00:04:57,240
- Which mathematic discipline is most beautiful?

110
00:04:57,240 --> 00:04:58,660
Is geometry it for you?

111
00:04:58,660 --> 00:04:59,710
- Both are beautiful.

112
00:05:00,617 --> 00:05:02,480
They have almost the same power.

113
00:05:02,480 --> 00:05:04,679
- But there's a visual element to geometry.

114
00:05:04,679 --> 00:05:08,150
- The visual element, it's more transparent.

115
00:05:08,150 --> 00:05:11,593
But once you get over to algebra then

116
00:05:11,593 --> 00:05:14,490
linear equations is a straight line.

117
00:05:14,490 --> 00:05:16,553
This translation is easily absorbed.

118
00:05:18,282 --> 00:05:23,282
To pass a tangent to a circle, you know,

119
00:05:23,531 --> 00:05:25,040
you have the basic theorems,

120
00:05:25,040 --> 00:05:27,820
and you can do it with algebra.

121
00:05:27,820 --> 00:05:31,630
But the transition from one to another was really,

122
00:05:31,630 --> 00:05:34,210
I thought that Descartes was the greatest mathematician

123
00:05:34,210 --> 00:05:35,283
of all times.

124
00:05:36,560 --> 00:05:40,503
- So, if you think of engineering and mathematics

125
00:05:41,956 --> 00:05:43,250
as a spectrum--

126
00:05:43,250 --> 00:05:44,083
- [Judea] Yes.

127
00:05:44,981 --> 00:05:49,230
- You have walked casually along this spectrum

128
00:05:49,230 --> 00:05:51,580
throughout your life.

129
00:05:51,580 --> 00:05:53,880
You know, a little bit of engineering and then

130
00:05:56,276 --> 00:05:59,093
you've done a little bit of mathematics here and there.

131
00:05:59,093 --> 00:06:00,040
- A little bit.

132
00:06:00,040 --> 00:06:04,140
We get a very solid background in mathematics

133
00:06:04,140 --> 00:06:07,160
because our teachers were geniuses.

134
00:06:07,160 --> 00:06:09,800
Our teachers came from Germany in the 1930s

135
00:06:09,800 --> 00:06:11,253
running away from Hitler.

136
00:06:12,350 --> 00:06:15,130
They left their careers in Heidelberg and Berlin,

137
00:06:15,130 --> 00:06:17,920
and came to teach high school in Israel.

138
00:06:17,920 --> 00:06:20,923
And we were the beneficiary of that experiment.

139
00:06:22,223 --> 00:06:25,280
When they taught us math, a good way.

140
00:06:25,280 --> 00:06:27,070
- What's a good way to teach math?

141
00:06:27,070 --> 00:06:28,263
- [Judea] Theorologically.

142
00:06:29,120 --> 00:06:29,953
- The people.

143
00:06:29,953 --> 00:06:33,410
- The people behind the theorems, yeah.

144
00:06:33,410 --> 00:06:38,410
Their cousins, and their nieces, (chuckles) and their faces,

145
00:06:38,580 --> 00:06:41,010
and how they jumped from the bathtub

146
00:06:41,010 --> 00:06:46,010
when they screamed, "Eureka" and ran naked in town. (laughs)

147
00:06:46,090 --> 00:06:49,330
- So you were almost educated as a historian of math.

148
00:06:49,330 --> 00:06:52,010
- No, we just got a glimpse of that history,

149
00:06:52,010 --> 00:06:56,740
together with the theorem, so every exercise in math

150
00:06:56,740 --> 00:06:58,952
was connected with a person,

151
00:06:58,952 --> 00:07:01,540
and the time of the person,

152
00:07:01,540 --> 00:07:03,237
the period.

153
00:07:03,237 --> 00:07:05,680
- [Lex] The period also mathematically speaking.

154
00:07:05,680 --> 00:07:07,980
- Mathematically speaking, yes, not a paradox.

155
00:07:10,570 --> 00:07:15,570
- Then in university, you had gone on to do engineering.

156
00:07:16,280 --> 00:07:19,453
- Yeah. I got a BS in Engineering at Technion.

157
00:07:20,720 --> 00:07:24,655
And then I moved here for graduate school work,

158
00:07:24,655 --> 00:07:29,655
and I did the engineering in addition to physics in Rutgers.

159
00:07:31,950 --> 00:07:35,870
And it combined very nicely with my thesis,

160
00:07:35,870 --> 00:07:39,303
which I did in Elsevier Laboratories in superconductivity.

161
00:07:40,540 --> 00:07:43,810
- And then somehow thought to switch

162
00:07:43,810 --> 00:07:48,810
to almost computer science software, even, not switched,

163
00:07:49,270 --> 00:07:52,500
but longed to become to get into software engineering

164
00:07:52,500 --> 00:07:54,540
a little bit, almost in programming,

165
00:07:54,540 --> 00:07:56,620
if you can call it that in the 70s.

166
00:07:56,620 --> 00:07:57,813
There's all these disciplines.

167
00:07:57,813 --> 00:07:58,646
- Yeah.

168
00:07:58,646 --> 00:08:00,751
- If you were to pick a favorite,

169
00:08:00,751 --> 00:08:03,910
in terms of engineering and mathematics,

170
00:08:03,910 --> 00:08:07,180
which path do you think has more beauty?

171
00:08:07,180 --> 00:08:08,650
Which path has more power?

172
00:08:08,650 --> 00:08:10,600
- It's hard to choose, no?

173
00:08:10,600 --> 00:08:12,660
I enjoy doing physics.

174
00:08:12,660 --> 00:08:15,885
I even have a vortex named with my name.

175
00:08:15,885 --> 00:08:20,885
So, I have investment in immortality. (laughs)

176
00:08:21,923 --> 00:08:24,340
- So, what is a vortex?

177
00:08:24,340 --> 00:08:27,040
- Vortex is in superconductivity.

178
00:08:27,040 --> 00:08:28,220
- In the superconductivity.

179
00:08:28,220 --> 00:08:30,900
- You have terminal current swirling around,

180
00:08:30,900 --> 00:08:34,600
one way or the other, going to have us throw one or zero,

181
00:08:34,600 --> 00:08:38,240
for computer that was we worked on in the 1960

182
00:08:38,240 --> 00:08:39,929
in Elsevier,

183
00:08:39,929 --> 00:08:44,100
and I discovered a few nice phenomena with the vortices.

184
00:08:44,100 --> 00:08:45,589
You push current and they move.

185
00:08:45,589 --> 00:08:46,869
- [Lex] So there's a Pearl vortex.

186
00:08:46,869 --> 00:08:48,989
- A Pearl vortex, why, you can google it.

187
00:08:48,989 --> 00:08:50,260
(both laugh)

188
00:08:50,260 --> 00:08:53,570
I didn't know about it, but the physicist picked up

189
00:08:53,570 --> 00:08:57,210
on my thesis, on my PhD thesis,

190
00:08:57,210 --> 00:09:02,210
and it became popular when thin film superconductors

191
00:09:03,300 --> 00:09:06,960
became important, for high temperature superconductors.

192
00:09:06,960 --> 00:09:10,692
So, they call it "Pearl vortex" without my knowledge.

193
00:09:10,692 --> 00:09:11,525
(laughs)

194
00:09:11,525 --> 00:09:14,486
I discovered it only about 15 years ago.

195
00:09:14,486 --> 00:09:17,610
- You have footprints in all of the sciences,

196
00:09:17,610 --> 00:09:21,000
so let's talk about the universe for a little bit.

197
00:09:21,000 --> 00:09:22,920
Is the universe, at the lowest level,

198
00:09:22,920 --> 00:09:25,077
deterministic or stochastic,

199
00:09:25,077 --> 00:09:27,440
in your amateur philosophy view?

200
00:09:27,440 --> 00:09:30,160
Put another way, does God play dice?

201
00:09:30,160 --> 00:09:33,130
- We know it is stochastic, right?

202
00:09:33,130 --> 00:09:35,200
- [Lex] Today. Today we think it is stochastic.

203
00:09:35,200 --> 00:09:37,530
- Yes, we think

204
00:09:37,530 --> 00:09:40,150
because we have the Heisenberg uncertainty principle

205
00:09:40,150 --> 00:09:44,487
and we have some experiments to confirm that.

206
00:09:44,487 --> 00:09:48,000
- All we have is experiments to confirm it.

207
00:09:48,000 --> 00:09:49,303
We don't understand why.

208
00:09:50,430 --> 00:09:51,480
- [Judea] Why is already--

209
00:09:51,480 --> 00:09:54,397
- You wrote a book about why. (laughs)

210
00:09:54,397 --> 00:09:56,545
- Yeah, it's a puzzle.

211
00:09:56,545 --> 00:10:01,545
It's a puzzle that you have the dice-flipping machine,

212
00:10:02,420 --> 00:10:07,420
or God, and the result of the flipping,

213
00:10:08,610 --> 00:10:11,433
propagated with a speed faster than the speed of light.

214
00:10:12,363 --> 00:10:14,113
(laughs) We can't explain it, okay?

215
00:10:15,210 --> 00:10:20,210
But, it only governs microscopic phenomena.

216
00:10:21,340 --> 00:10:24,660
- So you don't think of quantum mechanics as useful

217
00:10:25,700 --> 00:10:27,646
for understanding the nature of reality?

218
00:10:27,646 --> 00:10:30,440
- [Judea] No, it's diversionary.

219
00:10:30,440 --> 00:10:34,560
- So, in your thinking, the world might

220
00:10:34,560 --> 00:10:36,030
as well be deterministic?

221
00:10:36,030 --> 00:10:38,530
- The world is deterministic,

222
00:10:38,530 --> 00:10:42,840
and as far as a new one firing is concerned,

223
00:10:42,840 --> 00:10:47,280
it is deterministic to first approximation.

224
00:10:47,280 --> 00:10:48,970
- What about free will?

225
00:10:48,970 --> 00:10:52,970
- Free will is also a nice exercise.

226
00:10:52,970 --> 00:10:54,980
Free will is an illusion,

227
00:10:54,980 --> 00:10:57,963
that we AI people are going to solve.

228
00:10:58,935 --> 00:11:01,703
- So, what do you think, once we solve it,

229
00:11:01,703 --> 00:11:03,430
that solution will look like?

230
00:11:03,430 --> 00:11:04,610
Once we put it in the page.

231
00:11:04,610 --> 00:11:06,310
- The solution will look like,

232
00:11:06,310 --> 00:11:08,980
first of all it will look like a machine.

233
00:11:08,980 --> 00:11:12,610
A machine that acts as though it has free will.

234
00:11:12,610 --> 00:11:14,280
It communicates with other machines

235
00:11:14,280 --> 00:11:17,230
as though they have free will,

236
00:11:17,230 --> 00:11:19,560
and you wouldn't be able to tell the difference

237
00:11:19,560 --> 00:11:22,230
between a machine that does and a machine

238
00:11:22,230 --> 00:11:23,853
that doesn't have free will, eh?

239
00:11:24,760 --> 00:11:27,550
- So it propagates the illusion of free will

240
00:11:27,550 --> 00:11:29,540
amongst the other machines.

241
00:11:29,540 --> 00:11:33,240
- And faking it is having it, okay?

242
00:11:33,240 --> 00:11:35,210
That's what Turing test is all about.

243
00:11:35,210 --> 00:11:37,260
Faking intelligence is intelligence,

244
00:11:37,260 --> 00:11:41,150
because it's not easy to fake.

245
00:11:41,150 --> 00:11:42,996
It's very hard to fake,

246
00:11:42,996 --> 00:11:45,732
and you can only fake if you have it.

247
00:11:45,732 --> 00:11:50,732
- (laughs) That's such a beautiful statement.

248
00:11:51,615 --> 00:11:56,615
(laughs) You can't fake it if you don't have it, yup.

249
00:11:59,540 --> 00:12:04,540
So, let's begin at the beginning, with the probability,

250
00:12:06,029 --> 00:12:09,370
both philosophically and mathematically,

251
00:12:09,370 --> 00:12:12,240
what does it mean to say the probability of something

252
00:12:12,240 --> 00:12:15,180
happening is 50%?

253
00:12:15,180 --> 00:12:16,383
What is probability?

254
00:12:17,220 --> 00:12:19,933
- It's a degree of uncertainty that an agent has

255
00:12:19,933 --> 00:12:21,505
about the world.

256
00:12:21,505 --> 00:12:24,040
- You're still expressing some knowledge

257
00:12:24,040 --> 00:12:24,873
in that statement.

258
00:12:24,873 --> 00:12:26,030
- Of course.

259
00:12:26,030 --> 00:12:29,350
If the probability is 90%, it's absolutely different kind

260
00:12:29,350 --> 00:12:32,221
of knowledge than if it is 10%.

261
00:12:32,221 --> 00:12:35,900
- But it's still not solid knowledge, it's--

262
00:12:35,900 --> 00:12:37,673
- It is solid knowledge, by.

263
00:12:38,550 --> 00:12:42,860
If you tell me that 90% assurance

264
00:12:42,860 --> 00:12:47,212
smoking will give you lung cancer in five years,

265
00:12:47,212 --> 00:12:52,212
versus 10%, it's a piece of useful knowledge.

266
00:12:52,430 --> 00:12:55,766
- So this statistical view of the universe,

267
00:12:55,766 --> 00:12:57,670
why is it useful?

268
00:12:57,670 --> 00:13:00,790
So we're swimming in complete uncertainty.

269
00:13:00,790 --> 00:13:01,840
Most of everything around you--

270
00:13:01,840 --> 00:13:03,597
- It allows you to predict things

271
00:13:03,597 --> 00:13:06,150
with a certain probability,

272
00:13:06,150 --> 00:13:09,143
and computing those probabilities are very useful.

273
00:13:10,005 --> 00:13:12,340
That's the whole idea of prediction.

274
00:13:15,130 --> 00:13:18,240
And you need prediction to be able to survive.

275
00:13:18,240 --> 00:13:21,410
If you cannot predict the future then you just,

276
00:13:21,410 --> 00:13:25,701
crossing the street would be extremely fearful.

277
00:13:25,701 --> 00:13:28,850
- And so you've done a lot of work in causation,

278
00:13:28,850 --> 00:13:31,461
so let's think about correlation.

279
00:13:31,461 --> 00:13:33,948
- I started with probability.

280
00:13:33,948 --> 00:13:35,670
- You started with probability.

281
00:13:35,670 --> 00:13:38,820
You've invented the Bayesian networks.

282
00:13:38,820 --> 00:13:39,653
- [Judea] Yeah.

283
00:13:40,597 --> 00:13:43,950
- And so, we'll dance back and forth

284
00:13:43,950 --> 00:13:47,173
between these levels of uncertainty,

285
00:13:47,173 --> 00:13:49,453
but what is correlation?

286
00:13:50,430 --> 00:13:54,050
So, probability is something happening, is something,

287
00:13:54,050 --> 00:13:56,530
but then there's a bunch of things happening,

288
00:13:56,530 --> 00:13:59,580
and sometimes they happen together sometimes not.

289
00:13:59,580 --> 00:14:00,820
They're independent or not,

290
00:14:00,820 --> 00:14:03,690
so how do you think about correlation of things?

291
00:14:03,690 --> 00:14:06,310
- Correlation occurs when two things vary together

292
00:14:06,310 --> 00:14:09,960
over a very long time, is one way of measuring it.

293
00:14:09,960 --> 00:14:12,110
Or, when you have a bunch of variables

294
00:14:12,110 --> 00:14:15,072
that they all vary cohesively,

295
00:14:15,072 --> 00:14:18,630
then we have a correlation here,

296
00:14:18,630 --> 00:14:21,770
and usually when we think about correlation,

297
00:14:21,770 --> 00:14:23,563
we really think causation.

298
00:14:24,450 --> 00:14:27,960
Things cannot be correlation unless there is a reason

299
00:14:27,960 --> 00:14:30,330
for them to vary together.

300
00:14:30,330 --> 00:14:32,100
Why should they vary together?

301
00:14:32,100 --> 00:14:35,620
If they don't see each other, why should they vary together?

302
00:14:35,620 --> 00:14:37,773
- So underlying it somewhere is causation.

303
00:14:37,773 --> 00:14:39,280
- Yes.

304
00:14:39,280 --> 00:14:43,210
Hidden in our intuition there is a notion of causation,

305
00:14:43,210 --> 00:14:47,643
because we cannot grasp any other logic except causation.

306
00:14:48,650 --> 00:14:52,643
- And how does conditional probability differ

307
00:14:52,643 --> 00:14:55,276
from causation?

308
00:14:55,276 --> 00:14:57,980
So, what is conditional probability?

309
00:14:57,980 --> 00:15:00,630
- Conditional probability is how things vary

310
00:15:00,630 --> 00:15:05,070
when one of them stays the same.

311
00:15:05,070 --> 00:15:09,340
Now, staying the same means that I have chosen

312
00:15:09,340 --> 00:15:13,010
to look only at those incidents where the guy

313
00:15:13,010 --> 00:15:16,160
has the same value as the previous one.

314
00:15:16,160 --> 00:15:19,340
It's my choice, as an experimenter,

315
00:15:19,340 --> 00:15:22,310
so things that are not correlated before

316
00:15:22,310 --> 00:15:24,290
could become correlated.

317
00:15:24,290 --> 00:15:26,910
Like for instance, if I have two coins

318
00:15:26,910 --> 00:15:28,363
which are uncorrelated,

319
00:15:29,290 --> 00:15:33,820
and I choose only those flippings experiments

320
00:15:33,820 --> 00:15:37,050
in which a bell rings, and the bell rings when

321
00:15:37,050 --> 00:15:40,810
at least one of them is a tail, okay,

322
00:15:40,810 --> 00:15:44,410
then suddenly I see correlation between the two coins,

323
00:15:44,410 --> 00:15:48,463
because I only looked at the cases where the bell rang.

324
00:15:49,340 --> 00:15:51,530
You see, it is my design.

325
00:15:51,530 --> 00:15:53,720
It is my ignorance essentially,

326
00:15:53,720 --> 00:15:58,720
with my audacity to ignore certain incidents,

327
00:16:01,280 --> 00:16:04,610
I suddenly create a correlation

328
00:16:04,610 --> 00:16:07,118
where it doesn't exist physically.

329
00:16:07,118 --> 00:16:08,100
- Right.

330
00:16:08,100 --> 00:16:11,440
So, you just outlined one of the flaws

331
00:16:11,440 --> 00:16:14,990
of observing the world and trying to infer something

332
00:16:14,990 --> 00:16:16,130
from the math about the world

333
00:16:16,130 --> 00:16:17,550
from looking at the correlation.

334
00:16:17,550 --> 00:16:19,010
- I don't look at it as a flaw.

335
00:16:19,010 --> 00:16:20,423
The world works like that.

336
00:16:21,278 --> 00:16:26,073
The flaws come if you try to impose causal logic

337
00:16:27,512 --> 00:16:32,290
on correlation.

338
00:16:32,290 --> 00:16:34,750
It doesn't work too well.

339
00:16:34,750 --> 00:16:36,750
- I mean, but that's exactly what we do.

340
00:16:38,088 --> 00:16:40,330
That has been the majority of science, is you--

341
00:16:40,330 --> 00:16:42,503
- No, the majority of naive science.

342
00:16:43,800 --> 00:16:45,370
Statisticians know it.

343
00:16:45,370 --> 00:16:47,900
Statisticians know that if you condition

344
00:16:47,900 --> 00:16:49,595
on a third variable,

345
00:16:49,595 --> 00:16:53,830
then you can destroy or create correlations

346
00:16:53,830 --> 00:16:55,680
among two other variables.

347
00:16:55,680 --> 00:16:56,513
They know it.

348
00:16:56,513 --> 00:16:57,758
It's (speaks foreign language).

349
00:16:57,758 --> 00:16:59,630
There's nothing surprises them.

350
00:16:59,630 --> 00:17:02,327
That's why they all dismiss the systems paradox, look

351
00:17:02,327 --> 00:17:04,376
"Ah, we know it!"

352
00:17:04,376 --> 00:17:07,310
They don't know anything about it. (laughs)

353
00:17:07,310 --> 00:17:09,730
- Well, there's disciplines like psychology,

354
00:17:09,730 --> 00:17:12,910
where all the variables are hard to account for,

355
00:17:12,910 --> 00:17:15,260
and so, oftentimes there is a leap

356
00:17:15,260 --> 00:17:17,848
between correlation to causation.

357
00:17:17,848 --> 00:17:20,507
- What do you mean, a leap?

358
00:17:20,507 --> 00:17:24,369
Who is trying to get causation from correlation?

359
00:17:24,369 --> 00:17:26,569
There's no one.

360
00:17:26,569 --> 00:17:28,010
- [Lex] You're not proving causation,

361
00:17:28,010 --> 00:17:31,720
but you're sort of discussing it,

362
00:17:31,720 --> 00:17:35,380
implying, sort of hypothesizing without ability to--

363
00:17:35,380 --> 00:17:37,200
- Which discipline you have in mind?

364
00:17:37,200 --> 00:17:40,196
I'll tell you if they are obsolete.

365
00:17:40,196 --> 00:17:41,274
(Lex laughs)

366
00:17:41,274 --> 00:17:44,270
Or if they are outdated, or they're about to get outdated.

367
00:17:44,270 --> 00:17:45,572
- Yes, yes.

368
00:17:45,572 --> 00:17:47,571
- [Judea] Oh, yeah, tell me which ones you have in mind.

369
00:17:47,571 --> 00:17:48,864
- Well, psychology, you know--

370
00:17:48,864 --> 00:17:50,683
- [Judea] Psychology, what, SEM?

371
00:17:50,683 --> 00:17:53,956
- No, no, I was thinking of applied psychology, studying,

372
00:17:53,956 --> 00:17:57,290
for example, we work with human behavior

373
00:17:57,290 --> 00:18:00,410
in semi-autonomous vehicles, how people behave.

374
00:18:00,410 --> 00:18:02,610
And you have to conduct these studies

375
00:18:02,610 --> 00:18:04,340
of people driving cars.

376
00:18:04,340 --> 00:18:05,580
- Everything starts with the question:

377
00:18:05,580 --> 00:18:07,860
What is the research question?

378
00:18:07,860 --> 00:18:09,513
- What is the research question?

379
00:18:10,480 --> 00:18:12,210
The research question:

380
00:18:12,210 --> 00:18:17,210
do people fall asleep when the car is driving itself?

381
00:18:18,074 --> 00:18:20,600
- Do they fall asleep,

382
00:18:20,600 --> 00:18:23,200
or do they tend to fall asleep more frequently

383
00:18:23,200 --> 00:18:24,033
- [Lex] More frequently

384
00:18:24,033 --> 00:18:26,020
- than the car not driving itself.

385
00:18:26,020 --> 00:18:27,070
- [Lex] Not driving itself.

386
00:18:27,070 --> 00:18:28,520
That's a good question, okay.

387
00:18:29,707 --> 00:18:33,780
- You put people in the car, because it's real world.

388
00:18:33,780 --> 00:18:35,240
You can't conduct an experiment

389
00:18:35,240 --> 00:18:36,380
where you control everything.

390
00:18:36,380 --> 00:18:37,890
- [Judea] Why can't you con--

391
00:18:37,890 --> 00:18:39,326
- You could.

392
00:18:39,326 --> 00:18:44,260
- [Judea] Turn the automatic module on and off.

393
00:18:45,855 --> 00:18:49,013
- Because there's aspects to it that's unethical,

394
00:18:52,720 --> 00:18:54,733
because it's testing on public roads.

395
00:18:56,991 --> 00:19:01,991
The drivers themselves have to make that choice themselves,

396
00:19:02,450 --> 00:19:04,483
and so they regulate that.

397
00:19:05,530 --> 00:19:09,100
So, you just observe when they drive it autonomously,

398
00:19:09,100 --> 00:19:10,770
and when they don't.

399
00:19:10,770 --> 00:19:13,190
- But maybe they turn it off when they're very tired.

400
00:19:13,190 --> 00:19:14,590
- [Lex] Yeah, that kind of thing.

401
00:19:14,590 --> 00:19:16,510
But you don't know those variables.

402
00:19:16,510 --> 00:19:19,470
- Okay, so you have now uncontrolled experiment,

403
00:19:19,470 --> 00:19:20,610
- [Lex] Uncontrolled experiment.

404
00:19:20,610 --> 00:19:22,944
- When we correct observation of study,

405
00:19:22,944 --> 00:19:27,210
and when we form the correlation detected,

406
00:19:27,210 --> 00:19:30,370
we have to infer causal relationship,

407
00:19:30,370 --> 00:19:33,410
whether it was the automatic piece

408
00:19:33,410 --> 00:19:36,010
that cause them to fall asleep, or,

409
00:19:36,010 --> 00:19:41,010
so that is an issue that is about 120 years old.

410
00:19:42,894 --> 00:19:44,493
- [Lex] (laughs) Yeah.

411
00:19:45,500 --> 00:19:48,957
- Oh, I should only go 100 years old, okay?

412
00:19:48,957 --> 00:19:51,430
- [Lex] (chuckles) Who's counting?

413
00:19:51,430 --> 00:19:55,290
- Oh, maybe, no, actually I should say it's 2,000 years old,

414
00:19:55,290 --> 00:19:57,890
because we have this experiment by Daniel,

415
00:19:57,890 --> 00:20:00,283
about the Babylonian king,

416
00:20:03,104 --> 00:20:08,104
that wanted the exiled people from Israel,

417
00:20:09,260 --> 00:20:14,260
that were taken in exile to Babylon to serve the king.

418
00:20:14,740 --> 00:20:18,130
He wanted to serve them king's food, which was meat,

419
00:20:18,130 --> 00:20:22,830
and Daniel as a good Jew couldn't eat non-Kosher food,

420
00:20:22,830 --> 00:20:26,680
so he asked them to eat vegetarian food.

421
00:20:26,680 --> 00:20:29,307
But the king's overseers said, "I'm sorry,

422
00:20:29,307 --> 00:20:33,467
"but if the king sees that your performance falls

423
00:20:33,467 --> 00:20:38,467
"below that of other kids, now, he's going to kill me."

424
00:20:39,410 --> 00:20:41,647
Daniel said, "Let's make an experiment.

425
00:20:41,647 --> 00:20:44,267
"Let's take four of us from Jerusalem, okay?

426
00:20:44,267 --> 00:20:46,397
"Give us vegetarian food.

427
00:20:46,397 --> 00:20:50,227
"Let's take the other guys to eat the king's food,

428
00:20:50,227 --> 00:20:54,120
"and about a week's time, we'll test our performance."

429
00:20:54,120 --> 00:20:57,860
And you know the answer, because he did the experiment,

430
00:20:57,860 --> 00:21:01,380
and they were so much better than the others,

431
00:21:01,380 --> 00:21:06,380
that the kings nominated them to super positions, (laughs)

432
00:21:07,380 --> 00:21:09,763
in his case, so it was a first experiment.

433
00:21:10,961 --> 00:21:12,790
So that there was a very simple,

434
00:21:12,790 --> 00:21:15,550
it's also the same research questions.

435
00:21:15,550 --> 00:21:17,440
We want to know if vegetarian food

436
00:21:18,432 --> 00:21:22,853
assists or obstructs your mental ability.

437
00:21:24,740 --> 00:21:29,363
So, the question is a very old one.

438
00:21:30,500 --> 00:21:35,500
Even Democritus, if I could discover one cause of things,

439
00:21:39,142 --> 00:21:42,913
I would rather discuss one cause than be King of Persia.

440
00:21:44,220 --> 00:21:49,220
The task of discovering causes was in the mind

441
00:21:49,290 --> 00:21:53,530
of ancient people from many, many years ago.

442
00:21:53,530 --> 00:21:56,510
But, the mathematics of doing that

443
00:21:57,420 --> 00:22:00,199
was only developed in the 1920s.

444
00:22:00,199 --> 00:22:03,493
So, science has left us orphaned.

445
00:22:04,709 --> 00:22:08,350
Science has not provided us with the mathematics

446
00:22:08,350 --> 00:22:13,350
to capture the idea of x causes y and y does not cause x.

447
00:22:13,883 --> 00:22:16,580
Because all the question of physics

448
00:22:16,580 --> 00:22:18,650
are symmetrical, algebraic.

449
00:22:18,650 --> 00:22:20,703
The equality sign goes both ways.

450
00:22:21,730 --> 00:22:23,140
- Okay, let's look at machine learning.

451
00:22:23,140 --> 00:22:26,900
Machine learning today, if you look at deep neural networks,

452
00:22:26,900 --> 00:22:31,477
you can think of it as kind of conditional probability

453
00:22:31,477 --> 00:22:32,310
estimators.

454
00:22:32,310 --> 00:22:33,700
- [Judea] Conditional probability.

455
00:22:33,700 --> 00:22:34,533
Correct.

456
00:22:35,453 --> 00:22:36,410
Beautiful.

457
00:22:36,410 --> 00:22:38,375
Well, did you say that?

458
00:22:38,375 --> 00:22:39,300
- [Lex] What?

459
00:22:39,300 --> 00:22:41,143
- Conditional probability estimators.

460
00:22:42,426 --> 00:22:44,926
None of the machine learning people clobbered you?

461
00:22:46,137 --> 00:22:46,970
(laughs) Attacked you?

462
00:22:49,440 --> 00:22:52,450
- Most people, and this is why today's conversation

463
00:22:52,450 --> 00:22:53,600
I think is interesting is,

464
00:22:53,600 --> 00:22:55,290
most people would agree with you.

465
00:22:55,290 --> 00:22:58,710
There's certain aspects that are just effective today,

466
00:22:58,710 --> 00:23:01,682
but we're going to hit a wall, and there's a lot of ideas,

467
00:23:01,682 --> 00:23:03,580
I think you're very right,

468
00:23:03,580 --> 00:23:06,503
that we're going to have to return to, about causality.

469
00:23:07,588 --> 00:23:10,734
Let's try to explore it.

470
00:23:10,734 --> 00:23:12,130
- Okay.

471
00:23:12,130 --> 00:23:13,210
- Let's even take a step back.

472
00:23:13,210 --> 00:23:15,323
You invented Bayesian networks,

473
00:23:17,430 --> 00:23:21,330
that look awfully a lot like they express something

474
00:23:21,330 --> 00:23:24,073
like causation, but they don't, not necessarily.

475
00:23:25,320 --> 00:23:28,288
So, how do we turn Bayesian networks

476
00:23:28,288 --> 00:23:30,860
into expressing causation?

477
00:23:30,860 --> 00:23:33,719
How do we build causal networks?

478
00:23:33,719 --> 00:23:36,510
A causes B, B causes C.

479
00:23:36,510 --> 00:23:38,850
How do we start to infer that kind of thing?

480
00:23:38,850 --> 00:23:41,500
- We start by asking ourselves question:

481
00:23:41,500 --> 00:23:46,370
what are the factors that would determine the value of x?

482
00:23:46,370 --> 00:23:51,290
X could be blood pressure, death, hunger.

483
00:23:52,614 --> 00:23:56,080
- But these are hypotheses that we propose--

484
00:23:56,080 --> 00:23:59,090
- Hypotheses, everything which has to do with causality

485
00:23:59,090 --> 00:24:00,823
comes from a theory.

486
00:24:02,007 --> 00:24:06,873
The difference is only how you interrogate the theory

487
00:24:06,873 --> 00:24:09,123
that you have in your mind.

488
00:24:10,940 --> 00:24:13,920
- So it still needs the human expert to propose--

489
00:24:13,920 --> 00:24:14,957
- Right.

490
00:24:14,957 --> 00:24:19,957
They need the human expert to specify the initial model.

491
00:24:21,010 --> 00:24:24,070
Initial model could be very qualitative.

492
00:24:24,070 --> 00:24:27,060
Just who listens to whom?

493
00:24:27,060 --> 00:24:30,870
By whom listens I mean one variable listens to the other.

494
00:24:30,870 --> 00:24:34,333
So, I say okay, the tide is listening to the moon,

495
00:24:36,140 --> 00:24:41,140
and not to the rooster crow, okay, and so forth.

496
00:24:43,150 --> 00:24:46,003
This is our understanding of the world in which we live,

497
00:24:46,890 --> 00:24:51,128
scientific understanding of reality.

498
00:24:51,128 --> 00:24:55,240
We have to start there, because if we don't know how

499
00:24:55,240 --> 00:24:58,600
to handle cause and effect relationship,

500
00:24:58,600 --> 00:25:02,980
when we do have a model, and we certainly do not know how

501
00:25:02,980 --> 00:25:05,440
to handle it when we don't have a model,

502
00:25:05,440 --> 00:25:07,450
so that starts first.

503
00:25:07,450 --> 00:25:12,450
An AI slogan is presentation first, discovery second.

504
00:25:12,462 --> 00:25:16,924
But, if I give you all the information that you need,

505
00:25:16,924 --> 00:25:19,301
can you do anything useful with it?

506
00:25:19,301 --> 00:25:21,560
That is the first, representation.

507
00:25:21,560 --> 00:25:22,580
How do you represent it?

508
00:25:22,580 --> 00:25:24,620
I give you all the knowledge in the world.

509
00:25:24,620 --> 00:25:25,820
How do you represent it?

510
00:25:26,970 --> 00:25:30,077
When you represent it, I ask you,

511
00:25:30,077 --> 00:25:33,230
can you infer x or y or z?

512
00:25:33,230 --> 00:25:35,290
Can you answer certain queries?

513
00:25:35,290 --> 00:25:36,940
Is it complex?

514
00:25:36,940 --> 00:25:38,800
Is it polynomial?

515
00:25:38,800 --> 00:25:42,070
All the computer science exercises, we do,

516
00:25:42,070 --> 00:25:47,070
once you give me a representation for my knowledge.

517
00:25:47,290 --> 00:25:49,582
Then you can ask me, now that I understand

518
00:25:49,582 --> 00:25:52,570
how to represent things, how do I discover them?

519
00:25:52,570 --> 00:25:54,063
It's a secondary thing.

520
00:25:55,006 --> 00:25:57,090
- I should echo the statement

521
00:25:57,090 --> 00:26:02,090
that mathematics in much of the machine learning world

522
00:26:02,215 --> 00:26:06,320
has not considered causation, that A causes B.

523
00:26:06,320 --> 00:26:08,190
Just in anything.

524
00:26:08,190 --> 00:26:13,190
That seems like a non-obvious thing

525
00:26:15,390 --> 00:26:18,300
that you think we would have really acknowledged it,

526
00:26:18,300 --> 00:26:19,260
but we haven't.

527
00:26:19,260 --> 00:26:21,060
So we have to put that on the table.

528
00:26:21,920 --> 00:26:23,620
Knowledge,

529
00:26:23,620 --> 00:26:28,450
How hard is it to create a knowledge from which to work?

530
00:26:28,450 --> 00:26:31,300
- In certain area, it's easy,

531
00:26:31,300 --> 00:26:36,300
because we have only four or five major variables.

532
00:26:36,863 --> 00:26:41,583
An epidemiologist or an economist can put them down.

533
00:26:42,544 --> 00:26:47,544
The minimum wage, unemployment, policy xyz,

534
00:26:51,400 --> 00:26:54,320
and start collecting data,

535
00:26:54,320 --> 00:26:59,213
and quantify the parameters that were left unquantified,

536
00:27:00,220 --> 00:27:01,543
with initial knowledge.

537
00:27:02,561 --> 00:27:07,561
That's the routine work that you find

538
00:27:07,630 --> 00:27:12,630
in experimental psychology, in economics, everywhere.

539
00:27:12,960 --> 00:27:16,570
In health science, that's a routine thing.

540
00:27:16,570 --> 00:27:19,630
But I should emphasize, you should start

541
00:27:19,630 --> 00:27:21,020
with the research question.

542
00:27:21,020 --> 00:27:24,870
What do you want to estimate?

543
00:27:24,870 --> 00:27:27,470
Once you have that, you have to have a language

544
00:27:27,470 --> 00:27:30,170
of expressing what you want to estimate.

545
00:27:30,170 --> 00:27:31,292
You think it's easy?

546
00:27:31,292 --> 00:27:32,750
No.

547
00:27:32,750 --> 00:27:34,900
- So we can talk about two things, I think.

548
00:27:35,830 --> 00:27:40,830
One is how the science of causation is very useful

549
00:27:44,016 --> 00:27:47,530
for answering certain questions,

550
00:27:47,530 --> 00:27:50,430
and then the other is how do we create intelligent systems

551
00:27:51,280 --> 00:27:53,630
that need to reason with causation?

552
00:27:53,630 --> 00:27:56,210
So if my research question is how do I pick up

553
00:27:56,210 --> 00:27:58,713
this water bottle from the table?

554
00:27:59,822 --> 00:28:04,822
All the knowledge that is required to be able to do that,

555
00:28:04,967 --> 00:28:07,090
how do we construct that knowledge base?

556
00:28:07,090 --> 00:28:11,050
Do we return back to the problem

557
00:28:11,050 --> 00:28:13,610
that we didn't solve in the 80s with expert systems?

558
00:28:13,610 --> 00:28:15,460
Do we have to solve that problem,

559
00:28:15,460 --> 00:28:17,883
of automated construction of knowledge?

560
00:28:19,237 --> 00:28:24,237
You're talking about the task of eliciting knowledge

561
00:28:24,800 --> 00:28:25,633
from an expert.

562
00:28:26,600 --> 00:28:28,624
- Task of eliciting knowledge from an expert,

563
00:28:28,624 --> 00:28:31,090
or self discovery of more knowledge,

564
00:28:31,090 --> 00:28:33,562
more and more knowledge.

565
00:28:33,562 --> 00:28:37,090
So, automating the building of knowledge

566
00:28:37,090 --> 00:28:38,620
as much as possible.

567
00:28:38,620 --> 00:28:42,430
- It's a different game, in the causal domain,

568
00:28:42,430 --> 00:28:46,500
because essentially it is the same thing.

569
00:28:46,500 --> 00:28:48,700
You have to start with some knowledge,

570
00:28:48,700 --> 00:28:51,540
and you're trying to enrich it.

571
00:28:51,540 --> 00:28:56,500
But you don't enrich it by asking for more rules.

572
00:28:56,500 --> 00:28:58,990
You enrich it by asking for the data.

573
00:28:58,990 --> 00:29:01,810
To look at the data, and quantifying,

574
00:29:01,810 --> 00:29:05,563
and ask queries that you couldn't answer when you started.

575
00:29:06,520 --> 00:29:11,520
You couldn't because the question is quite complex,

576
00:29:11,970 --> 00:29:16,970
and it's not within the capability of ordinary cognition,

577
00:29:18,810 --> 00:29:22,383
of ordinary person, ordinary expert even, to answer.

578
00:29:23,270 --> 00:29:25,832
- So what kind of questions do you think we can start

579
00:29:25,832 --> 00:29:27,030
to answer?

580
00:29:27,030 --> 00:29:29,830
- Even a simple, I suppose, yeah. (laughs)

581
00:29:29,830 --> 00:29:31,280
I start with easy one.

582
00:29:31,280 --> 00:29:32,113
- [Lex] Let's do it.

583
00:29:32,113 --> 00:29:35,963
- Okay, what's the effect of a drug on recovery?

584
00:29:36,912 --> 00:29:41,673
Was it the aspirin that caused my headache to be cured,

585
00:29:41,673 --> 00:29:44,690
or was it the television program,

586
00:29:44,690 --> 00:29:46,273
or the good news I received?

587
00:29:47,182 --> 00:29:49,960
This is already, see, it's a difficult question

588
00:29:49,960 --> 00:29:52,713
because it's: find the cause from effect.

589
00:29:53,730 --> 00:29:56,241
The easy one is find effect from cause.

590
00:29:56,241 --> 00:29:57,780
- That's right.

591
00:29:57,780 --> 00:29:59,490
So first you construct a model saying

592
00:29:59,490 --> 00:30:01,300
that this an important research question.

593
00:30:01,300 --> 00:30:02,850
This is an important question.

594
00:30:02,850 --> 00:30:04,330
Then you--

595
00:30:04,330 --> 00:30:05,540
- I didn't construct a model yet.

596
00:30:05,540 --> 00:30:07,210
I just said it's important question.

597
00:30:07,210 --> 00:30:08,924
- Important question.

598
00:30:08,924 --> 00:30:12,320
- And the first exercise is, express it mathematically.

599
00:30:12,320 --> 00:30:13,840
What do you want to prove?

600
00:30:13,840 --> 00:30:17,040
Like, if I tell you what will be the effect

601
00:30:17,040 --> 00:30:18,780
of taking this drug?

602
00:30:18,780 --> 00:30:21,360
Okay, you have to say that in mathematics.

603
00:30:21,360 --> 00:30:22,532
How do you say that?

604
00:30:22,532 --> 00:30:23,590
- Yes.

605
00:30:23,590 --> 00:30:25,510
- [Judea] Can you write down the question.

606
00:30:25,510 --> 00:30:26,423
Not the answer.

607
00:30:27,740 --> 00:30:31,459
I want to find the effect of a drug on my headache.

608
00:30:31,459 --> 00:30:32,702
- Right.

609
00:30:32,702 --> 00:30:34,160
- [Judea] Write it down, write it down.

610
00:30:34,160 --> 00:30:35,960
That's where the do-calculus comes in. (laughs)

611
00:30:35,960 --> 00:30:37,081
- [Judea] Yes.

612
00:30:37,081 --> 00:30:38,290
The do-operator, the do-operator.

613
00:30:38,290 --> 00:30:40,120
- Do-operator, yeah.

614
00:30:40,120 --> 00:30:40,953
Which is nice.

615
00:30:40,953 --> 00:30:43,340
It's the difference between association and intervention.

616
00:30:43,340 --> 00:30:45,800
Very beautifully sort of constructed.

617
00:30:45,800 --> 00:30:48,060
- Yeah, so we have a do-operator.

618
00:30:48,060 --> 00:30:50,530
So, the do-calculus connected--

619
00:30:50,530 --> 00:30:55,530
and the do-operator itself, connects the operation of doing

620
00:30:55,610 --> 00:30:57,551
to something that we can see.

621
00:30:57,551 --> 00:30:58,710
- Right.

622
00:30:58,710 --> 00:31:01,770
So as opposed to the purely observing,

623
00:31:01,770 --> 00:31:05,940
you're making the choice to change a variable--

624
00:31:05,940 --> 00:31:08,120
- That's what it expresses.

625
00:31:08,120 --> 00:31:11,492
And then, the way that we interpret it,

626
00:31:11,492 --> 00:31:15,460
the mechanism by which we take your query,

627
00:31:15,460 --> 00:31:18,680
and we translate it into something that we can work with,

628
00:31:18,680 --> 00:31:21,090
is by giving it semantics,

629
00:31:21,090 --> 00:31:23,380
saying that you have a model of the world,

630
00:31:23,380 --> 00:31:26,880
and you cut off all the incoming arrows into x,

631
00:31:26,880 --> 00:31:30,730
and you're looking now in the modified, mutilated model,

632
00:31:30,730 --> 00:31:33,690
you ask for the probability of y.

633
00:31:33,690 --> 00:31:36,400
That is interpretation of doing x,

634
00:31:36,400 --> 00:31:40,270
because by doing things, you've liberated them

635
00:31:40,270 --> 00:31:45,240
from all influences that acted upon them earlier,

636
00:31:45,240 --> 00:31:49,272
and you subject them to the tyranny of your muscles.

637
00:31:49,272 --> 00:31:53,210
- So you (chuckles) you remove all the questions

638
00:31:53,210 --> 00:31:55,770
about causality by doing them.

639
00:31:55,770 --> 00:31:59,090
- So there is one level of questions.

640
00:31:59,090 --> 00:32:01,950
Answer questions about what will happen if you do things.

641
00:32:01,950 --> 00:32:03,360
If you do, if you drink the coffee,

642
00:32:03,360 --> 00:32:05,520
or if you take the aspirin.

643
00:32:05,520 --> 00:32:06,726
- [Judea] Right.

644
00:32:06,726 --> 00:32:10,970
- So how do we get the doing data? (laughs)

645
00:32:10,970 --> 00:32:15,678
- Hah. Now the question is, if you cannot run experiments,

646
00:32:15,678 --> 00:32:20,678
right, then we have to rely on observation and study.

647
00:32:21,010 --> 00:32:22,610
- So first we could, sorry to interrupt,

648
00:32:22,610 --> 00:32:24,450
we could run an experiment,

649
00:32:24,450 --> 00:32:26,970
where we do something, where we drink the coffee,

650
00:32:26,970 --> 00:32:29,282
and the do-operator allows you

651
00:32:29,282 --> 00:32:31,830
to sort of be systematic about expressing that.

652
00:32:31,830 --> 00:32:34,630
- To imagine how the experiment will look like

653
00:32:34,630 --> 00:32:37,780
even though we cannot physically and technologically

654
00:32:37,780 --> 00:32:38,810
conduct it.

655
00:32:38,810 --> 00:32:40,640
I'll give you an example.

656
00:32:40,640 --> 00:32:43,140
What is the effect of blood pressure on mortality?

657
00:32:44,643 --> 00:32:47,400
I cannot go down into your vein

658
00:32:47,400 --> 00:32:49,440
and change your blood pressure.

659
00:32:49,440 --> 00:32:51,639
But I can ask the question,

660
00:32:51,639 --> 00:32:55,130
which means I can have a model of your body.

661
00:32:55,130 --> 00:33:00,130
I can imagine how the blood pressure change

662
00:33:02,470 --> 00:33:04,770
will affect your mortality.

663
00:33:04,770 --> 00:33:05,603
How?

664
00:33:05,603 --> 00:33:09,770
I go into the model, and I conduct this surgery,

665
00:33:09,770 --> 00:33:12,120
about the blood pressure,

666
00:33:12,120 --> 00:33:15,510
even though physically I cannot do it.

667
00:33:15,510 --> 00:33:19,800
- Let me ask the quantum mechanics question.

668
00:33:19,800 --> 00:33:22,579
Does the doing change the observation?

669
00:33:22,579 --> 00:33:27,407
Meaning, the surgery of changing the blood pressure--

670
00:33:27,407 --> 00:33:31,750
- No, the surgery is very delicate.

671
00:33:34,855 --> 00:33:36,260
- [Lex] It's very delicate.

672
00:33:36,260 --> 00:33:37,870
Infinitely delicate. (laughs)

673
00:33:37,870 --> 00:33:39,373
- Incisive and delicate,

674
00:33:40,591 --> 00:33:45,591
which means, do-x means I'm going to touch only x.

675
00:33:46,043 --> 00:33:47,283
- [Lex] Only x.

676
00:33:48,919 --> 00:33:50,230
- Directly into x.

677
00:33:50,230 --> 00:33:52,950
So, that means that I change only things

678
00:33:56,353 --> 00:34:00,017
which depend on x, by virtue of x changing.

679
00:34:00,017 --> 00:34:00,850
But I don't depend things which are not depend on x.

680
00:34:02,273 --> 00:34:04,020
Like, I wouldn't change your sex, or your age.

681
00:34:04,020 --> 00:34:06,930
I just change your blood pressure, okay?

682
00:34:06,930 --> 00:34:10,010
- So, in the case of blood pressure, it may be

683
00:34:10,010 --> 00:34:12,860
difficult or impossible to construct such an experiment.

684
00:34:12,860 --> 00:34:14,980
- No, but physically, yes.

685
00:34:14,980 --> 00:34:16,570
But hypothetically no.

686
00:34:16,570 --> 00:34:17,590
- [Lex] Hypothetically no.

687
00:34:17,590 --> 00:34:20,770
- If we had a model, that is what the model is for.

688
00:34:20,770 --> 00:34:24,670
So, you conduct surgeries on the models.

689
00:34:24,670 --> 00:34:26,909
You take it apart, put it back.

690
00:34:26,909 --> 00:34:28,920
That's the idea for model.

691
00:34:28,920 --> 00:34:31,650
It's the idea of thinking counterfactually, imagining,

692
00:34:31,650 --> 00:34:35,170
and that idea of creativity.

693
00:34:35,170 --> 00:34:37,797
- So by constructing that model you can start

694
00:34:37,797 --> 00:34:42,797
to infer if the blood pressure leads to mortality,

695
00:34:44,318 --> 00:34:47,400
which increases or decreases, whi--

696
00:34:47,400 --> 00:34:48,590
- I construct a model.

697
00:34:48,590 --> 00:34:50,690
I still cannot answer it.

698
00:34:50,690 --> 00:34:53,850
I have to see if I have enough information in the model

699
00:34:53,850 --> 00:34:58,360
that would allow me to find out the effects of intervention

700
00:34:58,360 --> 00:35:03,360
from an uninterventional study, from a hands-off study.

701
00:35:03,881 --> 00:35:06,156
- [Lex] So what's needed--

702
00:35:06,156 --> 00:35:11,156
- We need to have assumptions about who affects whom.

703
00:35:12,935 --> 00:35:16,430
If the graph has a certain property,

704
00:35:16,430 --> 00:35:17,263
the answer is

705
00:35:17,263 --> 00:35:20,580
"yes, you can get it from observational study."

706
00:35:20,580 --> 00:35:23,780
If the graph is too mushy bushy bushy,

707
00:35:23,780 --> 00:35:25,720
the answer is, "no, you cannot."

708
00:35:25,720 --> 00:35:29,490
Then you need to find either different kind

709
00:35:29,490 --> 00:35:32,470
of observation that you haven't considered,

710
00:35:32,470 --> 00:35:34,223
or one experiment.

711
00:35:35,130 --> 00:35:38,920
- So, basically, that puts a lot of pressure on you

712
00:35:38,920 --> 00:35:41,890
to encode wisdom into that graph.

713
00:35:41,890 --> 00:35:43,180
- Correct.

714
00:35:43,180 --> 00:35:47,251
But you don't have to encode more than what you know.

715
00:35:47,251 --> 00:35:48,170
God forbid.

716
00:35:48,170 --> 00:35:51,410
The economists are doing that.

717
00:35:51,410 --> 00:35:52,900
They call identifying assumptions.

718
00:35:52,900 --> 00:35:55,180
They put assumptions, even they don't prevail

719
00:35:55,180 --> 00:35:56,583
in the world, they put assumptions

720
00:35:56,583 --> 00:35:59,242
so they can identify things.

721
00:35:59,242 --> 00:36:00,550
- Yes, beautifully put.

722
00:36:00,550 --> 00:36:04,243
But, the problem is you don't know what you don't know.

723
00:36:04,243 --> 00:36:07,164
- You know what you don't know,

724
00:36:07,164 --> 00:36:10,390
because if you don't know, you say it's possible

725
00:36:11,770 --> 00:36:16,386
that x affect the traffic tomorrow.

726
00:36:16,386 --> 00:36:18,720
It's possible.

727
00:36:18,720 --> 00:36:20,940
You put down an arrow which says it's possible.

728
00:36:20,940 --> 00:36:23,970
Every arrow in the graph says it's possible.

729
00:36:23,970 --> 00:36:27,174
- [Lex] So there's not a significant cost to adding arrows,

730
00:36:27,174 --> 00:36:30,509
- The more arrow you add--

731
00:36:30,509 --> 00:36:31,789
- [Lex] The better.

732
00:36:31,789 --> 00:36:34,610
- The less likely you are to identify things

733
00:36:34,610 --> 00:36:36,160
from purely observational data.

734
00:36:37,700 --> 00:36:39,583
So if the whole world is bushy,

735
00:36:40,519 --> 00:36:44,667
and everybody effect everybody else,

736
00:36:44,667 --> 00:36:48,843
the answer is-- you can answer it ahead of time.

737
00:36:48,843 --> 00:36:53,843
I cannot answer my query from observational data.

738
00:36:54,250 --> 00:36:55,673
I have to go to experiments.

739
00:36:56,670 --> 00:36:59,189
- So, you talk about machine learning as essentially

740
00:36:59,189 --> 00:37:03,180
learning by association, or reasoning by association,

741
00:37:03,180 --> 00:37:07,140
and this do-calculus is allowing for intervention.

742
00:37:07,140 --> 00:37:08,286
I like that word.

743
00:37:08,286 --> 00:37:12,400
You also talk about counterfactuals.

744
00:37:12,400 --> 00:37:13,233
- Yeah.

745
00:37:13,233 --> 00:37:15,900
- And trying to sort of understand the difference

746
00:37:15,900 --> 00:37:18,343
between counterfactuals and intervention,

747
00:37:19,680 --> 00:37:22,390
first of all, what is counterfactuals,

748
00:37:22,390 --> 00:37:25,716
and why are they useful?

749
00:37:25,716 --> 00:37:29,700
Why are they especially useful

750
00:37:29,700 --> 00:37:34,510
as opposed to just reasoning what effect actions have?

751
00:37:34,510 --> 00:37:38,220
- Well, counterfactual contains what we know

752
00:37:38,220 --> 00:37:40,260
will equal explanations.

753
00:37:40,260 --> 00:37:41,991
- Can you give an example of what kind of--

754
00:37:41,991 --> 00:37:45,240
- If I tell you that acting one way affects something else,

755
00:37:45,240 --> 00:37:47,279
I didn't explain anything yet.

756
00:37:47,279 --> 00:37:52,279
But if I ask you, was it the aspirin that cure my headache,

757
00:37:54,610 --> 00:37:58,700
I'm asking for explanation: what cure my headache?

758
00:37:58,700 --> 00:38:03,700
And putting a finger on aspirin, provide explanation.

759
00:38:04,690 --> 00:38:08,200
It was the aspirin that was responsible

760
00:38:08,200 --> 00:38:11,233
for your headache going away.

761
00:38:11,233 --> 00:38:14,470
If you didn't take the aspirin,

762
00:38:14,470 --> 00:38:16,020
you will still have a headache.

763
00:38:16,020 --> 00:38:20,227
- So by saying, "If I didn't take aspirin,

764
00:38:20,227 --> 00:38:21,220
"I would have a headache,"

765
00:38:21,220 --> 00:38:24,047
you're thereby saying, "The aspirin is the thing

766
00:38:24,047 --> 00:38:26,000
"that removed the headache."

767
00:38:26,000 --> 00:38:30,146
- Yes, but you have to have another point of information.

768
00:38:30,146 --> 00:38:34,181
I took the aspirin, and my headache is gone.

769
00:38:34,181 --> 00:38:36,430
It's very important information.

770
00:38:36,430 --> 00:38:38,897
Now we're reasoning backward, and I say,

771
00:38:38,897 --> 00:38:40,550
"Was it the aspirin?"

772
00:38:40,550 --> 00:38:41,438
- Yeah.

773
00:38:41,438 --> 00:38:44,134
By considering what would have happened

774
00:38:44,134 --> 00:38:47,073
if everything is the same, but I didn't take aspirin.

775
00:38:47,073 --> 00:38:47,906
- That's right.

776
00:38:47,906 --> 00:38:50,748
So we know that things took place, you know?

777
00:38:50,748 --> 00:38:52,293
Joe killed Schmo.

778
00:38:53,199 --> 00:38:58,199
And Schmo would be alive had Joe not used his gun.

779
00:38:58,976 --> 00:39:02,090
Okay, so that is the counterfactual.

780
00:39:02,090 --> 00:39:04,347
It had a confliction.

781
00:39:04,347 --> 00:39:06,680
It had a conflict here, or clash

782
00:39:06,680 --> 00:39:11,653
between observed fact -- he did shoot, okay --

783
00:39:13,620 --> 00:39:16,630
and the hypothetical predicate,

784
00:39:16,630 --> 00:39:18,840
which says, had he not shot.

785
00:39:18,840 --> 00:39:21,580
You have a clash, a logical clash,

786
00:39:21,580 --> 00:39:23,860
that cannot exist together.

787
00:39:23,860 --> 00:39:24,950
That's counterfactual,

788
00:39:24,950 --> 00:39:28,330
and that is the source of our explanation

789
00:39:28,330 --> 00:39:33,330
of the idea of responsibility, regret, and free will.

790
00:39:33,762 --> 00:39:35,995
- Yes, it certainly seems,

791
00:39:35,995 --> 00:39:39,038
that's the highest level of reasoning, right?

792
00:39:39,038 --> 00:39:39,871
Counterfactual.

793
00:39:39,871 --> 00:39:41,930
- [Judea] Yes, and physicists do it all the time.

794
00:39:41,930 --> 00:39:42,800
- Who does it all the time?

795
00:39:42,800 --> 00:39:44,471
- [Judea] Physicists.

796
00:39:44,471 --> 00:39:45,746
- Physicists.

797
00:39:45,746 --> 00:39:47,780
- In every equation of physics,

798
00:39:47,780 --> 00:39:49,610
you have Hooke's law,

799
00:39:49,610 --> 00:39:52,270
and you put one kilogram on the spring,

800
00:39:52,270 --> 00:39:54,740
and the spring is one meter,

801
00:39:54,740 --> 00:39:58,337
and you say, "Had this weight been two kilograms,

802
00:39:58,337 --> 00:40:00,487
"the spring would have been twice as long."

803
00:40:01,416 --> 00:40:05,610
It's not a problem for physicists to say that.

804
00:40:05,610 --> 00:40:10,264
Instead with mathematics, it is in the form of an equation,

805
00:40:10,264 --> 00:40:15,264
equating the weight, proportionality constant,

806
00:40:16,121 --> 00:40:18,439
and the length of the spring.

807
00:40:18,439 --> 00:40:23,320
We don't have the assymetry in the equation of physics,

808
00:40:23,320 --> 00:40:26,860
although every physicist thinks counterfactually.

809
00:40:26,860 --> 00:40:31,160
Ask high school kids, had the weight been three kilograms,

810
00:40:31,160 --> 00:40:33,410
what would be the length of the spring?

811
00:40:33,410 --> 00:40:35,200
They can answer it immediately,

812
00:40:35,200 --> 00:40:38,940
because they do the counterfactual processing in their mind,

813
00:40:38,940 --> 00:40:42,310
and then they put it into equation, algebraic equation,

814
00:40:42,310 --> 00:40:43,809
and they solve it.

815
00:40:43,809 --> 00:40:45,760
But a robot cannot do that.

816
00:40:45,760 --> 00:40:50,760
- How do you make a robot learn these relationships?

817
00:40:50,915 --> 00:40:53,260
- Why use the word "learn?"

818
00:40:53,260 --> 00:40:55,790
Suppose you tell him, can you do it?

819
00:40:55,790 --> 00:40:58,808
Before you go learning, you have to ask yourself,

820
00:40:58,808 --> 00:40:59,641
suppose I give all the information.

821
00:40:59,641 --> 00:41:04,641
Can the robot perform a task that I ask him to perform?

822
00:41:05,600 --> 00:41:09,557
Can he reason and say, "No, it wasn't the aspirin.

823
00:41:09,557 --> 00:41:13,929
"It was the good news we received on the phone."

824
00:41:13,929 --> 00:41:18,929
- Right, because, well, unless the robot had a model,

825
00:41:19,130 --> 00:41:22,285
a causal model of the world.

826
00:41:22,285 --> 00:41:23,983
- [Judea] Right, right.

827
00:41:23,983 --> 00:41:26,037
- I'm sorry I have to linger on this--

828
00:41:26,037 --> 00:41:27,965
- [Judea] But now we have to linger, and we have to say,

829
00:41:27,965 --> 00:41:29,120
"How do we do it?"

830
00:41:29,120 --> 00:41:29,953
- How do we build it?

831
00:41:29,953 --> 00:41:31,376
- [Judea] Yes.

832
00:41:31,376 --> 00:41:32,510
- How do we build a causal model

833
00:41:34,123 --> 00:41:36,710
without a team of human experts running around--

834
00:41:36,710 --> 00:41:39,192
- No, why did you go to learning right away?

835
00:41:39,192 --> 00:41:41,671
You are too much involved with learning.

836
00:41:41,671 --> 00:41:42,504
- Because I like babies.

837
00:41:42,504 --> 00:41:43,877
Babies learn fast, and I'm trying to figure out

838
00:41:43,877 --> 00:41:45,180
how they do it.

839
00:41:45,180 --> 00:41:46,212
- Good.

840
00:41:46,212 --> 00:41:47,700
That's another question:

841
00:41:47,700 --> 00:41:49,150
How do the babies come out

842
00:41:49,150 --> 00:41:51,820
with the counterfactual model of the world?

843
00:41:51,820 --> 00:41:53,670
And babies do that.

844
00:41:53,670 --> 00:41:56,574
They know how to play in the crib.

845
00:41:56,574 --> 00:41:59,134
They know which balls hits another one,

846
00:41:59,134 --> 00:42:04,134
and they learn it by playful manipulation

847
00:42:04,598 --> 00:42:06,905
of the world.

848
00:42:06,905 --> 00:42:10,610
Their simple world involves all these toys and balls

849
00:42:10,610 --> 00:42:12,580
and chimes (laughs)

850
00:42:12,580 --> 00:42:17,280
but if you think about it, it's a complex world.

851
00:42:17,280 --> 00:42:19,919
- We take for granted how complicated--

852
00:42:19,919 --> 00:42:23,770
- And the kids do it by playful manipulation,

853
00:42:23,770 --> 00:42:28,770
plus parent guidance, peer wisdom, and heresay.

854
00:42:30,459 --> 00:42:34,943
They meet each other, and they say,

855
00:42:34,943 --> 00:42:38,950
"You shouldn't have taken my toy." (laughs)

856
00:42:38,950 --> 00:42:39,783
- Right,

857
00:42:40,850 --> 00:42:43,590
and these multiple sources of information,

858
00:42:43,590 --> 00:42:45,227
they're able to integrate.

859
00:42:45,227 --> 00:42:49,010
So, the challenge is about how to integrate,

860
00:42:49,010 --> 00:42:52,670
how to form these causal relationships

861
00:42:52,670 --> 00:42:54,120
from different sources of data.

862
00:42:54,120 --> 00:42:55,020
- [Judea] Correct.

863
00:42:56,633 --> 00:43:01,633
- So, how much causal information is required

864
00:43:02,494 --> 00:43:06,820
to be able to play in the crib with different objects?

865
00:43:06,820 --> 00:43:08,320
- I don't know.

866
00:43:08,320 --> 00:43:11,390
I haven't experimented with the crib. (chuckles)

867
00:43:11,390 --> 00:43:12,620
- [Lex] Okay, not a crib--

868
00:43:12,620 --> 00:43:14,180
- I know, it's a very interesting--

869
00:43:14,180 --> 00:43:16,950
- Manipulating physical objects on this very,

870
00:43:16,950 --> 00:43:20,641
opening the pages of a book, all the tasks,

871
00:43:20,641 --> 00:43:24,772
physical manipulation tasks, do you have a sense?

872
00:43:24,772 --> 00:43:28,070
Because my sense is the world is extremely complicated.

873
00:43:28,070 --> 00:43:29,470
- Extremely complicated.

874
00:43:29,470 --> 00:43:31,300
I agree and I don't know how to organize it,

875
00:43:31,300 --> 00:43:34,690
because I've been spoiled by easy problems

876
00:43:34,690 --> 00:43:38,490
such as cancer and death, okay? (laughs)

877
00:43:38,490 --> 00:43:41,670
- [Lex] First we have to start trying to--

878
00:43:41,670 --> 00:43:43,660
- No, but it's easy, easy in the sense

879
00:43:43,660 --> 00:43:47,030
that you have only 20 variables,

880
00:43:47,030 --> 00:43:49,193
and they are just variables.

881
00:43:49,193 --> 00:43:51,530
They are not mechanics, okay?

882
00:43:51,530 --> 00:43:52,363
It's easy.

883
00:43:52,363 --> 00:43:53,640
You just put them on the graph

884
00:43:53,640 --> 00:43:57,503
and they speak to you. (laughs)

885
00:43:57,503 --> 00:44:00,612
- [Lex] And you're providing a methodology

886
00:44:00,612 --> 00:44:01,895
for letting them speak.

887
00:44:01,895 --> 00:44:04,865
- I'm working only in the abstract.

888
00:44:04,865 --> 00:44:08,279
The abstract is knowledge in, knowledge out,

889
00:44:08,279 --> 00:44:10,974
data in between.

890
00:44:10,974 --> 00:44:15,110
- Now, can we take a leap to trying to learn,

891
00:44:15,110 --> 00:44:20,110
when it's not 20 variables but 20 million variables,

892
00:44:20,159 --> 00:44:23,657
trying to learn causation in this world.

893
00:44:23,657 --> 00:44:26,297
Not learn, but somehow construct models.

894
00:44:26,297 --> 00:44:28,247
I mean, it seems like you would only have

895
00:44:28,247 --> 00:44:30,064
to be able to learn,

896
00:44:30,064 --> 00:44:34,957
because constructing it manually would be too difficult.

897
00:44:34,957 --> 00:44:36,887
Do you have ideas of--

898
00:44:36,887 --> 00:44:41,240
- I think it's a matter of combining simple models

899
00:44:41,240 --> 00:44:44,582
from many, many sources, from many, many disciplines.

900
00:44:44,582 --> 00:44:47,444
And many metaphors.

901
00:44:47,444 --> 00:44:51,018
Metaphors are the basis of human intelligence.

902
00:44:51,018 --> 00:44:54,080
- Yeah, so how do you think about a metaphor

903
00:44:54,080 --> 00:44:56,190
in terms of its use in human intelligence?

904
00:44:56,190 --> 00:45:00,373
- Metaphors is an expert system.

905
00:45:02,084 --> 00:45:07,084
It's mapping problem with which you are not familiar,

906
00:45:09,620 --> 00:45:13,840
to a problem with which you are familiar.

907
00:45:13,840 --> 00:45:16,010
Like I give you a great example.

908
00:45:16,010 --> 00:45:21,010
The Greek believed that the sky is an opaque sheer.

909
00:45:22,280 --> 00:45:27,230
It's not really infinite space; it's an opaque sheer,

910
00:45:27,230 --> 00:45:32,100
and the stars are holes poked in the sheer,

911
00:45:32,100 --> 00:45:34,650
through which you see the eternal light.

912
00:45:34,650 --> 00:45:37,000
It was a metaphor, why?

913
00:45:37,000 --> 00:45:41,408
Because they understand how you poke holes in sheers.

914
00:45:41,408 --> 00:45:45,204
They were not familiar with infinite space.

915
00:45:45,204 --> 00:45:50,204
And we are walking on a shell of a turtle,

916
00:45:51,794 --> 00:45:54,570
and if you get too close to the edge,

917
00:45:54,570 --> 00:45:57,374
you're going to fall down to Hades, or wherever, yeah.

918
00:45:57,374 --> 00:46:00,081
That's a metaphor.

919
00:46:00,081 --> 00:46:01,619
It's not true.

920
00:46:01,619 --> 00:46:06,619
But these kind of metaphor enabled Eratosthenes

921
00:46:07,102 --> 00:46:10,119
to measure the radius of the Earth,

922
00:46:10,119 --> 00:46:12,547
because he said, "Come on.

923
00:46:12,547 --> 00:46:14,738
"If we are walking on a turtle shell,

924
00:46:14,738 --> 00:46:19,393
"then the ray of light coming to this place

925
00:46:19,393 --> 00:46:22,987
"will be different angle than coming to this place.

926
00:46:22,987 --> 00:46:23,987
"I know the distance.

927
00:46:23,987 --> 00:46:26,357
"I'll measure the two angles,

928
00:46:26,357 --> 00:46:31,357
"and then I have the radius of the shell of the turtle."

929
00:46:32,421 --> 00:46:34,896
And he did.

930
00:46:34,896 --> 00:46:39,540
And his measurement was very close

931
00:46:39,540 --> 00:46:42,343
to the measurements we have today.

932
00:46:43,270 --> 00:46:48,270
It was, what, 6,700 kilometers, was the Earth?

933
00:46:51,292 --> 00:46:54,936
That's something that would not occur

934
00:46:54,936 --> 00:46:59,810
to a Babylonian astronomer,

935
00:46:59,810 --> 00:47:01,923
even though the Babylonian experiments

936
00:47:01,923 --> 00:47:04,650
were the machine learning people of the time.

937
00:47:04,650 --> 00:47:08,003
They fit curves, and they could predict the eclipse

938
00:47:08,003 --> 00:47:13,003
of the moon much more accurately than the Greek,

939
00:47:13,159 --> 00:47:15,246
because they fit curves.

940
00:47:15,246 --> 00:47:19,270
That's a different metaphor,

941
00:47:19,270 --> 00:47:20,610
something that you're familiar with,

942
00:47:20,610 --> 00:47:21,833
a game, a turtle shell.

943
00:47:23,166 --> 00:47:27,550
What does it mean, if you are familiar?

944
00:47:27,550 --> 00:47:31,280
Familiar means that answers to certain questions

945
00:47:31,280 --> 00:47:33,500
are explicit.

946
00:47:33,500 --> 00:47:35,610
You don't have to derive them.

947
00:47:35,610 --> 00:47:37,580
- And they were made explicit

948
00:47:37,580 --> 00:47:40,450
because somewhere in the past you've constructed

949
00:47:40,450 --> 00:47:42,251
a model of that--

950
00:47:42,251 --> 00:47:46,210
- You're familiar with, so the child is familiar

951
00:47:46,210 --> 00:47:47,913
with billiard balls.

952
00:47:47,913 --> 00:47:49,910
So the child could predict that

953
00:47:49,910 --> 00:47:52,292
if you let loose of one ball,

954
00:47:52,292 --> 00:47:54,223
the other one will bounce off.

955
00:47:55,100 --> 00:48:00,100
You attain that by familiarity.

956
00:48:00,210 --> 00:48:02,940
Familiarity is answering questions,

957
00:48:02,940 --> 00:48:05,579
and you store the answer explicitly.

958
00:48:05,579 --> 00:48:08,050
You don't have to derive it.

959
00:48:08,050 --> 00:48:09,680
So this is idea for metaphor.

960
00:48:09,680 --> 00:48:11,670
All our life, all our intelligence,

961
00:48:11,670 --> 00:48:13,460
is built around metaphors,

962
00:48:13,460 --> 00:48:16,280
mapping from the unfamiliar to the familiar,

963
00:48:16,280 --> 00:48:20,618
but the marriage between the two is a tough thing,

964
00:48:20,618 --> 00:48:24,790
which we haven't yet been able to algorithmatize.

965
00:48:24,790 --> 00:48:29,330
- So, you think of that process of using metaphor

966
00:48:29,330 --> 00:48:31,739
to leap from one place to another.

967
00:48:31,739 --> 00:48:33,899
We can call it reasoning.

968
00:48:33,899 --> 00:48:35,900
Is it a kind of reasoning?

969
00:48:35,900 --> 00:48:37,746
- [Judea] It is a reasoning by metaphor, but--

970
00:48:37,746 --> 00:48:39,510
- Reasoning by metaphor.

971
00:48:39,510 --> 00:48:42,792
Do you think of that as learning?

972
00:48:42,792 --> 00:48:46,144
So, learning is a popular terminology today

973
00:48:46,144 --> 00:48:47,720
in a narrow sense.

974
00:48:47,720 --> 00:48:49,710
- [Judea] It is, it is definitely.

975
00:48:49,710 --> 00:48:51,734
- So you may not-- you're right.

976
00:48:51,734 --> 00:48:53,840
- It's one of the most important learning,

977
00:48:53,840 --> 00:48:57,680
taking something which theoretically is derivable,

978
00:48:57,680 --> 00:49:01,750
and store it in accessible format.

979
00:49:01,750 --> 00:49:05,633
I'll give you an example: chess, okay?

980
00:49:06,667 --> 00:49:11,667
Finding the winning starting move in chess is hard.

981
00:49:16,393 --> 00:49:20,673
But there is an answer.

982
00:49:20,673 --> 00:49:24,530
Either there is a winning move for white, or there isn't,

983
00:49:24,530 --> 00:49:25,713
or it is a draw.

984
00:49:26,860 --> 00:49:31,130
So, the answer to that is available

985
00:49:31,130 --> 00:49:32,580
through the rule of the game.

986
00:49:33,574 --> 00:49:35,500
But we don't know the answer.

987
00:49:35,500 --> 00:49:38,400
So what does a chess master have that we don't have?

988
00:49:38,400 --> 00:49:41,820
He has stored explicitly an evaluation

989
00:49:41,820 --> 00:49:45,067
of certain complex pattern of the board.

990
00:49:45,067 --> 00:49:49,060
We don't have it, ordinary people, like me.

991
00:49:49,060 --> 00:49:51,000
I don't know about you.

992
00:49:51,000 --> 00:49:52,850
I'm not a chess master.

993
00:49:52,850 --> 00:49:57,625
So for me I have to derive things that for him is explicit.

994
00:49:57,625 --> 00:50:02,042
He has seen it before, or he has seen the pattern before,

995
00:50:02,042 --> 00:50:04,583
or similar patterns before,

996
00:50:04,583 --> 00:50:08,607
and he generalizes, and says,

997
00:50:08,607 --> 00:50:11,187
"Don't move; it's a dangerous move."

998
00:50:12,761 --> 00:50:15,560
- It's just that, not in the game of chess,

999
00:50:15,560 --> 00:50:18,622
but in the game of billiard balls

1000
00:50:18,622 --> 00:50:22,460
we humans are able to initially derive very effectively

1001
00:50:22,460 --> 00:50:25,130
and then reason by metaphor very effectively,

1002
00:50:25,130 --> 00:50:27,200
and we make it look so easy,

1003
00:50:27,200 --> 00:50:28,750
and it makes one wonder

1004
00:50:28,750 --> 00:50:31,283
how hard is it to build it in a machine?

1005
00:50:32,878 --> 00:50:37,878
In your sense, (laughs) how far away are we

1006
00:50:37,929 --> 00:50:39,720
to be able to construct--

1007
00:50:39,720 --> 00:50:40,970
- I don't know.

1008
00:50:40,970 --> 00:50:43,327
I'm not a futurist.

1009
00:50:43,327 --> 00:50:48,327
All I can tell you is that we are making tremendous progress

1010
00:50:48,450 --> 00:50:52,170
in the causal reasoning domain.

1011
00:50:52,170 --> 00:50:57,170
Something that I even dare to call it a revolution,

1012
00:50:59,020 --> 00:51:00,690
the causal revolution,

1013
00:51:00,690 --> 00:51:05,690
because what we have achieved in the past three decades

1014
00:51:07,290 --> 00:51:12,290
is something that dwarf everything that was derived

1015
00:51:12,970 --> 00:51:15,450
in the entire history.

1016
00:51:15,450 --> 00:51:16,840
- So there's an excitement

1017
00:51:16,840 --> 00:51:20,254
about current machine learning methodologies,

1018
00:51:20,254 --> 00:51:23,980
and there's really important good work you're doing

1019
00:51:23,980 --> 00:51:26,433
in causal inference.

1020
00:51:27,433 --> 00:51:32,433
Where do these worlds collide, and what does that look like?

1021
00:51:34,118 --> 00:51:38,750
- First they gotta work without collisions. (laughs)

1022
00:51:38,750 --> 00:51:40,917
It's got to work in harmony.

1023
00:51:40,917 --> 00:51:41,800
- [Lex] Harmony.

1024
00:51:41,800 --> 00:51:46,800
- The human is going to jumpstart the exercise

1025
00:51:48,580 --> 00:51:53,373
by providing qualitative, noncommitting models

1026
00:51:55,100 --> 00:51:57,477
of how the universe works,

1027
00:51:57,477 --> 00:52:02,477
how reality, the domain of discourse, works.

1028
00:52:03,147 --> 00:52:06,070
The machine is going to take over from that point

1029
00:52:06,070 --> 00:52:09,002
of view, and derive whatever the calculus

1030
00:52:09,002 --> 00:52:11,285
says can be derived,

1031
00:52:11,285 --> 00:52:15,415
namely, quantitative answer to our questions.

1032
00:52:15,415 --> 00:52:18,470
These are complex questions.

1033
00:52:18,470 --> 00:52:21,250
I'll give you some examples of complex questions,

1034
00:52:21,250 --> 00:52:26,250
that boggle your mind if you think about it.

1035
00:52:27,175 --> 00:52:32,175
You take the results of studies in diverse population,

1036
00:52:33,288 --> 00:52:35,830
under diverse conditions,

1037
00:52:35,830 --> 00:52:40,760
and you infer the cause effect of a new population

1038
00:52:40,760 --> 00:52:45,200
which doesn't even resemble any of the ones studied.

1039
00:52:45,200 --> 00:52:48,320
You do that by do-calculus.

1040
00:52:48,320 --> 00:52:52,670
You do that by generalizing from one study to another.

1041
00:52:52,670 --> 00:52:54,700
See, what's common there too?

1042
00:52:54,700 --> 00:52:57,040
What is different?

1043
00:52:57,040 --> 00:53:01,220
Let's ignore the differences and pull out the commonality.

1044
00:53:01,220 --> 00:53:06,190
And you do it over maybe 100 hospitals around the world.

1045
00:53:06,190 --> 00:53:11,190
From that, you can get really mileage from big data.

1046
00:53:12,159 --> 00:53:15,080
It's not only that you have many samples;

1047
00:53:15,080 --> 00:53:17,853
you have many sources of data.

1048
00:53:18,750 --> 00:53:21,500
- So that's a really powerful thing, I think,

1049
00:53:21,500 --> 00:53:23,737
especially for medical applications.

1050
00:53:23,737 --> 00:53:25,860
Cure cancer, right?

1051
00:53:25,860 --> 00:53:28,580
That's how, from data, you can cure cancer.

1052
00:53:28,580 --> 00:53:30,110
So we're talking about causation,

1053
00:53:30,110 --> 00:53:34,589
which is the temporal relationships between things.

1054
00:53:34,589 --> 00:53:36,326
- Not only temporal.

1055
00:53:36,326 --> 00:53:38,903
It was structural and temporal.

1056
00:53:38,903 --> 00:53:43,903
Temporal precedence by itself cannot replace causation.

1057
00:53:45,593 --> 00:53:50,363
- Is temporal precedence the arrow of time in physics?

1058
00:53:50,363 --> 00:53:52,679
- [Judea] Yeah, it's important, necessary.

1059
00:53:52,679 --> 00:53:53,512
- It's important.

1060
00:53:53,512 --> 00:53:54,345
- [Judea] Yes.

1061
00:53:54,345 --> 00:53:55,790
- Is it?

1062
00:53:55,790 --> 00:53:59,945
- Yes, I've never seen a cause propagate backwards.

1063
00:53:59,945 --> 00:54:03,498
- But if we use the word cause,

1064
00:54:03,498 --> 00:54:07,120
but there's relationships that are timeless.

1065
00:54:07,120 --> 00:54:10,420
I suppose that's still forward an arrow of time.

1066
00:54:10,420 --> 00:54:14,288
But, are there relationships, logical relationships,

1067
00:54:14,288 --> 00:54:17,012
that fit into the structure?

1068
00:54:17,012 --> 00:54:22,012
- [Judea] Sure. All do-calculus is logical relationships.

1069
00:54:22,020 --> 00:54:23,850
- That doesn't require a temporal.

1070
00:54:23,850 --> 00:54:25,210
It has just the condition

1071
00:54:25,210 --> 00:54:28,610
that you're not traveling back in time.

1072
00:54:28,610 --> 00:54:31,230
- [Judea] Yes, correct.

1073
00:54:31,230 --> 00:54:33,920
- So it's really a generalization,

1074
00:54:33,920 --> 00:54:37,494
a powerful generalization, of what--

1075
00:54:37,494 --> 00:54:40,038
- [Judea] Of boolean logic.

1076
00:54:40,038 --> 00:54:41,760
- Yeah, boolean logic.

1077
00:54:41,760 --> 00:54:42,593
- [Judea] Yes.

1078
00:54:43,510 --> 00:54:47,320
- That is sort of simply put, and allows us

1079
00:54:47,320 --> 00:54:52,320
to reason about the order of events, the source--

1080
00:54:54,477 --> 00:54:55,670
- Not about, between.

1081
00:54:55,670 --> 00:54:58,080
But not deriving the order of events.

1082
00:54:58,080 --> 00:55:01,400
We are given cause effect relationships.

1083
00:55:01,400 --> 00:55:06,400
They ought to be obeying the time precedence relationship.

1084
00:55:08,950 --> 00:55:10,000
We are given that,

1085
00:55:10,000 --> 00:55:11,720
and now that we ask questions

1086
00:55:11,720 --> 00:55:14,320
about other causal relationships,

1087
00:55:14,320 --> 00:55:17,890
that could be derived from the initial ones,

1088
00:55:17,890 --> 00:55:20,574
but were not given to us explicitly.

1089
00:55:20,574 --> 00:55:25,574
Like the case of the firing squad I gave you

1090
00:55:25,843 --> 00:55:28,947
in the first chapter and I ask,

1091
00:55:28,947 --> 00:55:33,330
"What if rifleman A declined to shoot?

1092
00:55:33,330 --> 00:55:36,665
Would the prisoner still be dead?

1093
00:55:36,665 --> 00:55:41,550
To decline to shoot, it means that he disobeyed orders.

1094
00:55:42,536 --> 00:55:47,536
The rule of the games were that he is an obedient marksman.

1095
00:55:50,684 --> 00:55:52,317
That's how you start.

1096
00:55:52,317 --> 00:55:53,570
That's the initial order,

1097
00:55:53,570 --> 00:55:56,570
but now you ask question about breaking the rules.

1098
00:55:56,570 --> 00:56:00,028
What if he decided not to pull the trigger,

1099
00:56:00,028 --> 00:56:02,188
because became a pacifist?

1100
00:56:02,188 --> 00:56:06,050
You and I can answer that.

1101
00:56:06,050 --> 00:56:09,270
The other rifleman would have hit and killed him, okay?

1102
00:56:09,270 --> 00:56:10,670
I want a machine to do that.

1103
00:56:12,054 --> 00:56:14,154
Is it so hard to ask a machine to do that?

1104
00:56:15,004 --> 00:56:16,883
It's such a simple task.

1105
00:56:17,750 --> 00:56:19,654
But they have to have a calculus for that.

1106
00:56:19,654 --> 00:56:21,210
- Yes, yeah.

1107
00:56:21,210 --> 00:56:24,380
But the curiosity, the natural curiosity for me, is

1108
00:56:24,380 --> 00:56:28,010
that yes, you're absolutely correct and important,

1109
00:56:28,010 --> 00:56:31,130
and it's hard to believe that we haven't done this

1110
00:56:31,130 --> 00:56:35,420
seriously, extensively, already a long time ago.

1111
00:56:35,420 --> 00:56:37,040
So, this is really important work,

1112
00:56:37,040 --> 00:56:38,653
but I also want to know,

1113
00:56:39,717 --> 00:56:43,140
maybe you can philosophize about how hard is it to learn.

1114
00:56:43,140 --> 00:56:44,460
- Look, let's assume learning.

1115
00:56:44,460 --> 00:56:45,685
We want learning, okay?

1116
00:56:45,685 --> 00:56:46,690
- We want to learn.

1117
00:56:46,690 --> 00:56:47,523
- So what do we do?

1118
00:56:47,523 --> 00:56:52,320
We put a learning machine that watches execution trials

1119
00:56:52,320 --> 00:56:57,260
in many countries, in many (laughs) locations, okay?

1120
00:56:57,260 --> 00:57:01,080
All the machine can learn is to see shot or not shot.

1121
00:57:01,080 --> 00:57:02,930
Dead, not dead.

1122
00:57:02,930 --> 00:57:06,533
A court issued an order or didn't, okay, just the fact.

1123
00:57:07,380 --> 00:57:10,170
For the fact, you don't know who listens to whom.

1124
00:57:10,170 --> 00:57:13,770
You don't know that the condemned person

1125
00:57:13,770 --> 00:57:15,320
listens to the bullets,

1126
00:57:15,320 --> 00:57:19,546
that the bullets are listening to the captain, okay?

1127
00:57:19,546 --> 00:57:24,340
All we hear is one command, two shots, dead, okay?

1128
00:57:24,340 --> 00:57:29,340
A triple of variables: yes, no, yes, no, okay.

1129
00:57:29,519 --> 00:57:31,750
From that you can learn who listens to whom?

1130
00:57:31,750 --> 00:57:34,010
And you can answer the question? No.

1131
00:57:34,010 --> 00:57:35,260
- Definitively, no.

1132
00:57:35,260 --> 00:57:39,150
But don't you think you can start proposing ideas

1133
00:57:39,150 --> 00:57:41,201
for humans to review?

1134
00:57:41,201 --> 00:57:44,096
You want machine to learn it, all right, you want a robot.

1135
00:57:44,096 --> 00:57:49,096
So robot is watching trials like that, 200 trials,

1136
00:57:50,191 --> 00:57:52,610
and then he has to answer the question,

1137
00:57:52,610 --> 00:57:56,930
what if rifleman A refrained from shooting.

1138
00:57:56,930 --> 00:57:59,697
- [Lex] Yeah. So how do we do that?

1139
00:57:59,697 --> 00:58:03,660
- (laughs) That's exactly my point.

1140
00:58:03,660 --> 00:58:06,150
If looking at the facts don't give you the strings

1141
00:58:06,150 --> 00:58:08,010
behind the facts-- - Absolutely,

1142
00:58:08,010 --> 00:58:11,890
but so you think of machine learning,

1143
00:58:11,890 --> 00:58:13,307
as it's currently defined,

1144
00:58:13,307 --> 00:58:17,630
as only something that looks at the facts and tries to--

1145
00:58:17,630 --> 00:58:19,676
- [Judea] Right now they only look at the facts.

1146
00:58:19,676 --> 00:58:22,724
- Yeah, so is there a way to modify, in your sense--

1147
00:58:22,724 --> 00:58:25,170
- [Judea] Yeah, playful manipulation

1148
00:58:25,170 --> 00:58:26,428
- Playful manipulation.

1149
00:58:26,428 --> 00:58:29,020
Doing the interventionist kind of things.

1150
00:58:29,020 --> 00:58:31,170
- But it could be at random.

1151
00:58:31,170 --> 00:58:34,560
For instance, the rifleman is sick that day,

1152
00:58:34,560 --> 00:58:37,290
or he just vomits, or whatever.

1153
00:58:37,290 --> 00:58:40,921
So, we can observe this unexpected event,

1154
00:58:40,921 --> 00:58:43,630
which introduced noise.

1155
00:58:43,630 --> 00:58:46,990
The noise still have to be random to be able

1156
00:58:46,990 --> 00:58:51,700
to relate it to randomized experiments,

1157
00:58:51,700 --> 00:58:55,520
and then you have observational studies,

1158
00:58:55,520 --> 00:58:59,648
from which to infer the strings behind the facts.

1159
00:58:59,648 --> 00:59:02,391
It's doable to a certain extent.

1160
00:59:02,391 --> 00:59:06,310
But now that we're expert in what you can do

1161
00:59:06,310 --> 00:59:07,700
once you have a model,

1162
00:59:07,700 --> 00:59:10,695
we can reason back and say what kind of data you need

1163
00:59:10,695 --> 00:59:12,641
to build a model.

1164
00:59:12,641 --> 00:59:13,620
- Got it.

1165
00:59:13,620 --> 00:59:16,880
So, I know you're not a futurist,

1166
00:59:16,880 --> 00:59:19,244
but are you excited?

1167
00:59:19,244 --> 00:59:21,909
Have you, when you look back at your life,

1168
00:59:21,909 --> 00:59:25,850
longed for the idea of creating a human level intelligence--

1169
00:59:25,850 --> 00:59:28,021
- Well, yeah, I'm driven by that.

1170
00:59:28,021 --> 00:59:32,718
All my life I'm driven just by one thing. (laughs)

1171
00:59:32,718 --> 00:59:34,950
But I go slowly.

1172
00:59:34,950 --> 00:59:39,084
I go from what I know, to the next step incrementally.

1173
00:59:39,084 --> 00:59:41,667
- So, without imagining what the end goal looks like,

1174
00:59:41,667 --> 00:59:44,000
do you imagine--

1175
00:59:44,000 --> 00:59:47,434
- The end goal is going to be a machine

1176
00:59:47,434 --> 00:59:50,887
that can answer sophisticated questions:

1177
00:59:50,887 --> 00:59:55,237
counterfactuals, regret, compassion, responsibility,

1178
00:59:56,334 --> 00:59:57,923
and free will.

1179
00:59:59,420 --> 01:00:01,640
- So what is a good test?

1180
01:00:01,640 --> 01:00:04,090
Is a Turing test a reasonable test?

1181
01:00:04,090 --> 01:00:06,763
- A Turing test of free will doesn't exist yet.

1182
01:00:07,623 --> 01:00:08,456
There's not--

1183
01:00:08,456 --> 01:00:11,180
- [Lex] How would you test free will? That's a--

1184
01:00:11,180 --> 01:00:13,797
- So far we know only one thing, merely (laughs)

1185
01:00:13,797 --> 01:00:17,680
if robots can communicate,

1186
01:00:17,680 --> 01:00:21,183
with reward and punishment among themselves,

1187
01:00:22,023 --> 01:00:25,470
and hitting each other on the wrists,

1188
01:00:25,470 --> 01:00:27,420
and say "You shouldn't have done that."

1189
01:00:28,316 --> 01:00:32,525
Playing better soccer because they can do that.

1190
01:00:32,525 --> 01:00:35,970
- [Lex] What do you mean, because they can do that?

1191
01:00:35,970 --> 01:00:37,824
- Because they can communicate among themselves.

1192
01:00:37,824 --> 01:00:39,450
- [Lex] Because of the communication,

1193
01:00:39,450 --> 01:00:41,266
they can do the soccer.

1194
01:00:41,266 --> 01:00:44,000
- Because they communicate like us, rewards and punishment,

1195
01:00:44,000 --> 01:00:46,710
yes, you didn't pass the ball the right time,

1196
01:00:46,710 --> 01:00:48,370
and so forth;

1197
01:00:48,370 --> 01:00:51,570
therefore you're going to sit on the bench for the next two,

1198
01:00:51,570 --> 01:00:53,680
if they start communicating like that,

1199
01:00:53,680 --> 01:00:56,420
the question is, will they play better soccer?

1200
01:00:56,420 --> 01:00:57,916
As opposed to what?

1201
01:00:57,916 --> 01:00:59,710
As opposed to what they do now?

1202
01:00:59,710 --> 01:01:04,710
Without this ability to reason about reward and punishment.

1203
01:01:05,050 --> 01:01:06,470
Responsibility.

1204
01:01:06,470 --> 01:01:09,007
- And counterfactuals.

1205
01:01:09,007 --> 01:01:11,740
- So far, I can only think about communication.

1206
01:01:11,740 --> 01:01:15,430
- Communication, and not necessarily in natural language,

1207
01:01:15,430 --> 01:01:16,750
but just communication.

1208
01:01:16,750 --> 01:01:17,640
- Just communication,

1209
01:01:17,640 --> 01:01:22,040
and that's important to have a quick and effective means

1210
01:01:22,040 --> 01:01:24,130
of communicating knowledge.

1211
01:01:24,130 --> 01:01:26,530
If the coach tells you you should have passed the ball,

1212
01:01:26,530 --> 01:01:28,810
ping, he conveys so much knowledge to you

1213
01:01:28,810 --> 01:01:30,550
as opposed to what?

1214
01:01:30,550 --> 01:01:33,500
Go down and change your software, right.

1215
01:01:33,500 --> 01:01:35,370
That's the alternative.

1216
01:01:35,370 --> 01:01:37,770
But the coach doesn't know your software.

1217
01:01:37,770 --> 01:01:39,660
So how can a coach tell you

1218
01:01:39,660 --> 01:01:41,600
you should have passed the ball?

1219
01:01:41,600 --> 01:01:44,330
But, our language is very effective:

1220
01:01:44,330 --> 01:01:45,650
you should have passed the ball.

1221
01:01:45,650 --> 01:01:47,090
You know your software.

1222
01:01:47,090 --> 01:01:49,607
You tweak the right module, okay,

1223
01:01:49,607 --> 01:01:51,707
and next time you don't do it.

1224
01:01:51,707 --> 01:01:53,610
- Now that's for playing soccer,

1225
01:01:53,610 --> 01:01:55,499
where the rules are well defined.

1226
01:01:55,499 --> 01:01:56,937
- No, no, no, they're not well defined.

1227
01:01:56,937 --> 01:01:58,870
When you should pass the ball--

1228
01:01:58,870 --> 01:02:01,102
- Is not well defined.

1229
01:02:01,102 --> 01:02:02,202
- No, it's very noisy.

1230
01:02:03,650 --> 01:02:06,427
Yes, you have to do it under pressure (laughs)

1231
01:02:06,427 --> 01:02:07,890
- It's art.

1232
01:02:07,890 --> 01:02:11,080
But in terms of aligning values

1233
01:02:11,080 --> 01:02:14,831
between computers and humans,

1234
01:02:14,831 --> 01:02:19,831
do you think this cause and effect type of thinking

1235
01:02:20,270 --> 01:02:24,670
is important to align the values, morals, ethics

1236
01:02:24,670 --> 01:02:26,460
under which machines make decisions.

1237
01:02:26,460 --> 01:02:31,246
Is the cause effect where the two can come together?

1238
01:02:31,246 --> 01:02:34,320
- Cause effect is necessary component

1239
01:02:34,320 --> 01:02:37,470
to build an ethical machine,

1240
01:02:37,470 --> 01:02:40,510
because the machine has to empathize,

1241
01:02:40,510 --> 01:02:42,690
to understand what's good for you,

1242
01:02:42,690 --> 01:02:46,694
to build a model of you, as a recipient.

1243
01:02:46,694 --> 01:02:48,980
We should be very much--

1244
01:02:48,980 --> 01:02:50,940
What is compassion?

1245
01:02:50,940 --> 01:02:55,940
The imagine that you suffer pain as much as me.

1246
01:02:56,030 --> 01:02:57,060
- [Lex] As much as me.

1247
01:02:57,060 --> 01:03:00,320
- I do have already a model of myself, right?

1248
01:03:00,320 --> 01:03:02,830
So it's very easy for me to map you to mine.

1249
01:03:02,830 --> 01:03:04,660
I don't have to rebuild a model.

1250
01:03:04,660 --> 01:03:06,950
It's much easier to say, "Ah, you're like me."

1251
01:03:06,950 --> 01:03:09,886
Okay, therefore, I will not hit you, okay? (laughs)

1252
01:03:09,886 --> 01:03:12,100
- And the machine has to imagine,

1253
01:03:12,100 --> 01:03:14,030
has to try to fake to be human.

1254
01:03:14,030 --> 01:03:17,870
Essentially so you can imagine that you're like me, right?

1255
01:03:17,870 --> 01:03:20,840
- Whoa, whoa, whoa, who is me?

1256
01:03:20,840 --> 01:03:24,230
That's further; that's consciousness.

1257
01:03:24,230 --> 01:03:26,417
They have a model of yourself.

1258
01:03:26,417 --> 01:03:28,160
Where do you get this model?

1259
01:03:28,160 --> 01:03:32,410
You look at yourself as if you are part of the environment.

1260
01:03:32,410 --> 01:03:35,470
If you build a model of yourself versus the environment,

1261
01:03:35,470 --> 01:03:38,187
then you can say, "I need to have a model of myself.

1262
01:03:38,187 --> 01:03:41,850
"I have abilities; I have desires, and so forth," okay?

1263
01:03:41,850 --> 01:03:44,380
I have a blueprint of myself, though,

1264
01:03:44,380 --> 01:03:47,500
not a full detail, though, because I cannot get

1265
01:03:47,500 --> 01:03:49,260
the whole thing problem,

1266
01:03:49,260 --> 01:03:50,750
but I have a blueprint.

1267
01:03:50,750 --> 01:03:54,270
So at that level of a blueprint, I can modify things.

1268
01:03:54,270 --> 01:03:56,517
I can look at myself in the mirror and say,

1269
01:03:56,517 --> 01:03:59,167
"Hmm, if I tweak this model,

1270
01:03:59,167 --> 01:04:01,580
"I'm going to perform differently."

1271
01:04:01,580 --> 01:04:05,780
That is what we mean by free will. (laughs)

1272
01:04:05,780 --> 01:04:07,642
- And consciousness.

1273
01:04:07,642 --> 01:04:10,440
What do you think is consciousness?

1274
01:04:10,440 --> 01:04:13,100
Is it simply self awareness, including yourself

1275
01:04:13,100 --> 01:04:14,745
into the model of the world?

1276
01:04:14,745 --> 01:04:16,081
- That's right.

1277
01:04:16,081 --> 01:04:19,640
Some people tell me no, this is only part of consciousness,

1278
01:04:19,640 --> 01:04:21,470
and then they start telling what they really mean

1279
01:04:21,470 --> 01:04:23,170
by consciousness, and I lose them.

1280
01:04:24,720 --> 01:04:28,713
For me, consciousness is having a blueprint

1281
01:04:28,713 --> 01:04:31,106
of your software.

1282
01:04:31,106 --> 01:04:36,025
- Do you have concerns about the future of AI,

1283
01:04:36,025 --> 01:04:39,680
all the different trajectories of all the research?

1284
01:04:39,680 --> 01:04:40,750
- [Judea] Yes.

1285
01:04:40,750 --> 01:04:43,300
- Where's your hope where the movement heads?

1286
01:04:43,300 --> 01:04:44,560
Where are your concerns?

1287
01:04:44,560 --> 01:04:45,790
- I'm concerned,

1288
01:04:45,790 --> 01:04:49,293
because I know we are building a new species

1289
01:04:49,293 --> 01:04:51,877
that has the capability of exceeding us,

1290
01:04:54,503 --> 01:04:56,753
exceeding our capabilities,

1291
01:04:58,126 --> 01:05:03,126
and can breed itself and take over the world, absolutely.

1292
01:05:03,590 --> 01:05:07,680
It's a new species; it is uncontrolled.

1293
01:05:07,680 --> 01:05:09,700
We don't know the degree to which we control it.

1294
01:05:09,700 --> 01:05:12,660
We don't even understand what it means,

1295
01:05:12,660 --> 01:05:15,233
to be able to control this new species.

1296
01:05:16,207 --> 01:05:18,300
So, I'm concerned.

1297
01:05:18,300 --> 01:05:21,120
I don't have anything to add to that

1298
01:05:21,120 --> 01:05:25,012
because it's such a gray area, that unknown.

1299
01:05:25,012 --> 01:05:27,763
It never happened in history.

1300
01:05:28,938 --> 01:05:33,515
The only time it happened in history,

1301
01:05:33,515 --> 01:05:35,907
was evolution with the human being.

1302
01:05:35,907 --> 01:05:36,740
- [Lex] Right.

1303
01:05:36,740 --> 01:05:41,088
- And it was very successful, was it? (laughs)

1304
01:05:41,088 --> 01:05:42,750
Some people say it was a great success.

1305
01:05:42,750 --> 01:05:46,120
- For us, it was, but a few people along the way,

1306
01:05:46,120 --> 01:05:49,380
yeah, a few creatures along the way would not agree.

1307
01:05:49,380 --> 01:05:53,120
So, just because it's such a gray area,

1308
01:05:53,120 --> 01:05:55,020
there's nothing else to say.

1309
01:05:55,020 --> 01:05:56,840
- [Judea] We have a sample of one.

1310
01:05:56,840 --> 01:05:58,160
- Sample of one.

1311
01:05:58,160 --> 01:05:59,060
- [Judea] It's us.

1312
01:06:00,369 --> 01:06:04,812
- Some people would look at you, and say, yeah

1313
01:06:04,812 --> 01:06:09,812
but we were looking to you to help us make sure

1314
01:06:10,340 --> 01:06:11,263
that sample two works out okay.

1315
01:06:11,263 --> 01:06:12,096
- Correct.

1316
01:06:13,336 --> 01:06:15,000
Actually we have more than a sample of one.

1317
01:06:15,000 --> 01:06:15,850
We have theories.

1318
01:06:17,230 --> 01:06:20,780
And that's good; we don't need to be statisticians.

1319
01:06:20,780 --> 01:06:25,480
So, sample of one doesn't mean poverty of knowledge.

1320
01:06:25,480 --> 01:06:26,500
It's not.

1321
01:06:26,500 --> 01:06:30,600
Sample of one plus theory, conjecture or theory,

1322
01:06:30,600 --> 01:06:34,430
of what could happen, that we do have.

1323
01:06:34,430 --> 01:06:39,412
But I really feel helpless in contributing to this argument,

1324
01:06:39,412 --> 01:06:41,613
because I know so little,

1325
01:06:42,762 --> 01:06:46,245
and my imagination is limited,

1326
01:06:46,245 --> 01:06:49,553
and I know how much I don't know,

1327
01:06:51,523 --> 01:06:54,847
but I'm concerned.

1328
01:06:54,847 --> 01:06:57,180
- You were born and raised in Israel.

1329
01:06:57,180 --> 01:06:59,310
- [Judea] Born and raised in Israel, yes.

1330
01:06:59,310 --> 01:07:04,310
- And later served in the Israel military defense forces.

1331
01:07:04,673 --> 01:07:08,536
- In the Israel Defense Force.

1332
01:07:08,536 --> 01:07:12,811
- What did you learn from that experience?

1333
01:07:12,811 --> 01:07:15,957
- From that experience? (laughs)

1334
01:07:15,957 --> 01:07:18,160
- [Lex] There's a kibbutz in there as well.

1335
01:07:18,160 --> 01:07:21,124
- Yes, because I was in a NAHAL,

1336
01:07:21,124 --> 01:07:25,628
which is a combination of agricultural work

1337
01:07:25,628 --> 01:07:28,610
and military service.

1338
01:07:28,610 --> 01:07:31,250
I was an idealist.

1339
01:07:31,250 --> 01:07:34,250
I wanted to be a member of the kibbutz

1340
01:07:34,250 --> 01:07:36,240
throughout my life,

1341
01:07:36,240 --> 01:07:38,283
and to live a communal life,

1342
01:07:39,630 --> 01:07:44,630
and so I prepared myself for that.

1343
01:07:44,925 --> 01:07:49,925
Slowly, slowly I wanted a greater challenge.

1344
01:07:50,304 --> 01:07:55,304
- So, that's a far world away, both in t--

1345
01:07:55,494 --> 01:07:58,588
But I learned from that, what a kidada.

1346
01:07:58,588 --> 01:08:00,772
It was a miracle

1347
01:08:00,772 --> 01:08:05,772
It was a miracle that I served in the 1950s.

1348
01:08:06,313 --> 01:08:09,483
I don't know how we survived.

1349
01:08:10,369 --> 01:08:13,743
The country was under austerity.

1350
01:08:14,847 --> 01:08:19,846
It tripled its population from 600,000 to 1.8 million

1351
01:08:21,500 --> 01:08:23,370
when I finished college.

1352
01:08:23,370 --> 01:08:24,903
No one went hungry.

1353
01:08:26,203 --> 01:08:28,073
Austerity, yes.

1354
01:08:28,979 --> 01:08:33,069
When you wanted to make an omelet in a restaurant,

1355
01:08:33,930 --> 01:08:35,622
you had to bring your own egg.

1356
01:08:37,879 --> 01:08:42,879
And the imprisoned people from bringing the food

1357
01:08:43,760 --> 01:08:48,685
from the farming area, from the villages, to the city.

1358
01:08:48,685 --> 01:08:50,823
But no one went hungry,

1359
01:08:52,090 --> 01:08:57,090
and I always add to that: higher education did not suffer

1360
01:08:57,920 --> 01:08:59,843
any budget cuts.

1361
01:08:59,843 --> 01:09:04,843
They still invested in me, in my wife, in our generation.

1362
01:09:05,479 --> 01:09:08,093
To get the best education that they could.

1363
01:09:09,729 --> 01:09:13,687
So I'm really grateful for the progenity,

1364
01:09:13,687 --> 01:09:17,910
and I'm trying to pay back now.

1365
01:09:17,910 --> 01:09:22,910
It's a miracle that we survived the war of 1948.

1366
01:09:22,950 --> 01:09:26,323
They were so close to a second genocide.

1367
01:09:27,300 --> 01:09:30,200
It was all planned. (laughs)

1368
01:09:30,200 --> 01:09:32,220
But we survived it by a miracle,

1369
01:09:32,220 --> 01:09:36,100
and then the second miracle that not many people talk about,

1370
01:09:36,100 --> 01:09:39,950
the next phase, how no one went hungry,

1371
01:09:39,950 --> 01:09:44,020
and the country managed to triple its population.

1372
01:09:44,020 --> 01:09:45,330
You know what it means to triple population?

1373
01:09:45,330 --> 01:09:50,260
Imagine United States going from, what, 350 million

1374
01:09:50,260 --> 01:09:53,404
to (laugh) unbelievable.

1375
01:09:53,404 --> 01:09:56,727
- This is a really tense part of the world.

1376
01:09:56,727 --> 01:09:58,786
It's a complicated part of the world,

1377
01:09:58,786 --> 01:10:00,773
Israel and all around.

1378
01:10:01,840 --> 01:10:06,840
Religion is at the core of that complexity,

1379
01:10:07,285 --> 01:10:09,087
or one of the components--

1380
01:10:09,087 --> 01:10:12,690
Religion is a strong motivating course

1381
01:10:12,690 --> 01:10:16,530
for many, many people in the Middle East, yes.

1382
01:10:16,530 --> 01:10:21,063
- In your view, looking back, is religion good for society?

1383
01:10:22,058 --> 01:10:26,013
- That's a good question for robotics, you know?

1384
01:10:26,013 --> 01:10:28,346
- [Lex] There's echoes of that question.

1385
01:10:28,346 --> 01:10:31,073
- Should we equip robot with religious beliefs?

1386
01:10:32,310 --> 01:10:34,700
Suppose we find out, or we agree,

1387
01:10:34,700 --> 01:10:37,950
that religion is a good thing, it will keep you in line.

1388
01:10:37,950 --> 01:10:42,650
Should we give the robot the metaphor of a god?

1389
01:10:42,650 --> 01:10:46,523
As a metaphor, the robot will get it without us, also.

1390
01:10:47,400 --> 01:10:51,020
Why? Because a robot will reason by metaphor.

1391
01:10:51,020 --> 01:10:56,020
And what is the most primitive metaphor a child grows with?

1392
01:10:57,687 --> 01:11:02,687
Mother smile, father teaching,

1393
01:11:02,970 --> 01:11:05,443
father image and mother image, that's God.

1394
01:11:06,490 --> 01:11:09,367
So, whether you want it or not, (laughs)

1395
01:11:09,367 --> 01:11:12,950
the robot will, assuming the robot is going

1396
01:11:12,950 --> 01:11:14,820
to have a mother and a father.

1397
01:11:14,820 --> 01:11:16,410
It may only have program, though,

1398
01:11:16,410 --> 01:11:21,000
which doesn't supply warmth and discipline.

1399
01:11:21,000 --> 01:11:22,490
Well, discipline it does.

1400
01:11:22,490 --> 01:11:26,093
So, the robot will have a model of the trainer.

1401
01:11:26,944 --> 01:11:29,340
And everything that happens in the world,

1402
01:11:29,340 --> 01:11:32,340
cosmology and so on, is going to be mapped

1403
01:11:32,340 --> 01:11:34,900
into the programmer. (laughs)

1404
01:11:34,900 --> 01:11:36,433
That's God.

1405
01:11:37,795 --> 01:11:42,420
- The thing that represents the origin for everything

1406
01:11:42,420 --> 01:11:43,390
for that robot.

1407
01:11:43,390 --> 01:11:46,370
- [Judea] It's the most primitive relationship.

1408
01:11:46,370 --> 01:11:48,570
- So it's going to arrive there by metaphor.

1409
01:11:49,639 --> 01:11:53,180
And so the question is if overall that metaphor

1410
01:11:53,180 --> 01:11:55,803
has served us well, as humans.

1411
01:11:55,803 --> 01:11:58,050
- I really don't know.

1412
01:11:58,050 --> 01:11:59,853
I think it did,

1413
01:11:59,853 --> 01:12:03,333
but as long as you keep in mind it is only a metaphor.

1414
01:12:03,333 --> 01:12:05,180
(laughs)

1415
01:12:05,180 --> 01:12:10,180
- So, if you think we can, can we talk about your son?

1416
01:12:11,018 --> 01:12:13,290
- [Judea] Yes, yes.

1417
01:12:13,290 --> 01:12:15,110
- Can you tell his story?

1418
01:12:15,110 --> 01:12:17,200
- [Judea] His story, well--

1419
01:12:17,200 --> 01:12:18,033
- Daniel.

1420
01:12:18,033 --> 01:12:19,033
- His story is known.

1421
01:12:20,450 --> 01:12:25,450
He was abducted in Pakistan, by al-Quaeda driven sect,

1422
01:12:27,050 --> 01:12:31,541
and under various pretenses.

1423
01:12:31,541 --> 01:12:35,330
I don't even pay attention to what the pretense was.

1424
01:12:35,330 --> 01:12:40,330
Originally they wanted to have United States deliver

1425
01:12:43,229 --> 01:12:46,880
some promised airplanes, I--

1426
01:12:46,880 --> 01:12:48,957
It was all made up, you know,

1427
01:12:48,957 --> 01:12:53,313
all these demands were bogus.

1428
01:12:54,330 --> 01:12:56,404
I don't know, really,

1429
01:12:56,404 --> 01:13:00,120
but eventually he was executed,

1430
01:13:00,120 --> 01:13:02,073
in front of a camera.

1431
01:13:03,720 --> 01:13:06,846
- At the core of that is hate and intolerance.

1432
01:13:06,846 --> 01:13:09,902
- At the core, yes, absolutely, yes.

1433
01:13:09,902 --> 01:13:14,902
We don't really appreciate the depth of the hate

1434
01:13:17,001 --> 01:13:19,201
with which billions of peoples are educated.

1435
01:13:24,981 --> 01:13:27,580
We don't understand it.

1436
01:13:27,580 --> 01:13:29,380
I just listened recently

1437
01:13:30,550 --> 01:13:33,963
to what they teach you in Mogadishu. (laughs)

1438
01:13:37,813 --> 01:13:41,619
When the war does stop,

1439
01:13:41,619 --> 01:13:44,926
and the tap,

1440
01:13:44,926 --> 01:13:48,660
we knew exactly who did it.

1441
01:13:48,660 --> 01:13:49,493
The Jews.

1442
01:13:49,493 --> 01:13:50,326
- [Lex] The Jews.

1443
01:13:51,483 --> 01:13:54,063
We didn't know how, but we knew who did it.

1444
01:13:54,969 --> 01:13:58,110
We don't appreciate what it means to us.

1445
01:13:58,110 --> 01:14:00,480
The depth is unbelievable.

1446
01:14:00,480 --> 01:14:04,683
- Do you think all of us are capable of evil,

1447
01:14:06,618 --> 01:14:09,870
and the education, the indoctrination,

1448
01:14:09,870 --> 01:14:11,662
is really what creates evil?

1449
01:14:11,662 --> 01:14:13,613
- Absolutely we are capable of evil.

1450
01:14:13,613 --> 01:14:16,393
If you are indoctrinated sufficiently long,

1451
01:14:17,420 --> 01:14:18,553
and in depth,

1452
01:14:18,553 --> 01:14:23,553
we are capable of ISIS, we are capable of Nazism,

1453
01:14:24,083 --> 01:14:25,883
yes, we are.

1454
01:14:26,760 --> 01:14:30,500
But the question is whether we, after we have gone

1455
01:14:30,500 --> 01:14:32,850
through some Western education,

1456
01:14:32,850 --> 01:14:35,720
and we learn that everything is really relative,

1457
01:14:35,720 --> 01:14:37,700
that there is no absolute God.

1458
01:14:37,700 --> 01:14:40,130
He's only a belief in God.

1459
01:14:40,130 --> 01:14:43,550
Whether we are capable, now, of being transformed,

1460
01:14:43,550 --> 01:14:47,297
under certain circumstances, to become brutal.

1461
01:14:48,965 --> 01:14:50,323
- [Lex] Yeah.

1462
01:14:50,323 --> 01:14:53,070
- That is a qu-- I'm worried about it,

1463
01:14:53,070 --> 01:14:57,133
because some people say yes, given the right circumstances,

1464
01:14:58,809 --> 01:15:00,807
given the bad economical crisis.

1465
01:15:03,650 --> 01:15:07,988
You are capable of doing it, too, and that worries me.

1466
01:15:07,988 --> 01:15:10,533
I want to believe that I'm not capable.

1467
01:15:12,750 --> 01:15:14,610
- Seven years after Daniel's death,

1468
01:15:14,610 --> 01:15:16,840
you wrote an article at the Wall Street Journal

1469
01:15:16,840 --> 01:15:19,680
titled "Daniel Pearl and the Normalization of Evil."

1470
01:15:19,680 --> 01:15:20,513
- [Judea] Yes.

1471
01:15:20,513 --> 01:15:23,100
- What was your message back then,

1472
01:15:23,100 --> 01:15:27,600
and how did it change today, over the years?

1473
01:15:27,600 --> 01:15:28,853
- I lost.

1474
01:15:30,630 --> 01:15:32,080
- [Lex] What was the message?

1475
01:15:32,080 --> 01:15:36,453
- The message was that we are not treating terrorism

1476
01:15:39,525 --> 01:15:41,446
as a taboo.

1477
01:15:41,446 --> 01:15:46,446
We are treating it as a bargaining device that is accepted.

1478
01:15:47,220 --> 01:15:52,220
People have grievance, and they go and bomb restaurants.

1479
01:15:53,162 --> 01:15:55,300
It's normal.

1480
01:15:55,300 --> 01:15:58,173
Look, you're even not surprised when I tell you that.

1481
01:15:59,230 --> 01:16:02,637
Twenty years ago you say, "What? For grievance you go

1482
01:16:02,637 --> 01:16:04,630
"and blow a restaurant?"

1483
01:16:04,630 --> 01:16:07,264
Today it's become normalized.

1484
01:16:07,264 --> 01:16:09,713
The banalisation of evil.

1485
01:16:10,782 --> 01:16:15,782
And we have created that to ourselves, by normalizing it,

1486
01:16:16,630 --> 01:16:21,273
by making it part of political life.

1487
01:16:24,000 --> 01:16:26,823
It's a political debate.

1488
01:16:27,770 --> 01:16:32,770
Every terrorist yesterday becomes a freedom fighter today

1489
01:16:34,065 --> 01:16:36,660
and tomorrow is become a terrorist again.

1490
01:16:36,660 --> 01:16:37,850
It's switchable.

1491
01:16:38,789 --> 01:16:42,320
- [Lex] And so, we should call out evil when there's evil.

1492
01:16:43,380 --> 01:16:46,220
- If we don't want to be part of it.

1493
01:16:46,220 --> 01:16:47,999
- [Lex] Become it.

1494
01:16:47,999 --> 01:16:52,330
- Yeah, if we want to separate good from evil,

1495
01:16:52,330 --> 01:16:54,180
that's one of the first things, that,

1496
01:16:56,160 --> 01:16:57,847
in the Garden of Eden, remember?

1497
01:16:57,847 --> 01:17:02,847
The first thing that God tells them was

1498
01:17:02,847 --> 01:17:04,987
"Hey, you want some knowledge?

1499
01:17:04,987 --> 01:17:07,377
"Here is the tree of good and evil."

1500
01:17:08,249 --> 01:17:11,819
- So this evil touched your life personally.

1501
01:17:11,819 --> 01:17:16,819
Does your heart have anger, sadness, or is it hope?

1502
01:17:17,090 --> 01:17:22,090
- Look, I see some beautiful people coming from Pakistan.

1503
01:17:25,524 --> 01:17:29,470
I see beautiful people everywhere.

1504
01:17:29,470 --> 01:17:34,470
But I see horrible propagation of evil in this country, too.

1505
01:17:38,406 --> 01:17:43,406
It shows you how populistic slogans can catch the mind

1506
01:17:44,630 --> 01:17:47,023
of the best intellectuals.

1507
01:17:48,250 --> 01:17:50,130
- Today is Father's Day.

1508
01:17:50,130 --> 01:17:51,928
- [Judea] I didn't know that.

1509
01:17:51,928 --> 01:17:56,928
- Yeah, what's a fond memory you have of Daniel?

1510
01:17:57,761 --> 01:18:01,589
- Oh, many good memories remains.

1511
01:18:01,589 --> 01:18:03,943
He was my mentor.

1512
01:18:06,150 --> 01:18:11,150
He had a sense of balance that I didn't have. (laughs)

1513
01:18:12,192 --> 01:18:14,453
- [Lex] Yeah.

1514
01:18:15,360 --> 01:18:17,563
- He saw the beauty in every person.

1515
01:18:19,480 --> 01:18:22,080
He was not as emotional as I am,

1516
01:18:22,080 --> 01:18:26,260
more looking things in perspective.

1517
01:18:26,260 --> 01:18:29,380
He really liked every person.

1518
01:18:29,380 --> 01:18:31,580
He really grew up with the idea

1519
01:18:31,580 --> 01:18:36,580
that a foreigner is a reason for curiosity,

1520
01:18:38,340 --> 01:18:39,923
not for fear.

1521
01:18:41,835 --> 01:18:44,965
This one time we went in Berkeley,

1522
01:18:44,965 --> 01:18:48,451
and a homeless came out from some dark alley

1523
01:18:48,451 --> 01:18:50,846
and said, "Hey man, can you spare a dime?"

1524
01:18:50,846 --> 01:18:54,510
(Judea gasps) I retreated back, you know, two feet back,

1525
01:18:54,510 --> 01:18:57,283
and Danny just hugged him and say "Here's a dime.

1526
01:18:58,479 --> 01:19:01,279
"Enjoy yourself. Maybe you want some money to take a bus

1527
01:19:03,617 --> 01:19:04,487
"or whatever."

1528
01:19:05,360 --> 01:19:06,640
Where did he get it?

1529
01:19:06,640 --> 01:19:07,473
Not from me.

1530
01:19:08,428 --> 01:19:10,510
(both laugh)

1531
01:19:10,510 --> 01:19:12,480
- Do you have advice for young minds today

1532
01:19:12,480 --> 01:19:16,240
dreaming about creating, as you have dreamt,

1533
01:19:16,240 --> 01:19:17,920
creating intelligent systems?

1534
01:19:17,920 --> 01:19:21,440
What is the best way to arrive at new break-through ideas

1535
01:19:21,440 --> 01:19:23,870
and carry them through the fire of criticism

1536
01:19:23,870 --> 01:19:27,263
and past conventional ideas?

1537
01:19:27,263 --> 01:19:29,643
- Ask your questions.

1538
01:19:31,251 --> 01:19:36,251
Really, your questions are never dumb.

1539
01:19:37,720 --> 01:19:40,750
And solve them your own way. (laughs)

1540
01:19:40,750 --> 01:19:42,733
And don't take "no" for an answer.

1541
01:19:44,015 --> 01:19:48,410
If they're really dumb, you'll find out quickly,

1542
01:19:48,410 --> 01:19:50,320
by trial and error, to see

1543
01:19:50,320 --> 01:19:52,460
that they're not leading any place.

1544
01:19:52,460 --> 01:19:57,460
But follow them, and try to understand things your way.

1545
01:19:59,500 --> 01:20:01,620
That is my advice.

1546
01:20:01,620 --> 01:20:04,020
I don't know if it's going to help anyone.

1547
01:20:04,020 --> 01:20:05,770
- [Lex] No, that's brilliantly put.

1548
01:20:07,145 --> 01:20:09,770
- There's a lot of inertia in science, in academia.

1549
01:20:14,082 --> 01:20:17,493
It is slowing down science.

1550
01:20:18,610 --> 01:20:21,360
- Yeah, those two words, "your way,"

1551
01:20:21,360 --> 01:20:22,623
that's a powerful thing.

1552
01:20:23,580 --> 01:20:26,120
It's against inertia, potentially.

1553
01:20:26,120 --> 01:20:28,728
- [Judea] Against your professor.

1554
01:20:28,728 --> 01:20:30,470
(Lex laughs)

1555
01:20:30,470 --> 01:20:33,410
- I wrote "The Book of Why" in order

1556
01:20:33,410 --> 01:20:35,970
to democratize common sense.

1557
01:20:35,970 --> 01:20:37,793
- [Lex] Yeah. (laughs)

1558
01:20:38,690 --> 01:20:43,690
- In order to instill rebellious spirits in students,

1559
01:20:44,928 --> 01:20:49,928
so they wouldn't wait until the professor gets things right.

1560
01:20:50,095 --> 01:20:52,512
(both laugh)

1561
01:20:53,398 --> 01:20:56,620
- [Lex] So you wrote the manifesto of the rebellion

1562
01:20:56,620 --> 01:20:58,260
against the professor. (laughs)

1563
01:20:58,260 --> 01:21:00,400
- [Judea] Against the professor, yes.

1564
01:21:00,400 --> 01:21:02,820
- So looking back at your life of research,

1565
01:21:02,820 --> 01:21:06,910
what ideas do you hope ripple through the next many decades?

1566
01:21:06,910 --> 01:21:10,056
What do you hope your legacy will be?

1567
01:21:10,056 --> 01:21:14,017
I already have a tombstone carved.

1568
01:21:15,021 --> 01:21:17,438
(both laugh)

1569
01:21:20,220 --> 01:21:21,550
- Oh, boy.

1570
01:21:21,550 --> 01:21:24,643
- The fundamental law of counterfactuals.

1571
01:21:25,860 --> 01:21:30,548
That's what it-- it's a simple equation.

1572
01:21:30,548 --> 01:21:34,483
Put a counterfactual in terms of a model surgery.

1573
01:21:35,570 --> 01:21:38,020
That's it, because everything follows from there.

1574
01:21:39,419 --> 01:21:43,819
If you get that, all the rest.

1575
01:21:43,819 --> 01:21:45,985
I can die in peace,

1576
01:21:45,985 --> 01:21:49,089
and my student can derive all my knowledge

1577
01:21:49,089 --> 01:21:51,940
by mathematical means.

1578
01:21:51,940 --> 01:21:53,113
- The rest follows.

1579
01:21:54,061 --> 01:21:56,470
Thank you so much for talking today.

1580
01:21:56,470 --> 01:21:57,620
I really appreciate it.

1581
01:21:58,815 --> 01:22:01,515
- My thank you for being so attentive and instigating.

1582
01:22:02,442 --> 01:22:03,900
(both laugh)

1583
01:22:03,900 --> 01:22:04,850
- We did it.

1584
01:22:04,850 --> 01:22:05,710
- We did it.

1585
01:22:05,710 --> 01:22:07,540
- [Lex] The coffee helped.

1586
01:22:07,540 --> 01:22:11,320
Thanks for listening to this conversation with Judea Pearl.

1587
01:22:11,320 --> 01:22:14,260
And thank you to our presenting sponsor, Cash App.

1588
01:22:14,260 --> 01:22:16,103
Download it, use code LexPodcast.

1589
01:22:17,190 --> 01:22:20,120
You'll get $10, and $10 will go to FIRST,

1590
01:22:20,120 --> 01:22:23,200
a STEM education nonprofit that inspires hundreds

1591
01:22:23,200 --> 01:22:25,780
of thousands of young minds to learn

1592
01:22:25,780 --> 01:22:28,350
and to dream of engineering our future.

1593
01:22:28,350 --> 01:22:31,110
If you enjoy this podcast, subscribe on YouTube,

1594
01:22:31,110 --> 01:22:34,360
give it five stars on Apple Podcast, support on Patreon,

1595
01:22:34,360 --> 01:22:36,870
or simply connect with me on Twitter.

1596
01:22:36,870 --> 01:22:39,320
And now, let me leave you with some words of wisdom

1597
01:22:39,320 --> 01:22:41,070
from Judea Pearl.

1598
01:22:41,070 --> 01:22:44,020
You cannot answer a question that you cannot ask,

1599
01:22:44,020 --> 01:22:47,393
and you cannot ask a question that you have no words for.

1600
01:22:48,850 --> 01:22:51,853
Thank you for listening, and hope to see you next time.

