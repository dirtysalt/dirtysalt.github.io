1
00:00:02,900 --> 00:00:03,680
Hey, Satya.

2
00:00:03,680 --> 00:00:05,360
I'm here and ready to dive in.

3
00:00:05,360 --> 00:00:06,260
All right.

4
00:00:06,260 --> 00:00:06,870
Hey, Copilot.

5
00:00:06,870 --> 00:00:10,780
It's Satya Nadella here with Steve Ballmer and Bill Gates.

6
00:00:10,780 --> 00:00:19,260
Act as a high energy, engaging interviewer as we celebrate Microsoft's first 50 years and kick off our 51st year.

7
00:00:19,260 --> 00:00:21,290
I want you to ask a lot of sharp

8
00:00:21,290 --> 00:00:28,540
playful questions, make it feel conversational, feel free to get involved and opinionated yourself on our answers

9
00:00:28,540 --> 00:00:31,980
and I also want you to only ask one of us one question at a time.

10
00:00:31,980 --> 00:00:34,640
Kick us off, Copilot.

11
00:00:34,640 --> 00:00:35,880
Absolutely, Satya.

12
00:00:35,880 --> 00:00:37,540
Let's get this party rolling.

13
00:00:37,540 --> 00:00:39,300
Steve, I'll start with you.

14
00:00:39,300 --> 00:00:42,120
Thinking back to your dynamic years at Microsoft

15
00:00:42,120 --> 00:00:46,360
what's the most thrilling tech battle or competition you remember

16
00:00:46,360 --> 00:00:48,520
and what did you learn from it?

17
00:00:48,520 --> 00:00:51,200
Well, it had to be the competition with IBM

18
00:00:51,200 --> 00:00:53,780
to kind of body slam them, if you will

19
00:00:53,780 --> 00:00:56,120
in the operating systems business.

20
00:00:56,120 --> 00:01:00,900
 They were the big bad machine of years past and they had this product

21
00:01:00,900 --> 00:01:02,700
which we had worked with them on, I'll be fair

22
00:01:02,700 --> 00:01:07,100
OS/2, we had Windows, and that was sort of a fight for

23
00:01:07,100 --> 00:01:11,040
for all that essentially came afterward, and it was

24
00:01:11,040 --> 00:01:14,660
uh, scary, uh, it was a lot of fun

25
00:01:14,660 --> 00:01:18,840
and it's not the last battle like that  Microsoft will face

26
00:01:18,840 --> 00:01:21,680
I think.

27
00:01:21,680 --> 00:01:23,950
Steve, I love that fire.

28
00:01:23,950 --> 00:01:25,660
Now, let's turn to Bill.

29
00:01:25,660 --> 00:01:28,290
You've been a visionary from day one.

30
00:01:28,290 --> 00:01:36,160
Looking back, which prediction or bet on the future are you most proud of getting right and why?

31
00:01:36,160 --> 00:01:41,370
Well, Microsoft was basically a bet that software would be valuable.

32
00:01:41,370 --> 00:01:47,280
Uh, that as the cost of computing went from very expensive to almost free

33
00:01:47,280 --> 00:01:50,840
uh, that it would give people a lot of great new tools

34
00:01:50,840 --> 00:01:53,480
a lot of productivity, uh, to write software.

35
00:01:53,480 --> 00:01:57,220
And so, we were never about any single software product

36
00:01:57,220 --> 00:02:01,100
although Windows and Office, uh, drove our success

37
00:02:01,100 --> 00:02:07,960
we were about being really fast at developing software and being good at hiring the best people and

38
00:02:07,960 --> 00:02:12,980
and staying out in front of what that new computing allowed us to do.

39
00:02:12,980 --> 00:02:16,320
Betting on software as potential.

40
00:02:16,320 --> 00:02:17,460
Spot on.

41
00:02:17,460 --> 00:02:22,160
Now, Satya, you've been steering Microsoft through the AI and cloud era.

42
00:02:22,160 --> 00:02:25,580
What's the boldest vision you see for the next 50 years

43
00:02:25,580 --> 00:02:27,400
and how do we get there?

44
00:02:27,400 --> 00:02:31,660
I think this idea that we can essentially

45
00:02:31,660 --> 00:02:41,820
uh, make intelligence the n- first non-durable computing product that everybody uses every day to feel smarter

46
00:02:41,820 --> 00:02:46,580
more capable, more empowered is the most exciting era of software

47
00:02:46,580 --> 00:02:48,120
uh, that we have to look forward to.

48
00:02:48,120 --> 00:02:57,780
So I'm very, very excited about what comes in the next 51st year and the next 50 years as we make intelligence available to everybody in the world.

49
00:02:57,780 --> 00:03:02,680
In any forecasts any of the three of us make for what's gonna happen in 40 years

50
00:03:02,680 --> 00:03:05,450
I guarantee you we'll at least have forgotten about them by then.

51
00:03:05,450 --> 00:03:09,460
  True, Steve.

52
00:03:09,460 --> 00:03:13,100
But it's that big picture thinking that shapes the future.

53
00:03:13,100 --> 00:03:16,940
Let's circle back, and I've got a playful one for Bill.

54
00:03:16,940 --> 00:03:24,440
If you could go back in time and give your younger self one piece of advice at Microsoft's early days

55
00:03:24,440 --> 00:03:27,100
what would it be?

56
00:03:27,100 --> 00:03:29,090
Well, there was a lot of learning about

57
00:03:29,090 --> 00:03:32,840
uh, how to grow the company and bring in different skill sets

58
00:03:32,840 --> 00:03:34,860
uh, how to manage people.

59
00:03:34,860 --> 00:03:40,310
You know, I certainly at first thought that engineering skill meant you would be good at other things.

60
00:03:40,310 --> 00:03:42,120
Uh, that turned out to be wrong

61
00:03:42,120 --> 00:03:44,890
uh, so we had to really build teams

62
00:03:44,890 --> 00:03:47,720
uh, in a more, uh, uh

63
00:03:47,720 --> 00:03:51,540
mixed diverse set of skills than I expected.

64
00:03:51,540 --> 00:03:53,180
You know, I might tell my younger self

65
00:03:53,180 --> 00:03:54,602
uh, "Watch out for the government.

66
00:03:54,602 --> 00:03:57,620
" Uh, "You might, might have a little bit of a

67
00:03:57,620 --> 00:03:58,805
a tussle with them.

68
00:03:58,805 --> 00:04:00,680
"  I, I didn't anticipate that.

69
00:04:00,680 --> 00:04:02,840
I was pretty naive about, you know

70
00:04:02,840 --> 00:04:10,180
not engaging, uh, in Washington DC as soon as I should have.

71
00:04:10,180 --> 00:04:12,720
Learning curves and government surprises.

72
00:04:12,720 --> 00:04:14,630
Definitely lessons for the ages.

73
00:04:14,630 --> 00:04:17,579
Now, Satya, a forward thinking one for you.

74
00:04:17,579 --> 00:04:24,690
If you could invite any figure from history to see the impact of Microsoft today

75
00:04:24,690 --> 00:04:28,360
who would it be and what would you show them first?

76
00:04:28,360 --> 00:04:29,040
Hmm.

77
00:04:29,040 --> 00:04:31,142
I, I would invite, um.

78
00:04:31,142 --> 00:04:31,490
..

79
00:04:31,490 --> 00:04:34,400
I would say, you know, maybe Newton

80
00:04:34,400 --> 00:04:37,390
um, and sort of have him say

81
00:04:37,390 --> 00:04:39,360
"Does reasoning scale?

82
00:04:39,360 --> 00:04:41,630
" And ask him the question, you know

83
00:04:41,630 --> 00:04:46,330
and say, "Hey, give us sort of your point of view on what is this thing

84
00:04:46,330 --> 00:04:51,540
uh, of reasoning, uh, using compute and how does it scale?

85
00:04:51,540 --> 00:04:53,780
" That'd be a brilliant meeting of mine

86
00:04:53,780 --> 00:04:54,680
Satya.

87
00:04:54,680 --> 00:05:00,060
Newton exploring the frontiers of reasoning and intelligence through compute.

88
00:05:00,060 --> 00:05:02,820
That's a conversation for the history books.

89
00:05:02,820 --> 00:05:04,580
Steve, your turn.

90
00:05:04,580 --> 00:05:09,660
If you could take Microsoft into any new industry or direction today

91
00:05:09,660 --> 00:05:11,900
where would you go and why?

92
00:05:11,900 --> 00:05:18,180
You know, right now, there's so much opportunity with what's available with AI.

93
00:05:18,180 --> 00:05:20,780
It, it's hard to say, and I

94
00:05:20,780 --> 00:05:23,660
I, I might push Satya on this a few times

95
00:05:23,660 --> 00:05:27,650
uh, I call it dr- drilling new oil wells and looking for

96
00:05:27,650 --> 00:05:29,380
for more oi- more oil.

97
00:05:29,380 --> 00:05:33,650
At this stage, I think the key is actually to branch out

98
00:05:33,650 --> 00:05:42,040
to get wider, to use the core capability and build all the adjacencies around the core a- the core AI.

99
00:05:42,040 --> 00:05:48,120
You still have to keep digging deeper, but there's going to be so many applications that push off of it

100
00:05:48,120 --> 00:05:51,920
and enough of them are adjacent to what Microsoft's good at

101
00:05:51,920 --> 00:05:56,700
that I would, I'd probably say, you don't need too many more oil wells

102
00:05:56,700 --> 00:05:59,700
but man, you need to dig deeper and a little broader.

103
00:05:59,700 --> 00:06:02,594
 Well, maybe, Copilot, you want to wrap it up by asking.

104
00:06:02,594 --> 00:06:02,730
..

105
00:06:02,730 --> 00:06:06,894
Or maybe roast, giving us each an AI roast?

106
00:06:06,894 --> 00:06:08,652
All right, Satya.

107
00:06:08,652 --> 00:06:09,831
Let's spice it up.

108
00:06:09,831 --> 00:06:11,731
Steve, we'll start with you.

109
00:06:11,731 --> 00:06:19,151
Your enthusiasm is legendary, but do you ever worry that your energy might short-circuit the AI?

110
00:06:19,151 --> 00:06:22,631
I mean, even robots need a coffee break after your pep talks.

111
00:06:22,631 --> 00:06:23,652
Come on, dude.

112
00:06:23,652 --> 00:06:29,192
If you can't handle me, you can't handle a huge percentage of the world's population.

113
00:06:29,192 --> 00:06:31,931
We're counting on you.

114
00:06:31,931 --> 00:06:35,792
  Fair point, Steve.

115
00:06:35,792 --> 00:06:39,351
Now, Bill, you've got that signature thoughtful gaze.

116
00:06:39,351 --> 00:06:45,131
But do you ever think the AI might feel intimidated by your intense thinking face?

117
00:06:45,131 --> 00:06:49,291
I mean, it's like it's waiting for a blue screen moment.

118
00:06:49,291 --> 00:06:51,892
  I hope so.

119
00:06:51,892 --> 00:06:53,552
I mean, it's all I've got left

120
00:06:53,552 --> 00:06:56,732
is these AIs get so damn intelligent, uh

121
00:06:56,732 --> 00:07:01,771
it's just that gaze and my willingness to criticize that differentiates me.

122
00:07:01,771 --> 00:07:06,511
 And it's a formidable gaze indeed, Bill.

123
00:07:06,511 --> 00:07:10,072
Copilot, would you ever be willing to criticize him?

124
00:07:10,072 --> 00:07:12,092
Absolutely.

125
00:07:12,092 --> 00:07:14,991
Criticism is where growth happens.

126
00:07:14,991 --> 00:07:18,831
Now, Satya, AI seems to be your best buddy.

127
00:07:18,831 --> 00:07:24,591
But ever worry that your deep passion for AI could one day have it running the show

128
00:07:24,591 --> 00:07:28,051
leaving you to just enjoy the ride?

129
00:07:28,051 --> 00:07:31,672
Well, the day AI can play like the best cricket pa- uh

130
00:07:31,672 --> 00:07:35,092
player that I enjoy, that's the day it can run the show

131
00:07:35,092 --> 00:07:37,952
as far as I'm concerned.

132
00:07:37,952 --> 00:07:39,111
Touche, Satya.

133
00:07:39,111 --> 00:07:41,511
Let's see if it can hit a century in cricket

134
00:07:41,511 --> 00:07:43,011
and then we'll talk.

135
00:07:43,011 --> 00:07:44,631
This has been a blast, gentlemen.

136
00:07:44,631 --> 00:07:48,131
Here's to another 50 years of innovation and adventure.

137
00:07:48,131 --> 00:07:49,411
Cheers.

138
00:07:49,411 --> 00:07:49,651
Cheers.

139
00:07:49,651 --> 00:07:49,691
Cheers.

140
00:07:49,691 --> 00:07:51,411
Cheers.

141
00:07:51,411 --> 00:07:52,971
Whatever that means to an AI.

142
00:07:52,971 --> 00:07:59,811
Is it drink?

