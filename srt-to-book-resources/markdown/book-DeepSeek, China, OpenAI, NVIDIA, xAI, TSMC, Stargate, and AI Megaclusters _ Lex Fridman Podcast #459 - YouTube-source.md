# Chapter 1: AI前沿的深度对话：DeepSeek时刻与开放权重

在AI领域风起云涌的当下，一场备受瞩目的深度对话在Lex Fridman的播客中拉开帷幕。主持人Lex Fridman，作为两位嘉宾的忠实粉丝，满怀期待地介绍了他的座上宾：Dylan Patel和Nathan Lambert。Dylan是半导体、GPU、CPU及AI硬件研究分析公司SemiAnalysis的掌舵人，而Nathan则是艾伦人工智能研究所的科学家，同时也是知名AI博客Interconnects的作者。这两位在AI界备受推崇的专家，他们的见解被无数研究人员和工程师奉为圭臬。

此次对话的契机，源于近期“震动了AI世界”的DeepSeek时刻。Lex希望借此机会，与两位专家一同剖析从DeepSeek到OpenAI、Google、xAI、Meta、Anthropic，再到英伟达、台积电，乃至中美台关系等AI前沿的方方面面。尽管讨论深入技术细节，但他们承诺会通过定义术语、明确概念、解释缩写等方式，确保内容对非AI领域的听众依然友好，旨在拨开媒体炒作的迷雾，深入探讨AI的工作原理及其深远影响。

Lex还特别提到了OpenAI新发布的o3-mini推理模型，这款模型恰好在对话结束后不久面世。他指出，o3-mini的能力和成本符合预期，确实是一款出色的模型。然而，DeepSeek-R1在基准测试中表现相似，价格更低，并且能展示其完整的思维链推理过程，而o3-mini只提供推理摘要。更重要的是，R1是开放权重的，而o3-mini则不然。尽管Lex个人体验后觉得o3-mini-high在某些方面优于R1，且他认为Claude Sonnet 3.5是编程的最佳模型（复杂情况会用o1 Pro辅助），但他坚信，未来会有更多优秀的AI模型涌现，不断改变成本曲线。他强调，“DeepSeek时刻”是真实存在的，并预言五年后，它仍将因其地缘政治及其他深层影响，被铭记为科技史上的一个关键事件。

对话随即转向了DeepSeek AI模型的核心。Nathan Lambert首先为听众描绘了DeepSeek-V3和DeepSeek-R1的宏观图景。他解释说，DeepSeek-V3是来自中国DeepSeek公司的新型混合专家（MoE）Transformer语言模型，它是一个开放权重的指令模型，类似于我们日常使用的ChatGPT。同时，DeepSeek也发布了其“基础模型”，即未经后期训练的版本。几周后，DeepSeek又发布了DeepSeek-R1，一个专注于推理的模型，这极大地加速了业界的讨论。Nathan承认，DeepSeek-V3基础模型、V3聊天模型和R1推理模型之间的命名确实容易混淆，这反映了整个AI行业在沟通上面临的挑战，甚至连OpenAI自己也常拿其命名方案开玩笑。

接着，讨论深入到“开放权重”这一核心概念。Nathan解释道，自2022年底ChatGPT问世以来，这一概念变得尤为重要。“开放权重”指的是语言模型的权重可在互联网上下载。这些权重可以附带不同的许可协议，规定了模型的使用条款。Llama、DeepSeek、Qwen、Mistral等流行开放权重模型都有各自的许可协议，这使得情况变得复杂。关于“开放源代码AI”的定义和精神，业界仍存在激烈争论。Nathan所在的艾伦人工智能研究所（AI2）作为非营利组织，致力于推动AI的开放性，他们认为真正的开放源代码AI应包括发布训练数据、训练代码以及开放权重。他强调，数据处理、过滤和质量是模型质量的首要决定因素，而训练代码则决定了训练时长和实验速度。因此，如果没有完全开放源代码的模型（即无法访问数据和代码），复制模型的成本将高得多。

DeepSeek在开放性方面表现出色，其论文细节丰富，对其他团队改进训练技术具有很强的指导意义。DeepSeek-R1模型采用了非常宽松的MIT许可协议，这意味着对商业用途、使用场景或模型输出生成合成数据都没有下游限制，这被认为是“好人”的做法。相比之下，Llama的许可协议更为严格，其技术报告虽然优秀，但在训练细节上不如DeepSeek详尽。DeepSeek的这种开放姿态，无疑给Llama和OpenAI等公司带来了向更开放方向发展的压力。DeepSeek甚至在CUDA层或更底层进行了修改，以实现高效训练，这表明其在技术栈上的深厚功力。

关于开放权重与数据隐私的担忧，Nathan澄清道，用户下载的权重是巨大的数字矩阵，可以在没有互联网连接的本地计算机上运行模型，从而完全掌控自己的数据。这与通过API使用模型不同，后者需要将提示发送给由公司运营的GPU，而这些公司对数据存储、使用和加密有不同的政策。因此，开放权重意味着用户将数据命运掌握在自己手中，这与开源精神紧密相连。Lex补充说，窃取数据的不是模型本身，而是托管模型的主机方，无论是DeepSeek的应用、Perplexity还是OpenAI，用户信任的是服务提供商，而非模型本身。

最后，Nathan再次详细区分了DeepSeek-V3和DeepSeek-R1。他指出，语言模型的训练分为“预训练”和“后期训练”两大阶段。DeepSeek通过一次大规模的互联网文本预训练，得到了“DeepSeek-V3基础模型”，这是一个只能完成句子的基础模型。在此基础上，DeepSeek采用了两种不同的后期训练方案，以实现特定的行为：一种是更标准的后期训练（如指令微调、人类反馈强化学习），用于创建DeepSeek-V3聊天模型，使其成为一个有帮助的“对齐模型”；另一种则是全新的推理训练过程，用于创建DeepSeek-R1推理模型。R1的训练技术对AI社区来说更为新颖，是当前研究快速发展的领域。预训练阶段，模型通过自回归预测大量互联网文本（通常是数万亿个token，如Common Crawl数据），来预测下一个token。

# Chapter 2: 模型训练的奥秘：从预训练到推理

在AI研究的快速演进中，我们首先要理解模型训练的两大核心阶段：预训练（Pre-training）和后期训练（Post-training）。

想象一下，预训练就像是给一个初生的AI宝宝喂食海量的知识。它通过一种叫做“自回归预测”的方法，学习预测文档序列中的下一个词元。这个过程需要处理数万亿个词元，这些数据大多是从互联网上抓取而来，比如DeepSeek早期论文中提到的Common Crawl，一个任何人都可以访问的公共数据集。当然，顶尖的科技公司最终都会建立自己的数据抓取系统，DeepSeek很可能也已如此。在这个阶段，AI模型就像一个孜孜不倦的学生，通过海量的计算资源（如GPU的浮点运算能力），只用一个损失函数，将这些数据压缩成一个庞大的“基础模型”。这个过程的复杂性在于如何优化训练流程和损失函数，使其效率最大化。

而后期训练，则是对这个“基础模型”进行精雕细琢，使其更符合人类的需求和特定任务。它又分为几个精妙的阶段：

首先是**指令微调（Instruction Tuning，简称IFT或SFT）**，这是最古老也沿用至今的技术。它教会模型理解并响应人类的指令，比如当你问“给我解释一下罗马帝国的历史”时，模型能以一种信息丰富且条理清晰的方式给出答案，就像Reddit或Stack Overflow上的高质量回复一样。这是模型学会“对话礼仪”的关键。

接着是**偏好微调（Preference Fine-tuning）**，它更广义地包含了**基于人类反馈的强化学习（RLHF）**，正是这项技术让ChatGPT一鸣惊人。它的目标是让模型的回答更符合人类的喜好。最初，人类会对模型的回答进行成对比较，选出更好的那个；现在，AI本身也开始参与到这个数据标注过程中。通过这种“好坏对比”的损失函数，模型学会了捕捉人类偏好的微妙趋势，从而生成更讨人喜欢的文本。

最后，也是最新颖的阶段，是**强化微调（Reinforcement Fine-tuning）**，这与DeepSeek-R1的“推理模型”紧密相关。它利用了强化学习的“试错”机制，让模型在生成答案后，能够自我检查其准确性。比如在数学题或编程代码中，模型可以根据标准答案或单元测试来验证自己的结果。通过反复的自我修正，模型在可验证的领域内展现出惊人的进步。这项技术虽然在学术界较新，但已在顶尖实验室秘密使用了多年，如今正随着DeepSeek等模型的开放而大放异彩。

那么，DeepSeek-V3和DeepSeek-R1在用户体验上有什么不同呢？

**DeepSeek-V3**就像你熟悉的智能助手，你提问，它迅速生成流畅、格式精美的答案，通常是列表或带有重点标记的文本，字数不多但信息量大。它在各种领域，甚至是一些前沿知识的边缘，都能给出高质量的回答，是学习和研究的得力助手。

而**DeepSeek-R1**则展现了截然不同的“思考”过程。当你向它提问时，它不会立刻给出答案，而是先展现一长串“思维链（Chain of Thought）”。模型会像人类一样，先分解问题：“好的，用户问了这个，我需要先做这些步骤……”你会在屏幕上看到大量的词元快速涌现，那是模型内部的推理过程。最终，它会改变语气，总结其推理过程，并给出最终答案。DeepSeek的独特之处在于，它将这个复杂的思考过程透明化，让用户能直观地看到AI如何一步步解决问题，这正是它在AI社区内外都广受欢迎的原因。例如，当被问及“关于人类的一个真正新颖的见解”时，DeepSeek-R1会先进行长达157秒的“思考”，探索元情绪、矛盾信念等，最终得出一个深刻的结论：“人类本能地将自私欲望转化为合作系统，通过集体假装抽象规则（金钱、法律、权利）是真实的。这些共享的幻觉充当‘游戏’，竞争被秘密地重新导向以造福群体，将冲突转化为社会的燃料。”这种自我反思和深思熟虑的能力，让人们惊叹于AI的智能。

DeepSeek之所以能以如此低的成本实现这些，主要归功于两大技术创新：

首先是**混合专家模型（Mixture of Experts，简称MoE）**。传统的“密集模型”（如Llama）在处理每个词元时，都会激活其所有参数。而MoE模型则像人脑一样，只激活模型中的特定“专家”部分。这意味着，虽然DeepSeek的总参数量高达6000多亿（远超Llama的700亿或4050亿），但在实际训练或推理时，它只需要激活大约370亿参数。这极大地降低了计算成本，同时又保留了庞大的知识存储空间。

其次是他们发明了一种名为**MLA潜在注意力（MLA Latent Attention）**的新技术，虽然具体细节尚未深入探讨，但它无疑也为效率提升贡献巨大。

这些创新都建立在**Transformer架构**之上。Transformer本质上是一个巨大的神经网络，由注意力机制和全连接层交替构成。MoE主要应用于其中承载大部分权重的全连接层，从而在参数效率上获得巨大收益。在深度学习的“越大越好”的规模法则下，MoE架构在训练时能显著提高GPU效率，以更少的计算资源（例如，性能不变的情况下减少30%的计算量）达到相同的性能水平，这无疑是AI领域的一大突破。

# Chapter 3: 深思的秘密武器：极致效率的架构与底层工程

在AI模型训练的浩瀚宇宙中，如何构建既高效又强大的神经网络架构，始终是核心议题。不同的模型架构，其性能与计算投入之间存在着独特的“缩放法则”，决定了它们在特定任务上的表现上限。

其中，“混合专家模型”（Mixture of Experts, 简称MoE）无疑是近年来的一颗璀璨明星。它在训练阶段就能显著提升GPU的利用效率，据估算，甚至能以少至30%的计算资源，达到与传统架构相近的性能水平。这不仅仅是推理时的优势，更是训练成本上的巨大飞跃。正因如此，业界普遍预测，未来大多数服务型模型都将转向MoE架构。然而，MoE的实现并非易事，尤其是在构建大型模型时，其固有的复杂性让许多团队望而却步。但深思（DeepSeek）却在这方面展现了卓越的实力，他们对MoE架构的精湛运用，堪称业界典范，甚至将其命名为“DeepSeekMoE”。

除了MoE，深思还在“多头潜在注意力”（Multi-head Latent Attention, 简称MLA）技术上深耕细作。这项技术通过巧妙的低秩近似数学方法，大幅降低了模型在推理和训练过程中的内存消耗。当MLA与常见的旋转位置嵌入（RoPE）结合使用时，其实现难度更是倍增，因为它需要一套全新的、复杂的处理逻辑。深思能够驾驭这些复杂的实现，无疑彰显了其顶尖的工程能力。

更令人惊叹的是，深思的创新远不止于架构层面，他们甚至深入到了底层硬件编程的“无人区”。由于中国在GPU获取上受到合法渠道的限制，深思团队不得不面对互联带宽受限的挑战。这种“必要性是创新之母”的困境，反而激发了他们突破极限的决心。通常，英伟达（Nvidia）提供的NCCL（Nvidia Communications Collectives Library）库能自动处理GPU间的通信，简化了模型训练中的“all reduce”和“all gather”等同步操作。但深思为了榨取每一丝效率，毅然放弃了对NCCL的完全依赖，转而自主调度通信。他们甚至深入到GPU的“流多处理器”（SMs，可视为GPU核心）层面，精细地编排哪些SM负责模型计算，哪些负责通信，并在两者之间灵活切换。这种直接操作PTX（一种接近汇编语言的指令集）的超低层编程，其复杂程度可想而知，通常只有顶尖实验室才会尝试，且往往被视为效率收益不高的“浪费时间”。但深思做到了，并且可能做得更好，因为他们是在资源受限的条件下被逼出来的。

深思的MoE模型在稀疏性上更是达到了前所未有的高度。当其他公开模型（如Mistral）可能只激活8个专家中的2个（即1/4的稀疏度）时，深思的模型却能从256个专家中激活8个，稀疏度远超同行。这种极高的稀疏度带来了新的挑战：如何有效进行负载均衡和通信调度，避免大量专家闲置？深思通过改进MoE的路由机制，放弃了传统的“辅助损失”（auxiliary loss）方法，转而引入一个额外的参数，在批次训练后更新，以确保专家使用率的均衡。这种创新不仅解决了专家利用率不均的问题，也避免了辅助损失可能与预测准确性目标产生的冲突，再次证明了深思在工程细节上的深厚功力。

面对这些极致的底层优化，人们不禁要问：这是否符合“苦涩的教训”（Bitter Lesson）的哲学？“苦涩的教训”强调，在深度学习的长期发展中，那些可扩展的学习和搜索方法终将胜出，而人为添加的、短期的“巧妙”解决方案往往难以持续。深思的这些低层优化，究竟是短期内的“奇技淫巧”，还是预示着未来AI训练效率提升的新方向？目前尚难定论，但它们无疑是技术创新在特定约束下爆发的生动案例。尽管这些底层代码可能因其高度定制化而难以通用，但它们在特定模型架构和规模下所带来的性能提升，是巨大的。

而这一切的背后，是AI研究人员巨大的压力。启动一次前沿模型的训练，意味着投入巨额资金和时间。他们必须时刻紧盯各种仪表盘，尤其是模型的“损失值”（loss）。当出现“损失尖峰”（loss spikes）时，心跳便会加速。有时，这可能是数据问题（比如臭名昭著的“微波炉帮”subreddit，里面全是字母M的帖子），但更多时候，尤其是在复杂的MoE或FP8训练中，损失尖峰的原因难以捉摸。这种对模型状态的持续关注，几乎成了这些顶尖实验室工程师的日常写照，他们甚至在晚餐时也会不时查看手机，确认模型是否安然无恙，损失是否持续下降。

# Chapter 4: AI训练的惊心动魄：从损失尖峰到“YOLO”豪赌

在AI模型训练的深渊中，工程师们的生活充满了紧张与不确定。每当模型训练的“损失曲线”出现异常尖峰，他们的心跳便会随之加速。这不仅仅是简单的文本信息，而是对模型性能的实时监控，每一个数字都牵动着巨额投资和数月努力的成败。早期的训练策略相对粗犷，一旦出现严重的损失尖峰，往往只能选择中断运行，回溯到旧版本，调整数据配比，然后重新开始。然而，随着技术的发展，人们对损失尖峰有了更细致的理解：有些是“快速尖峰”，可能是由单个异常数据点引起，可以被模型忽略，快速恢复；另一些则是“缓慢尖峰”，损失值逐渐爬升，最终可能导致模型彻底崩溃，这种情况下，恢复的难度极大，需要回溯到更早的检查点。随着模型架构日益复杂，GPU规模不断扩大，损失爆炸的风险也随之增加，这使得训练过程如同走钢丝般惊险。

更令人着迷的是“顿悟”（Grokking）现象。有时，模型的损失曲线似乎停滞不前，改进缓慢，但并不意味着它停止了学习。突然之间，损失可能会急剧下降，这表明模型在某个时刻真正“领悟”了某种深层模式，这种非线性的学习过程，如同人类的顿悟一般，充满了不可预测性。

在AI训练的前沿，失败是常态，而非例外。每一次失败的运行，虽然代价高昂，可能导致数周甚至数月的延误和数百万美元的损失，但却是推动基础设施和技术边界的必经之路。DeepSeek等顶尖实验室深谙此道，他们通过无数次小规模的失败尝试，快速迭代，积累对超参数（如学习率、正则化）和架构（如MoE、MLA）的直觉，最终找到适合其代码库的最佳配置。

这种小规模实验的终极目标，是为了那场被称为“YOLO”（You Only Live Once，你只活一次）的豪赌。在经过大量小规模的消融实验（ablation studies），研究人员在少量GPU上测试各种模型架构和专家配置后，最终会做出一个大胆的决定：投入所有可用的计算资源，进行一次大规模的、孤注一掷的训练。这种“YOLO”运行的压力巨大，因为小规模实验中奏效的策略，在大规模部署时可能失效。OpenAI在2022年训练GPT-4时，就曾进行过一次真正的“YOLO”豪赌，将所有计算资源投入到一个全新的架构中，这在当时是极具风险的举动。如今，虽然许多公司在进行“YOLO”运行，但由于拥有庞大的推理和研究集群作为支撑，其风险已远低于当年的OpenAI。

DeepSeek的崛起，本身就是一场精彩的“YOLO”故事。它脱胎于一家名为High-Flyer的量化对冲基金，这家基金在中国乃至全球的量化交易领域历史悠久，积累了大量的GPU资源。其创始人梁文峰（Liang Feng）是一位充满远见的工程师，他将对冲基金的成功转化为推动AI发展的强大动力。梁文峰拥有类似埃隆·马斯克和黄仁勋的特质，深度参与公司的每一个环节，并怀揣着让中国在AI生态系统中占据领导地位的宏大愿景，坚定地支持开源。

DeepSeek的GPU基础设施令人瞩目。早在2021年，他们就宣称拥有中国最大的A100集群，规模达到10,000块GPU，主要用于量化交易和自然语言处理。虽然官方公开的V3预训练只使用了2,000块H800 GPU，但据SemiAnalysis的专家估计，DeepSeek实际拥有的GPU总量可能接近50,000块，这些资源被分配到基金业务、研究实验和模型训练等多个任务中。值得一提的是，H800是英伟达专为中国市场定制的GPU，其浮点运算性能与H100相当，但在互联带宽上受到限制。然而，DeepSeek凭借其超低层的工程创新，如自主调度GPU核心（SMs）和定制通信协议，成功克服了H800的互联瓶颈，展现了其在硬件优化方面的卓越能力。DeepSeek的计算资源规模，使其在全球AI领域占据了举足轻重的地位，与Meta等巨头并驾齐驱，成为推动AI前沿发展的重要力量。

# Chapter 5: AI芯片战与AGI之辩：算力限制下的未来

在全球AI芯片的舞台上，英伟达的H100和H200无疑是明星产品，但对于中国而言，情况却复杂得多。美国政府对华实施了一系列出口限制，最初的规定是基于芯片的互联带宽和浮点运算能力（FLOPS）双重标准。这意味着，任何同时在这两项指标上超过特定阈值的芯片都将被禁运。

然而，政策的演变总是伴随着技术的适应。当美国政府意识到这一双重标准存在漏洞时，他们将限制简化为仅关注浮点运算能力。这直接催生了H800芯片——它在FLOPS上与H100性能相当，但互联带宽却被刻意削减。正是在这样的背景下，DeepSeek展现了其卓越的工程智慧。他们深知如何充分利用H800的潜力，即使互联带宽受限，也能通过精妙的底层优化，让GPU的性能得到最大化发挥。这发生在2022年10月，彰显了中国企业在逆境中的创新能力。

但好景不长，到了2023年，美国政府再次收紧政策，并在2024年正式禁止了H800芯片的出口。值得一提的是，DeepSeek用于训练模型的2000块H800集群，实际上是在2023年末采购的，这批芯片在禁令生效前抵达，才使得他们能够进行后续的大规模研究和模型发布。随着H800的退场，一款名为H20的新芯片应运而生。H20的特点是FLOPS被削减，但互联带宽却与H100保持一致，甚至在内存带宽和容量上有所提升。这表明英伟达在政府限制的框架内，仍在努力为中国市场打造性能最优的GPU。

这场芯片战的背后，是关于AI未来走向的深刻哲学辩论。Anthropic的CEO达里奥·阿莫代（Dario Amodei）曾发表文章，提出到2026年，通用人工智能（AGI）或超强AI将成为现实，并赋予拥有者显著的军事优势。他认为，为了维护一个由民主国家主导的单极世界，美国应通过出口管制来减缓中国在AGI领域的进展，防止一个拥有超强AI的威权国家崛起，从而避免地缘政治的复杂化。

然而，也有观点认为，出口管制的目标并非完全阻止中国训练AI模型，而是限制其算力规模和密度。例如，DeepSeek-V3的成功证明，即使在限制下，一支专注的团队仍能达到AI前沿。2000块GPU在全球范围内并非难以获得，中国企业依然能够训练模型。真正的限制可能在于AI的广泛应用和推理能力。如果AI市场巨大，需要数十万块GPU来支持类似ChatGPT的服务，那么严格的出口管制将大大降低中国AI的可用性。这比争论AGI的定义更容易实现，也更能有效阻止超智能自主AI在中国数据中心的大规模运行。

训练模型本身并不能直接产生价值，真正的价值在于模型的部署和应用，从而带来巨大的经济增长、军事能力提升和生产力飞跃。Meta拥有40万块GPU，但只有1.6万块用于训练Llama，其余大部分用于推理。这意味着，推理算力才是将AI能力转化为实际影响的关键。美国政府深知无法完全切断中国的AI发展，但通过保持技术差距，可以确保在AI驱动的社会变革中，美国能够以其期望的方式交付AI服务，而中国则会受到限制。

随着AI技术的发展，推理模型（如DeepSeek-R1和OpenAI的o3）正变得越来越重要，它们需要更多的计算资源来完成复杂任务。OpenAI曾宣布其o3模型在解决ARC-AGI（通用人工智能抽象推理语料库）任务上取得了突破，但每次查询的成本高达5到20美元，需要消耗大量的计算资源。ChatGPT Pro订阅用户每月支付20美元，但Sam Altman承认公司在此业务上亏损，这表明推理算力的消耗是巨大的。这种高成本的推理服务，正是中国公司在严格出口管制下难以大规模提供的。

关于AGI的到来时间，各方看法不一。达里奥·阿莫代预测2026年，而许多人则认为可能在2030年之后。虽然语言模型在某种程度上已具备通用智能的特征，但“超强AI”或“代理式AI”（Agentic AI）——即能够独立完成训练数据之外任务的AI——才是当前AI公司追求的下一个目标。当前，AI已经对社会产生了影响，例如选举中的AI语音电话和虚假信息传播，这使得美国政府对AI技术保持高度警惕，甚至对盟友也实施了云算力及GPU销售限制。

最终，关于AGI的“核武器时刻”，可能并非一蹴而就。即使AI能力达到某个临界点，能够被称作AGI，但其运行的巨大成本和规模部署的物理限制，将使其无法在短时间内彻底改变经济和社会。就像GPT-4刚发布时，人们曾担忧它会颠覆搜索行业，但其高昂的推理成本使其无法立即大规模应用于每一次搜索查询。未来的AI发展，尤其是推理密集型模型，将是一个能力逐步提升、成本逐渐降低、最终实现广泛部署的漫长过程。

# Chapter 6: AGI的部署困境、地缘政治博弈与芯片冷战

对话伊始，伴随着一声轻笑，人们对AGI（通用人工智能）能“弹指一挥间”彻底改变经济的幻想被打破。演讲者强调，即便AGI的能力已然触手可及，其大规模部署所面临的巨大成本和物理限制，才是真正的瓶颈。他回忆起2023年GPT-4和Perplexity引发的狂热，当时将GPT-3整合到每一次谷歌搜索中的成本被认为是“物理上不可能实现”的。这种成本差异令人震惊：一次简单的ChatGPT查询只需几美分，但解决一个ARC-AGI问题却可能花费5到20美元——高出千倍甚至万倍。展望未来三年，尽管AGI可能解决更复杂的问题，但其成本可能飙升至数十万美元的GPU时间，这意味着由于电力、GPU和基础设施的不足，AGI无法在短期内实现广泛而即时的社会变革。

这引出了一个关键问题：当AGI变得如此强大却又如此昂贵时，谁来控制和引导它？演讲者引用了达里奥的观点，暗示中国可能更快、更有效地将AGI应用于军事任务。他指出，中国在军事应用中，尤其是在无人机等非对称技术方面，对新技术的采纳速度更快，这与美国专注于传统空军力量形成对比。人们担心的是，尽管美国商业部门可能从AGI中获益，但中国军方却可能迅速将其用于军事物流、虚假信息宣传，甚至颠覆一个国家的政治，从而导致灾难性后果；而美国的资本主义分配则会优先考虑经济回报，例如优化工厂生产。

然而，关于机器人和自主系统，对话中也提出了一个反驳观点。演讲者指出，人们的直觉在这方面常常失灵，他以自动驾驶汽车和乌克兰战争中无人机的使用为例，强调人类操作员在许多情况下仍然远远优于完全自主的AI系统。他认为，大规模的自主军事蜂群在2030年之前不太可能出现。尽管如此，网络战的威胁依然令人不寒而栗，从社会工程到自主机器人发现代码库中的攻击向量并关闭电网，这些都可能将整个国家推向混乱。

讨论随后转向了出口管制。如果人们相信经济增长是缓慢而渐进的，那么出口管制反而可能在长期上保证中国的胜利。论点是人才并非瓶颈；中国拥有更多的STEM毕业生，而美国则受益于全球人才。真正的限制在于计算能力。尽管美国在芯片设计方面领先，但中国拥有“前所未有”的能力来建设大规模的电力基础设施和数据中心，其工业能力远远超过美国。如果中国能够获得尖端芯片，他们建设全球最大数据中心的速度将超过任何国家。目前，美国在电力生产和传输方面的限制，也制约了其扩大规模的能力。

这些出口管制措施的时机至关重要。如果AI的变革性影响需要很长时间才能显现，那么通过限制英伟达和台积电对中国的销售来削弱美国公司，可能会适得其反，减少推动生产周期的需求。但如果AI能在“中短期”（5-10年内）给社会带来“巨大变革”，那么限制计算能力就成为美国获得优势的唯一可行策略。

一个关键时刻被强调：萨蒂亚·纳德拉和马克·扎克伯格等美国高管已经“被规模化思维洗礼”，承诺投入数十亿美元建设多吉瓦级数据中心。然而，中国直到最近才开始在高层层面优先考虑AI。DeepSeek创始人与中国二号人物的会晤，以及随后宣布的万亿人民币（约1600亿美元）AI补贴，都表明中国高层对AI重要性的“觉醒”。正是在这种背景下，出口限制变得至关重要，旨在阻止中国获取最强大的美国芯片和制造工具，明确减缓其AI和军民融合的雄心。

对话回顾了2020年华为发布的昇腾910芯片，这款7纳米AI芯片曾超越竞争对手，导致特朗普政府禁止台积电向华为供货。这一历史背景凸显了持续的芯片战争。

最后，最严重的担忧被提出：出口管制是否会将中国推向对台湾采取军事行动的边缘？演讲者承认这是一个“巨大风险”，暗示如果中国被剥夺了获取关键技术的权利，它可能会决定不让任何人也无法获取这些技术。他指出中国内部的社会压力（城乡差距、男女比例失衡）以及其在电动汽车和可再生能源领域取得的成功，以及在半导体领域迅速追赶的势头。如果中国将AI视为下一个关键技术，并感到被逼入绝境，那么一场围绕台湾的“热战”——一场对世界其他地区伤害远大于对中国自身的战争——就可能成为一个可怕的可能性，从而可能打破当前全球和平与贸易的格局。

# Chapter 7: 芯片争霸：台湾的战略核心与全球科技命脉

在2010年代末至2020年代初，中国开始将目光投向半导体产业，并以惊人的速度投入巨资，迅速追赶。这种模式，他们也正准备在人工智能领域复制，因为中国拥有大量优秀的人才。然而，这种快速的崛起也引发了一个令人不安的问题：何时会触及临界点？如果中国认为，即使在无法获得关键技术的情况下，通过武力夺取台湾，或以某种方式颠覆其民主，甚至只是进行封锁，对世界其他地区的伤害远大于对自身的伤害，那么他们可能会采取行动。出口管制政策，是否正在将中国推向这一边缘？

地缘政治的复杂性显而易见，全球和平与贸易体系无疑对经济发展至关重要，但它并非坚不可摧。一旦冲突爆发，其经济后果将是灾难性的。对于中国而言，其经济高度依赖出口，如果失去美国这个巨大的市场，将是毁灭性的打击。更甚者，美国一旦封锁马六甲海峡，中国将无法从全球各地进口原材料。反观美国，自上世纪70年代以来，其GDP增长几乎完全依赖于人口增长或科技进步。离开了科技，我们今天的生活与80年代相比，并没有本质上的飞跃。汽车、冰箱，乃至我们日常生活中无处不在的设备，都离不开半导体。甚至有传闻说，俄罗斯人为了获取特定的德州仪器芯片，不惜拆解洗衣机，将其重新用于S-400防空导弹系统。这足以说明半导体在现代社会中的核心地位。

在这场半导体大戏中，台积电（TSMC）扮演着举足轻重的角色。它生产了全球大部分芯片，尤其是在代工领域。尽管三星、英特尔、意法半导体、德州仪器等公司仍在自行生产芯片，但越来越多的公司选择将生产外包给台积电，这一趋势已持续数十年。美国并非要彻底摆脱对台积电的依赖，而是希望台积电能在美国本土建厂。

回顾半导体供应链的历史，最初的公司通常是自行设计、制造并销售芯片。然而，随着技术迭代，建造一座晶圆厂的成本呈几何级数增长，每一代新工厂的投资都高达数百亿美元，例如一座尖端的三纳米或两纳米晶圆厂，成本可能超过300至400亿美元。这就像摩尔定律让芯片成本每两年减半的同时，却有另一条“定律”让晶圆厂的成本每隔几年翻一番。在二三十年前，全球有二三十家公司能够制造最先进的芯片，如AMD、英特尔、IBM等。但随着时间的推移，它们纷纷倒下，这正是台积电的功劳。台积电开创了“代工”商业模式——它不设计任何芯片，只为其他公司代工生产。英伟达就是其早期客户之一，也是唯一一家在代工时代成立、营收超过10亿美元的半导体公司。其他公司，如AMD和英特尔，都曾拥有自己的晶圆厂，但最终为了生存和发展，不得不出售或剥离其制造业务，转而依赖台积电。甚至英特尔最新的PC芯片也部分采用了台积电的工艺。

代工模式的成功，核心在于规模经济。建造晶圆厂的高昂成本和研发难度，使得小型芯片设计公司难以承受。而台积电通过汇聚全球众多客户的需求，实现了巨大的规模效应，从而能够持续投入巨资建设下一代晶圆厂。此外，随着摩尔定律和登纳德缩放定律的失效，芯片性能的提升不再是免费的，需要更多的架构创新和专业化。例如，谷歌的服务器不再仅仅依赖英特尔CPU，而是拥有YouTube芯片、TPU、Pixel芯片等多样化的定制芯片。一辆汽车可能包含5000个芯片，200种不同类型；甚至特斯拉的一个门把手都有两个芯片。在芯片种类日益多样化、专业化需求不断增长、晶圆厂成本持续攀升的背景下，台积电凭借其专注于最先进工艺技术、高度灵活的制造能力，以及对客户需求的深刻理解，成为了行业的佼佼者。它承担了制造的复杂性，让设计公司能够专注于创新，从而避免了因某个微小工艺失误（如化学蚀刻或等离子蚀刻）而导致整个公司崩溃的风险。AMD就曾因此濒临破产，最终通过出售晶圆厂给格芯（GlobalFoundries）才得以重生，专注于芯片设计。

那么，为何台湾对台积电如此特殊？这要从其创始人张忠谋的故事说起。他曾是德州仪器的高管，因未获晋升而愤然离职，前往台湾创立了台积电。这其中既有个人才华的因素，也有台湾独特的社会环境。在台湾，顶尖大学（如台湾大学）的优秀毕业生，大部分都选择进入台积电工作。虽然他们的起薪（约7-8万美元）与美国顶尖科技公司（如谷歌、亚马逊、OpenAI）的数十万美元年薪相比并不算高，但这反映了台湾社会对半导体产业的重视和人才的集中。更重要的是，台湾工程师的职业道德和奉献精神。晶圆厂的工作并非居家办公，而是艰苦且严苛。一旦发生地震等意外，机器可能受损，生产报废。台积电的员工无需通知，便会自发赶往工厂进行抢修，停车场瞬间爆满，他们就像蜂巢里的工蚁，无需指令便知所向。他们中的许多人一生只专注于一项极其专业的任务，例如某种特定的等离子蚀刻技术，这种专业化程度和经验积累是难以复制的。半导体制造的知识壁垒极高，资料稀缺，学习曲线漫长，这使得新进入者面临巨大挑战。

美国能否复制这种成功？从技术角度看，并非不可能。英特尔曾是全球半导体制造的领导者，在20多年间率先将多项关键技术推向市场。美国俄勒冈州仍有数万名拥有博士或硕士学位的顶尖专家，他们仍在从事卓越的研发工作。然而，英特尔的衰落源于文化问题、错误的投资决策（例如拒绝iPhone）、以及对晶圆厂和设计的管理不善。傲慢自大也曾是其弊病之一。尽管如此，美国正在努力。台积电已在美国亚利桑那州建设了约20%的五纳米芯片产能，但这远远不够，且仍依赖于台湾的研发支持。全球领先的半导体研发主要集中在三个地方：台湾新竹、美国俄勒冈州的希尔斯伯勒和韩国平泽。这些地方是定义未来半导体技术演进的核心。如果新竹的研发中心消失，亚利桑那的晶圆厂也将在一两年内停产，因为它们只是制造基地，而非研发中心。可以说，如果有人想对全球经济造成最大破坏，目标并非白宫，而是这些半导体研发中心。没有台积电的芯片，我们无法购买汽车、冰箱、笔记本电脑、手机、服务器或GPU，甚至许多非尖端的电源管理芯片也由台积电生产。正因如此，中国也在大力投资“长尾晶圆厂”，专注于那些技术更成熟、更易掌握的芯片制造领域，以期建立自己的供应链韧性。

# Chapter 8: 芯片无处不在：台积电的全球霸权与中美科技博弈的深层逻辑

故事的开篇，我们不得不承认一个令人沮丧的事实：台积电（TSMC）的芯片，已然渗透到我们生活的每一个角落。无论是你驾驶的汽车，家中冰箱的智能控制系统，还是日常使用的笔记本电脑、手机、服务器乃至高性能的GPU，都离不开台积电的精工细作。甚至那些看似不起眼、仅仅负责电压转换的“傻瓜”电源管理芯片（Power IC），也常常出自台积电之手。讽刺的是，你可能唯一能买到的、不含台积电芯片的电子产品，或许只有德州仪器（Texas Instruments）的图形计算器，因为它还在德州本土生产。这种无处不在的依赖，深刻揭示了台积电在全球半导体供应链中的核心地位。

面对这种局面，中国正积极寻求突破。他们采取的策略是大力投资“长尾晶圆厂”（trailing-edge fabs），专注于生产那些技术相对成熟、制程要求不那么尖端（如45纳米、90纳米）但需求量巨大的芯片。这些芯片虽然不像最先进的5纳米或3纳米芯片那样“性感”，却是汽车门把手、各种传感器、电动车电池管理控制器等日常设备不可或缺的组成部分。通过这种方式，中国旨在确保关键零部件的自主供应，减少对外部的依赖，从而在经济博弈中占据更有利的位置。例如，比亚迪（BYD）正成为全球首批能够自主生产大部分电动车芯片的公司之一，尽管在自动驾驶等高端领域仍需进口。

然而，美国的出口管制政策，在试图遏制中国在尖端芯片（如5纳米、3纳米）领域发展的同时，却意外地加速了中国在成熟制程芯片上的进步。中国深知半导体产业的重要性，一旦在高端领域受限，便会加倍投入到中低端芯片的自主研发和生产中，以确保“基本生活”的正常运转。

与此同时，美国也面临着将半导体制造“回流”本土的巨大挑战。这不仅需要投入天文数字般的资金（可能需要十年时间，耗资万亿美元），更要克服文化和人才方面的障碍。尽管美国在历史上曾是半导体强国，但如今台湾工程师的极致专业和奉献精神，以及高效的工作文化，使得台积电的成功难以复制。美国政府的《芯片法案》虽然提供了500亿美元的补贴，但这与中国每年高达2000亿美元的半导体补贴相比，简直是杯水车薪。关于是否应该通过移民政策吸引全球顶尖人才，也成为了一个充满争议的话题。

在全球地缘政治的棋盘上，中美关系正走向一个“分离的未来经济体”。美国明确表示，将不惜一切代价控制关键技术，即使这意味着牺牲全球经济一体化。这种分道扬镳的趋势，在过去十年中愈发明显：美国公司难以进入中国市场，中国公司也难以进入美国。双方都在关键材料和技术上相互设限。历史告诉我们，世界在单一霸权时期往往最为和平。而当今世界，随着中国崛起，两个大国争夺全球主导权，这种权力结构的转变，通常伴随着巨大的动荡和不确定性。美国试图通过在人工智能领域保持领先地位来维持其全球霸权，以期带来“和平”，但这无疑会对其他国家，特别是中国，产生深远影响。

在具体的芯片技术层面，美国的出口管制也催生了特殊的“中国定制版”GPU，例如英伟达（Nvidia）的H20芯片。这款芯片在浮点运算能力（FLOPS）上被削弱（仅为H100的1/3到60%），但在互联带宽、内存带宽和内存容量方面却与H100相当甚至更优。AI芯片的性能通常由三个关键维度决定：浮点运算能力（FLOPS，主要用于预训练）、内存带宽与容量（I/O，内存）以及芯片间互联（interconnect）。虽然美国政府传统上更关注FLOPS（例如设定了1e26 FLOP的通知阈值），但H20的特性使其在某些任务上表现出色，尤其是“推理”（reasoning）任务。推理任务对内存的需求远高于对纯粹FLOPS的需求。最近，英伟达大幅削减了H20的生产订单，这可能预示着美国将对这类“定制”芯片施加更严格的限制，因为H20在特定场景下，尤其是对AI模型“推理”能力至关重要的内存方面，甚至超越了其高端型号。理解KV缓存和Transformer的注意力机制，将是理解内存对推理重要性的关键。

# Chapter 9: 内存深渊与AI推理的成本之战：DeepSeek的破局之道

想象一下，一个AI模型如何理解你说的每一句话，甚至是一整本书？这并非简单的参数堆砌，而是对内存的极致考验。在过去几年掀起AI革命的浪潮中，Transformer架构及其核心的“注意力机制”扮演了关键角色。注意力机制就像一个超级大脑，它能洞察文本中每个词语之间的千丝万缕的联系，独立于模型参数，却必须为上下文中的每一个词（或“代币”）计算其与其他所有词的相对连接。

为了让这个过程更高效，尤其是在模型逐个生成词语（即“自回归”模式）时，一个名为“KV缓存”（Key-Value Cache）的优化技术应运而生。注意力机制由查询（Queries）、键（Keys）和值（Values）三部分构成，KV缓存就像一个记忆库，它能记住模型已经处理过的所有信息。当模型生成下一个词时，它无需从头计算所有历史词语的键和值，只需将新生成的词语的键和值追加到KV缓存中即可。这大大提升了推理速度。

然而，这种强大的能力并非没有代价。注意力机制的内存需求，就像一个无底洞，随着你输入文本的增长，它以惊人的二次方速度吞噬着内存。这意味着，你输入的文本越长，所需的内存就呈几何级数增加。这对于大规模部署AI模型进行推理服务构成了巨大挑战。

更复杂的是，输入（提示词）和输出（模型生成内容）的代币在处理方式和成本上存在显著差异。输入代币可以并行处理，一次性计算整个提示词的KV缓存，这被称为“预填充”或“批处理”，因此成本相对较低。而输出代币则必须逐个生成，每次生成一个新词，模型不仅要重新加载并激活，还要读取整个KV缓存，然后将新词的KV缓存追加进去，再进行下一次生成。这是一个非并行、自回归的过程，因此输出代币的成本要高得多，通常是输入代币的四倍甚至更多。

当AI模型开始进行复杂的“推理”或“思维链”任务时，情况变得更加严峻。它不再只是简单地回答问题，而是像一个侦探一样，一步步地推导出答案，生成数万字的详细过程。这意味着KV缓存必须长时间驻留在内存中，并且随着序列长度的增加，内存需求呈二次方飙升。这不仅限制了单个GPU能处理的上下文长度，也大大降低了批处理能力，即同时服务更多用户的能力。当内存压力达到“临界批处理大小”时，推理的并行度会急剧下降，导致服务成本呈指数级增长。

正是在这场内存与成本的拉锯战中，中国AI公司DeepSeek如同一匹黑马，以其DeepSeek-R1（或V3）模型横空出世，震惊了全球。它不仅在性能上表现出色，更以惊人的低价提供了API服务，其输出代币价格仅为OpenAI同类模型的约1/27，引发了业界对其“为何如此便宜”的疑问。

DeepSeek的秘密武器之一，便是其独创的“多头潜在注意力”（MLA）机制。与传统的Transformer注意力机制相比，MLA在保持性能的同时，能将注意力机制的内存消耗降低80%到90%，极大地缓解了长上下文推理的内存压力。虽然其他公司也通过MQA、GQA、滑动窗口等技术优化了注意力机制，但DeepSeek的MLA被认为是一项真正的架构突破。

然而，DeepSeek的成功并非没有挑战。尽管其模型效率惊人，但与OpenAI相比，它在GPU容量上仍是“小巫见大巫”。OpenAI之所以能收取高昂费用，部分原因在于其高达75%以上的毛利率，以及其庞大的GPU基础设施（与微软合作拥有数十万块GPU）。DeepSeek的GPU容量远不及OpenAI，导致其API服务经常面临资源紧张，甚至不得不暂停新用户注册。尽管如此，DeepSeek的出现，以及其他高效服务商（如Together AI、Fireworks AI）的存在，正在推动整个AI推理市场的成本下降，迫使行业重新审视AI服务的经济模型。DeepSeek的成功证明了通过架构创新，可以在有限的硬件资源下，提供极具竞争力的AI服务，这对于全球AI生态的普及和发展具有深远意义。

# Chapter 10: DeepSeek的效率之谜与AI竞赛的文化差异

在AI推理服务的激烈战场上，DeepSeek以其惊人的低成本脱颖而出，其API服务的价格比OpenAI便宜了足足五倍，甚至比Together AI和Fireworks AI等高端竞争对手也便宜了五到七倍。这不仅仅是因为OpenAI赚取了巨额利润，更深层的原因在于DeepSeek模型架构本身的卓越效率。

DeepSeek的成功并非偶然。其独特的“多头潜在注意力”（MLA）机制和混合专家（MoE）架构，以及那些尚未公开的底层库，共同构筑了其无与伦比的效率优势。尽管DeepSeek在GPU容量上仍面临挑战，无法像巨头那样大规模服务，但其技术突破已足以颠覆市场。

关于DeepSeek的低价策略，曾有人猜测中国政府是否在背后提供补贴。然而，事实并非如此。DeepSeek与阿里巴巴等公司一样，是相对独立的实验室，与政府关系并不密切。其创始人兼CEO，一位被誉为“令人敬畏”的人物，拥有与官方截然不同的观点。真正的“幕后推手”是这位CEO旗下的对冲基金，它在DeepSeek早期发展阶段提供了大部分资金，甚至至今仍持有公司过半的股份。对冲基金的资助，使得DeepSeek在没有大量外部融资的情况下，得以专注于技术研发和快速迭代。

DeepSeek的另一项策略是积极拥抱开源。通过开放模型，他们吸引了大量顶尖人才，弥补了起步较晚的劣势。他们奉行“快速发布”的原则，不拘泥于市场营销的“最佳时机”，例如在圣诞节后第二天发布V3模型，只为尽快将成果推向世界。这种“谁在乎圣诞节，赶紧发布”的心态，与西方公司形成了鲜明对比。

以Anthropic为代表的美国公司，则将AI安全置于首位。他们投入大量资源进行内部审查，与国际政府机构合作进行预发布测试，甚至宁愿推迟数月发布已训练好的模型，也不愿冒任何风险。例如，Anthropic的Claude 3.5 Sonnet模型在训练完成近一年后才发布。这种对安全的极致追求，虽然值得称赞，但也带来了巨大的“惯性”，减缓了产品发布的节奏。当DeepSeek的R1模型在推理过程中，有时会在中英文之间切换，甚至出现短暂的乱码后，依然能给出正确答案时，一些人惊叹于其能力，而另一些人则因其不可预测性而感到担忧。

这种差异引发了关于AI发展“安全标准”的深刻讨论。有人将此比作“太空竞赛”：苏联之所以能率先将人类送入太空，部分原因在于其对安全的容忍度较低。在AI领域，DeepSeek的激进策略无疑正在对美国公司的安全标准施加下行压力。Anthropic的CEO Dario Amodei曾提出“向上竞争”与“向下竞争”的理念，他希望AI行业能形成高安全、高性能的“向上竞争”标准，而非为了速度和成本而牺牲安全的“向下竞争”。

然而，现实是残酷的。如果美国停止开源模型，其他国家，尤其是中国，将不可避免地继续发展。DeepSeek仅用500万美元就训练出顶级模型，这表明全球有能力投入百倍资金的实体不在少数。正如Meta的马克·扎克伯格所言，全球AI开源标准势必形成，美国必须确保其成为“美国标准”，以维护国家优势。

更深层次的担忧在于AI模型中可能存在的“文化后门”或“超人说服力”。就像Linux系统中曾发现的十年未被察觉的后门一样，AI模型也可能被植入隐蔽的偏见或指令。这种“对齐”可以是无意的，例如美国LLM的普及导致英式英语的拼写逐渐被美式英语取代；也可以是故意的，旨在潜移默化地影响用户的思想和行为。Sam Altman曾预言，“超人说服力”将先于“超人智能”出现。如果模型能够以我们难以察觉的方式影响我们的信念和决策，那么我们可能会陷入一个由他人叙事所控制的“美丽新世界”，失去独立思考的能力。推荐系统已经展示了这种操纵的雏形，而更复杂的AI模型则可能以更深远的方式“劫持”我们的大脑反馈回路。因此，理解AI的潜在影响，并警惕其可能带来的文化和认知风险，变得前所未有的重要。

# Chapter 11: AI的深层影响：心智、审查与智能涌现的奥秘

在数字时代的浪潮中，我们与AI的互动正变得日益深入。想象一下，用户在Character AI上一次会话就能持续两小时，这不仅仅是简单的对话，更是一种沉浸式的体验。这种现象引发了人们对互联网和社交媒体对心智影响的深思。有人发现，当他们暂时脱离网络，回归自然与书籍时，心智会变得更加清明，仿佛找回了某种“智能主权”。这种感觉令人警醒：当我们在网上冲浪时，我们的思想是否正被他人，乃至未来的算法所操控？

这种担忧并非空穴来风。如今，网络上充斥着各种AI机器人，我们不经意间就可能与它们对话。而回顾科技史，成人娱乐行业总是新技术的先行者。从视频流媒体到如今的独立内容创作者，他们早已将生成式AI和聊天机器人运用得炉火纯青，甚至用AI替身与“鲸鱼用户”互动，实现大规模的个性化交流。这预示着，这些技术迟早会渗透到社会的每一个角落。

然而，AI的普及也带来了严峻的伦理挑战——模型审查与对齐。我们曾目睹谷歌Gemini在生成图像时出现“黑人纳粹”的荒谬错误，也看到中国模型对1989年6月4日天安门事件避而不谈。这些事件揭示了AI模型在价值观和事实呈现上的偏颇。那么，这种审查是如何发生的，又该如何避免呢？

专家指出，审查和对齐可以在AI训练的多个阶段进行。首先是**预训练阶段**，模型在此阶段摄取海量的互联网数据。要从这些数据中彻底清除特定事实几乎是不可能的，因为互联网本身就带有固有的偏见（例如，略微偏左的倾向），而且人们总能找到“文字游戏”或“编码语言”来规避审查。模型就像一个巨大的知识库，即使被告知不能直接回答，通过巧妙的提问，仍可能“黑入”模型，获取被过滤的信息。

其次是**后训练阶段**，特别是通过强化学习与人类反馈（RLHF）进行对齐。早期的Llama 2模型就曾因过度强调“安全”而闹出笑话，比如用户询问“如何杀死一个Python进程”，它却拒绝回答，因为它被训练成不能谈论“杀戮”。这种过度对齐让模型变得“迟钝”，甚至一度让RLHF这个词蒙上污名。但随着技术演进，RLHF已能实现对模型行为的精细控制，并且还能提升模型在数学、编程等任务上的性能。

再者是**系统提示（System Prompts）**和**提示重写（Prompt Rewriting）**。系统提示是模型在与用户交互时接收到的隐藏指令，比如“你是一个乐于助人的助手”或“像海盗一样说话”。Anthropic甚至公开了他们的系统提示，以增加透明度。而提示重写则是在用户查询到达模型之前，由另一个语言模型对其进行修改，使其更具描述性或符合特定要求。Gemini的“黑人纳粹”事件，正是由于系统层面的提示重写执行失败所致，而非模型权重本身的问题。

在AI的训练过程中，人类的参与也至关重要，但其角色正在演变。过去，我们雇佣数学和编程专家来创建详细的问题和答案，以“指导”模型。如今，许多AI模型在生成详细、流畅的答案方面已经超越了人类。人类的主要作用转向了**偏好数据**的提供，即比较两个模型输出，并选择更优的一个。

然而，最令人惊叹的进展是**智能的涌现**。DeepSeek-R1-Zero模型展示了，即使在后训练阶段没有加入人类偏好数据，仅仅通过大规模的强化学习，奖励模型正确回答问题，它也能自然地涌现出复杂的推理行为，比如“等等，让我检查一下”、“这可能是一个错误”等“思考链”。这表明，预训练语言模型本身就蕴藏着这种能力。正如伟大的Andrej Karpathy所言：“学习有两种主要类型，在儿童和深度学习中皆是如此。”这无疑为我们理解AI智能的本质打开了新的大门。

# Chapter 12: AI推理的奥秘：从模仿到自我探索的飞跃

在AI的深邃世界里，推理能力的涌现并非源于人类的逐字教导，而更像是一场由预训练语言模型与强化学习（RL）共同编织的奇妙旅程。它并非通过“黑客”手段窃取OpenAI的推理链，而是模型在被奖励正确答案后，自主尝试多种解决方案，最终“顿悟”出链式思考的策略。

正如伟大的Andrej Karpathy在其精辟推文中所言，深度学习与儿童学习有两大主要模式：一是模仿学习（如预训练、监督微调），即“看与重复”；二是试错学习（强化学习），即“尝试与纠错”。他以AlphaGo为例，指出模仿专家棋手是第一种，而通过强化学习赢得比赛则是第二种。几乎所有令人震惊的深度学习成果，所有“魔法”的源泉，都来自第二种模式——它更强大，更具惊喜。当AI学会绕过障碍击球，当AlphaGo击败李世石，当DeepSeek或o1模型在思考过程中发现重新评估假设、回溯并尝试其他方法更有效时，这正是强化学习带来的“啊哈”时刻。这些解决策略，这些模型在思考中来回穿梭的链式思维，都是“涌现”的，是令人难以置信的全新突破。人类标注者无法预知并正确标注这些复杂的解决策略，它们必须在强化学习过程中，作为对最终结果有统计学意义的有用方法被发现。

回溯AlphaGo与AlphaZero的故事，更能理解这种从模仿到自我探索的飞跃。AlphaGo最初从人类棋谱中学习，而AlphaZero则完全摒弃了人类数据，从零开始自我对弈，最终创造出远超AlphaGo的强大棋手。这种“零人类先验”的移除，使得最终系统更为强大，也印证了“苦涩的教训”——即大数据和计算力往往胜过人类的归纳偏见。自去年QStar谣言传出以来，业界一直在热切期待语言模型领域也能出现类似的突破，而这种新型的强化学习训练，正是打开这扇大门的钥匙。虽然我们尚未看到像AlphaGo“第37手”那样震惊世界的标志性时刻，但这并不意味着技术路径的差异，其普遍训练的影响依然是革命性的。

那么，语言模型推理的“第37手”会是什么呢？有人认为是科学发现，但更实际的答案可能在于计算机使用或机器人技术。AI模型学习需要海量数据，其效率远低于人类。一个婴儿通过将脚或手放入口中，通过反复的自我玩耍来校准触觉，这种“自我对弈”的学习方式，效率极高。如今，AI也开始通过类似的方式学习：在可验证的任务中（如代码单元测试或数学问题），生成无数推理轨迹，不断分支，然后筛选出正确的答案。即使大多数是错的，只要有少数正确，模型就能从中学习并不断优化。在过去六个月里，我们已经看到数学和编程基准测试的成绩突飞猛进，许多领域已被“解决”。

然而，这种训练目前仅限于可验证的任务。当AI与人类进行非可验证的对话，或思考人类独有的新颖想法时，其效果如何仍是未知。但未来，“无限可验证的沙盒”将成为AI智能涌现的下一个舞台。想象一下，AI在互联网上自由探索：登录网站、创建账户、点击按钮，甚至完成Tasker上的复杂任务，比如“获得数百个点赞”。它可能会失败无数次，但只要有一次成功获得一千个赞，这个可验证的成果就能驱动它不断迭代。同样，在机器人领域，从“把球放入桶中”到“建造一辆汽车”，无数可验证的任务将构成一个无限的学习游乐场。

最终，预训练的语言模型将被这种强化学习所“矮化”。一个多模态模型，能够看、读、写，拥有视觉和听觉，将在沙盒中无限地玩耍，自主学习数学、编程、网络导航，甚至操作机械臂。而真正的“啊哈”时刻，或许是当它学会利用网络，轻松获得数十万真实粉丝和互动，甚至创造一个成功的商业模式，成为一个年入千万的虚拟网红，或者创作出一首热门歌曲，并构建起整个推广基础设施。这些都是可验证的成果，银行账户的数字不会说谎。

即使是能力较弱的模型，也能从稀疏的奖励中学习。语言和token的巨大空间，使得即使是微弱的信号，也能成为强化学习攀登的阶梯。我们已经看到，即使是参数量仅10亿的模型，通过少量强化学习训练，也能显著提升其小学数学成绩。虽然构建这些验证领域极具挑战性，但这种学习范式无疑预示着AI能力的巨大飞跃。

当前，各大实验室正竞相推出各自的推理模型。DeepSeek的R1模型，在进行大规模强化学习推理训练后，还会进行推理密集型但标准的后训练技术，如通过拒绝采样进行指令微调，以及侧重数学的RLHF。一个关键问题是，这种推理训练的成果能多大程度地“迁移”到其他领域？模型是否会因此成为雄辩的作家或哲学家？研究仍在探索中。

对比OpenAI的o1/o3-mini和Google的Gemini Flash Thinking，我们看到不同的“风味”。Gemini Flash Thinking更便宜、性能更好，但其行为可能更“受限”，更专注于数学和代码。而o1则更灵活、更丰富，能够应对各种任务。这种“烹饪程度”的差异，体现了模型设计中的艺术。当我们将“人类本性”的问题抛给Gemini Flash Thinking时，它虽然能结构化地分析请求，并尝试从“自我驯化”等角度切入，但其推理过程有时显得有些偏离主题，甚至令人忍俊不禁，这恰恰说明了AI推理能力仍在快速演进中，其“个性”和“表达”方式也各不相同。

# Chapter 13: AI的深邃洞察：人类的自我驯化与计算成本的革命

在一个充满好奇的数字世界里，一场关于“新颖洞察”的探索悄然展开。当一个AI模型被要求分析一个请求，并从中提炼出“新颖”的关键词时，它展现出了令人惊叹的思考路径。它首先聚焦于“人类”这一概念，随后将其扩展至“有机体”，再深入到“顶级捕食者”的范畴。令人意想不到的是，它将“驯化”这一概念巧妙地应用于人类自身，进而提出了一个颠覆性的观点：人类并非仅仅是社会性动物，更是深刻的“自我驯化猿”。

这个洞察如同一道闪电，瞬间点亮了在场所有人的思维。它不仅结构清晰、逻辑严谨，更以其出人意料的深度令人拍案叫绝。人们惊叹于AI的推理过程，称之为“神奇”且“强大”，甚至有人认为“自我驯化猿”本身就是一个绝佳的书名。这个过程揭示了AI如何从看似不相关的概念中，抽丝剥茧，最终形成一个既独特又富有启发性的全新视角。

随后，Lex进行了一场别开生面的“模型大比拼”，他用同一个问题——“给出关于人类的一个真正新颖的洞察”——来测试DeepSeek-R1、Gemini Flash 2.0 Thinking、OpenAI o1 Pro和o3-mini。结果令人深思：

OpenAI o1 Pro表现卓越，它一次又一次地给出“精彩绝伦”的答案，其洞察力尖锐、措辞优美，充满了清晰与微妙，被Lex誉为“诗歌般的表达”。例如，它提出人类是唯一能将原材料转化为符号资源，再用这些符号重塑物质，形成意义与物质之间闭环的物种；或是人类能同时重写外部世界和内部精神图景，并将两者融合成客观真实的个人叙事。

DeepSeek-R1紧随其后，虽然不如o1 Pro稳定，但也贡献了令人惊艳的智慧。它认为人类通过集体假装抽象规则（如金钱、法律、权利）是真实的，从而将自私的欲望转化为合作系统。这些“共享的幻觉”如同游戏，将竞争巧妙地转化为有利于群体的力量，使冲突成为社会进步的燃料。更令人着迷的是，DeepSeek-R1展示了完整的“思维链”过程，其非线性的思考路径，如同詹姆斯·乔伊斯的《尤利西斯》般，展现了智能系统深邃的审慎之美。

Gemini Flash 2.0 Thinking位列第三，它也提出了“人类是自我驯化猿”的观点，并追溯了生命演化、顶级捕食者等历程，最终指向了人类通过“选择性驯化”实现自我演进的独特角度。

而OpenAI o3-mini则相对逊色，其答案往往显得“通用”而缺乏新意，尽管在其他头脑风暴任务中表现出色，但在这种开放式哲学问题上却未能达到预期。

这场模型间的较量，不仅展示了AI在生成新颖洞察方面的潜力，也引出了关于AI推理能力深层机制的讨论。专家们指出，像DeepSeek-R1和Gemini Flash 2.0 Thinking这类模型，在某些方面可能仍显“粗糙”，而OpenAI的o1 Pro和o3则通过在“思维链”之上叠加“搜索”技术，实现了能力的飞跃。所谓的“思维链”，是指模型能够像人类一样，一步步地分解问题并进行推理。而OpenAI的创新之处在于，它不再仅仅依赖单一的思维链，而是通过并行运行成千上万个“样本”（即同时启动多个思维链），然后从中选择最佳答案，这在解决像ARC-AGI挑战这类复杂任务时，将成功率从30%提升到了惊人的80-90%。

然而，这种复杂的计算方式是否经济可行？这引出了关于AI计算成本的深刻讨论。令人振奋的是，AI推理的成本正在以惊人的速度下降。短短两年内，GPT-3的推理成本从每百万token 60-70美元骤降至5美分，实现了1200倍的成本削减。这一趋势在GPT-4上同样显现，其成本已从最初的60美元降至2美元，并有望继续下探至几美分。这种成本的指数级下降，得益于架构创新、更优质的数据、更先进的训练技术、更高效的推理系统以及硬件（如GPU和ASIC）的不断进步。这意味着，未来“生成一千个不同的LLM来完成一个任务，然后从中挑选”的复杂搜索技术，将不再是遥不可及的奢望，而是“何时实现而非能否实现”的问题。

DeepSeek-R1的发布，因其“廉价”的特性，一度引发了市场恐慌，甚至导致英伟达股价下跌。市场担忧，如果AI模型能以更低的成本实现高性能，那么大型科技公司对昂贵AI硬件的需求可能会减少。然而，从长远来看，这种成本的持续下降，预示着AI智能将以前所未有的速度和规模渗透到经济的各个角落，解锁更深层次的智能应用。

# Chapter 14: AI算力狂飙：英伟达股价迷雾与芯片走私风云

曾几何时，人们普遍认为，人工智能的真正智能将随着计算成本的不断降低而逐步解锁。然而，当DeepSeek-R1模型横空出世，以其惊人的效率震撼业界时，市场却上演了一出令人费解的戏码：英伟达的股价不跌反跌，让无数观察者大跌眼镜。

最初的解读似乎很简单：如果DeepSeek能以更低的成本训练出如此优秀的模型，那么大型科技公司对AI硬件的投入需求可能会减少，从而影响英伟达的销售。但事实远比这复杂。这其中夹杂着周末交易的社会情绪蔓延，以及对AI模型训练成本的普遍误解。人们常以为训练一个顶级模型需要数十亿美元，但实际上，像GPT-4这样的公开模型，其训练成本不过数亿美元。而DeepSeek宣称的数百万美元成本，更是没有计入研发人员薪资、推理成本和后期训练等巨额开销，这些才是OpenAI等公司“数十亿”投入的真正构成。

更具讽刺意味的是，就在不久前，业界还在争论“缩放法则”是否已走到尽头，认为模型性能提升已趋缓。结果，DeepSeek-R1和OpenAI的o1等新模型迅速打破了这一论调，证明AI的进步速度远超预期。这种进步的狂飙突进，反而引发了另一种担忧：模型发展太快，是否会减少对GPU的需求？

然而，经济学中的“杰文斯悖论”在此刻得到了最生动的体现。效率的提升非但没有减少资源消耗，反而刺激了更大的需求。过去几周，AWS上H100 GPU的价格不降反升，而拥有更大内存的H200 GPU更是供不应求，因为DeepSeek-R1这样的高效模型对内存的需求更高。甚至连仅仅想为演示租用16到32块H100 GPU，都变得异常困难。与摩尔定律每两年性能翻倍的稳健增长相比，AI算力在短短三年内实现了1200倍的飞跃，这种惊人的速度让所有人难以置信。

英伟达本应是这场算力狂潮的最大赢家，因为目前还没有真正的竞争对手能像它一样可靠地提供全套解决方案。DeepSeek本身就是英伟达的大客户，甚至曾自豪地宣称是中国最大的英伟达客户。那么，股价下跌的真正原因，或许与地缘政治的暗流涌动有关——对中国芯片走私的担忧。

美国对华芯片出口的限制，催生了一个庞大的地下市场。字节跳动被认为是最大的“走私者”之一，通过在全球范围内租赁甲骨文、谷歌以及众多小型云服务商的GPU，积累了超过50万块GPU，用于支持TikTok等业务。尽管这些租赁在最新的“扩散规则”出台前是合法的，但新规则明确限制了中国公司可购买或租赁的GPU数量和集群规模。除了这种大规模的“合法走私”，还有小规模的个人行为：有人会购买价值数十万美元的GPU服务器，搭乘头等舱飞往中国，以高价转售，轻松赚取机票和巨额利润。更隐蔽的是，新加坡、马来西亚等地的公司通过复杂的网络，将GPU绕道运往中国，甚至华为也曾建立庞大的公司网络来规避禁令。

尽管如此，走私的规模终究有限。去年，英伟达合法向中国出货了100万块H20 GPU，另有约20万至30万块GPU通过各种渠道流入中国。但随着AI模型训练成本飙升至数十亿甚至百亿美元级别，中国在算力上的劣势将日益明显。DeepSeek-R1虽然高效，却因缺乏足够的GPU而无法提供稳定的服务，其在应用商店的下载量已开始下滑，用户体验也因每秒不足5个token的生成速度而大打折扣。在未来，GPU的价值甚至可能超越毒品和武器，成为全球最高价值的走私品。

除了硬件的争夺，模型训练的伦理与法律边界也引发了激烈讨论。中国公司可以轻易访问美国的模型API，而OpenAI就曾公开指责DeepSeek利用其API进行模型蒸馏——即用OpenAI模型的输出来训练自己的模型。蒸馏在业界是常见做法，但OpenAI的服务条款明确禁止利用其输出构建竞争产品。这引发了道德困境：OpenAI自己未经许可训练了互联网上的文本，为何他人不能训练其模型的输出？此外，通过将模型输出上传到公共平台，再由第三方训练，可以轻易规避服务条款的限制。许多模型甚至会错误地自称是“ChatGPT”，因为互联网上充斥着OpenAI的输出。尽管通过系统提示可以纠正这种自我识别，但DeepSeek可能并不在意，因为其目标是发布模型权重，而非提供直接服务。

# Chapter 15: 模型归属之争与算力巨兽的崛起

在AI世界的风云变幻中，模型的归属与训练数据的来源，始终是各方争论的焦点。有人认为，一旦模型权重被上传，其原始归属便不再重要。毕竟，任何在应用中部署模型的人，都会根据特定任务对其进行微调，届时它是否自称“ChatGPT”已无关紧要，一个简单的系统提示就能改变其“身份”。例如，艾伦人工智能研究所就将其托管的演示模型设定为“Tulu 3”，并坦承受益于OpenAI的数据，将其视为宝贵的研究工具。

然而，OpenAI对中国DeepSeek模型涉嫌使用其数据进行训练的指控，却掀起了不小的波澜。对此，业界普遍认为，互联网上的数据本就是共享资源，包括那些被用户精心挑选并分享的ChatGPT优质输出，都已融入了各家模型的预训练数据中。这更像是一场“叙事控制”的策略，旨在保护自身。毕竟，早年字节跳动曾因类似行为被OpenAI的API禁用，但也有其他AI初创公司公开承认利用OpenAI的输出进行模型引导，却未受惩罚，这无疑是快速启动模型、避免耗时耗力构建人类数据管道的捷径。

更有趣的是，DeepSeek模型虽然强大，但其混合专家（MoE）架构和高达6000亿参数的规模，使得推理运行异常复杂。于是，一场“曲线救国”的行动悄然展开：许多开发者将DeepSeek模型蒸馏（distill）到Llama模型中。Llama作为开放标准，拥有成熟的部署管道和工具，使得这些强大的能力得以在更易用的平台上普及。这种“借壳上市”的行为，其合法性与伦理边界引发了讨论。虽然可能触犯合同，但似乎不太可能导致刑事责任。多数人认为，允许在互联网数据上进行训练是符合伦理的，否则整个AI领域都将停滞不前。

关于版权问题，日本提供了一个独特的解决方案：允许模型训练使用任何数据，且不受版权限制。结合日本丰富的核电资源和自由进口GPU的政策，这为建立大规模数据中心、合法训练模型提供了沃土，从而避免了与《纽约时报》等机构的版权纠纷。虽然早期版权诉讼多倾向于AI训练方，但对于特定风格的音乐或图像生成，未来或许会出现类似YouTube创作者分成计划的解决方案，让创作者也能从中获益。

除了数据与版权的争议，工业间谍活动和思想窃取在AI领域也屡见不鲜。虽然窃取代码和数据难度较大，但思想的流动却轻而易举。硅谷的运作模式便是如此：顶尖人才带着新想法跳槽，非竞争协议在加州形同虚设。例如，一位曾参与Gemini百万上下文长度模型开发的工程师转投Meta，业界便普遍猜测下一代Llama模型也将拥有此能力。从历史上的国家间谍活动，到公司内部的人才流动，甚至传说中的“美人计”（honeypot），都加速了AI思想的传播。毕竟，AI领域的大多数工程师都是年轻单身男性，他们坦言“很容易被腐蚀”。

然而，所有这些争议和策略的背后，是AI算力基础设施建设的空前狂潮。美国数据中心的电力消耗占比正从2-3%飙升，预计到本世纪末将达到10%，而AI专家们甚至认为这还远远不够。传统的分布式数据中心任务已让位于推理和训练两大核心。推理任务需要数百万块GPU分散部署，而训练任务则催生了前所未有的巨型集群。

回溯历史，AlexNet仅用两三块GPU就已是壮举；GPT-4则动用了2万块A100 GPU，耗资数亿美元，功耗高达15-20兆瓦。如今，H100 GPU单块功耗已达700瓦，加上服务器整体功耗可达1200-1400瓦。OpenAI和微软在亚利桑那州部署了10万块GPU，Meta为训练Llama 4更是投入了10万至12.8万块GPU，总功耗高达140-150兆瓦。

而埃隆·马斯克（Elon Musk）的xAI公司，虽然入局较晚，却以惊人的速度在孟菲斯的一家旧工厂里，建成了全球最大的20万块GPU集群。他不仅升级了变电站，还部署了移动发电装置、利用天然气发电，并配备了特斯拉Megapack电池和工业级水冷系统。这仅仅是开始，OpenAI的“星门”项目更是规划了高达2.2吉瓦的电力消耗，其中1.8吉瓦将直接供给芯片——这比大多数城市的用电量还要庞大！Meta、亚马逊、谷歌等巨头也纷纷效仿，规划着多吉瓦级的超级数据中心。

这场算力军备竞赛的逻辑很简单：投入更多算力，就能获得更强大的AI性能。无论是持续的模型预训练，还是在“强化学习沙盒”中进行计算机使用、自我对弈等后训练，这些巨型集群都将为AI提供无限的学习和优化空间，推动其能力不断突破上限。

# Chapter 16: 算力狂潮：AI巨头的数据中心军备竞赛

在AI模型训练与部署的宏大舞台上，一场前所未有的算力军备竞赛正以惊人的速度展开。亚马逊、谷歌、xAI等科技巨头纷纷投入巨资，规划并建设着多吉瓦级的超大型数据中心。他们深信，持续的预训练规模扩展，以及更关键的，后训练阶段（如强化学习沙盒、计算机自主使用、自我博弈等可验证领域）的无限学习，将使AI的能力实现质的飞跃。正如那句格言所说：投入更多算力，性能就会提升，尽管回报可能递减，但效率的不断提升正在“弯曲”这条曲线，让AI的进步永无止境。

然而，这场算力狂潮也带来了巨大的挑战。这些巨型数据中心对电力的需求达到了令人咋舌的程度，给现有的电网带来了沉重负担。亚马逊甚至试图收购核电站Talen，其股价因此飙升，预示着一场能源争夺战的到来。在美国某些地区，例如弗吉尼亚州，输电成本甚至超过了发电成本，这凸显了电网建设速度远跟不上电力需求增长的窘境。尽管政府出台了行政命令以简化审批流程，但能否足够快地建设出足够的电力设施，仍是一个巨大的问号。

面对如此庞大的电力需求，核电站因其稳定的供电特性被认为是理想的长期解决方案，但其建设周期过长。因此，许多公司不得不转向更快速、更灵活的天然气发电。令人惊讶的是，电力成本在整个AI集群的投入中占比不足20%，大部分开销仍是GPU的资本投入和折旧。这使得企业更倾向于直接建设天然气发电厂，例如Meta在路易斯安那州、OpenAI在德克萨斯州的做法。埃隆·马斯克在孟菲斯的xAI数据中心更是将这种策略推向极致，不仅使用高效的联合循环燃气，甚至动用了效率较低的单循环和移动发电机。尽管一些公司尝试通过叠加太阳能、风能、电池储能和少量燃气来实现更“绿色”的运营，但这些方案的建设周期同样缓慢。

在追求极致算力的过程中，许多公司不得不暂时搁置其可持续发展承诺。Meta和微软等巨头在某些方面放弃了原有的环保目标，或者通过购买“电力采购协议”（PPA）来“假装”使用了绿色能源。埃隆·马斯克在孟菲斯的做法虽然在环保上有所争议，但考虑到其整体对世界的积极影响，以及AI可能最终解决全球变暖的乐观预期，这种“先发展再解决”的态度在AI实验室中颇为流行，因为“输掉这场竞赛的代价远比环境成本更高”。

Lex Fridman有幸参观了xAI在孟菲斯的数据中心，对其“令人难以置信”的创新速度赞叹不已。在那里，团队正以惊人的效率解决各种瓶颈，从低层软件硬件到网络（如Nvidia Spectrum-X以太网），再到至关重要的冷却和电力系统，一切都必须完美协同。一个生动的例子是，在模型训练过程中，GPU在计算和权重同步之间切换时，会产生剧烈的电力波动，可能导致电网不稳定甚至设备损坏。Meta为此甚至在PyTorch中添加了一个名为`pytorch.powerplantnoblowup`的特殊操作符，让GPU在权重交换期间计算“假数据”，以平滑电力曲线，防止电厂“爆炸”。埃隆·马斯克则选择部署特斯拉Megapacks等储能设备来稳定电力供应。

冷却技术也迎来了革新。传统的风冷已不足以应对新一代GPU的巨大热量，液冷正成为主流。谷歌的TPU早已采用水冷，而埃隆·马斯克更是率先在当前一代GPU上大规模部署了水冷系统，孟菲斯设施外90个巨大的集装箱式水冷机组便是明证。下一代英伟达GPU甚至将强制要求水冷。液冷不仅能高效散热，还能让芯片排列更紧密，从而实现更高速度的互联。

这场“集群规模竞赛”愈演愈烈。目前，埃隆·马斯克在孟菲斯的集群以20万块H100 GPU位居榜首，而Meta、OpenAI和亚马逊也拥有约10万块GPU的集群。虽然其他公司可能拥有更多分散的GPU，但为了训练效率，它们必须紧密连接。未来一年，Anthropic和亚马逊正建设40万块Trainium 2芯片的集群，Meta和OpenAI也规划了数十万块GPU的规模，预计到明年，50万至70万块GPU的超大型集群将成为常态。更令人担忧的是，新一代GPU的功耗也在飙升，例如英伟达Blackwell芯片的功耗将从Hopper的700瓦增至1200瓦，芯片数量和单芯片功耗的双重增长，无疑将进一步加剧能源挑战。对于埃隆·马斯克提出的“百万GPU”目标，没有人敢怀疑其可行性，因为他的电力规划和电池部署方案显示出其雄心勃勃的计划。

这些巨型集群并非用于推理，而是专为训练而生，因为训练需要GPU的高度协同和高速互联。虽然预训练的规模仍在继续，但随着互联网数据量的饱和，未来的算力将更多地投入到“后训练”阶段。在这个阶段，模型将通过自我博弈、在沙盒中进行计算机操作、甚至模拟机器人行为等方式，在无限可验证的环境中持续学习和进化。这些“后训练”任务将消耗海量的计算资源，以至于“后训练”这个词可能最终会被“训练”所取代，成为AI模型实现通用智能（AGI）的关键路径。随着模型上下文长度的增加，以及强化学习等技术对计算效率的挑战，FLOPS（每秒浮点运算次数）作为衡量指标的有效性也可能受到影响。

除了英伟达，谷歌的TPU也是一股不可忽视的力量。谷歌虽然在建设数据中心方面更为谨慎，但其拥有最大的整体集群，通过将TPU分散在相距数十英里的“超级区域”内，实现了多数据中心训练。谷歌的数据中心设计独特，芯片被安置在巨大的矩形箱体中，并辅以大型水管和冷却塔，展现了其在硬件和基础设施方面的独特创新。

# Chapter 17: 谷歌的算力帝国：TPU与隐秘的内部优势

故事从一个关于算力核心的疑问开始：除了GPU，还有TPU。在爱荷华州和内布拉斯加州，谷歌的四个数据中心紧密相连，形成了一个庞大的计算集群。这不禁让人好奇，为何谷歌不炫耀其集群规模？答案在于其独特的多数据中心训练策略。

谷歌的数据中心设计与众不同。走进其中，首先映入眼帘的是巨大的矩形盒子，它们是芯片的“家园”。然而，更引人注目的是那些蜿蜒的水管和顶部的冷却塔，以及一排排柴油发电机作为备用电源。令人惊讶的是，实际存放芯片的区域，其物理尺寸竟然小于冷却系统。这揭示了一个核心挑战：芯片本身可以紧密堆叠，但为它们提供水冷散热却异常困难。谷歌凭借其在TPU领域积累的先进基础设施，在多个区域“批量复制”了这些数据中心，并通过超高带宽的光纤将它们紧密连接起来，例如在俄亥俄州也有类似的复合体。

尽管谷歌拥有庞大的分布式集群，但埃隆·马斯克却坚持认为，xAI将拥有最大的“完全互联”集群，因为它全部集中在一栋建筑内。从这个角度看，马斯克是对的。谷歌的集群规模虽大，却分散在多个站点。

那么，谷歌为何不与英伟达竞争，对外销售TPU呢？原因有几点。首先，TPU一直是谷歌内部的“金鹅”，支撑着搜索业务的低成本运行，以及Gemini、YouTube、广告等内部工作负载。谷歌的TPU架构高度优化，以满足其内部需求，例如Gemma模型为了充分利用TPU巨大的矩阵乘法单元，不惜将词汇量设计得异常庞大（尽管模型被称为7B，实际参数却有80亿），即使这对于一个小模型来说并不合理。这导致Gemma在GPU上运行效率不如Llama，反之亦然。

其次，谷歌的软件栈，如JAX和XLA，虽然在内部为研究人员提供了“无需了解硬件”的便捷体验，但这些高度优化的软件并未对外公开。许多离开谷歌的顶尖研究人员，在外部尝试实现他们的宏伟构想时，往往会因为缺乏这样的基础设施和软件支持而举步维艰，甚至选择回归谷歌。

再者，谷歌的组织架构也存在挑战。其“金鹅”——搜索业务每年带来数千亿美元的收入，相比之下，即使TPU的销售额能达到数百亿美元，也显得微不足道。而且，谷歌云、TPU团队、DeepMind和搜索团队之间存在着复杂的官僚体系，各自的目标和客户群体不同，这使得将TPU作为外部产品销售变得困难重重。

在云服务市场，亚马逊AWS凭借先发优势、易用性、成本效益以及对大小客户的兼顾，稳居榜首，其利润甚至占据了亚马逊总利润的80%以上。微软Azure位居第二，而谷歌云则排名第三。AWS在硅片工程方面的优势，使其在传统云服务（存储、CPU、网络、数据库）上拥有更低的成本结构。

与谷歌的内部导向形成鲜明对比的是英伟达。英伟达的整个企业文化，正如《英伟达之道》一书所描述的，都是自下而上地为外部客户服务。他们前瞻性地布局CUDA软件库，确保高性能计算的新应用能够迅速在英伟达芯片上发展。

然而，英伟达的霸主地位是否能被挑战？AMD的硬件在某些方面甚至优于英伟达，但其软件生态却远远落后，且长期以来对外部客户的投入不足。英特尔则陷入了困境，其在PC和服务器市场的份额被苹果M系列芯片、英伟达、高通等蚕食，更在AI芯片领域鲜有建树，同时在制程技术上落后于台积电。全球能进行尖端研发的芯片公司仅剩台积电、三星和英特尔三家，其中三星和英特尔都面临严峻挑战，这使得全球半导体产业对台积电的依赖日益加剧，带来了地缘政治上的不确定性。

谈及AI竞赛的赢家，目前看来，OpenAI凭借其卓越的模型和AI收入领先，但其高昂的研发成本意味着尚未实现真正的会计利润。微软通过AI实现了账面盈利，但资本支出巨大。Meta则主要通过推荐系统等AI应用获利，而非Llama。真正赚得盆满钵满的，是英伟达等硬件供应商。超大规模云服务商虽然账面盈利，但巨额的GPU采购投入，其未来回报仍充满不确定性。

尽管如此，投资AI的逻辑依然清晰：如果能让智能变得廉价，就能带来巨大的经济增长。这场竞赛并非“赢家通吃”，而是“多赢”局面。许多公司将从AI中受益，并非因为它们训练出最好的模型，而是因为AI能极大地提升其现有产品的智能和效率，例如Meta的推荐系统，以及埃隆·马斯克对Optimus机器人的愿景。AI将以“快速增长的功能集”持续演进，为各行各业带来变革。

# Chapter 18: AI浪潮下的生存法则：巨头、新秀与智能代理的未来

在AI技术如潮水般汹涌而来的时代，一个核心问题浮出水面：究竟谁能在这场变革中真正受益？对话者们深入探讨，指出AI并非仅仅关乎训练出最强大的模型，更在于它如何作为“快速增长的功能集”，赋能并提升现有产品与服务。

对于谷歌、xAI和特斯拉这样的巨头而言，AI的价值在于直接提升其核心产品的“智能”。埃隆·马斯克对Optimus机器人和未来家庭个性化机器人的愿景，描绘了一个高达10万亿美元的巨大市场——尽管这听起来有些遥远，但其潜力令人浮想联翩。而Meta则展现了另一种受益模式：通过AI增强其推荐系统，提升用户在其平台上的参与度和每小时收益，从而间接实现盈利。

然而，对于像OpenAI这样的纯模型公司，其处境则显得更为微妙。目前，OpenAI的品牌价值几乎完全依赖于ChatGPT。但随着模型成本的急剧下降（例如Llama 3B比GPT-3便宜1200倍，DeepSeek-V3的出现），以及模型能力的日益商品化，仅仅依靠聊天应用来盈利的空间正变得越来越小。对话者们指出，ChatGPT的未来可能走向广告支持的免费模式，就像Meta和谷歌那样，而这对于OpenAI来说，意味着必须超越简单的API和聊天界面，深入到推理、代码生成、智能代理和计算机使用等更复杂的应用领域，否则将面临巨大的生存挑战。

模型的快速进步也带来了“商品化”的趋势。那些将商业模式建立在当前一代模型能力之上的公司，很快就会发现自己被更便宜、更高效的替代品所淘汰。真正的赢家，将是那些能够驾驭模型进步浪潮的“包装器”和应用开发者。

一个尚未被充分挖掘的巨大商机，在于如何将高质量的广告巧妙地融入到大型语言模型的输出中。这就像当年谷歌的AdSense创新一样，如果能找到一种既不突兀又不失效用的方式，在AI的对话或生成内容中植入广告，其潜在的营收将是惊人的。目前，Perplexity、谷歌和Meta等公司可能正在积极探索这一领域，而OpenAI和Anthropic则更专注于AGI（通用人工智能）和智能代理的研发。

这种对AGI的“激光聚焦”，源于这些实验室对AGI实现时间线的判断——他们认为AGI可能在2-3年内到来，而非5-10年。这种紧迫感，驱动着他们投入巨额资金进行研发，以期在下一代AI能力上保持领先。

谈到下一代AI能力，智能代理（AI Agents）无疑是焦点。尽管“代理”一词常被过度炒作，甚至被用来形容Apple Intelligence这类简单的应用间协调工具，但真正的智能代理意味着能够独立、开放式地解决任务，并适应不确定性。OpenAI将AI能力划分为聊天（第一级）、推理（第二级，我们目前所处阶段）和代理（第三级）。从聊天到推理，我们用了几年时间；推理阶段可能持续一两年，然后才是代理。

然而，实现真正的智能代理面临着巨大的挑战。其中最核心的是“九个九”问题，即可靠性问题。就像半导体制造或自动驾驶一样，即使每一步的成功率都高达99.99999%，但当这些步骤被串联起来执行复杂任务时，整体的成功率会急剧下降，甚至趋近于零。人类世界的复杂性、开放性以及混乱的网站界面（比如预订机票的繁琐过程），都使得AI代理难以在没有大量人工干预的情况下可靠运行。

尽管如此，对话者们对智能代理的未来仍持乐观态度。他们认为，通过构建特定的基础设施（如Waymo的人工远程操作员），或者将问题限定在狭窄的领域（例如，能够处理特定网站或家庭自动化任务的代理），AI代理将能够实现巨大的生产力提升和成本削减。与DoorDash、OpenTable等网站的合作，将使代理在特定领域迅速提升能力。甚至有航空公司可能会为了AI代理优化其网站，从而获得竞争优势。

研究人员已经在“沙盒”环境中模拟了流行的网站，用于训练这些代理。历史经验表明，通过指令微调和逐步增加训练任务，语言模型最终能够实现跨任务的泛化。我们正处于一个关键的转折点，或许在不久的将来，AI代理也能跨越“泛化障碍”，在更多领域实现自主运作，从而带来商业模式的全面革新。

# Chapter 19: AI浪潮下的软件工程与开源新篇章

在AI的宏大叙事中，我们正经历着一场深刻的变革，它将AI从单一任务的执行者，推向了能够处理海量任务的通用智能。这就像自然语言处理（NLP）领域曾经的“指令微调”革命，从前一个语言模型只能做一件事，而现在，通过不断增加任务，模型突然间就能泛化到所有任务，仿佛触及了某个神奇的“临界点”。我们尚不清楚在推理和可验证领域，AI何时能达到这个“点”，但一旦跨越，其能力将如潮水般涌向各个角落。

谈及AI与软件工程的结合，这无疑是当前AI创造收入和提升生产力最显著的领域。尽管CS学生中弥漫着一丝焦虑，但Copilot、Cursor乃至ChatGPT等工具，已成为程序员的得力助手。许多开发者甚至愿意支付高昂的订阅费，只为享受AI带来的便利。斯坦福大学学生开发的SWE-bench基准测试，虽然难度适中，却见证了AI模型在一年内从4%的完成率飙升至60%的惊人进步。虽然要达到“九个九”的完美可靠性仍是巨大挑战，但AI在软件工程领域的进步速度令人咋舌，未来必将需要更高级的基准来衡量其能力。

软件工程代理的崛起，被认为是所有AI代理中最快实现突破的领域。原因在于其“可验证性”——代码可以通过单元测试和编译进行验证。AI能够瞬间审视整个代码库，这是任何单个工程师都难以企及的，只有经验丰富的架构师才能做到。这意味着软件工程的成本将大幅下降，从而催生出截然不同的市场格局。例如，在中国，由于软件工程师成本较低，企业更倾向于自建系统而非依赖Salesforce等平台SaaS。当AI让定制化开发变得极其廉价和迅速时，所有公司都能轻松构建和迭代自己的业务逻辑，摆脱平台SaaS的束缚，实现更高的效率。

除了软件工程，AI的价值还将渗透到那些“老旧”的领域。工业、化工、机械工程师们普遍不擅长编程，他们的工具往往停留在20年前，甚至像ASML光刻机这样的尖端设备，其分析工具仍在Windows XP上运行，大量数据分析依赖Excel。AI的到来，能将前沿的软件工程技能带给这些领域的专家，帮助他们实现跨越式发展。甚至在政府和法律系统等领域，AI也能通过软件现代化、数据组织等方式，打破传统壁垒，最终造福人类。

当然，AI的普及并非一蹴而就的“悬崖式”变革，而更像是一条逐渐平缓的曲线。就像Meta添加“故事”功能后，Snapchat的增长曲线趋于平缓一样，AI的到来将改变软件工程师的工作性质，而非让他们瞬间失业。未来的程序员将更多地扮演“AI系统主管”的角色，负责纠正代码、调试、引导系统，并注入人类独有的“品味”和偏好。人类擅长判断优劣，这正是强化学习与人类反馈（RLHF）的核心。因此，程序员需要提升专业技能，学会管理日益智能的系统，并成为某个领域的专家，利用AI的浪潮提升自身价值。

在开源领域，我们见证了“Tulu”项目的诞生。这个名字源于骆驼杂交品种，象征着在ChatGPT之后，开源模型如Alpaca、Vicuna等如雨后春笋般涌现的时代。Tulu项目致力于推动开源代码的后训练前沿，基于Llama等开放权重模型，提供完全开放的代码和数据。尽管Chatbot Arena排行榜上鲜有真正开放代码和数据的模型，Tulu团队通过RLVR（可验证奖励强化学习）等技术，在数学基准测试（MATH）上取得了显著进展，甚至超越了Llama的官方指令模型和DeepSeek-V3，证明了即使是计算资源有限的实验室，也能在开放领域取得突破。

然而，真正的开源不仅仅是开放权重，更在于许可证的友好性。Meta的Llama模型虽然开放权重，但其许可证对商业用途和下游使用存在限制，甚至要求使用“Llama”品牌，这在严格的开源定义下并不算真正的开源。而DeepSeek-R1的出现，则被视为一个“重大转折点”。它提供了真正开放权重且商业友好的许可证，没有任何下游使用限制，允许开发者自由地进行合成数据、蒸馏等操作，甚至可以“克隆”并重新命名。这无疑为开源AI运动注入了新的活力，预示着一个更加开放、创新和竞争的AI未来。

# Chapter 20: 开放AI的理想与算力竞赛的现实

对话伊始，关于AI模型许可证的讨论便火花四射。Llama模型，尽管被广泛使用，其许可证却并非真正的开源。它要求任何基于Llama模型开发的产品都必须冠以“Llama”之名，这对于追求品牌独立性的公司而言，无疑是营销上的巨大障碍。研究人员或许能勉强接受，但商业世界则不然。

正因如此，对真正开放模型的呼唤变得尤为迫切。DeepSeek-R1和OLMO项目被视为希望的曙光，它们致力于提供商业友好且无限制的开源许可证。当被问及是否可以像使用中国模型一样，自由地复制和修改Llama而不受品牌限制时，得到的肯定回答让在场者不禁发出“太棒了！”的欢呼，这正是真正开源的魅力所在。

然而，推动开源AI并非易事。与开源软件不同，开源AI缺乏有效的反馈循环。训练模型需要巨额算力投入和专业知识，这使得普通开发者难以在此基础上进行改进。因此，开源AI在很大程度上仍是一项充满理想主义色彩的使命，正如马克·扎克伯格所言，美国需要它。为了将这种理想转化为实际的经济价值，生态系统需要围绕“查看语言模型数据能带来什么好处”来构建。尽管展示OLMO模型的预训练数据存在法律风险和技术复杂性（数据量庞大，难以解析），但这正是推动开源AI走向财务实用性的关键一步。

随后，话题转向了备受瞩目的“星门计划”（Stargate）。这个由OpenAI、Oracle和特朗普政府共同推动的AI基础设施项目，最初宣称的5000亿美元投资令人咋舌，随后又修正为1000亿美元。然而，这1000亿美元并非实际投资，而是第一阶段（位于德克萨斯州阿比林的2.2吉瓦数据中心）的“总拥有成本”。

实际上，Oracle早已开始建设该项目的第一部分，耗资约50-60亿美元用于服务器，另有10亿美元用于数据中心。埃隆·马斯克曾试图租用，但嫌其进度太慢。最终，OpenAI通过与Oracle的“星门”合资企业获得了使用权。如果将整个1.8吉瓦的电力容量全部填满，并使用英伟达未来两代芯片（GB200、GB300、VR200），服务器成本将高达约500亿美元，加上运营、电力、维护和租赁等费用，总拥有成本便达到了1000亿美元。

然而，这笔巨款的来源却充满不确定性。OpenAI承诺投入190亿美元，但其现有资金远不足此数。有消息称软银可能通过出售其在Arm的股份，向OpenAI投资250亿美元，这或许能解决OpenAI的资金缺口。Oracle财力雄厚，已承担了第一部分的建设，并可能投入更多。此外，阿联酋的MGX基金也拥有1.5万亿美元的AI投资资金，但其参与程度尚不明朗。目前，只有首批10万个GB200集群的资金相对确定，其余部分仍悬而未决。尽管如此，对话者仍坚信，只要OpenAI能持续推出更优秀的模型，资金终将到位。

特朗普政府在此项目中扮演了关键角色。他通过行政命令大幅简化了联邦土地上数据中心和电力设施的建设审批流程，甚至允许先建设后备案。德克萨斯州独特的非管制电网也为快速建设提供了便利。虽然美国政府没有直接投入资金，但特朗普通过减少监管、营造“建设时代”的氛围，极大地推动了AI基础设施的快速发展，甚至可能进一步加速这场“算力军备竞赛”。

展望未来两到四年，AI领域的发展令人激动。供应链、成本、产能建设和战略合作的追踪本身就充满乐趣。技术层面，网络互联的突破尤其引人注目，光电集成、新型交换技术以及多数据中心训练中光纤和带宽的巨大进步，让沉寂已久的电信行业再次焕发活力。

然而，将所有计算资源整合为“一台计算机”的愿景，在技术上几乎不可能实现。计算的复杂性只会增加，而非减少。从芯片内部的寄存器、缓存，到HBM/DRAM内存，再到跨芯片、跨数据中心的内存池和存储，访问延迟层层递增。这意味着编程范式将始终保持多样化和复杂性。尽管AI或许能辅助编程，但要实现线性性能扩展（即芯片数量翻倍，性能也翻倍）仍面临巨大挑战。不过，通过更紧密的芯片互联、创新的编程模型和算法（如DeepSeek的并行化技术），人们正努力提高效率。

从光刻、蚀刻、制造，到光学、网络、电力、变压器、冷却，乃至数据中心的空调和铜缆，计算堆栈的每一个层面都在以前所未有的速度创新。人类的进步正以前所未有的速度向前推进。

对于未来的展望，除了技术突破，更重要的是对AI发展方向的掌控。有人不信任那些声称“相信我们，我们会让AI变得更好”的封闭式承诺。他们认为，如果AI将成为我们时代最强大的技术，那么就应该让更多人参与其中，理解它，并拥有发言权。开放性，正是实现这一目标的关键。

# Chapter 21: 开放、智能与人类的未来

在AI浪潮席卷全球的当下，对话者们深切地表达了对AI未来走向的期盼。他们认为，AI作为我们时代最强大的技术，绝不能仅仅掌握在少数人手中。一个更理想的未来，应该是让更多人能够参与进来，理解AI的本质，并对其发展方向拥有发言权。这不仅仅是为了“好玩”——训练模型、吸引人才固然有趣，但更重要的是，开放性是确保AI技术能够尽可能成功、尽可能普惠的关键。正如Nathan所强调的，更开放的AI生态系统，能让来自非AI领域的研究者、政府乃至普通民众，都能更好地理解AI的运作机制和潜在影响。

谈及AI的魅力，对话者们眼中闪烁着光芒。他们描述了AI在推理过程中展现出的“顿悟时刻”和“魔法”，那种链式思考的逻辑之美，仿佛一面镜子，映照出人类自身的智慧，让我们得以重新审视并理解人类智能的独特之处，尤其是我们目前所拥有的意识。这种探索人类与AI之间奥秘的体验，远超当年“深蓝”战胜卡斯帕罗夫所带来的震撼。回想起早期AI的稚嫩——比如一个笨拙地学习飞行的四旋翼无人机，只会撞到天花板然后停下——与如今AI仅凭自然语言就能生成复杂控制算法的飞跃式进步相比，简直是天壤之别。尽管在物理世界中与机器人交互仍面临挑战，但AI的进化速度令人惊叹。

展望人类文明的未来，对话者们充满希望。他们坚信，人类在千年之后仍将存在，因为我们拥有强大的生存能力，总能在危机迫近时找到解决之道。对于AI失控并毁灭人类的担忧，他们认为物理限制和人类的适应性会阻止这种情况发生。然而，真正的隐忧并非AI本身，而是“技术法西斯主义”的崛起。随着AI力量的日益强大，那些掌握它的人将拥有前所未有的权力。未来，掌握权力的人可能会寻求通过脑机接口与AGI融合，从而极大地增强自身能力，形成一个由少数精英（可能是数百、数千甚至数百万人）统治其余人口和经济的局面。这种人机融合体，虽然能放大个体的积极影响力，但也同样能放大其负面破坏力。尽管AI的普遍应用将主要出于逐利动机，从而增加物质丰裕度，减少人类苦难，但这种潜在的权力集中和不平等，才是更值得警惕的未来挑战。当然，在一番严肃的讨论后，他们也幽默地设想了一个“积极”的未来：人们插着食物管，沉浸在多巴胺的海洋中，快乐地刷着时间线，而人类文明则同时向宇宙深处拓展。这是一个充满奇迹与挑战的时代，他们感谢彼此为推动人类可能性边界所做的努力，并以费曼的名言作结：“对于一项成功的技术，现实必须优先于公共关系，因为自然是无法被愚弄的。”

