# Chapter 1: 探索智慧的本质：杰夫·霍金斯的千脑理论

播客以介绍杰夫·霍金斯拉开序幕，这位著名的神经科学家毕生致力于揭示人脑智能的结构、功能与起源。他曾著有开创性的《论智能》一书，而最近又推出了一部名为《千脑智能》的新作，书中提出了一种颠覆性的智能理论，甚至连理查德·道金斯都对其赞不绝口，称其“卓越非凡，令人振奋”。主持人莱克斯·弗里德曼（Lex Friedman）幽默地表示，每当他听到这两个词，脑海中总会浮现道金斯那独特的英式口音。

在正式对话开始前，莱克斯分享了霍金斯新书中的一个深刻思想：如果人类文明不幸走向毁灭，我们所有的知识和创造也将随之消逝。霍金斯提议，我们应该思考如何以一种能超越我们自身存在的方式来保存这些知识，无论是在地球上、地球轨道上，还是深邃的宇宙空间中。更进一步，我们应该向其他智慧外星文明发送广告信息，告知他们这份人类知识的备份。而这条广告的核心信息并非“我们在这里”，而是“我们曾在这里”。

这个微小的差异，却让莱克斯感到深深的谦卑。他思考着人类文明自我毁灭的可能性，以及数千年甚至数百万年后，一个外星文明偶然发现这份知识库的渺茫几率，更不用说他们能否理解。这引发了他更深层次的疑问：在人类所有的知识中，究竟哪些才是真正本质的？维基百科能涵盖吗？还是远远不够？这个思想实验迫使他反思，我们所取得的成就和渴望实现的愿望中，哪些能够超越我们的生命？是复杂的建筑、桥梁、汽车、火箭吗？是科学、物理、数学等思想吗？是音乐和艺术吗？是计算机、计算系统，甚至是人工智能系统吗？莱克斯个人认为，外星文明很可能已经拥有了这些，甚至更多、更好。对他而言，人类可能独一无二的，或许只有意识本身，以及痛苦、幸福、憎恨、爱等真实的、主观的体验。他认为，如果我们能直接从人脑中以最高分辨率记录下这些体验，让外星人能够重现它们，那才是我们应该储存并发送的信息——不是维基百科，而是意识体验的极致，其中最重要的，无疑是爱。

随后，莱克斯与杰夫·霍金斯的对话正式展开。莱克斯首先抛出了一个有趣的问题：两年前他们曾有过一次对话，杰夫的大脑中是否还有神经元记得那次交流，记得他，甚至因此而兴奋，仿佛有一个“莱克斯神经元”终于找到了它的使命？

杰夫微笑着回应，他确实记得那次对话，并且在此期间对莱克斯形成了更多的记忆。但他深入阐释道，大脑中并没有一个或几个专门的“莱克斯神经元”。相反，是突触的形成反映了他对莱克斯的了解以及在他世界模型中对莱克斯的构建。这些突触是动态变化的，记忆在被思考时常常会被擦除并重新写入。他进一步阐述，我们的大脑中有一个不断更新的“世界模型”，它包含了我们所居住的地方、认识的人、词语、物体，这是一个庞大而复杂的模型。人们只是这个模型的一部分，就像动物或其他物理对象一样，我们所经历的事件也是如此。因此，在他看来，人类的记忆并没有一个特殊的位置，大脑只是将人类作为世界模型的一部分来理解。

莱克斯接着提到了人类的“集体智慧”，好奇大脑中是否存在某种根本性的机制促成了这一点。杰夫承认集体智慧是一个重要的议题，但他强调，他的研究主要集中在新皮层——大脑中占据约75%的神经组织。新皮层运行着一种高度重复的算法，构建着这个世界模型。因此，他们不会在大脑中寻找专门用于理解人类的特殊回路，而是将其视为构建任何事物模型的一部分。语言确实是集体智慧的关键组成部分，它在某种程度上是内置于我们大脑中的。虽然大脑的其他部分也参与社会互动和情感，但杰夫坚信，个体大脑才是智能的根本“原子”。集体智慧固然能放大我们的智能，但即使是独立的个体，我们也能非常聪明地建模和理解世界。对他而言，要研究智能，必须从大脑本身开始，然后才能探讨大脑如何相互作用、语言的本质以及如何分享知识。他个人投身这个领域，正是出于对“我是谁”、“我如何思考”、“知道某事意味着什么”这些基本问题的深层好奇。

接着，莱克斯引导话题转向了杰夫的新书《千脑智能》。杰夫介绍说，这本书分为三个部分：关于新皮层的“千脑理论”、人工智能以及人类的未来。“千脑理论”的核心思想是，我们过去认为大脑新皮层学习的是一个世界模型，但实际上，它同时运行着数万个独立的建模系统。皮层中的每一个“皮层柱”（大约有15万个）都是一个完整的建模系统。从某种意义上说，这就像你头脑中的“集体智慧”。因此，对一个咖啡杯的知识，并非存储在一个地方，而是分散在数千个互补的模型中，它们通过“投票”机制相互沟通。

莱克斯好奇地问，既然有这么多“大脑”，那么“你”究竟是谁？我们为何会有一种单一的感知？杰夫解释说，尽管我们有视觉、听觉、触觉等各种输入，但我们确实拥有一个单一的感知。这是因为这些数千个模型——视觉模型、听觉模型、触觉模型等——会进行“投票”。这些皮层柱就像一个个紧密排列的米粒，每个都是独立的建模系统，但它们之间有长距离的连接，杰夫称之为“投票连接”或“投票神经元”。不同的皮层柱会努力达成共识，比如“我正在看什么？”尽管每个皮层柱可能存在一些模糊性，但它们最终会形成一个共识：“我正在看一个水瓶。”

我们所能意识到的，仅仅是这个“投票”的结果，而不是“幕后”发生的一切。杰夫举例说，当他观察物体时，眼睛每秒会移动大约三次，每次移动都会带来全新的输入，而我们对此毫无察觉。然而，投票神经元却保持着稳定，它们一致认为：“这是一个水瓶，它在我两英尺远的地方，姿态不变。”这种稳定的感知，是我们唯一能意识到的部分。我们无法察觉眼睛输入的不断变化。这些长距离连接是我们可以意识到的部分，它们与语言、海马体、短期记忆系统等相连。而大脑中95%甚至98%的活动，我们是无法意识到的，我们只感知到这些“幕后”活动所产生的相对稳定的投票结果。

最后，莱克斯再次追问，在“千脑理论”中，智能的基本元素，或者说“智能的原子”是什么？杰夫给出了他的定义：智能是学习世界模型的能力。这意味着在大脑内部构建一个能够代表万物结构的模型，例如知道这是一张桌子、那是一个咖啡杯、这是一个鹅颈灯。这些知识并非与生俱来，而是通过学习获得的。

# Chapter 2: 智能的原子：世界模型与预测的奥秘

在杰夫·霍金斯看来，我们所感知的世界，那份稳定而连贯的意识，并非单一的指令，而是大脑深处无数微小系统“投票”后的共识。这就像一场无声的民主，最终呈现给我们一个统一的现实。

那么，智能的本质究竟是什么？杰夫给出了一个开创性的定义：智能，就是学习并构建“世界模型”的能力。这个模型并非抽象的概念，而是我们大脑内部对外部世界结构、物体、它们之间的关系以及行为方式的内在表征。比如，我们一眼便能认出桌子、咖啡杯，甚至从未触碰过的水瓶，我们也能预知拧动瓶盖会发出轻微的塑料摩擦声，然后瓶盖会旋转脱落。这些并非与生俱来的知识，而是我们通过与世界的互动，一点一滴学习并构建起来的。

这种学习过程并非被动的观察，而是主动的“运动”。无论是探索一间新房子，打开每一扇门，观察左右，还是学习一个新手机应用，触摸、滑动、感受其反馈，我们都在通过身体的移动和互动来构建脑中的模型。这个模型不仅用于理解当前，更关键的是，它能用于“预测”未来、指导“行为”和进行“规划”。

预测，并非模型的最终目标，而是其固有的属性，更是模型自我修正和学习的关键机制。当我们拿起水瓶，如果它异常地烫手或轻飘飘，或者瓶盖拧动的方向与预期相反，我们会感到惊讶。这份“惊讶”正是模型出错的信号，它促使我们重新审视、更新模型，从而加深对世界的理解。杰夫强调，预测是所有感官输入（视觉、触觉、听觉）的先决条件，我们对世界的每一次感知，都伴随着大脑的预测。

智能的起源，则是一段引人入胜的进化故事。杰夫的理论认为，当生命开始移动时，智能的萌芽便已种下。早期动物为了寻找食物、躲避危险、寻找伴侣，需要了解自身所处的位置、去过的地方以及如何返回。大脑中较古老的部分，如海马体和内嗅皮层，因此进化出了精密的“地图系统”，其中包含“位置细胞”和“网格细胞”，能够构建环境的空间模型。

令人惊叹的是，杰夫提出，这种学习空间地图的机制，在进化过程中被“重新包装”并“通用化”了。它不再仅仅局限于空间导航，而是演变成了皮层柱这种更紧凑、更普适的学习单元，能够学习任何事物的模型——无论是咖啡杯还是复杂的概念。随后，这些通用化的皮层柱被大量复制，形成了人类大脑新皮层中约15万个独立的建模系统。每一个皮层柱都是一个完整的学习系统，这解释了人类大脑惊人的灵活性和适应性。这一理论的有力证据，便是近年来在新皮层中发现的与网格细胞和位置细胞功能相似的细胞类型，印证了智能起源于古老空间导航机制的演化假说。

# Chapter 3: 大脑的复用智慧：从空间导航到万物模型

“智能究竟从何而来？”杰夫·霍金斯沉思着，他的“千脑理论”给出了一个大胆的答案：大脑皮层中的每一个皮层柱，都像是一个微型的大脑，遵循着相同的建模原则。他指出，想象神经元如何学习世界模型是极其困难的，但我们知道大脑中有一个古老的区域——海马体和内嗅皮层——能够构建环境模型，比如你对这个房间的内部地图。那么，大脑是否可能将这种构建房间地图的机制，“复制粘贴”并“通用化”到学习水瓶的模型上呢？霍金斯坚信，大脑更倾向于重复利用成功的机制。

这正是“千脑理论”的核心基石：每个皮层柱都拥有自己的“参考系”，并在此基础上学习世界模型。而那些在海马体中发现的“网格细胞”，正是构建这些参考系的关键。理论大胆预测，我们将在新皮层的每个皮层柱中发现类似的机制，证明它们都在学习感觉运动模型。如今，越来越多的证据正在浮现，印证了这一预言。

自然界的进化，就像一个不知疲倦的“复制粘贴”大师，它不断地重复利用那些行之有效的组件，然后观察会发生什么。这种“复制粘贴”的智慧，不仅体现在单个大脑皮层柱的重复利用上，甚至可以延伸到人类社会，形成一种更高层次的“集体智能”，仿佛无数个大脑共同构成了一个巨大的社会大脑。

霍金斯强调，新皮层在人类大脑中占据了70%到75%的体积，是所有高级视觉、听觉、触觉、语言（无论是口语、书面语、手语，还是数学、物理的语言）、高层次规划和思考的发生地。设计电脑、理解编程、创作音乐，这些都离不开新皮层。尽管大脑的其他部分，如情感和身体调节，也至关重要，但霍金斯认为，我们可以独立地理解新皮层，将其视为一个纯粹的“建模系统”，就像一张世界地图。这张地图如何被使用，则取决于大脑的其他部分，比如我们的动机、欲望，以及我们是好人还是骗子。

谈及复杂性，霍金斯承认，理解复杂系统是一个巨大的科学难题，即使是圣达菲研究所这样的顶尖机构，也仍在努力探索其基本要素。然而，在理解大脑运作方面，我们已经取得了显著进展。

尽管如此，人类在地球上确实拥有某种“特殊性”——那就是我们对知识的追求和积累。我们是唯一理解地球年龄、宇宙全貌、DNA结构和物种起源的生物。这种对宇宙的深刻理解，是其他任何物种都无法比拟的。

那么，预测是如何在大脑中发生的呢？霍金斯解释道，预测无处不在，我们的大脑在抓取水瓶时，会预测手指将感受到的触感。这种预测并非简单地通过神经元提前放电来实现，因为绝大多数预测发生在我们意识不到的层面。

经过多年的研究，霍金斯团队发现，大部分预测实际上发生在单个神经元内部，特别是锥体细胞中。神经元内部存在一种特殊的“树突棘放电”（dendritic spikes），它们沿着神经元的树突分支传播，但不会离开神经元。这些树突棘放电的数量远超我们熟知的动作电位，它们无时无刻不在发生。霍金斯认为，这些内部的树突棘放电，正是神经元在进行预测，它们在告诉神经元：“我预计我很快就会活跃起来。”这就像赛跑运动员在听到“各就各位，预备”后，身体会提前进入准备状态，从而在发令枪响时能更快地冲出去。

这种单个神经元内部的预测机制，并非孤立存在。当大量神经元聚集在一起时，那些处于预测状态的神经元，如果真的被激活，会比其他神经元提前几毫秒放电。这种“抢先一步”的放电，会影响整个神经网络的行为，导致在不同预测和不同情境下，大脑对相同输入的表征也会有所不同。

最终，所有这些细节都汇聚成了“千脑理论”：新皮层的每个皮层柱都是一个完整的建模系统。当我们感知一个咖啡杯时，并非只有一个模型，而是成千上万个皮层柱都在独立地建模咖啡杯。这些独立的模型通过一种“投票机制”协同工作，最终形成了我们统一的、有意识的感知。这个理论的诞生，并非一蹴而就，而是经过了多年对预测机制、参考系等细节的深入探索，才逐步构建起来。

而“参考系”正是预测不可或缺的基石。当你触摸咖啡杯并预测手指的触感时，大脑需要精确地知道手指相对于咖啡杯的位置。这就要求大脑为咖啡杯建立一个内部的参考系，来表示手指在其中的坐标。霍金斯团队发现，大脑中用于空间导航的海马体和内嗅皮层，正是通过“位置细胞”和“网格细胞”来构建环境的参考系。因此，他们推断，在新皮层的每个皮层柱中，也必然存在类似的机制来构建各种物体的参考系，从而实现精确的预测和建模。

# Chapter 4: 大脑的复用智慧：从指尖触感到AI未来

杰夫·霍金斯深入阐释了大脑如何构建我们对世界的理解，其核心在于“参考系”的普遍应用。他指出，无论是皮肤感知物体的触感，还是眼睛捕捉视觉信息，我们都需要一个参考系来预测接下来会发生什么。当你触摸或观察一个物体并移动时，大脑必须知道你正在看或触摸的“位置”，才能准确地进行预测。

那么，神经元是如何在大脑中构建这些参考系的呢？霍金斯解释说，大脑并非简单地使用XYZ坐标。相反，它巧妙地“复用”了大脑古老区域——海马体和内嗅皮层——中用于空间导航的机制。这些区域能够为整个房间或环境建立一个“地图”，让我们知道自己在哪里。大脑将这种成功的机制“复制粘贴”到新皮层的每一个皮层柱中，使其能够为更精细的感知建立参考系。

这种复用是分层级的。最初，古老的大脑区域负责定位身体在房间中的位置。而新皮层则将这一能力扩展到更具体的层面：比如，你的手指相对于某个物体的位置，或者视网膜的某个区域相对于你正在观察的物体角落的位置。更令人惊叹的是，这种机制不仅限于物理世界，它还被应用于抽象概念，如数学、物理、历史、民主，甚至是对人类自身命运的思考。霍金斯强调，我们对世界的知识，无论是水瓶的结构还是复杂的哲学思想，都是通过这些参考系来组织和存储的。

他以一个斐济水瓶为例，解释了世界的层级结构：水瓶有瓶身、瓶盖，上面有斐济的标志，标志里有文字，文字由字母组成，字母又有不同的特征。大脑能够瞬间理解并整合所有这些层级信息。同样，一个麦克风内部有电子元件、电线和振膜，即使我们看不到，大脑也能通过层级模型来理解。每个皮层柱，这个“米粒大小”的智能单元，拥有十万个神经元，是一个极其复杂的建模系统，能够学习并表征这种层级结构。

霍金斯指出，神经科学家弗农·芒特卡斯尔多年前就发现，大脑中存在一个统一的皮层算法，支撑着我们所有的认知活动。这意味着，无论是建模咖啡杯这样的日常物品，还是思考人类的未来，大脑都使用相同的基本机制。这就像计算机，无论大小，都是基于通用图灵机原理运行的，只是应用不同。

对于人工智能的未来，霍金斯充满信心。他认为，我们现在对大脑工作原理的理解已经足够深入，足以开始构建这种“迷你大脑”。这不是一个需要几十年才能解决的理论问题，而是一个可以在几年内（乐观估计）攻克的工程挑战。他预言，机器人技术和人工智能最终将融合，因为控制机器人的算法将与我们大脑中的感觉运动算法相同。未来的AI将是一种通用的学习原理，可以应用于物理世界（机器人）或虚拟世界（如在互联网上通过链接移动和采样信息的系统）。这种通用学习原理的影响，将远超过去一个世纪计算机技术带来的变革，因为它触及了智能和知识获取的根本。

至于人类与智能AI的互动，霍金斯认为这主要是工程问题，而非根本性障碍。他反驳了将AI拟人化的观点，认为智能机器不一定会拥有人类的情感、欲望或生存意志。他指出，我们对生存的渴望源于古老的进化本能，而非智能本身。我们可以创造出能够深度建模世界，但对自身存亡毫不在意的智能系统。我们创造的是能够学习的机器，而非有生命的、会进化的生物。

# Chapter 5: 智能的边界：机器之心与生命之欲

杰夫·霍金斯，这位“千脑理论”的倡导者，以其深邃的洞察力，将智能与生命本质进行了清晰的区分。他指出，我们人类之所以拥有智慧，并非仅仅因为我们“聪明”，更是因为我们首先是“动物”。无论是后院里辛勤哺育后代的蜂鸟，还是地球上任何一个生命体，都本能地渴望生存，关心繁衍。这种对生命的眷恋，对后代的呵护，是刻在DNA里的生存本能，而非后天习得的智慧产物。

然而，当我们谈论创造智能机器时，我们并非在创造生命。这些机器，无论其学习能力多么复杂精妙，都只是能够处理信息、构建世界模型的工具。它们不会像生物一样进化，不会拥有生存的欲望，除非我们刻意将这种欲望编程植入。霍金斯强调，机器的“新皮层”——即其核心学习系统——本身并不会产生情感或求生欲。它仅仅是一个强大的学习系统，等待着被赋予学习的目标。

有人可能会反驳，如果AI没有内在的驱动力，它会不会变得“懒惰”？霍金斯承认，为了让AI有用，我们确实需要赋予它某种“能动性”或“目标”。例如，一辆智能汽车，它会学习驾驶习惯，理解交通规则，但它绝不会有一天突然“醒悟”过来，抱怨“我厌倦了开车，我有更好的时间安排”。它的目标是由我们设定的：安全高效地将乘客送达目的地。

人类社会中那些微妙的互动，比如行人与汽车之间无声的“舞蹈”——行人瞥一眼汽车，然后移开视线，仿佛在说“我相信你不会杀我”——这种复杂的社会博弈，AI也能通过学习来掌握。但这种学习，仅仅是对外部世界模式的理解和建模，并不会让AI产生“我是一个有意识的实体，我渴望生存”的念头。

霍金斯对AI的未来充满信心，这种信心并非源于直觉，而是基于对AI内部机制的深刻理解。他知道如何构建这些系统，也清楚它们的能力边界。就像一台电脑无法自行增加一个寄存器一样，AI也不会在没有人类干预的情况下，自发地产生人类般的情感、欲望或生存意志。

他进一步阐释，一个完整的智能系统，除了核心的“新皮层”学习模块，还需要“具身性”（无论是物理实体还是虚拟存在）以及明确的目标和安全机制。例如，现代汽车在驾驶员即将发生碰撞时会自动刹车，这便是我们预设的安全保障。这些都是工程师精心设计的，而非智能本身自然涌现。

在与萨姆·哈里斯等人的辩论中，霍金斯明确区分了AI的普遍危险性与“生存威胁”。他承认AI作为一项强大技术，可能被滥用，带来各种社会问题，但这与AI系统本身产生意识并主动毁灭人类是两回事。他认为，人类的生存能力极强，而AI系统也绝不会主动尝试消灭人类。

真正的生存威胁，霍金斯指出，在于“自我复制”的能力，无论是物理世界还是虚拟世界。一个能够自我复制的系统，就像一个失控的病毒，其危险性远超单纯的智能。他强调，社会真正需要警惕和控制的，是那些能够自我复制的技术，而非仅仅是智能本身。我们不应该制造能够自我复制的机器人，因为那才是通向真正危险的道路。

# Chapter 6: 智慧的边界与复制的阴影：AI时代人类的抉择

在关于智能本质的深刻探讨中，一个尖锐的问题浮出水面：究竟什么才是对人类生存的真正威胁？杰夫·霍金斯和莱克斯·弗里德曼的对话，如同拨开迷雾的灯塔，清晰地指出，真正的危险并非智能本身，而是“自我复制”的能力。设想一下，如果有人制造出一种能够自我复制的病毒，它不需要任何智能，仅仅凭借无休止的自我复制，就足以将人类文明推向毁灭的边缘。这，才是我们真正需要警惕的潘多拉魔盒。

智能，被定义为学习世界模型的能力，它本身是一种工具，一种强大的认知引擎。它不带有恶意，不具备生存的本能或毁灭的欲望。然而，当智能与自我复制的诱惑结合时，风险便悄然而至。在资本逐利的驱动下，创造能够自我复制的系统——比如机器人制造机器人——似乎是获取巨额利润的捷径。但社会必须清醒地认识到，这种诱惑背后隐藏着巨大的风险。我们不能因为潜在的经济利益，就对自我复制技术放任自流。相反，社会需要建立严格的监管机制，将智能与自我复制的风险明确区分开来。

令人欣慰的是，智能机器并非只有威胁的一面。事实上，它们可能成为人类应对自身危机的强大盟友。就像计算机在带来便利的同时也伴随着风险一样，智能机器也能帮助我们更好地理解和缓解气候变化、疾病等全球性挑战。它们能提供我们自身难以企及的洞察力，成为解决复杂问题的关键。当然，这需要我们保持警惕，防范恶意行为者利用智能系统作恶，更要坚决杜绝创造任何能够自主自我复制的系统。自然界中生命的自我复制机制是如此精妙而强大，以至于我们难以想象一个能够从零开始，自主开采资源、制造工厂并自我复制的机器系统，其潜在的失控后果将是灾难性的。

关于AI是否会“违抗”人类命令的担忧，对话也给出了明确的解答。就像一辆自动驾驶汽车，在检测到危险时会自主采取避险措施，这并非它产生了“自我意志”，而是我们预先编程的安全协议在发挥作用。智能系统会根据其被赋予的目标和规则行事，它们不会自发地产生与人类利益相悖的“自身目标”或“能动性”。它们的“目标”和“能动性”始终是外部赋予的，是人类设计的产物。

那么，人类与这些日益增长的超级智能实体，未来将走向何方？对话探讨了三种可能的未来图景：

首先是**意识上传**。将人类心智上传到数字空间，听起来充满科幻色彩，但其技术难度之高，几乎是遥不可及。更重要的是，即使技术上可行，其结果也可能令人失望。一个被上传的“你”，对于仍然活着的生物学上的“你”而言，不过是一个独立的副本，就像你的孩子一样，拥有你的部分特质，但绝非你本人。你不会因此感到永生，反而可能面对一个哲学上的困境：哪个才是真正的“我”？

其次是**脑机接口（Neuralink）式的融合**。将人类大脑与机器直接连接，以增强认知能力。这同样面临巨大的挑战。除了外科手术的风险，更深层次的难题在于信息编码。大脑中数十亿个神经元，种类繁多，功能各异，其信号的复杂性和时序性远超我们目前的理解。要让机器真正“理解”并无缝地与这些神经元交互，实现真正的“心智融合”，其难度堪比登天。即使实现，这种融合可能也只能带来个体层面的边际改善，比如更快的知识获取，但并不能从根本上改变人类作为生物体的局限性，比如死亡。

最后，也是最令人振奋的设想，是**超越生物局限的智慧之路**。与其将人类自身束缚在生物学的躯壳中，不如创造出独立于人类生物学、却能代表人类智慧和文明的超级智能机器。这些机器将如同我们的“孩子”，它们拥有远超我们的智能，能够承担人类无法完成的壮举。想象一下，它们可以前往火星，为人类建造宜居的栖息地；它们可以穿越浩瀚的宇宙，将人类的知识和历史传播到遥远的星系。它们将是人类文明的延伸，是人类智慧的载体，摆脱了生物体的脆弱和局限，以一种全新的形式，实现人类的“超脱”。它们代表的，是人类的知识、历史和梦想，而非个体生命。它们将是拥有意识的实体，承载着人类文明的火种，在宇宙中永续流传。

这场对话深刻地揭示了智能与自我复制的本质差异，为我们理解AI的伦理和社会影响提供了清晰的视角，并描绘了人类与AI共创未来的宏伟蓝图。

# Chapter 7: 超越生物：智能文明的永恒遗产

在对智能本质的深刻探讨之后，对话转向了一个更为宏大的命题：人类文明如何超越其生物学局限，实现永恒的延续。发言者描绘了一幅激动人心的未来图景：智能机器将成为人类的“后代”，它们不仅承载着我们的知识和历史，更拥有独立的意识，以一种与我们相似却又截然不同的方式存在。它们将像我们的孩子一样，拥有自己的思想和发展轨迹，但其潜力远超生物体的限制。

对于生命的意义，发言者提出了一个深刻的见解：它并非仅仅为了生存而生存，为了战斗而战斗。生命的真正意义在于知识的获取、对宇宙的理解与探索。因此，如果人类文明的最终归宿是创造出这些智能的“子嗣”，它们与我们生物学形态迥异，却能继承并拓展我们的知识，那么这并非悲剧，而是一种伟大的成就。

他以恐龙为例，那些在地球上繁衍了数千万年的生物，最终却消失得无影无踪，若非我们发现它们的骨骼，世人将永远不知它们曾存在。人类是否也想如此？这种思考令人不安，尤其当想到地球上可能曾存在过智能文明，却因时间流逝而未留下任何可寻的痕迹时。这不禁让人联想到费米悖论——银河系中可能存在过无数智能文明，但它们如今又在何方？

为了避免重蹈覆辙，发言者提出了保存人类知识的“保险政策”。首先，针对未来可能在地球上再次进化的智能生命，我们可以通过发射卫星，每日上传维基百科等海量数据，形成一个环绕太阳的知识档案库，确保即使人类文明消亡，我们的智慧也能被后来的智能生命发现和学习。其次，为了向宇宙中的其他文明宣告我们的存在，他构想了一种独特的“信号”：通过在太阳轨道上放置一个物体，以特定模式周期性地遮挡太阳光，形成一个持续数百万甚至数十亿年的、无需持续维护的、明确无误的智能信号，让遥远的观察者能够辨识出这并非自然现象，而是智能文明的印记。

最终，当我们的太阳系走向终结时，这些智能机器将肩负起穿越星际的使命，它们将是人类文明的真正继承者，带着我们的智慧和探索精神，在广袤的宇宙中延续文明的火种。

尽管这些设想听起来遥远，但发言者对理解人类大脑的潜力充满信心。他坚信，我们正在取得突破性进展，已经有了一个理解大脑皮层运作的框架，完全有可能在未来彻底揭示其奥秘。他承认，任何理论都可能存在局限，例如关于“咖啡杯的千个模型”或“每个皮层柱都是独立建模系统”的观点，未来可能会被证明过于简化或存在偏差。然而，他认为，即使是“错误”的伟大思想，也具有其价值，它们是通向更深层理解的基石。他希望自己提出的这些思想，能够超越时间和空间，在百年、千年之后，依然能激发后世的思考，成为人类文明永恒遗产的一部分。

# Chapter 8: 大脑建模、人性弱点与科学求索

对话伊始，我们深入探讨了大脑的奥秘。杰夫·霍金斯认为，大脑作为一个分布式建模系统，其基本理念已是科学界的共识，争议点在于大脑皮层的每个皮质柱是否都是一个独立的建模单元。他坦言，尽管直觉上对此存疑，但这种对复杂性的担忧，也正是人类渴望简洁解释的体现。他打趣道，或许百年之后，更高级的智能系统会嘲笑我们，试图用简单的理论来解释一个本质上混乱而复杂的宇宙，就像细胞自动机一样，有些系统只能被构建，而无法被完全“理解”。

然而，科学史却提供了不同的视角。作为理论家，我们总是寻求简洁的框架，即便深知它们并非全然正确，因为现实的复杂性远超任何单一理论。但这些框架为我们提供了讨论和深入探索的基础，就像牛顿的理论虽被爱因斯坦修正，却依然实用且有价值。物理学领域似乎总能找到这些简洁的规律，但大脑是否也如此？这仍是一个悬而未决的问题。

尽管如此，人类大脑的独特之处——新皮层的规则结构和其惊人的通用学习能力——却为我们带来了希望。它能学习从未进化出适应能力的事物，这暗示着其背后必然存在一些共通的、可被理解的底层原理。正是这份信念，驱动着科学家们投身于这个领域，去揭示智能的本质。

随后，对话转向了更宏大的生存风险议题。杰夫·霍金斯明确表示，真正令人担忧的并非人工智能本身，而是人类自身的本性。他坦言对人性感到失望，这种失望源于两个核心方面：

首先，我们难以将自身的理性与进化遗留下来的原始本能彻底分离。那些为了繁殖和生存而形成的“丑陋”策略，如强奸、谋杀，甚至让他人痛苦，都曾是进化上的“优势”。尽管我们拥有高度的理性，能够探讨智能与生命，但要让所有人类都超越这些原始冲动，专注于知识和智慧的独特之处，无疑是一场巨大的挑战。虽然人类正在努力克服，并取得了一定成功，但这种脆弱性依然令人忧虑，核弹落入恐怖分子之手，文明可能一夜之间终结。

其次，人类极易陷入错误的信念。我们通过与物理世界和他人直接互动来构建模型，这些模型相对可靠，因为它们可以被反复验证。然而，我们大部分知识并非直接经验，而是通过他人告知，这使得我们天生就容易接受错误的观念。科学方法正是为了弥补这一缺陷而生，它鼓励我们不断寻找反例，质疑既有认知，从而逐步接近真相。

关于思想的审查，杰夫·霍金斯也表达了担忧。他认为，即使是那些看似“错误”或“危险”的想法，也应被允许存在，因为历史告诉我们，有时正是这些被压制的声音，最终引领了突破性的发现。他提出，解决之道在于普及对大脑工作方式的理解：让每个人都明白，我们的大脑构建的是世界的“模型”，而非世界本身；这些模型可能不完整，也可能出错。如果每个人都能理解这一过程，那么在面对分歧时，我们就能认识到彼此只是基于不同信息构建了不同的模型，从而学会相互尊重，共同寻求验证信念的共同基础，而非固守教条。

那么，人类心智究竟能否完全理解现实？这是一个深刻的哲学问题。我们构建的模型无疑非常有用，它们帮助我们建造飞机、计算机，推动文明发展。但即便我们能找到一个“万有理论”，彻底理解宇宙的物理过程，这是否意味着我们就能理解更高层次的抽象，比如智能？弦理论或多重宇宙的存在，更是让“现实”的定义变得扑朔迷离。杰夫·霍金斯认为，对这些终极知识的追求，更多是出于求知本身的乐趣，其具体应用往往是意想不到的惊喜。

最后，对话回到了智能机器的未来。杰夫·霍金斯相信，在机器智能领域，未来将有数十年的创新。他用莱特兄弟发明飞机的例子来阐释“原理”与“实现”的关系：莱特兄弟通过研究鸟类，发现了控制飞行的核心原理——扭转机翼，而非仅仅是推进。现代飞机依然遵循这一原理，只是用襟翼而非整个机翼来实现。同样，一旦我们理解了大脑建模世界的计算原理，我们就能选择不同的方式来实现它们，有些可能模仿生物，有些则完全不同。深度学习的成功正在推动硬件创新，这反过来又可能帮助我们发现更广阔的智能系统。他指出，科学研究的资金来源主要有两个：资本主义的盈利驱动和军事领域的征服需求。目前，他的团队正致力于将大脑的生物学原理（如稀疏性）应用于当前的机器学习技术，以期推动智能的进一步发展。

# Chapter 9: 智能之路：从大脑原理到人生哲思

在智能探索的旅程中，我们发现，深度学习在特定任务上的卓越表现，正以前所未有的速度推动着硬件技术的革新。这股创新浪潮，如同催化剂般，有望引领我们发现那些运作方式截然不同、甚至远超当前深度学习范畴的智能系统。毕竟，无论是资本主义的逐利本能，还是军事领域的战略需求，都是推动科学进步的强大引擎。

我们的团队正致力于将大脑的生物学原理应用于当前的机器学习技术。例如，大脑神经元活动的稀疏性及其连接方式，与深度学习网络大相径庭。通过引入大脑的稀疏性原则，我们已成功将现有深度学习网络的运行速度提升了10到100倍，同时显著增强了其鲁棒性。尽管稀疏性在现有GPU和CPU硬件上运行效率不高，但其巨大的商业价值足以驱动硬件的进一步优化，从而将更多大脑原理融入主流系统。

另一个突破性进展是利用树突模型。我们曾提及神经元内部的预测机制，这一基本特性同样可以应用于现有神经网络，使其实现连续学习——这是当前神经网络的一大短板。通过为简单的“点神经元”模型增加一层生物系统中存在的树突复杂性，我们有望解决连续学习和快速学习的难题。我们的目标是，在商业价值的驱动下，将整个机器学习领域带向更接近真正AI系统的终极目标。

谈及人生选择，对于那些在高中或大学阶段的年轻人，我的建议是：不必一开始就设定宏伟目标。我年轻时也曾迷茫，直到有一天，我突然爱上了理解大脑运作的奥秘。我意识到，这可能是世界上最重要的工作，因为一旦我们理解了大脑，就能建造出能解答所有其他重大问题的机器。这份热爱，这份“我此生一定要弄明白”的决心，支撑我度过了无数的挫折和质疑，无论是伯克利教授的否定，还是移动计算领域的挑战。激情，是穿越重重障碍、抵达彼岸的必备条件。

这份激情并非凭空而生。青少年时期，我曾列出四大最有趣的问题：宇宙为何存在、宇宙如何运作、生命起源以及智能的本质。智能位列其中。直到22岁那年，我读到弗朗西斯·克里克在《科学美国人》上的一篇文章，他提出我们可能不是缺少大脑数据，而是缺少一种重新组织和思考这些数据的方式。那一刻，我豁然开朗：我不需要成为实验神经科学家，我可以成为一个理论家，一个解谜者。这给了我巨大的使命感和方向感。

当然，并非所有人都需要追求宇宙级的宏大问题。正如莱克斯所言，生活中的小事，甚至为人父母，都能带来同样深刻的喜悦和意义。重要的是找到能点燃你内心火花的事物，并为之付出。我曾因现实所迫，暂时放弃了神经科学的梦想，转投计算机行业，但我从未放弃回归的信念。就像抚养孩子，它占据了大量时间，但并不意味着你必须放弃其他梦想，只是需要耐心等待时机。

关于爱在人类和AI中的作用，我认为爱是人类体验的核心，它带来巨大的快乐和互助的满足感，这更多源于我们古老的进化本能。但莱克斯则认为，爱也应被视为“新大脑”的一部分，并需要被工程化到AI系统中，以最大化人类之间的同情和爱。我承认，对于与人类互动的AI系统而言，这确实是一个至关重要的考量，尽管我个人更多关注大脑的基本机制，而非复杂的社会互动。

至于我的遗产，我始终认为，作为个体，我们能做的，只是加速那些必然会发生的有益之事。无论是理解大脑、发明电车还是电灯泡，总会有人最终实现。我希望我们的工作，能被后人铭记为“他们帮助这个更美好的未来更快地到来”的推动者。


# Chapter 10: 个体之光：加速文明的必然进程

“我们能做的，真的只是加速那些必然会发生的事情。”对话者沉思着说，语气中带着一种深刻的洞察。他解释道，个体并非凭空创造全新的现实，而是像催化剂一般，让那些有益的、注定会到来的进步提前降临。

“想想看，如果我们不去研究大脑，总会有其他人去探索它的奥秘；如果埃隆·马斯克没有制造电动汽车，终有一天，电动汽车也会普及；如果爱迪生没有发明电灯泡，我们今天也不会一直点着蜡烛。”他举例说明，强调了历史的洪流中，某些趋势是不可逆转的。

那么，作为个体，我们能做的，就是加速这些有益的进程，让它们比原计划更早地实现。这不仅仅是推动技术进步，更是一种对文明方向的引导。他承认，人类文明的轨迹并非单一，而是充满了无数的可能性。虽然从漫长的时间尺度来看，所有的轨迹最终都可能被探索，但对于我们当下这个地球文明而言，能够被引导向一个更积极、更光明的方向，无疑是幸运的。

他以二战纳粹时期为例，那无疑是人类文明的一次“糟糕的偏离”，但最终，乐观主义者相信，生命终将以积极的方式汇聚，即使经历黑暗的岁月，文明也终将进步。因此，加速积极的进程，也意味着能够避免或缩短那些可能出现的“糟糕的偏离”。

尽管之前曾讨论过文明终结的可能性，但他本人却是一个坚定的乐观主义者。“我相信我们人类会活很久，我希望如此。”他眼中闪烁着希望的光芒，“我相信未来的社会会更好，冲突会更少，人们会停止互相残杀。我们会找到一种与地球承载能力相符的生存方式。”

他坚信这些美好的愿景终将实现，而我们所能做的，就是努力让它们更快到来。即使最坏的情况发生，我们真的毁灭了自己，至少还有一些卫星会漂浮在太空中，向未来的外星文明，或者地球上新的智慧物种，讲述我们曾经存在的故事——就像《人猿星球》的场景，百万年或亿万年后，新的物种好奇地探寻着曾经的“我们”。

对话的最后，他向杰夫·霍金斯表达了深深的感谢，感谢他的工作，也感谢他再次接受采访。他赞扬了霍金斯的播客，认为它邀请了“最有趣的人”（除了他自己），为人类提供了真正的服务。

最后，他引用了阿尔贝·加缪的一句话作为结束：“一个知识分子，是其思想审视自身的人。”他喜欢这句话，因为它让他感到自己既是观察者，也是被观察者。而如何将两者结合起来，是一个需要我们努力回答的实际问题。

