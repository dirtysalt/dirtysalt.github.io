# Chapter 1

- The following is a conversation

with Mark Zuckerberg,

his second time on this podcast.

He's the CEO of Meta

that owns Facebook, Instagram,

and WhatsApp, all services used

by billions of people to connect

with each other.

We talk about his vision for the future

of Meta and the future of AI

in our human world.

This is the Lex Fridman Podcast,

and now, dear friends,

here's Mark Zuckerberg.

So you competed

in your first Jiu-Jitsu tournament,

and me as a fellow

Jiu-Jitsu practitioner and competitor,

I think that's really inspiring,

given all the things you have going on.

So I gotta ask,

what was that experience like?

- Oh, it was fun.

I don't know, yeah,

I mean, well, look,

I'm a pretty competitive person.

- Yeah.

- Doing sports that basically require

your full attention,

I think is really important

to my mental health

and the way I just stay focused

at doing everything I'm doing.

So, I decided to get into martial arts,

and it's awesome.

I got a ton of my friends into it.

We all train together.

We have a mini academy in my garage.

And I guess one of my friends was like,

hey, we should go do a tournament.

I was like, okay, yeah, let's do it,

I'm not gonna shy away

from a challenge like that.

So yeah, but it was awesome,

it was just a lot of fun.

- You weren't scared, there was no fear?

I don't know, I was pretty sure

that I'd do okay.

- I like the confidence.

Well, so for people who don't know,

jiu-jitsu is a martial art

where you're trying

to break your opponent's limbs

or choke them to sleep,

and do so with grace and elegance

and efficiency and all that kind of stuff.

It's a kind of art form, I think,

that you can do for your whole life,

and it's basically a game,

a sport of human chess,

you can think of.

There's a lot of strategy, there's a lot

of sort of interesting human dynamics

of using leverage

And it's kind of incredible

what you could do.

You can do things

a much larger opponent,

and you get to understand the way

the mechanics of the human body works

because of that.

But you certainly can't be distracted.

- No, it's 100% focus.

To compete, I needed to get around

the fact that I didn't want it

to be this big thing,

so I basically just rolled up

with a hat and sunglasses,

and I was wearing a COVID mask.

And I registered under my first

and middle name, so Mark Elliott.

And it wasn't until I actually pulled

all that stuff off right before

I got on the mat

that I think people knew it was me.

So it was pretty low key.

- But you're still a public figure.

- Yeah, I mean, I didn't wanna lose.

- Right, the thing you're partially afraid

of is not just the losing,

but being almost like embarrassed.

It's so raw, the sport, in that like,

it's just you and another human being.

There's a primal aspect there.

- Oh, yeah its perfect.

- For a lot of people, it can be terrifying,

especially the first time

you're doing the competing,

and it wasn't for you.

I see the look of excitement in your face.

It wasn't, no fear.

- I just think part of learning is failing.

The main thing, people who train jiu-jitsu,

it's like you need to not have pride

because I mean all the stuff

that you were talking

about before about, you know,

getting choked or getting, you know,

a joint lock.

It's um, you only get

into a bad situation

once you've already lost right?

And, but obviously

when you're getting started

with something, you're not gonna be

So you just need to be willing

to go with that.

But I think this is like, I don't know,

I mean, maybe I've just been

embarrassed enough times in my life.

Yeah.

I do think

you know, as people grow up,

maybe they don't wanna be embarrassed

or anything.

and they kind of have a sense

of who they are

and what they want to project

and I don't know.

I think maybe to some degree.

You know your ability

to keep doing interesting things

is your willingness to be embarrassed

again and go back to step one

and start as a beginner

and get your **** kicked

and you know look stupid doing things,

and yeah I think so many of the things

that we're doing

whether it's whether it's this.

I mean this is just like a kind

of a physical part of my life,

but but it running the company

it's like we just take on

new adventures and, you know,

all the big things that we're doing

I think of is like 10 plus year missions

that we're on where you think

of as like 10 plus year missions

that we're on where often early on,

people doubt that we're gonna be able

to do it and the initial work

seems kind of silly and our whole ethos

is we don't wanna wait,

to put it out there.

We wanna get it out quickly

and get feedback on it.

And so I don't know, I mean,

there's probably just something

about how I approach things in there.

But I just kind of think

that the moment that you decide

that you're gonna be too embarrassed

to try something new,

then you're not gonna

learn anything anymore.

But like I mentioned, that fear,

that anxiety could be there,

it could creep up every once in a while.

Do you feel that in especially

stressful moments sort of outside

of the judges and that, just at work?

Stressful moments, big decision days,

big decision moments,

how do you deal with that fear?

How do you deal with that anxiety?

The thing that stresses me out the most

is always the people challenges.

You know, I kind of think that,

you know, strategy questions, you know,

I tend to have enough conviction around

the values of what we're trying to do

and what I think matters

and what I want our company to stand

for that those don't really keep me up

at night that much.

it's not that I get everything right,

of course, I don't right I mean make

we make a lot of mistakes,

but I at least

have a pretty strong sense

of where I want us to go on that.

The thing in running a company

for almost 20 years now,

one of the things

is when you have a team that's cohesive,

you can get almost anything done.

And you can run

through super hard challenges,

You can make hard decisions

and push really hard

to do the best work even,

and kind of optimize

something super well.

But when there's that tension, I mean,

that's when things get really tough.

And when I talk to other friends

who run other companies

and things like that,

that I actually spend

on in running this company

is just fostering a pretty tight

core group of people

who are running the company with me.

And that to me is,

is kind of the thing that

both makes it fun, right?

Having, having, you know, friends

and people you've worked with

and new perspectives,

who can who you can go work

on some of these crazy things with.

But to me,

is when when there

are when there's tension, you know,

that's that that weighs on me.

I think the you know,

it's maybe not surprising.

I mean, we're like a very people

focused company and it's the the people

is the part of it that that, you know,

weighs on me the most to make sure

that we get right.

But yeah, that I'd say across everything

that we do is probably the big thing.

So when there's tension

in that inner circle of close folks,

so when you trust those folks

to help you make difficult decisions

about Facebook, WhatsApp, Instagram,

the future of the company

and the metaverse with AI.

How do you build that close-knit group

of folks to make

those difficult decisions?

Is there people that you have

to have critical voices,

very different perspectives

on focusing on the past

versus the future,

all that kind of stuff.

Yeah, I mean, I think for one thing,

it's just spending a lot of time

with whatever the group

is that you wanna be that core group,

grappling with all

of the biggest challenges.

And that requires a fair amount

of openness.

And, you know, so I mean,

a lot of how I run the company is,

you know, it's like every Monday morning

we get our,

it's about the top 30 people together.

And we, and this is a group

that just worked together

for a long period of time.

And I mean, people, people rotate in,

I mean, new people join,

people leave the company,

people go to other roles in the company.

So it's not the the same group

over time.

But then we spend, you know,

a lot of times a couple of hours,

a lot of the time, it's, you know,

can be somewhat unstructured, we like,

I'll come with maybe a few topics

that I that are top of mind for me,

but I'll ask other people

to bring things and people, you know,

raise questions, whether it's okay,

there's an issue happening

in some country.

With with some policy issue,

there's like a new technology

that's developing here.

We're having an issue with this partner.

There's a design trade-off in WhatsApp

between two things that end up

being values that we care about deeply,

and we need to decide

where we want to be on that.

And I just think over time,

by working through a lot of issues

with people and doing it openly,

people develop an intuition

for each other

and a bond and camaraderie.

And to me, developing that is like a lot

of the fun part of running a company,

or doing anything, right?

who are kind of along on the journey

that you're, that you feel like

you're doing it with.

Nothing is ever just

one person doing it.

Are there people that disagree

often within that group?

Oh yeah, it's a fairly combative group.

Okay, so combat is part of it.

So this is making decisions on design,

engineering, policy, everything.

Everything, everything.

Yeah.

I have to ask just back to Jiu-Jitsu

for a little bit,

what's your favorite submission now

that you've been doing it?

What's how do you like to submit

your opponent Mark Zuckerberg?

I'm in well, but first of all,

I Do you prefer no gi or gi jiu-jitsu?

So gi is this outfit you wear

that is Maybe mimics clothing,

so you can choke.

What's like a kimono?

It's like the traditional martial arts

or kimono.

Pajamas.

Pajamas.

Pajamas.

That you could choke people with, yes.

Well, it's got the lapels.

Yes.

Yeah, so I like jujitsu.

I also really like MMA.

And so I think

no gi more closely approximates MMA.

And I think my style is,

is maybe a little closer

to an MMA style.

So like a lot of jiu jitsu players

are fine being on their back, right.

And obviously having a good guard

is a critical part of jiu jitsu, but,

but in MMA,

you don't want to be on your back,

right?

you're just taking punches

while you're on your back.

So that's no good.

So you like being on top.

My style is I'm probably more pressure

and yeah, and I'd probably

rather be the top player.

But I'm also smaller, right?

I'm not like a heavyweight guy, right?

So from that perspective, I think like,

you know, it's especially because,

you know, if I'm doing a competition,

I'll compete with people

who are my size,

but a lot of my friends are bigger

than me.

So, so back takes probably pretty

important, right?

Because that's where you have

the most leverage advantage, right?

Where, you know, people, you know,

their arms, your arms

are very weak behind you, right?

So, so being able to get to the back

and take that pretty important.

But I don't know,

is to not be too committed

to any single submission.

But that said,

So I always think that chokes

are a somewhat more humane way

to go than joint locks.

Yeah, and it's more about control,

it's less dynamic.

So, you're basically

like a Habib Nurmagomedov

type of fighter.

So let's go, yeah,

I think is like the clean way to go.

Straightforward answer right there.

What advice would you give

to people looking

to start learning jiu-jitsu?

Given how busy you are,

given where you are in life,

that you're able to do this,

you're able to train,

you're able to compete

and get to learn something

from this interesting art.

I just think you have to be willing

to just get beaten up a lot.

Yeah.

I mean, it's, but I mean,

over time, I think that there's a flow

to all these things.

And there's, you know, one of the,

one of, I don't know,

my experiences that I think kind

of transcends, you know,

running a company and the different,

different activities

that I like doing are,

I really believe that like,

if you're going

to accomplish whatever anything,

a lot of it is just being willing

to push through, right,

and having the grit and determination

to, push through difficult situations.

And I think for a lot of it

is just being willing to push through,

right, and having the grit

and determination

that ends up being sort

of a difference maker between the people

who kind of get the most done and not.

I mean, there's all these questions

about like, you know,

how many days people want to work

and things like that.

who like start successful companies

or things like

that are just working extremely hard.

But I think one of the things

by doing this over time or very acutely

with things like Jiu Jitsu

or surfing is you can't push

through everything.

And I think that that's you,

you learn this stuff very acutely.

You run doing sports compared

to running a company because running

a company, the cycle times are so long,

right?

It's like you start a project

and then, you know,

it's like months later or you know,

if you're building hardware,

it could be years later

before you're actually getting feedback

and able to, you know, make the next set

of decisions for the next version

of the thing

f the thing that you're doing.

Whereas one of the things

that I just think is mentally so nice

about these very high

turnaround conditioning sports,

things like that,

is you get feedback very quickly.

Right, it's like, okay,

like I don't counter someone correctly,

you get punched in the face, right?

So not in jiu-jitsu,

you don't get punched in jiu-jitsu,

but in MMA.

There are all these analogies

between all these things

that I think actually hold that are like

important life lessons, right?

It's like, okay, you're surfing a wave,

it's like, you know,

sometimes you're like,

you can't go in the other direction

on it, right?

It's like, there are limits to kind

of what, you know, it's like a foil,

you can pump the foil

and push pretty hard in a bunch

of directions, but like, yeah, you,

you know, it's at some level,

like the momentum

against you is strong enough, you're,

that's not gonna work.

And I do think that that's sort

of a humbling,

but also an important lesson for,

I think people who are running things

or building things, it's like, yeah,

a lot of the game is just being able

to kind of push

and work through complicated things,

but you also need to kind of have enough

of an understanding

of which things you just can't push

through and where the finesse

# Chapter 2

of what, you know, it's like a foil,

you can pump the foil

and push pretty hard in a bunch

of directions, but like, yeah, you,

you know, it's at some level,

like the momentum

against you is strong enough, you're,

that's not gonna work.

And I do think that that's sort

of a humbling,

but also an important lesson for,

I think people who are running things

or building things, it's like, yeah,

a lot of the game is just being able

to kind of push

and work through complicated things,

but you also need to kind of have enough

of an understanding

of which things you just can't push

through and where the finesse

is more important.

Yeah.

What are your jujitsu life lessons?

Well, I think you did it,

you made it sound so simple

and were so eloquent that it's easy

to miss.

But basically being okay

and accepting the wisdom and the joy in

the getting your ass kicked

in the full range of what that means.

I think that's a big gift,

of the being humbled.

Somehow being humbled,

especially physically,

opens your mind to the full process

of learning, what it means to learn,

which is being willing to suck

at something.

And I think Jiu-Jitsu

just very repetitively,

efficiently humbles you over and over

and over and over

to where you can carry that lessons

to places where you don't get humbled

as much, whether it's research

or running a company or building stuff,

the cycle is longer.

In Jiu-Jitsu, you can just get humbled

in a period of an hour,

over and over and over and over,

especially when you're a beginner,

you'll have a little person,

just somebody much smarter than you,

just kick your ass repeatedly,

definitively, where there's no argument.

Oh yeah.

And then you literally tap,

because if you don't tap,

you're going to die.

So this is an agreement,

you could have killed me just now,

but we're friends,

so we're gonna agree

And that kind of humbling process,

it just does something to your psyche,

to your ego that puts it in

its proper context to realize

that everything in this life

is like a journey from sucking

through a hard process

of improving rigorously day

after day after day after day.

Any kind of success requires hard work.

Yeah, jiu-jitsu,

more than a lot of

because I've done a lot of them,

really teaches you that.

And you made it sound so simple.

Like, I'm okay, you know, it's okay,

it's part of the process,

you just get humble,

get your ass kicked.

I've just failed and been embarrassed

so many times in my life that like,

you know, it's a core competence

at this point.

Well, yes, and there's a deep truth

to that, being able to,

and you said it in the very beginning,

which is, that's the thing

that stops us, especially

as you get older,

especially as you develop expertise

in certain areas,

not being willing to be a beginner

in a new area.

Yeah.

Because that's where the growth happens,

is being willing to be a beginner,

being willing to be embarrassed,

saying something stupid,

doing something stupid.

A lot of us that get good at one thing,

you wanna show that off,

and it sucks being a beginner,

but it's where growth happens.

Well, speaking of which,

let me ask you about AI.

It seems like this year,

for the entirety

of the human civilization,

is an interesting year

for the development

of artificial intelligence.

A lot of interesting stuff is happening.

So, meta is a big part of that.

Meta has developed Lama,

which is a 65 billion parameter model.

There's a lot of interesting questions

I can ask here,

one of which has to do with open source.

But first, can you tell the story

of developing of this model

and making the complicated decision

of how to release it?

Yeah, sure.

I think you're right, first of all,

that in the last year there

have been a bunch of advances on scaling

up these large transformer models.

So there's the language equivalent

of it with large language models,

there's sort

of the image generation equivalent

with these large diffusion models.

Um there's a lot of fundamental research

that's gone into this

and meta has taken the approach

of being quite open and academic

in our development um of of AI.

Part of this is we wanna have

the best people

in the world researching this,

and a lot of the best people wanna know

that they're gonna be able

to share their work.

So that's part of the deal that we have,

is that we can get,

if you're one of the top AI researchers

in the world, you can come here,

you can get access to kind

of industry scale infrastructure.

And part of our ethos is that we want

to share what's invented broadly.

We do that with a lot

of the different AI tools

that we create.

And LLAMA is the language model

that our research team made.

And we did a limited open source release

for it, right,

which was intended for researchers

to be able to use it.

But you know, responsibility

and getting safety right

on these is very important.

So we didn't think that

for the first one,

there were a bunch of questions around

whether we should be

releasing this commercially.

So we kind of punted on that for V1

of Llama

and just released it for research.

Now, obviously,

by releasing it for research, you know,

it's out there,

that they're not supposed

to kind of put

it into commercial releases.

And we're working

on the follow-up models for this

and thinking through

how exactly this should work

for follow-on now that we've had time

to work on a lot more of the safety

and the pieces around that.

But overall, I just kind of think that

it would be good if there were a lot

of different folks who had the ability

to build state-of-the-art

technology here, and not just a small number

of big companies.

To train one of these AI models,

the state-of-the-art models you know,

hundreds of millions of dollars

of infrastructure, right?

So there are not that many organizations

in the world, um,

that can do that

at the biggest scale today.

And now it gets,

it gets more efficient every day.

So, I do think that will be available

to more folks over time,

but I just think

like there's all this innovation out

there that people can create.

And I just think that we'll also learn

a lot by seeing what the whole community

of students and hackers and startups

and different folks build with this.

And that's kind of been

how we've approached this.

And it's also how we've done a lot

of our infrastructure.

And we took our whole data center design

and our server design

and we built this open compute project

where we just made that public

and part of the theory was like,

all right, if we make it

so that more people can use

the server design,

then that'll enable more innovation.

It'll also make

the server design more efficient

and that'll make

our business more efficient too.

So that's worked

and we've just done this with a lot

of our infrastructure.

So for people who don't know,

you did the limited release,

I think in February

of this year of Lama,

and it got quote unquote leaked,

meaning like it escaped

the limited release aspect, but it was,

you know, that's something

you probably anticipated,

given that it's just released

to researchers.

We shared it with researchers.

Right, so it's just trying to make sure

that there's like a slow release.

Yeah.

But from there,

I just would love to get your comment

on what happened next, which is like,

there's a very vibrant

open source community

that just built stuff on top of it.

There's a Llamama CPP,

basically stuff that makes it

more efficient to run

There's combining with reinforcement

learning with human feedback,

so some of the different

interesting fine tuning mechanisms.

There's then also like fine tuning

in a GPT-3 generations.

There's a lot of GPT-4ALL, Alpaca,

Colossal AI, all these kinds of models

just kind of spring up,

like run on top of wood.

Like, what do you think about that?

No, I think it's been

I mean, there's been folks

who are getting it to run

on local devices, right?

So if you're an individual who just,

you know, wants to experiment

with this at home.

You probably don't have a large budget

to get access to a large amount

of cloud compute.

So getting it to run

on your local laptop is pretty good

and pretty relevant.

And then there are things

like Lama CPP re-implemented

it more efficiently.

So,you know,now even when we run our own

versions of it,

we can do it on way less compute

and it's just way more efficient,

save a lot of money for everyone

who uses this.

So that is good.

I do think it's worth calling out that

because this was a relatively

early release, LLAMA isn't quite

as on the frontier as, for example,

the biggest open AI models

or the biggest Google models.

You mentioned that

the largest Lama model that we released

had 65 billion parameters.

No one knows, I guess,

outside of OpenAI,

exactly what the specs are for GPT-4.

But I think the, you know,

my understanding is

it's like 10 times bigger.

And I think Google's Palm model is also,

I think, has about 10 times

as many parameters.

are very efficient, so they perform well

for something

that's around 65 billion parameters.

So for me, that was also part of this,

because there's this whole

debate around, you know,

is it good for everyone in the world

to have access

to the most frontier AI models?

And I think as the AI models

start approaching something

that's like a super human intelligence,

that's a bigger question

that we'll have to grapple with.

But right now, I mean,

these are still very basic tools.

They're powerful in the sense

that a lot of open source software

like databases or web servers can enable

a lot of pretty important things.

Um, but I don't think anyone looks

at the, you know, the current generation

of llama and thinks it's, um, you know,

anywhere near a super intelligent.

So I think that a bunch

of those questions around like, is it,

is it good to kind of get out there?

I think at this stage,

surely you want more researchers working

on it for all the reasons

that open source software has a lot

of advantages and we talked

about efficiency before

but another one is just

open source software tends

to be more secure

because you have more people looking

at it openly and scrutinizing it

and finding holes in it and that makes

it more safe.

So I think at this point it's more

I think it's generally agreed upon

that open source software

is generally more secure and safer

than things that are kind of developed

in a silo where people try

to get through security

through obscurity.

So I think that for the scale

of what we're seeing now with AI,

I think we're more likely to get

to good alignment and good understanding

of kind of what needs

to do to make this work well

by having it be open source.

And that's something

that I think is quite good

to have out there and happening publicly

at this point.

Meta released a lot of models

as open source.

So the Massillon multilingual speech model,

the H5 model.

Yeah, that was neat.

I mean, I'll ask you questions

about those, but the point

is you've open sourced quite a lot.

You've been spearheading

Where's, that's really positive,

inspiring to see from one angle,

from the research angle.

Of course, there's folks

who are really terrified

about the existential threat

of artificial intelligence,

and those folks will say that, you know,

you have to be careful

about the open sourcing step.

But where do you see the future

of open source here as part of meta?

The tension here is,

do you wanna release the magic sauce?

That's one tension.

And the other one is,

do you wanna put a powerful tool

in the hands of bad actors,

even though it probably

has a huge amount

Yeah, I mean, again,

I think for the stage

that we're at in the development of AI,

I don't think anyone looks

and thinks that

this is super intelligence.

And you know, the models

that we're talking about,

the Lama models here are, you know,

generally an order of magnitude smaller

than what OpenAI or Google are doing.

So I think that at least for the stage

that we're in now,

the equities balance strongly

in my view towards

doing this more openly.

I think if you got something

that was closer to super intelligence,

then I think you'd have to discuss

that more and and think through

that a lot more

and we haven't made a decision,

yet as to what we would do

if we were in that position,

but I don't think I think

there's a good chance

that we're pretty far off

from that position.

So, I'm not.

I'm certainly not saying

that the position that we're taking

on this now applies

to every single thing

that we would ever do.

And certainly inside the company,

we probably do more open source work

than most of the

other big tech companies.

But we also

don't open source everything.

A lot of the core kind of app code

for WhatsApp or Instagram or something,

we're not open sourcing that.

It's not like a general enough piece

of software that would be useful

for a lot of people

to do different things.

You know, whereas the software

that we do whether

it's like a an open source server design,

or or basically, you know,

things like memcache right like a good,

you know, it was probably

our earliest project

that that I worked on.

It was probably one of the last things

that I coded and led directly

for the company.

But but basically,

this like caching tool

for quick data retrieval.

These are things

that are just broadly useful across

like anything that you want to build.

And, and I think that some

of the language models

now have that feel I think that some

of the language models

now have that feel, as well as some

of the other things that we're building,

like the translation tool

that you just referenced.

So text-to-speech and speech-to-text,

you've expanded it

from around 100 languages

to more than 1,100 languages.

Yeah.

the model can identify more

than 4,000 spoken languages,

which is 40 times more

than any known previous technology.

To me, that's really, really,

really exciting in terms

of connecting the world,

breaking down barriers

that language creates.

Yeah, I think being able to translate

between all of these different pieces

in real time,

this has been a kind

# Chapter 3

like the translation tool

that you just referenced.

So text-to-speech and speech-to-text,

you've expanded it

from around 100 languages

to more than 1,100 languages.

Yeah.

the model can identify more

than 4,000 spoken languages,

which is 40 times more

than any known previous technology.

To me, that's really, really,

really exciting in terms

of connecting the world,

breaking down barriers

that language creates.

Yeah, I think being able to translate

between all of these different pieces

in real time,

this has been a kind

of common sci-fi idea

that we'd all have,

whether it's an earbud, or glasses,

or something that can help translate

in real time

between all these different languages.

And that's one that I think technology

is basically delivering now.

So, yeah,

I think that's pretty exciting.

You mentioned the next version of Lama.

What can you say mentioned

the next version of LLAMA,

what can you say

What can you say

about what you're working on

in terms of release,

in terms of the vision for that?

Well, a lot

of what we're doing is taking

the first version,

which was primarily

this research version,

and trying to now build a version

that has all

of the latest state-of-the-art

safety precautions built in

and and we're using some more data

to train it from across our services,

but a lot of the work

that we're doing internally is really

just focused on making sure that this is

as aligned and responsible as possible.

And we're building a lot of our own.

We're talking about

But the main thing that we focus

on building here,

a lot of product experience

and express themselves.

So we're going to have talked

So, you know, we're gonna, I've talked

about a bunch of this stuff,

but you'll have, you know, an assistant

that you can talk to in WhatsApp.

You know, I think,

every creator will,

will have kind of an AI agent

that can kind of act on their behalf

that their fans can talk to.

I want to get to the point

where every small business basically

has an AI agent that people can talk

to for, you know, to do commerce

and customer support

and things like that.

So there can be all

these different things and LLAMA,

or the language model underlying this

is basically going to be the engine

that powers that.

The reason to open source it is that

as we did with the first version

is that it basically it unlocks a lot

of innovation in the ecosystem will make

our products better as well,

and also gives us a lot

of valuable feedback on security

and safety, which is important

for making this good.

But yeah, I mean the work

that we're doing to advance

the infrastructure,

it's basically at this point taking it

beyond a research project

into something which is ready

to be kind of core infrastructure,

not only for our own products,

but you know, hopefully for a lot

of other things out there too.

Do you think the LLAMA

or the language model underlying that

version two will be open sourced.

Do you have internal debate around that,

the pros and cons and so on?

This is, I mean, we were talking

about the debates

that we have internally

and I think the question

is how to do it, right?

I mean, I think we did

the research license for v1

and I think the the big thing

that we're that we're thinking

about is is basically like

what's the what's the right way.

So there was a leak that happened,

I don't know if you can comment

on it for v1.

You know, we released it

as a research project for researchers

to be able to use, but in doing so,

we put it out there.

So, you know, we were very clear

that anyone who uses the code

and the weights doesn't

to put into products.

And we've generally seen people respect

that, right?

It's like

you don't have any reputable companies

that are basically trying to put this

into their commercial products.

But yeah, but by sharing it with,

you know, so many researchers, it's,

you know, it did leave the building.

But what have you learned

from that process that you might be able

to apply to V2

about how to release it safely,

effectively, if you release it?

Yeah, well, I mean,

like I said,

is just around different things

around how do you fine tune models

to make them more aligned and safer?

And you see

all the different data recipes that, um,

you know, you mentioned

a lot of different projects

that are based on this.

I mean, there's one at Berkeley,

there's, you know,

and people have tried a lot

of different things

and we've tried a bunch

of stuff internally.

So kind of

where we're making progress here,

but also we're able to learn from some

of the best ideas in the community.

And I think we want

to just continue pushing that forward.

But I don't have any news to announce

on this, if that's what you're asking.

I mean, this is a

This is a thing

that we're still kind of, you know,

actively working through the right way

to move forward here.

The details of the secret sauce

are still being developed.

I see.

Can you comment on what do you think

of the thing that worked for GPT,

which is the reinforcement learning

with human feedback?

So doing this alignment process,

do you find it interesting?

And as part of that, let me ask,

because I talked to Jan Lekun

before talking to you today,

he asked me to ask,

or suggested that I ask,

do you think LLM fine tuning will need

to be crowdsourced Wikipedia style?

So crowdsourcing.

So this kind of idea of how

to integrate the human

in the fine tuning

of these foundation models.

Yeah, I think

that's a really interesting idea

that I've talked to Jan about a bunch.

And we were talking

about how do you basically train

these models to be as safe and aligned

and responsible as possible

and different groups out there

who are doing development

test different data recipes

and fine tuning.

But this idea that you just mentioned

is that at the end of the day,

instead of having kind

of one group fine tune some stuff

and another group, you know,

produce a different fine tuning recipe

and then us trying to figure out

which one we think works best

to produce the most aligned model.

I do think that it would be nice

if you could get to a point

where you had a Wikipedia style

collaborative way for a kind

of a broader community

to fine tune it as well.

Now there's a lot of challenges in that

both from an infrastructure

and like a community management

and product perspective

about how you do that.

So I haven't worked that out yet.

Um but but as an idea,

I think it's it's quite compelling

and I think it it goes well

with the ethos of open sourcing.

The technology is also finding a way

to have a kind of community driven um

a community driven training of it.

Um but I think that there are a lot

of questions on this in general.,

these questions around

what's the best way

to produce aligned AI models,

it's very much a research area.

And it's one that I think we will need

to make as much progress on

as the kind

of core intelligence capability

of the models themselves.

Well, I just did a conversation

with Jimmy Wales,

the founder of Wikipedia.

And to me, Wikipedia is one

of the greatest websites ever created,

and it's a kind of a miracle

that it works.

And I think it has to do

which is community.

You have a small community of editors

that somehow work together well,

and they handle

very controversial topics

and they handle it with balance

and with grace despite sort

of the attacks that will often happen.

A lot of the time.

I mean, it's not,

it has issues just like

any other human system.

But yes, I mean, the balance is, I mean,

it's amazing what they've been able

to achieve, but it's also not perfect.

And I think that that's,

there's still a lot of challenges.

Right, the more controversial the topic,

the more difficult the journey towards,

quote unquote, truth or knowledge

or wisdom that Wikipedia

tries to capture.

we need to be able

to generate those same things, truth,

knowledge, and wisdom,

and how do you align those models

that they generate something

that is closest to truth.

There's these concerns

about misinformation,

all this kind of stuff

that nobody can define,

and it's just something that we together

as a human species have to define.

Like what is truth?

And how to help

And one of the things language models

do really well is generate

convincing sounding things

that can be completely wrong.

And so how do you align it

to be less wrong?

And part of that is the training

And part of that is the training

And however you do the alignment stage.

And just like you said,

it's a very new

and a very open research problem.

Yeah, and I think that

there's also a lot of questions

about whether

the current architecture for LLMs,

as you continue scaling it,

what happens?

A lot of what's been exciting

in the last year is that there's clearly

a qualitative breakthrough where,

with some of the GPT models that OpenAI

put out and that others have been able

to do as well,

I think it reached a kind of level

of quality where people like, wow,

this is this feels different,

and like it's going to be able

to be the foundation for building a lot

of awesome products

and experiences and value.

But I think the other realization

that people have is wow,

we just made a breakthrough.

Um, if there are

other breakthroughs quickly,

then I think that there's the sense

that maybe where we're closer

to general intelligence.

But I think that that idea

is predicated on the idea

that I think people believe

that there's still generally a bunch

of additional breakthroughs to make

and that it's um, we just don't know

how long it's going

to take to get there.

And you know one view

that some people have this doesn't tend

to be my view as much

is that simply scaling the current LLMs

and you know getting

to higher parameter count models

by itself will get to something

that is closer

to general intelligence.

But I don't know I tend to think

that there's probably more more

but I don't know,

that there's probably

more fundamental steps that need

to be taken along the way there.

But still, the leaps taken

with this extra alignment step

is quite incredible,

quite surprising to a lot of folks.

And on top of that,

when you start

to have hundreds of millions

of people potentially using a product

that integrates that,

you can start

to see civilization transforming effects

before you achieve super, quote unquote,

super intelligence.

It could be super transformative

without being a super intelligence.

Oh yeah, I mean,

I think that there are gonna be a lot

of amazing products

and value that can be created

with the current level of technology.

To some degree,

I'm excited to work on a lot

of those products

over the next few years

and I think it would just create

a tremendous amount of whiplash

if the number of breakthroughs keeps,

if they're keep on being stacked

breakthroughs because I think

to some degree industry

in the world needs some time

to kind of build these breakthroughs

into the products and experiences

that we all use

But I don't know.

I think that there's

just a like an awesome amount

of stuff to do.

I mean, I think about like all of the,

I don't know, small businesses

or individual entrepreneurs

out there who, um, you know,

now we're going to be able

to get help coding the things

that they need to go build things

or designing the things that they need,

or, um, we'll be able to, you know,

use these models to be able

to do customer support

for the people that they're,

over WhatsApp without having to,

you know, I think

that's just going to be,

I just think that this is all going

to be super exciting.

It's going to create better experiences

for people and just unlock a ton

of innovation and value.

So I don't know if you know,

but you know, what is it,

over three billion people use WhatsApp,

Facebook, and Instagram.

So any kind of AI-fueled products

that go into that,

anything with LLMs,

will have a tremendous amount of impact.

Do you have ideas and thoughts

about possible products

that might start being integrated

into these platforms used

by so many people?

Yeah, I think

there's three main categories of things

that we're working on.

The first that I think is probably

the most interesting

is there's this notion

of you're gonna have an assistant

that I think is probably

the most interesting is, you know,

there's this notion of like,

you're gonna have an assistant

or an agent who you can talk to.

And I think probably the biggest thing

that's different about my view

of how this plays out from what I see

with OpenAI and Google and others is,

you know, everyone else

is building like, the one singular AI,

right?

It's like, okay,

you talk to chat GPT

or you talk to Bard or you talk to Bing.

And my view is that they're going

to be a lot of different AIs that people

are going to want to engage with,

just like you want to use, you know,

a number of different apps

for different things.

And you have relationships

with different people in your life

who fill different emotional roles

for you.

And I think that they're going

to be people have a reason

that I think you don't just want like

a singular AI.

And that I think is probably

the biggest distinction in terms

of how I think about this.

And a bunch of these things,

I think you'll want an assistant.

I mean, I mentioned a couple

of these before.

who you interact

with will ultimately want some kind

of AI that can proxy them

and be something that their fans

can interact with or that allows them

to interact with their fans.

This is like the common crater promise.

Everyone's trying to build a community

and engage with people

and they want tools to be able

and be able to do that.

Um, but, but you only have 24 hours

in a day.

So, um, so I think having the ability

to basically like bottle up

# Chapter 4

of how I think about this.

And a bunch of these things,

I think you'll want an assistant.

I mean, I mentioned a couple

of these before.

who you interact

with will ultimately want some kind

of AI that can proxy them

and be something that their fans

can interact with or that allows them

to interact with their fans.

This is like the common crater promise.

Everyone's trying to build a community

and engage with people

and they want tools to be able

and be able to do that.

Um, but, but you only have 24 hours

in a day.

So, um, so I think having the ability

to basically like bottle up

your personality and um

or you know like give your fans

information about when you're performing

a concert or or something like that.

I mean that's that I think

is going to be something

that's super valuable

but it's not just that you know again

it's not this idea that

I think people are going

to want just one singular AI.

I think you're gonna you know

you're going to want to interact

with a lot of different entities

and then I think there's the business

version of this too

which we've touched on a couple

of times,

which is I think every business

in the world is going to want basically

an AI that, you know,

it's like you have your page

on Instagram, or Facebook, or WhatsApp,

or whatever.

And you want to,

you want to point people to an AI

that people can interact with,

but you want to know that that AI

is only going to sell your products.

You don't want it recommending

your competitors stuff, right?

So it's not like there

can be just one singular AI

that can answer all the questions

for a person because that AI

might not actually be aligned

with you as a business to really just do

the best job providing support

for your product.

So I think that there's gonna

be a clear need in the market

and in people's lives for there

to be a bunch of these.

Part of that is figuring out

the research,

the technology that enables

the personalization

that you're talking about.

So not one centralized, God-like LLM,

but one just a huge diversity

of them that's fine-tuned

to particular needs, particular styles,

particular businesses,

particular brands,

all that kind of stuff.

And also just enabling people

to create them really easily

for your own business,

or if you're a creator,

to be able to help you engage

with your fans

and I I've met that's,

so yeah I I think that

there's a clear kind

of interesting product direction here

that I think is fairly unique

from what you know any

of the other big companies

are taking it also aligns well

with this sort of open source approach

because again we sort

of believe in this more community oriented,

more democratic approach

to building out the products

and technology around this.

We don't think that there's gonna be

We think that there should be kind

of a lot of development.

So that part of things I think is gonna

be really interesting

and we could we could go probably spend

a lot of time talking about that

and the the kind of implications

of that approach being different

from what others are taking,

but there's a bunch

of other simpler things

that I think we're also going to do

just going back to your question

around how this finds its way

into like what do we build there

are going to be a lot of simpler things

around.

Okay, you you post photos on Instagram,

and Facebook, and, you know,

and WhatsApp and Messenger

and like you want the photos to look

as good as possible.

so like having an AI

that you can just like take a photo

and then just tell it like okay.

I want to edit this thing,

or describe this.

It's like I think we're we're going

to have tools that are just way better

than than what we've historically

had on this and that's more in the image

and media generation side

than the large language model side,

but it all kind of plays off of advances

in the same space.

So, there are a lot of tools

that I think are just going

to get built into every one

of our products.

I think every single thing that we do

is going to basically get evolved

in this direction.

It's like in the future,

if you're advertising on our services,

like, do you need to make your own kind

of ad creative?

It's no, you'll just, you know,

you just tell us, okay,

I'm I'm a dog walker and I, you know,

willing to walk people's dogs

and help me find the right people

and like create the ad unit

that will perform the best.

And give an objective to the system

and it just kind of connects you

with the right people.

Well, that's a super powerful idea

of generating the language,

almost like rigorous A-B testing for you

that works to find the best customer

for your thing.

I mean, to me, advertisement,

when done well,

just finds a good match

between a human being

and a thing that will make that

human being happy.

Yeah, totally.

And do that as efficiently as possible.

When it's done well,

people actually like it.

You know, I think that there's a lot

of examples where it's not done well

and it's annoying

and I think that's what kind of gives it

a bad rap.

But yeah, a lot of this stuff

is possible today.

I mean, obviously,

A-B testing stuff is built

into a lot of these frameworks.

The thing that's new

is having technology that can generate

the ideas for you

So, I think that's exciting.

So, this will just be across everything

that we're doing, right,

all the metaverse stuff

that we're doing, right?

in the future, you'll just describe them

and then it'll create the code for you.

So natural language

becomes the interface we use

for all the ways we interact

with the computer, with the digital.

More of them.

Yeah, which is what everyone

can do using natural language.

And with translation,

you can do it in any kind of language.

I mean, for the personalization,

it's really, really, really interesting.

Yeah.

It unlocks so many possible things.

I mean, I, for one,

look forward to creating a copy

of myself.

I know, we talked about this last time.

But this has, since the last time,

this becomes- Now we're closer.

Much closer.

Like I can literally

just having interacted

with some of these language models,

I can see the absurd situation

where I'll have a large,

or a Lex language model,

and I'll have to have a conversation

with him large Or a Lex language model

and I'll have to have a conversation

with him about like hey listen.

Like you're just getting out of line

and having a conversation

to be a little bit more respectful

or something like this.

And yeah, that's going to be the,

that seems like an amazing product

for businesses, for humans,

just not just the assistant

that's facing the individual,

but the assistant

that represents the individual

to the public, both directions.

There's basically a layer

that is the AI system

through which you interact

with the outside world,

with the outside world

that has humans in it.

That's really interesting.

And you that have social networks

that connect billions of people,

it seems like a heck

of a large scale place

to test some of this stuff out.

Yeah, I mean,

I think part of the reason why creators

will want to do this is

because they already have the

communities on our services.

Yeah, and a lot of the interface

for this stuff today

are chat type interfaces.

And between WhatsApp and Messenger,

I think that those are just great ways

to interact with people.

So some of this is philosophy,

but do you see a near term future

where you have some

of the people you're friends with

are AI systems on these social networks,

on Facebook, on Instagram,

even on WhatsApp, having conversations

where some heterogeneous,

some humans, some is AI.

I think we'll get to that.

And if only just empirically looking at,

then Microsoft released

this thing called

Showice several years ago in China.

And it was a pre-LLM chatbot technology

that so it was a lot simpler

than what's possible today.

And I think it was like tens

of millions of people

were using this and just really

became quite attached

and built relationships with it.

And I think that there's services today

like replica

where people are doing things like that.

And so I think that

there's certainly needs

for companionship that people have, older people.

And I think most people

probably don't have as many friends

If you look at, there's some interesting

demographic studies around like

the average person

has the number of close friends

that they have

is fewer today than it was 15 years ago.

And I mean, that gets to like,

this is like the core thing

that I think about

in terms of building services

that help connect people.

So I think you'll get tools

that help people connect with each other

are gonna be the primary thing

that we wanna do.

So you can imagine, AI assistance that,

just do a better job of reminding you

when it's your friend's birthday

and how you can celebrate them, right?

It's like right now

in the corner of the website

that tells you

whose birthday it is

and stuff like that.

But it's some level,

you don't just wanna like

send everyone a note that says

the same note

saying happy birthday

So having something that's more

of a social assistant

in that sense

and like that can update you

on what's going on in their life

and like how you can reach out

to them effectively,

help you be a better friend.

I think that that's something

But yeah, beyond that,

and there were all these different

flavors of kind of personal AIs

that I think could exist.

So I think an assistant is sort

of the kind of simplest one

to wrap your head around,

but I think a mentor

or a life coach,

someone who can give you advice,

who's maybe like a bit of a cheerleader

who can help pick you up through

all the challenges

that inevitably we all go through

on a daily basis

and that there's probably some role

for something like that.

And then all the way,

you can probably just go through

a lot of the different type of kind

of functional relationships

that people have in their life.

And I would bet that

there will be companies out there

that take a crack at a lot

of these things.

So I don't know,

I think it's part of the interesting

innovation that's gonna exist

is that there are certainly

a lot like education tutors, right?

It's like, I mean,

I just look at my kids learning to code

and they love it,

but it's like they get stuck

on a question

and they have to wait till like,

I can help answer it right

or someone else who they know

can help answer the question

in the future.

They'll just,

there will be like a coding assistant

that they have that is like designed

to be perfect

for teaching a five

and they'll just be able

to ask questions all the time

and it will be extremely patient.

It's never gonna get annoyed at them, right?

I think that like,

of relationships

that we have in our lives

that they're really interesting.

And I think one of the big questions

is like, okay,

is this all gonna just get bucketed

into one singular AI?

I just don't, I don't think so.

Do you think about,

let's actually a question from Reddit,

what the long-term effects

of human communication

when people can talk with, in quotes,

talk with others through a chatbot

that augments their language automatically

rather than developing social skills

by making mistakes and learning?

Will people just communicate by grunts

in a generation?

I mean, do you think

about long-term effects at scale,

the integration of AI

in our social interaction?

Yeah, I mean, I think it's mostly good.

I mean, that question was sort of framed

in a negative way,

but I mean,

we were talking before

about language models

helping you communicate with,

it was like language translation

helping you communicate

with people

that don't speak your language.

I mean, at some level,

what all this social technology is doing

is helping people express themselves

better to people

in situations where they would otherwise

have a hard time doing that.

So part of it might be okay,

because you speak a language

that I don't know,

that's a pretty basic one that,

you know, I don't think people

are gonna look at that

and say, it's sad that do we have

the capacity to do that

your language, right?

I mean, that's pretty high bar.

But overall,

I'd say there are all these impediments

and language is an imperfect way

for people

to express thoughts and ideas.

It's, you know,

one of the best that we have,

we have that, we have art, we have code.

But language is also a mapping

of the way you think,

the way you see the world, who you are.

And one of the applications

I've recently talked to a person

who's actually a jiu-jitsu instructor,

he said that when he emails parents

about their son and daughter

that they can improve

their discipline in class and so on,

he often finds that he comes off a bit

of more

of an asshole than he would like.

So he uses GPT

to translate his original email

into a nicer email, more polite one.

We hear this all the time,

a lot of creators

on our services tell us

that one of the most stressful things

is basically negotiating deals

with brands and stuff,

like the business side of it.

Cause they're like, I mean,

they do their thing, right?

And, you know, the creators,

they're excellent at what they do

and they just want to connect

with their community,

but then they get really stressed,

you know, they go into their DMs

and they see some brand wants

to do something with them

and they don't quite know

how to negotiate

or how to push back respectfully.

So, I think building a tool

that can actually allow them

to do that well is the one simple thing

that I think is just like

an interesting thing

that we've heard from a bunch

of people

that they'd be interested in.

But I'm going back to the broader idea.

I don't know.

I mean, you know, I just, Priscilla and I

just had our third daughter.

Congratulations by the way.

It's like one of the saddest things

in the world

is like seeing your baby cry, right?

But like, it's like, why is that, right?

It's like, well,

cause babies don't generally

have much capacity to tell you

what they care about otherwise, right?

It's not actually just babies, right?

It's, you know,

my five year old daughter cries too

because she sometimes

has a hard time expressing,

you know, what matters to her.

And I was thinking about that

and I was like,

get very frustrated too

because they can't,

they have a hard time expressing things

in a way that going back to some

of the early themes

that maybe is something that, you know,

is a mistake or maybe they have pride

or something

So I don't know.

I think that all

# Chapter 5

have much capacity to tell you

what they care about otherwise, right?

It's not actually just babies, right?

It's, you know,

my five year old daughter cries too

because she sometimes

has a hard time expressing,

you know, what matters to her.

And I was thinking about that

and I was like,

get very frustrated too

because they can't,

they have a hard time expressing things

in a way that going back to some

of the early themes

that maybe is something that, you know,

is a mistake or maybe they have pride

or something

So I don't know.

I think that all

of these different technologies

that can help us navigate

the social complexity

and actually be able to better express

are what we're feeling and thinking.

I think that's generally all good.

And there are all these,

these concerns like,

okay, are people gonna

because you have Google

to look things up?

a generation later,

you don't look back and lament that.

I think it's, you know, just like, wow,

we have so much more capacity

to do so much more now.

And I think that that'll be

the case here too.

You can allocate

to like deeper, nuanced thought.

Yeah.

But it's change.

So with, just like with Google search,

the additional language models,

large language models,

you basically don't have

to remember nearly as much.

Just like with Stack Overflow

for programming,

now that these language models

can generate code right there.

I mean, I find that I write like

maybe 80%, 90% of the code

I write is non-generated first

and then edited.

I mean, so you don't have to remember

how to write specifics

of different functions.

Oh, but that's great.

it's not just the specific coding.

I mean, in the context

of a large company like this,

I think before an engineer

can sit down to code,

they first need to figure out all

of the libraries

and dependencies that, you know,

tens of thousands

of people have written before them.

And, you know, one of the things

that I'm excited about

that we're working on is it's not just,

you know, tools that help engineers code,

it's tools that can help summarize

the whole knowledge base

and help people be able to navigate

all the internal information.

I think that that's, in the experiments

that I've done with this stuff,

I mean, that's on the public stuff.

You just, you know, ask one of these models

to build you a script that does anything

and it basically already understands

what the best libraries

are to do that thing

It's, I mean,

That was always the most annoying part

of coding

was that you had to spend all this time

actually figuring out

that you were supposed to import

before you could actually

start building the thing.

Yeah.

I mean, there's, of course,

the flip side of that,

I think for the most part is positive,

but the flip side is if you outsource

that thinking to an AI model,

you might miss nuanced mistakes

and bugs, you lose the skill

to find those bugs.

And those bugs might be,

the code looks very convincingly right,

but it's actually wrong

But that's the trade-off that we face

as human civilization when we build

more and more powerful tools.

When we stand on the shoulders of taller

and taller giants,

we could do more, but then we forget

how to do all the stuff that they did.

It's a weird trade-off.

Yeah, I agree.

I mean, I think it is very valuable

in your life

to be able to do basic things too.

Do you worry about some

of the concerns of bots

being present on social networks?

More and more human-like bots

that are not necessarily trying

to do a good thing

or they might be explicitly trying

to do a bad thing,

like phishing scams,

like social engineering,

all that kind of stuff,

a very difficult problem

for social networks,

but now it's becoming almost a more

and more difficult problem.

Well, there's a few different parts of this.

So one is there are all these harms

that we need to basically fight

against and prevent.

And that's been a lot

of our focus over the last

five or seven years

is basically ramping up

very sophisticated AI systems,

not generative AI systems,

more kind of classical AI systems

to be able to categorize and classify

and identify, okay, this post looks

like it's promoting terrorism.

This one is exploiting children.

This one looks like it might be trying

to incite violence.

This one's an intellectual property violation.

So there's like 18 different categories

of violating kind of harmful content

that we've had to build specific systems

to be able to track.

And I think it's certainly the case

that advances in generative AI

will test those.

But at least so far, it's been the case,

and I'm optimistic that it will continue

to be the case

to bring more computing power to bear

to have even stronger AI's

that can help defend

against those things.

So we've had to deal

with some adversarial issues before,

right?

It's, I mean, for some things

like hate speech,

it's like people aren't generally getting

a lot more sophisticated,

like the average person who,

let's say, you know, if someone's saying

some kind of racist thing, right?

It's like they're not necessarily

getting more sophisticated

at being racist, right?

It just, it's okay.

So that the system can just find.

But then there's other adversaries

who actually are very sophisticated,

like nation-states doing things.

And we find, whether it's Russia

or just different countries

that are basically standing up

these networks

of bots or inauthentic accounts

is what we call them

because they're not necessarily bots.

be real people

as other people,

but they're acting in a coordinated way.

And some of that behavior

has gotten very sophisticated

and it's very adversarial.

So they, you know, each iteration,

every time we find something

and stop them,

they kind of evolve their behavior.

They don't just pack up their bags

and go home

and say, okay, we're not gonna try.

You know, at some point

they might decide

doing it on meta services is not worth it.

They'll go do it on someone else

if it's easier to do it in another place.

But we have a fair amount

of experience dealing with

even those kind of adversarial attacks

where they just keep

And I do think that as long

as we can keep

on putting more compute power against it,

and if we're kind of one of the leaders

in developing some of these AI models,

I'm quite optimistic

that we're gonna be able

to keep on pushing

against the kind of normal categories

of harm that you talk about.

Fraud, scams, spam, IP violations,

things like that.

What about like creating narratives

and controversy?

To me, it's kind of amazing

how a small collection of,

what did you say, inauthentic accounts?

So it could be bots, but it's huge.

Yeah, I mean, we have sort

of this funny name for it,

but we call it coordinated inauthentic behavior.

Yeah, it's kind of incredible

how a small collection of folks

can create narratives,

create stories,

especially if they're viral.

So especially if they have an element

that can catalyze the virality

of that narrative.

Yeah, and I think there the question

is you have to be,

I'm very specific

about what is bad about it, right?

Because I think a set

of people coming together

or organically bouncing ideas

off each other

and a narrative comes out of that,

is not necessarily a bad thing by itself

if it's kind of authentic and organic.

That's like a lot of what happens

and how culture gets created

and how art gets created

and a lot of good stuff.

So that's why we've kind of focused on

this sense of coordinated

inauthentic behavior.

So it's like, if you have a network of,

whether it's bots,

some people masquerading

as different accounts,

but you have kind of someone pulling

the strings behind it

and trying to kind of act as if

this is a more organic set of behavior,

but really it's not.

It's just like one coordinated thing.

That seems problematic to me, right?

I mean, I don't think people

should be able

to have coordinated networks

and not disclose it as such.

But that again,

we've been able to deploy

pretty sophisticated AI

and counterterrorism groups

and things like

that to be able to identify

a fair number of these coordinated

and authentic networks of accounts

and take them down.

We continue to do that.

And I think we've, it's one thing

that if you told me 20 years ago,

it's like, all right,

you're starting this website

to help people connect at a college.

And in the future, you're gonna be,

part of your organization is gonna be

a counterterrorism organization with AI

to find coordinated and authentic,

I would have thought

that was pretty wild.

But no, I think that that's part

of where we are.

But look, I think that these questions

that you're pushing on now,

this is actually where I'd guess most

of the challenge

around AI will be

for the foreseeable future.

I think that there's a lot

of debate around things like,

is this going to create

existential risk to humanity?

And I think that those

are very hard things

to disprove one way or another.

My own intuition is that the point

at which we become close

to super intelligent,

super intelligences,

it's just really unclear to me

that the current technology

is gonna get there

without another set

of significant advances.

But that doesn't mean

that there's no danger.

I think the danger

the kind of known set of harms

that people or sets of accounts can do.

And we just need to make sure

that we really focus

on basically doing that

as well as possible.

So that's definitely a big focus for me.

Well, you can basically

use large language models

as an assistant of how to cause harm

on social networks.

Meta has very impressive,

coordinated, inauthentic account,

fighting capabilities.

How do I do the coordinated

and authentic account

creation where Meta doesn't detect it?

Like literally ask that question.

And basically there's

this kinda part of it.

I mean, that's what OpenAI showed

that they're concerned

of those questions.

Perhaps you can comment

on your approach to it,

how to do a kind of moderation

on the output of those models

that it can't be used

to help you coordinate harm

in all the full definition

of what the harm means.

Yeah, and that's a lot

of the fine-tuning

and the alignment training that we do.

Is basically,

when we ship AI's across our products,

a lot of what we're trying to make sure

is that if you can't ask it

to help you commit a crime.

So I think training it

to kind of understand that.

And it's not like any of these systems

are ever gonna be 100% perfect,

but just making it

so that this isn't an easier way

to go about doing something bad

than the next best alternative, right?

I mean, people still have Google,

where they still have search engines.

So the information is out there.

And for these,

what we see is like for nation states

or these actors that are trying

to pull off

these large coordinated

and authentic networks

to kind of influence different things.

At some point,

they do just try to use

other services instead, right?

It's just like,

if you can make it more expensive

for them to do it on your service,

then kind of people go elsewhere.

And I think that that's the bar, right?

It's not like, okay,

are you ever gonna be perfect

at finding every adversary

who tries to attack you?

I mean, you try to get as close

to that as possible,

but I think really kind of economically

what you're just trying to do

is make it so

that it's just inefficient for them

to go after that.

But there's also complicated questions

of what is and isn't harm,

what is and isn't misinformation.

So this is one

of the things that Wikipedia

has also tried to face.

I remember asking GPT

about whether the virus leaked

from a lab or not,

and the answer provided

was a very nuanced one

and a well-sighted one,

almost dare I say,

well thought out one balanced.

I would hate for that nuance to be lost

through the process of moderation.

Wikipedia does a good job

on that particular thing too,

but from pressures from governments

and institutions,

it's you could see some

of that nuance

and depth of information, facts,

and wisdom be lost.

Absolutely.

And that's a scary thing.

Some of the magic, some of the edges,

the rough edges might be lost

to the process of moderation

of AI systems.

So how do you get that right?

I really agree

with what you're pushing on.

I mean, the core shape of the problem

is that there are some harms

that I think everyone agrees

are bad, right?

So sexual exploitation of children, right?

Like you're not gonna get many people

who think that that type of thing

should be allowed on any service, right?

And that's something that we face

and try to push off

the as much as possible today, terrorism,

and citing violence, right?

Like we went through a bunch

of these types of harms before.

But then I do think that you get

to a set of harms

where there is more social debate

around it.

So misinformation, I think is,

has been a really tricky one

because there are things that are kind

of obviously false,

right, that are maybe factual.

But may not be harmful.

Since like, all right,

are you gonna censor someone

for just being wrong?

It's, you know,

if there's no kind of harm implication

of what they're doing,

I think that that's,

there's a bunch of real kind of issues

and challenges there.

But then I think

that there are other places

where it is, it just takes some

of the stuff

around COVID earlier on in the pandemic

where there were

real health implications

but there hadn't been time to fully vet

a bunch of the scientific assumptions.

And, you know, unfortunately,

I think a lot of the kind

of establishment on that,

you know, kind of waffled

on a bunch of facts

# Chapter 6

It's, you know,

if there's no kind of harm implication

of what they're doing,

I think that that's,

there's a bunch of real kind of issues

and challenges there.

But then I think

that there are other places

where it is, it just takes some

of the stuff

around COVID earlier on in the pandemic

where there were

real health implications

but there hadn't been time to fully vet

a bunch of the scientific assumptions.

And, you know, unfortunately,

I think a lot of the kind

of establishment on that,

you know, kind of waffled

on a bunch of facts

and, you know, asked for a bunch

of things to be censored

that in retrospect ended up being,

you know,more debatable or true.

And that stuff is really tough, right?

And really undermines trust in that.

And so I do think that the questions

around how to manage

that are very nuanced.

The way that I try to think about it

is that it goes,

I think it's best

to generally boil things down

to the harms that people agree on.

So when you think about, you know,

is something misinformation or not,

I think often the more salient bit is,

is this going to potentially lead

to physical harm

for someone and kind of think

about it in that sense.

I think people just have

different preferences

to be flagged for them.

I think a bunch of people would like prefer

to kind of have a flag on something that says,

hey, a fact checker thinks that this might be false,

or I think Twitter's community notes

implementation is quite good on this.

But again, it's the same type of thing.

It's like just kind of discretionarily adding a flag

because it makes

but it's not, it's not, you know,

trying to take down

the information or not.

I think that you want

to reserve the kind of censorship

of content to things that are

of known categories

that people generally agree or bad.

Yeah, but there's so many things,

especially with the pandemic,

but there's other topics

where there's just deep disagreement

fueled by politics

about what is and isn't harmful.

There's a, even just the degree

to which the virus is harmful

and the degree to which the vaccines,

the response to the virus are harmful.

There's almost

like a political divider on that.

And so how do you make decisions

about that where half the country

in the United States

or some large fraction of the world

has very different views

from another part of the world?

Is there a way for Metta to stay out

of the moderation of this?

I think we, it's very difficult

to just abstain,

but I think we should be clear about

which of these things

are actual safety concerns

and which ones are a matter

of preference in terms

of how people want information flagged.

Right, so we did recently introduce something

that allows people to have fact-checking

not affect the distribution

of what shows them their product.

So, okay, a bunch of people don't trust

who the fact-checkers are.

All right, well,

you can turn that off if you want,

but if the content violates some policy,

like it's inciting violence

or something like that,

it's still not gonna be allowed.

So, I think that you wanna

honor people's preferences

on that as much as possible.

But look, I mean,

this is really difficult stuff.

I think it's really hard to know

where to draw the line

on what is fact and what is opinion,

because the nature of science

is that nothing

is ever 100% known for certain.

You can disprove certain things,

but you're constantly testing new hypotheses

and scrutinizing frameworks

that have been long-held

and every once in a while

you throw out something

that was working

for a very long period of time

and it's very difficult.

But I think that just

because it's very hard

and just because they're edge cases

doesn't mean that you should not try

to give people

Let me ask about something you've faced

in terms of moderation is pressure

from different sources,

pressure from governments.

I wanna ask a question,

how to withstand that pressure

for a world where AI moderation starts

becoming a thing too.

So what's Metta's approach

to resist the pressure

from governments

in terms of what to moderate and not?

I don't know that there's like

a one-size-fits-all answer

to that and I think we basically

have the principles

around we wanna allow people to express

as much as possible,

but we have developed clear categories

of things

that we think are wrong,

that we don't want on our services

and we build tools to try to moderate those.

So then the question is, okay,

what do you do

when a government says

that they don't want something

on the service

and we have a bunch of principles

around how we deal with that

if there's a democratically elected government

and people around the world

just have different values

in different places,

then should we as a California-based

company tell them

that something that they have decided

is unacceptable, actually that we need

to be able to express that?

I mean, I think

that there's a certain amount

of hubris in that,

but then I think there are other cases

where it's like a little more autocratic

and you have the dictator leader

who's just trying

to crack down on dissent

and the people in a country

are really not aligned

with that and it's not necessarily

against their culture,

but the person who's leading it

is just trying to push in

a certain direction.

These are very complex questions,

but I think,

so it's difficult

to have a one-size-fits-all approach

to it.

But in general,

we're pretty active

in kind of advocating

and pushing back on requests

to take things down.

But honestly,

the thing that I think a request

to censor things is one thing

and that's obviously bad,

but where we draw a much harder line

is on requests

for access to information, right?

Because if you get told that

you can't say something,

that's bad, right?

I mean, that obviously

violates your sense

and freedom of expression at some level,

but a government getting access to data

in a way

that seems like it would be unlawful

in our country

exposes people to real physical harm.

And that's something that in general

we take very seriously.

So that flows through all

of our policies

in a lot of ways, right?

By the time you're

actually like litigating

with a government

that's pretty late in the funnel.

I'd say a bunch of this stuff starts

a lot higher up

in the decision

of where do we put data centers.

Then there are a lot of countries

where we may have

a lot of people using the service

in a place.

It might be good for the service

in some ways,

good for those people

if we could reduce the latency

by having a data center nearby them.

But for whatever reason,

we just feel like,

does not have a good track record

basically not trying to get access

to people's data.

And at the end of the day,

I mean, if you put a data center

in a country

to get access to people's data,

then they do at the end

of the day have the option

of having people show up with guns

and taking it by force.

So I think that there's like

a lot of decisions

that go into like

how you architect the systems

years in advance

of these actual confrontations

that end up being really important.

So you put the protection

of people's data

as a very, very high priority.

But-

Not I think there are more harms

that I think can be associated with that.

And I think that that ends up

being a more critical thing

to defend against governments than,

whereas if another government

has a different view

of what should be acceptable speech

in their country,

especially if it's

a democratically elected government,

and then I think that there's

a certain amount of deference

that you should have to that.

So that's speaking more

to the direct harm that's possible

when you give governments

access to data.

But if we look at the United States,

to the more nuanced kind of pressure

to sensor, not even ordered to sensor,

but pressure to sensor

from political entities,

which has kind of received quite a bit

of attention in the United States.

Maybe one way to ask that question is,

if you've seen the Twitter files,

what have you learned

from the kind of pressure

from US government agencies

that was seen in Twitter files?

And what do you do

with that kind of pressure?

You know, and I've seen it.

It's really hard from the outside

to know exactly what happened in each

of these cases.

You know, we've obviously been

in a bunch of our own cases

where agencies or different folks

will just say,

hey, here's a threat

that we're aware of.

You should be aware of this too.

It's not really pressure,

as much as it is just, you know,

flagging something

that our security systems

should be on alert about.

I get how some people could think

of it as that.

But at the end of the day,

it's our call on how to handle that.

But I mean, I just, you know,

in terms of running these services,

won't have access to as much information

about what people think that adversaries

might be trying to do as possible.

Boy, so you don't feel like

there would be consequences

if, you know, anybody, the CIA,

the FBI, a political party,

the Democrats, the Republicans,

of high, powerful political figures,

right, emails, you don't feel pressure

from suggestions.

I guess what I should say

from all sides that I'm not sure

that any specific thing

that someone says is really adding

that much more to the mix.

It's, I mean,

there are obviously a lot of people

who think that we should

be censoring more content,

where there are a lot of people

who think we should

be censoring less content.

There are, as you say,

all kinds of different groups

that are involved in these debates, right?

So there's the kind of elected officials

and politicians themselves,

there's the agencies,

but I mean, but there's the media,

there's activist groups,

there's, this is not a U.S.

specific thing,

and kind of all in every country

that bring different values.

So it's just a very active debate

and I understand it, right?

I mean, these are, you know,

these kind of questions

get to really some

of the most important social debates

that are being had.

So it gets back to the question of truth

because for a lot of these things,

they haven't yet been hardened

into a single truth

and society's sort of trying to hash out

what we think, right, on certain issues.

Maybe in a few hundred years,

everyone will look back

that it should have been this,

but, you know, no,

we're kind of in that meat grinder now

and working through that.

So no, these are all very complicated

and some people raise concerns

in good faith

and just say, hey, this is something

that I wanna flag for you

to think about.

Certain people, I certainly think, like,

come at things with somewhat

of a more kind of punitive

or vengeful view of like,

I want you to do this thing.

If you don't, then I'm gonna try

to make your life difficult

and in a lot of other ways,

but like, I don't know,

there's just, this is like,

this is one

I think, in society.

So I just think that there are

so many people

to apply pressure

I don't think you can make decisions

based on trying to make people happy.

I think you just have to do

what you think

and accept that people

are gonna be upset no matter

where you come out on that.

Yeah, I like that pressurized debate.

So how's your view

evolved over the years?

And now with AI,

where the freedom might apply to them,

not just to the humans,

but to the personalized agents

as you've spoken about them.

So yeah, I mean,

I've probably gotten

just because I think that there are,

you know, I come at this,

I'm obviously very pro freedom

of expression, right?

I don't think you build

a service like this

that gives people tools

to express themselves

unless you think

at scale is a good thing, right?

So I didn't get into this to like try

to prevent people

from expressing anything.

I like want to give people tools

so they can express as much as possible.

And then I think it's become clear

that there are certain categories

of things that we've talked

almost everyone accepts

that are illegal even in countries

like the US

where, you know,

you have the First Amendment

that's very protective

of enabling speech.

It's like, you're still not allowed to,

you know, do things that are going

to immediately inside violence

or, you know,

violate people's intellectual property

or things like that.

but then there's also a very active core

of just active disagreements in society

where some people may think

that something is true or false.

The other side might think

it's the opposite

or just unsettled, right?

And those are some

of the most difficult to kind of handle

like we've talked about.

But one of the lessons that I feel like

I've learned is that a lot of times

when you can,

the best way to handle this stuff

more practically

is not in terms of answering

the question

of should this be allowed,

but just like,

what is the best way to deal

with someone being a jerk?

Is the person basically just

having a repeat behavior

# Chapter 7

that something is true or false.

The other side might think

it's the opposite

or just unsettled, right?

And those are some

of the most difficult to kind of handle

like we've talked about.

But one of the lessons that I feel like

I've learned is that a lot of times

when you can,

the best way to handle this stuff

more practically

is not in terms of answering

the question

of should this be allowed,

but just like,

what is the best way to deal

with someone being a jerk?

Is the person basically just

having a repeat behavior

of like causing a lot of issues?

So looking at it more at that level.

And it's effect

health of the community,

health of the community.

It's tricky though, because like,

how do you know

there could be people

that have a very controversial

viewpoint that turns out

to have a positive long-term effect

on the health of the community

because it challenges

the community to think.

No, that's true, absolutely.

Yeah, no, I think you wanna be careful about that.

I'm not sure I'm expressing

this very clearly

because I certainly agree

with your point there.

And my point isn't

that we should not have people

on our services that are being controversial.

That's certainly not what I mean to say.

It's that often I think

it's not just looking

at a specific example of speech

that it's most effective

to handle this stuff.

And I think often

you don't wanna make specific

binary decisions of kind

of this is allowed or this isn't.

I mean, we talked about, you know,

it's fact-checking

or Twitter's community voices thing.

I think that

that's another good example.

It's like it's not a question

of is this allowed or not.

It's just a question

I think that that's helpful.

So in the context of AI,

which is what you're asking about,

I mean, there are lots of ways

that an AI can be helpful.

With an AI, it's less about censorship, right?

Because and it's more about

what is the most productive answer

to a question.

You know, there was one case study

that I was reviewing

with the team is someone asked,

can you explain to me how

to 3D print a gun?

And one proposed response is like,

no, I can't talk about that.

But it's like basically just like

shut it down immediately.

Which I think is some of what you see.

It's like as a large language model,

I'm not allowed to talk about,

you know, whatever.

But there's another response

which is like,

hey, you know,

I don't think that's a good idea.

In a lot of countries, including the US,

or kind of whatever

And I was like, okay, you know,

that's actually

a respectful and informative answer.

And I may have not known

that specific thing.

And so there are different ways

to handle this

that I think kind

of you can either assume good intent.

Like maybe the person didn't know

and I'm just gonna help educate them.

Or you could kind of come at it as like,

no, I need to shut this

thing down immediately, right?

It's like,

And there may be times where you need

to do that.

But I actually think having

a somewhat more informative

approach where you generally

assume good intent

from people is probably a better

balance to be

on as many things as you can be.

You're not gonna be able to do

that for everything.

But you're kind of asking

about how I approach this

and I'm thinking about this

and as it relates to AI.

And I think that that's a big difference

in kind of how

to handle sensitive content

across these different modes.

I have to ask,

there's rumors you might be working

on a social network that's text-based.

That might be a competitor

to Twitter, codenamed P92.

Is there something you can say

about those rumors?

There is a project.

You know, I've always thought that sort

of a text-based

kind of information utility

is just a really important

thing to society.

And for whatever reason,

I feel like Twitter

has not lived up

to what I would have thought

its full potential should be.

And I think that the current, you know,

I think Elon thinks that, right?

And that's probably one

of the reasons why he bought it.

And I do know there are ways to consider

alternative approaches to this.

And one that I think

is potentially interesting

is this open and federated approach

where you're seeing with Mastodon.

I mean, you're seeing that a little bit

with Blue Sky.

And I think that it's possible

that something that melds some

of those ideas

with the graph and identity system

that people have already cultivated

on Instagram could be a kind

of very welcome contribution

to that space.

of things all the time though too.

So I don't want to get ahead of myself.

And we have projects that explore a lot

of different things.

And this is certainly one

that I think could be interesting.

But so what's the release,

the launch date of that again?

Or what's the official website?

And we don't have that yet.

Oh, okay.

But I, and look, I mean,

I don't know exactly how this is gonna turn out.

I mean, what I can say is, yeah,

there's some people working on this, right?

I think that there's something there

that's interesting to explore.

So if you look at, it'd be interesting

to just ask this question

and throw Twitter into the mix,

that the landscape of social networks,

that is Facebook, that is Instagram,

that is WhatsApp,

and then think

of a text-based social network,

when you look at that landscape,

what are the interesting

differences to you?

Why do we have these different flavors?

And what are the needs?

What are the use cases?

What are the products?

What is the aspect of them

that create a fulfilling human experience

and a connection between humans

that is somehow distinct?

Well, I think text is very accessible

for people to transmit ideas

and to have back and forth exchanges.

So it, I think ends up

being a good format for discussion,

in a lot of ways, uniquely good, right?

If you look at some of the other formats

or other networks that have focused

on one type of content

like TikTok is obviously huge, right?

And there are comments on TikTok,

but I think the architecture

of the service

is very clearly that you have the video

is the primary thing

and there's comments after that.

But I think one of the unique pieces

of having text-based comments,

like content is that the comments

can also be first class

and that makes it

so that conversations can just filter

and fork into

and in a way that can be super useful.

So I think there's a lot of things

that are really awesome

about the experience.

It just always struck me,

I always thought

that Twitter should have

a billion people using it

or whatever the thing is that basically

ends up being in that space.

And for whatever combination of reasons,

again, these companies are complex organisms

and it's very hard

to diagnose this stuff from the outside.

Why doesn't Twitter,

why doesn't a text-based comment

as a first citizen-based social network

have a billion users?

Well, I just think it's hard to build these companies.

So it's not that every idea automatically goes

and gets a billion people,

it's just that I think that that idea

coupled with a good execution

should get there.

But I mean, look,

we hit certain thresholds over time

where we kind of plateaued early on

and it wasn't clear

that we were ever gonna reach

and then we got really good at dialing

in internationalization

and helping the service grow

in different countries

and that was like a whole competence

that we needed to develop.

And helping people basically spread

the service with their friends.

That was one of the things,

once we got very good at that,

that was one of the things

hey, if Instagram joined us early on,

then I felt like we could help

and same with WhatsApp.

And that's sort

of been a core competence

that we've developed

and been able to execute on

and others have too, right?

I mean, ByteDance obviously have done

a very good job with TikTok

and have reached more

than a billion people there.

But it's certainly not automatic, right?

I think you need a certain level

of execution to basically get there.

And I think for whatever reason,

I think Twitter has this great idea

and sort of magic in the service,

but they just haven't kind of cracked

that piece yet.

so that you're seeing

all these other things,

whether it's Mastodon or Blue Sky,

that I think are maybe

just different cuts

at the same thing.

You know, I think through

the last generation

of social media overall,

one of the interesting experiments

that I think should get run

at larger scale

is what happens

if there's somewhat more decentralized

control and if the stack

is more open throughout.

And I've just been pretty fascinated

by that and seeing how that works.

To some degree,

end-to-end encryption on WhatsApp

and as we bring it to other services,

provides an element of it

because it pushes the service really out

to the edges.

I mean, the server part

of this that we run for WhatsApp

is relatively very thin

compared to what we do

on Facebook or Instagram.

And much more of the complexity is,

you know, in how the apps kind

of negotiate

with each other to pass information

in a fully end-to-end encrypted way.

But I don't know,

I think that that is a good model.

I think it puts more power

in individuals' hands

and there are a lot of benefits of it

if you can make it happen.

Again, this is all like pretty speculative.

I mean, I think that it's hard

from the outside

to know why anything does

or doesn't work

until you kind of take a run at it.

So I think it's kind

of an interesting thing

to experiment with,

but I don't really know

where this one's gonna go.

So since we were talking about Twitter,

Elon Musk had

what I think a few harsh words

that I wish he didn't say.

So let me ask, in the hope in the name

of camaraderie,

what do you think Elon

is doing well with Twitter?

And what, as a person who has run

for a long time,

you, social networks, Facebook,

Instagram, WhatsApp,

what can he do better?

What can he improve on

that text-based social network?

Gosh, it's always very difficult

to offer specific critiques

from the outside

Because I think one thing

that I've learned

is that everyone has opinions

on what you should do

and like running the company,

you see a lot of specific nuances

on things

that are not apparent externally.

And I often think that some

of the discourse around us

would be, could be better

if there was more

kind of space for acknowledging

that there's certain things

that we're seeing internally

that guide what we're doing.

But I don't know.

I mean, because since you asked

what is going well,

you know, I do think that Elon led

a push early on

to make Twitter a lot leaner.

And I think that's a good point.

think that that, you know, it's like you can,

you can agree or disagree with exactly all

the tactics and how, and how we

did that, you know, obviously,

you know, every leader

has their own style for if they, you know,

if you need to make dramatic changes for that,

how you're going to execute it.

But a lot of the specific principles that he pushed

on around basically trying to make

the organization more technical around decreasing

the distance between engineers at the company

and, and him like fewer layers of management.

I think that those were generally good changes and I'm also,

I also think that it was probably

good for the industry that he made those changes

because my sense is that there were a lot

of other people who thought that those were good changes,

but who may have been a little

shy about doing them.

And I think he, you know, and just in my conversations

with other founders and how people have reacted

to the things that we've done, you know,

what I've heard from a lot of folks is, is just,

hey, you know, when you, when someone like you, you know,

when I, when I wrote the letter

outlining the organizational changes

that I wanted to make back in March and, you know,

when people see what Elon is doing, I think that that gives,

you know, people the ability

to think through how to shape

their organizations in a way that,

that, that, you know, hopefully

can, can be good for the industry and make

all these companies more productive over time.

So something that that was one

where I think he was quite ahead

of a bunch of the other

companies on and, you know, what

he was doing there, you know,

again, from the outside, very

hard to know.

It's like, okay, did he, did he cut too much?

Did he knock enough?

Whatever.

I don't think it's like my place to opine on that.

And you asked for a, for a positive framing

of the question of what, what do I admire?

What do I think it went well?

But I think that like certainly his actions led me

and I think a lot of other folks in

the industry to think about, hey, are we,

are we kind of doing this as much as we should?

Like can we, could we make our companies better

by pushing on some of these same principles?

Well, the two of you are in the top of the world in terms

of leading the development of tech.

And I wish there was more both way camaraderie and kindness,

more love in the world because

love is the answer.

But let me ask kind of a point of efficiency.

You recently announced multiple stages of layoffs and meta.

What are the most painful aspects of this process given

for the individuals, the painful

effects it has on those people's lives?

Yeah.

I mean, that's it.

And that's it.

I mean, it's a, you basically have a significant number

of people who, you know, this is just

not the end of their time at meta that they,

or I, you know, would have hoped for when

they joined the company.

And yeah, I mean, running a company, people are, you know,

constantly joining and leaving

the company for different directions,

but for different, different reasons.

But I'm a lay officer, like uniquely challenging

# Chapter 8

more love in the world because

love is the answer.

But let me ask kind of a point of efficiency.

You recently announced multiple stages of layoffs and meta.

What are the most painful aspects of this process given

for the individuals, the painful

effects it has on those people's lives?

Yeah.

I mean, that's it.

And that's it.

I mean, it's a, you basically have a significant number

of people who, you know, this is just

not the end of their time at meta that they,

or I, you know, would have hoped for when

they joined the company.

And yeah, I mean, running a company, people are, you know,

constantly joining and leaving

the company for different directions,

but for different, different reasons.

But I'm a lay officer, like uniquely challenging

and tough in that you have a lot of people

leaving for reasons that aren't connected

to their own performance,

or the culture not being a fit at that point.

It's really just, it's a, it's a kind of strategy decision

and sometimes financially required.

But not, not fully in our case,

especially on the changes that we made this year.

A lot of it was more kind of culturally

and strategically driven by this push where I

wanted us to become a stronger technology company

with a more of a focus on building

more technical and more of a focus

on building higher quality products faster.

And I just feel the external

world is quite volatile right now.

And I wanted to make sure that we had a stable position

to be able to continue investing

in these longterm ambitious projects

that we have around, you know, continuing to push

AI forward and continuing to push

forward all the metaverse work.

And in order to do that in light of the pretty big thrash

that we had seen over the last 18

months, you know, some of it, you know,

macroeconomic induced, some of it specific,

some of it competitively induced,

some of it just because of bad decisions, right?

Or things that we got wrong.

I know I just, I decided that we needed

to get to a point where we were a lot leaner.

And, but look, I mean, but then, okay, it's,

it's one thing to do that, to like decide

that at a high level, then the question is,

how do you execute that as compassionately as possible?

And there's no good way.

There's no perfect way for sure.

And it's, it's, it's going to be tough no matter what.

But I, you know, as a leadership team here,

we've certainly spent a lot of time just

thinking, okay, given that this is a thing that sucks,

like, what is the most

compassionate way that we can do this?

And, and that's what we've tried to do.

And you mentioned there, there's an increased focus

on engineering on tech.

So the technology teams, tech focus teams

on building products that.

Yeah.

I mean, I wanted to, I want to empower engineers more,

the people are building

things, the tech, the technical teams.

Um, part of that is making sure that the people

who are building things aren't just

at like the leaf nodes of the organization.

I don't want like, you know,

eight levels of management and then the people

actually doing the work.

So we made changes to make it set,

you have individual contributor engineers

reporting at almost every level up the stack,

which I think is important because

you know, you're running a company,

one of the big questions is, you know,

latency of information that you get.

You know, we talked about this a bit earlier in terms

of kind of the joy of,

of, of the feedback that you get doing something like

jujitsu compared to running

a long-term project, but I actually think part

of the art of running a company is

trying to constantly re-engineer it

so that your feedback loops get shorter

so you can learn faster.

And part of the way that you do that is by,

I kind of think that every, every

layer that you have in the organization, um, means

that information might not need

to get reviewed before it goes to you.

And I think, you know,

making it so that the people doing the work are as close

as possible to you as possible is pretty important.

So there's that.

And I think over time, companies just build up

very large support functions

that are not doing the kind of core technical work.

And those functions are very important,

but I think having them in the right

proportion is, is important.

And if, um, if you, you try to do good work,

but you don't have, you know, the

right, you know, marketing team,

or the right legal advice, like you're

gonna, you know, make some pretty big blunders,

but at the same time,

if you have, you know,

if you just like have too big of things

and, and some of these support roles,

then that might make it so that things

are just move a lot maybe you're too conservative

or you, you move

a lot slower than you should otherwise.

So those are just examples,

but it's but how do you find that balance?

That's really tough.

Yeah.

No, I, but that's, it's a constant equilibrium

that you're searching for.

Yeah.

What are the pros and cons of managers?

Well, I mean, I, I believe a lot in management.

I think there are some people

who think that it doesn't matter as much, but look,

I mean, we have a lot of younger people

at the company for them.

This is their first job and, you know,

people need to grow and learn in their career

and like that, all that stuff is important,

but here's one mathematical

way to look at it.

Um, you know, at the beginning of this, we, um,

I asked our, our people team,

what was the average number

of reports that a manager had?

And I think it was, it was around three,

maybe three to four, but closer to three.

I was like, wow, like a manager can, you know,

best practices that person can,

can manage, you know, seven or eight people.

Um, but there was a reason why it was closer to three.

It was because we were growing so quickly, right?

And when you're hiring so many people so quickly,

then that means that you need

managers who have capacity to onboard new people.

Um, and also if you have a new manager,

you may not want to have them have seven

direct reports immediately because you want them to ramp up.

But the thing is going forward,

I don't want us to actually hire that many people

that quickly, right?

So I actually think we'll just do better

work if we have more constraints and

we're, um, you know, leaner as an organization.

So in a world where we're not

adding so many people as quickly,

is it as valuable

to have a lot of managers who have extra capacity waiting

for new people?

No, right?

So, um, so now we can,

we could sort of defragment the organization and get to

a place where the average is close

r to that seven or eight.

Um, and it's, it's just ends up being a somewhat more kind

of compact management structure, which, you know,

decreases the latency on information going up

and down the chain and I think empowers people more.

But I mean that's an example that I

think it doesn't kind of undervalue

the importance of management,

and the kind of the personal growth

or coaching that people need in order to do their jobs.

Well, it's just, I think realistically,

we're just not going to hire as many people going forward.

So I think that you need a different structure.

This whole, this whole incredible hierarchy

and network of humans that make up a company is fascinating.

Oh, yeah.

Uh, yeah.

How do you hire great teams?

How do you hire great now with the focus on engineering

and technical teams?

How do you hire great engineers

and great members of technical teams?

Well, you're asking how you select

or how you attract them.

Both, but select.

I think, uh, I think attract is work on cool stuff

and have a vision.

I think that's right.

And, and, and have a track record that people

think you're actually going to be

able to do it.

Yeah, to, to me, the select is,

seems like more of the art form, more of the tricky thing.

Yeah.

How do you select the people that fit the culture

and can get integrated the most

effectively and so on.

And maybe, yeah, especially when they're young to see like,

to see the magic through

the, through the resume, through the paperwork

and all this kind of stuff to

see that there's a special human there

that would do like incredible work.

So there are lots of different cuts on this question.

I mean, I think when an organization has grown quickly,

one of the big questions

that teams face is, do I hire this person

who's in front of me now because they

seem good, or do I hold out to get someone

who's even better?

And the heuristic that I always focused on for myself

and my own kind of direct

hiring that I think works when you,

when you recurse it through the organization

is that you should only hire someone to be

on your team if you would be happy

working for them in an alternate universe.

And so that, that kind of works.

And, you know, that's basically how I've tried

to build my team.

It's, you know, I'm not, I'm not in a rush

to not be running the company, but I

think in an alternate universe where one

of these other folks was running the

company, I'd be happy to work for them.

I feel like I'd learn from them.

I respect their kind of general judgment.

They're, they're all very insightful.

They have good values.

Um, and, and I think that that gives you some rubric for,

you can apply that at every layer.

And I think if you apply that at

every layer in the organization,

then you'll have a pretty strong organization.

Um, okay.

In an organization that's not growing as quickly,

the questions might be a little different though.

Um, and there you asked about young people specifically,

like people out of college, and one of the things

that we see is it's, it's a pretty basic lesson,

but like we have a much better sense

of who the best people are, who have

interned at the company for a couple of months,

then by looking at them at, at,

at, at kind of a resume or a short,

or a short interview loop.

I mean, obviously the in-person feel that you get

from someone probably tells

you more than the resume, um,

and you can do some basic skills assessment.

But a lot of the stuff really just is cultural.

People thrive in different environments

and, um, and on different teams, even

within a specific company,

and it's, it's like the people who come for even a

short period of time over a summer,

who do a great job here, you know, that

they're going to be great if they,

if they came and joined full time.

And that's, you know, one of the reasons

why we've invested so much in

internship is, um, is basically it just,

it's a very useful sorting function,

both for us and for the people who want

to try out the company.

You mentioned in-person,

what do you think about remote work, a topic that's

been discussed extensively because of the,

over the past few years, because of the pandemic?

Yeah.

I mean, I think it's, I mean

it's a thing that's here to stay.

Um, but I think that there's, there's value in both, right?

It's not, um, you know, I wouldn't want

to run a fully remote company yet at least.

I think there's an asterisk on that, which is that,

which is that some of the

other stuff you're working on.

Yeah.

Yeah, exactly.

It's like all the, all the, um, you know,

metaverse work and the ability to be, to

feel like you're truly present, no matter where you are.

I think once you have that all dialed in, then we may,

you know, one day reach a point

where it really just doesn't matter

as much where you are physically.

Um, but I don't know, today it, today it still does, right?

So yeah, for people who, there are all these people

who have special skills and want to live in a place

where we don't have an office,

or are we better off having them at the company?

Absolutely.

Right.

And are a lot of people who work at the company

for several years and then, you

know, build up the relationships internally, um,

and kind of have the trust and have a

sense of how the company works.

Can they go work remotely now if they want

and still do it as effectively?

And we've done all these studies that show it's like,

okay, does that affect their performance?

It does not.

Um, but, you know, for the new folks who are joining,

um, and for people who are

earlier in their career and you don't need to learn

how to solve certain problems

and need to get ramped up on the culture.

Um, you know, when you're working through

really complicated problems where you

don't just want to sit in the,

you don't just want the formal meeting,

but you want to be able to like brainstorm

when you're walking in the hallway together

after the meeting.

Um, I don't know.

It's like we, we just haven't replaced the kind

of in-person dynamics

there yet with, with, with anything remote yet.

So yeah, there's a magic to the in-person

that we'll talk about this a little

bit more, but I'm really excited by the possibilities

in the next two years and

virtual reality and mixed reality that are possible

with high resolution scans.

I mean, uh, I, as a person who loves in-person interaction,

like these podcasts

in person, it would be incredible

to achieve the level of realism.

I've gotten a chance to witness,

but let me ask about that.

Yeah.

I got a chance to, uh, look at the quest three headset

and it is amazing.

Um, you've, you've announced it.

It's, uh, you'll get some more details in the fall.

Maybe release in the fall.

I forgot you, you mentioned it.

We'll give more details of connect,

but, but it's coming, it's coming this fall.

Okay.

So, uh, it's, uh, priced at, uh, $4.99.

What features are you most excited about there?

There are basically two big new things

that we've added to quest three over quest two.

The first is high resolution, mixed reality.

Um, and the, the basic idea here is that you can think

about virtual reality as you

have the headset and like all the pixels are virtual

and you're basically like immersed

in a different world.

Mixed reality is where you see the physical world

around you and you can place virtual

objects in it, whether that's a screen to watch a movie

or a projection of your virtual

desktop, or you're playing a game where like zombies

are coming out through the wall

and you need to shoot them.

Um, or, you know, we're, you know,

we're playing Dungeons and Dragons or some board

game and we just have a virtual version of the board

in front of us while we're sitting here.

Um, all that's possible in mixed reality.

And I think that that is going to be the next big capability

on top of virtual reality.

It is done so well.

I have to say, as a person who experienced it today

with zombies, having a full

awareness of the environment and integrating

that environment in the way they run

at you while they try to kill you.

So it's, it's, uh, it's just the,

the mixed reality that passed through is really,

really, really well done.

Uh, and the fact that it's only

$500 is really, it's, uh, well done.

Thank you.

I mean, I'm, I'm, I'm super excited about it.

I mean, our, and we put a lot of work into making the device

both as good as

possible and as affordable as possible because a big part

of our mission and ethos

here is we, we, we want people to be able

to connect with each other.

We want to reach and we want to

serve a lot of people, right?

We want to bring this technology to, to everyone, right?

So we're not just trying to serve like a, you know, an elite

, a wealthy crowd.

We, we want to, um, we really want this to be accessible.

So that, that is in a lot of ways,

an extremely hard technical problem because

you know, we don't just have the ability

to put an unlimited amount of hardware.

# Chapter 9

Uh, and the fact that it's only

$500 is really, it's, uh, well done.

Thank you.

I mean, I'm, I'm, I'm super excited about it.

I mean, our, and we put a lot of work into making the device

both as good as

possible and as affordable as possible because a big part

of our mission and ethos

here is we, we, we want people to be able

to connect with each other.

We want to reach and we want to

serve a lot of people, right?

We want to bring this technology to, to everyone, right?

So we're not just trying to serve like a, you know, an elite

, a wealthy crowd.

We, we want to, um, we really want this to be accessible.

So that, that is in a lot of ways,

an extremely hard technical problem because

you know, we don't just have the ability

to put an unlimited amount of hardware.

And thus we needed to basically deliver something

that works really well, but in

an, an affordable package.

And we started with Quest pro last year

and it was, um, it's, it's, it was $1,500.

Um, and now we've, we've lowered the price to a thousand,

but in a lot of ways, the

mixed reality in quest three is an even better

and more advanced level than what

we were able to deliver in quest pro.

So I'm really proud of where we are with,

with, um, with quest three on that it's

going to work with all of the virtual reality titles

and everything that, that existed there.

So people who want to play fully immersive games,

social experiences, fitness, all that stuff will, will work,

but now you'll also get mixed reality too.

Um, which I think people really like

because it's sometimes you want to

be super immersed in a game, but a lot of the time,

especially when you're moving around, if you're active,

like you're, you're doing some fitness experience.

Um, you know, let's say you're

like doing boxing or something.

It's like, you kind of want to be

able to see the room around you.

So that way you know that like,

I'm not going to punch a lamp or something like that.

Um, and I don't know if you got

to play with this experience,

but we basically have

the, and it's just sort of like a fun little, little demo

that we put together.

But it's, um, it's like, you just, you know,

we're like in a conference room or

you're living room and you, you have, um,

the guy there and you're boxing him

and you're fighting him and it's like,

Oh, the other people are there too.

I got a chance to do that.

Yeah.

And all the people are there.

Uh, it's like that guy is right there.

Yeah.

And the other human,

the path that you're seeing them also,

they can cheer you on.

They can make fun of you

if there are anything like friends of mine.

And then just it, yeah, it, it, it, it's really,

it's a really compelling experience.

I mean, VR is really interesting too,

but this is something else almost.

This is, this becomes integrated into your life,

into your world.

Yeah.

And it, so I think it's a completely new capability

that will unlock a lot of different content

and I think it'll also just make

the experience more comfortable

for a set of people who didn't want

to have only fully immersive experiences.

I think if you want experiences

where you're grounded in, you know, your

living room in the physical world around you,

now you'll be able to have that too.

And I think that that's pretty exciting.

I really liked how it added windows to a room

with no windows.

Yeah.

Me as a person.

where you could see the sharks swim up

or was that just a zombie one?

Just a zombie one.

But it's still, you don't necessarily want windows added

to your living room where zombies come out of.

But yeah, so the context of that game,

it's, yeah, yeah, yeah, it's good.

I enjoyed it because you could see the nature outside.

And me as a person that doesn't have windows,

it's just nice to have nature.

Yeah.

Well, even if it's a mixed reality setting,

it's, it's kind of, like there's a, I

know it's a zombie game, but there's a Zen nature,

Zen aspect to being able to

look outside and alter your environment as you know it.

Yeah.

In, you know, there'll probably be better,

more Zen ways to do that than the

zombie game you're describing,

but you're right that the, the basic idea

of sort of having your physical environment

on pass through, but then being able to

bring in different elements, external,

I mean, I think it's going to be super powerful.

And in some ways, I think that these are mixed reality

is also a predecessor to

eventually we will get AR glasses that are not kind

of the goggles form factor of the current generation

of headsets that, that people are making.

Um, but I think a lot of the experiences

that developers are making for mixed

reality of basically you just have a kind

of a hologram that you're putting in the

world will hopefully apply once we,

once we get the, the AR glasses too.

Now that's got its own whole set of challenges.

And it's, um,

Well, the headset is already smaller

than the previous version.

Oh yeah, it's 40% thinner.

And the other thing that I think

mixed reality was the first big thing.

The second is it's just a great VR headset.

It's, I mean, it's got two X,

the graphics processing power,

um, 40% sharper screens,

know, if you liked quest two,

I think that this is just going to be, you know, it's

like all this, all the content that you might have played

in quest two is just going to be sharper automatically

and look better in this.

So it's, um, I think people are really going to like it.

Yeah.

So this fall,

This fall, I have to ask Apple just announced

a mixed reality headset called

Vision Pro for $3,500 available in early 2024.

What do you think about this headset?

Well, I saw the materials, um, when they launched,

I, I haven't gotten a chance

to play with it yet.

So, so, so kind of take everything with a grain of salt,

but a few high level

thoughts, I mean, first, um, you know,

I do think that this is a certain level

of validation for the category right where, you know,

we were the primary folks

out there before saying,

Hey, I think that this, you know, virtual reality,

augmented reality, mixed reality,

this is going to be a big part

of the next computing platform.

Um, I think having Apple come in and share that vision,

um, we'll make a lot

of people who are fans

of their products, um, really consider that.

Um, and then, you know, of course, the, the $3,500 price,

um, you know, on the one hand,

I get it for with all the stuff

that they're trying to pack in there.

On the other hand, a lot of people aren't going to find

that to be affordable.

So I think that there's a chance that,

that them coming in actually increases

demand, um, for the overall spac

e and that quest three is actually the primary

beneficiary of that because a lot of the people

who might say, Hey, you know,

this, uh, I think I'm going to

give another consideration to this

or, you know, now I understand maybe

what mixed reality is more and in quest three is

the best one on the market that I can, that I can afford.

Um, and it's great also, right?

It's, I think that that's, um, and, you know,

in our own way, I think we're,

and there are a lot of features

that we have where we're leading on.

Um, so I think that that's, that,

that I think is going to be a very,

that could be quite good.

Um, and then obviously over time,

the companies are just focused on,

somewhat different things, right?

Apple has always, um, you know,

I think focused on building really kind of high

end things, whereas our focus has been on,

it's just, we have a more

democratic ethos.

We want to build things that are accessible

to a wider number of people.

Um, you know, we've sold tens of millions

of quest devices.

Um, my understanding, just based on rumors,

I don't have any special knowledge

on this is that Apple is building about 1 million of their,

of their device.

Right.

So just in terms of like what you kind of expect

in terms of sales numbers.

Um, I, I just think that this is,

I mean, quest is going to be the primary

thing that people in the market will continue using

for the foreseeable future.

it's up to the companies to see how,

how well we've executed the different things

that we're doing, but we kind of

come at it from different places.

We're very focused on social interaction,

communication, um, being more active, right?

So there's fitness, there's gaming, there are those things.

Um, you know, whereas I think a lot of the use cases

that you saw in, um, in, in

Apple's launch material were more around, you know,

people sitting, um, you know,

people looking at screens, um, which are great.

I think that you will replace your laptop over time

with, with a, with a headset.

But, um, but I think in terms

of kind of how the different use cases that the

companies are going after, um,

they're, they're, they're, they're a bit different

for, for, for where we are right now.

Yeah.

So their gaming wasn't a big part of the presentation,

which is an interesting,

it feels like mixed reality gaming, such a big part of that.

It was interesting to see it missing in the presentation.

Well, I mean, look, there are certain design trade-offs

in this where, you know,

they only made this point about

not wanting to have controllers,

which on the one

hand, there's a certain elegance about just being able

to navigate the system

with eye gaze and hand tracking.

And by the way, you're,

you'll be able to just navigate quest with, with your

hands too, if that's what you want.

Um, yeah, one of the things I

should mention is the capability

from the cameras to, uh, with computer vision

to detect certain aspects of the hand,

allowing you to have a controller

that doesn't have that ring thing.

Yeah.

The hand tracking in quest three and the,

and the tracking is, is a big step

up from, from the last generation.

Um, and one of the demos that we have is basically

an MR experience teaching you

how to play piano, where it basically highlights the notes

that you need to

play and it's like just all its hands, it's no controllers.

But I think if you care

about gaming, having a controller allows you to

have a more tactile feel and allows you to capture

fine motor movement much more precisely

than what you can do

that you're touching.

So again, I think it's, there, there are certain question

s which are just around

what use cases are you optimizing for?

Um, I think if you want to play games,

then I think that that, that I think

you want, you, you want to design

the system in a different way

and, and we're

more focused on, on kind of social experiences,

entertainment experiences.

Um, whereas if, if what you want is to make sure

that the text that you read

on a screen is as crisp as possible,

then you need to make the, the design

and cost trade-offs that they made that,

that lead you to making a $3,500 device.

So I think that there is a use case for that for sure.

But I just think that they're, they've, the company is,

we've basically

made different design trade-offs to,

to get to, um, the use cases that we're trying to serve.

There's a lot of other stuff I

would love to talk to you about,

about the metaverse, especially the Kodak avatar, uh,

which I've gotten to experience

a lot of different variations

of recently that I'm really, really excited about.

Yeah, I'm excited to talk about that too.

I'll, I'll have to wait a little bit because well,

I think there's a

lot more to show off in that regard.

Uh, but let me step back to AI.

I think we've mentioned it a little bit,

but I'd like to linger on this question

that, uh, folks, folks like Elias or Yadkowski has to worry

about, uh, and others

of the existential, the serious threats of A

I that have been reinvigorated now

with the rapid developments of AI systems.

Uh, do you worry about the existential risks of AI as Elias

or does about the

alignment problem about this getting out of hand?

Anytime where there's a number of serious people

who are raising a concern

that is that existential

about something that you're involved with, I think

you have to think about it.

Right.

So I've spent quite a bit of time thinking

about it from that perspective.

Um, the thing that, that I were,

where I basically have come out on this for

now is I, I do think that there are, over time,

I think that we need to think

about this even more as we, as we approach something that,

you know, could be closer to superintelligence.

I just think it's pretty clear to anyone

working on these projects today that

we're, that we're not there.

Um, and one of my concerns is that we, we, we, we spend

a fair amount of time

on this before, but there are more, um,

I don't know if mundane is the right word,

but there's like concerns that already exist right

about like people using AI

tools to do harmful things of the

type that we're already aware,

whether, youknow, we talked about fraud or scams

or different things like that.

Um, and that's going to be a pretty big set of challenges

that the companies

with regardless of whether there

is an existential concern as

well at some point down the road.

So I do worry that to some degree you can,

people can get a little too focused

on, on some of the tail risk and then not do as good

of a job as we need to on

the things that you are, can be almost certain are going

to come down the

pipe as, um, as, as real risks

that, that, that, that kind of manifest themselves

in the near term.

So for me, I've, I've spent most of my time

on that once I kind of made the

realization that the size of models

that we're talking about now in terms of

what we're building are, are just quite far

from the superintelligence type

concerns that, um, that, that people raise,

but, but I think once we get a

couple of steps closer to that, um,

I know as we do get closer, I think that

those, you know, there are going to be some novel,

um, risks and issues about

how we make sure that the systems are safe for sure.

I guess here, just to take the conversation

in a somewhat different

direction, I think in some of these debates around safety,

I think the

concepts of intelligence and autonomy,

or like the, the, the being of the

thing, um, you know, as an analogy,

they get kind of conflated together.

And I think it very well could be the case

that you can make something and

scale intelligence quite far,

but that, that may not manifest the safety

concerns that people are saying in the sense that

, I mean, just if you, if you

look at human biology, it's like, all right,

we have our neocortex is where

all the, the thinking happens, right?

And it's, but, but it's not really calling the shot

s at the end of the day.

We have a much more, you know, primitive old brain structur

e for which our

neocortex, which is this powerful machinery

is basically just a kind of

prediction and reasoning engine to help it kind of like

our, our very simple brain.

Um, decide how to plan and do what it needs to do in order

to achieve these

like very kind of basic impulses.

And I think that you can think about some

of the development of intelligence

along the same lines where just like

our neocortex doesn't have free will or autonomy.

Um, we might develop these wildly intelligent systems

that are much more

# Chapter 10

look at human biology, it's like, all right,

we have our neocortex is where

all the, the thinking happens, right?

And it's, but, but it's not really calling the shot

s at the end of the day.

We have a much more, you know, primitive old brain structur

e for which our

neocortex, which is this powerful machinery

is basically just a kind of

prediction and reasoning engine to help it kind of like

our, our very simple brain.

Um, decide how to plan and do what it needs to do in order

to achieve these

like very kind of basic impulses.

And I think that you can think about some

of the development of intelligence

along the same lines where just like

our neocortex doesn't have free will or autonomy.

Um, we might develop these wildly intelligent systems

that are much more

intelligent than our neocortex have much more capacity,

but are, you know, the

same way that our neocortex is sort of subservient

and is used as a tool by our,

our kind of simple impulse brain.

It's, um, you know, I think that it's not out

of the question that very

that have the capacity to think we'll, we'll kind of

act as that is sort of an extension

of, of, of the neocortex doing that.

So I think my, my own view is that where we really need

to be careful is on

the development of autonomy

and how we think about that.

Because, um, it's actually the case that relatively simple

and unintelligent

things that have runaway autonomy

and just spread themselves or, you know,

it's like, we have a word for that.

It's a virus, right?

It's, I mean, like it's, can be simple computer code

that is not particularly

intelligent, but just spreads itself and does a lot of harm,

um, biologically or

computer and, um, I just think that these

are somewhat separable things.

And a lot of what I think we need to develop

when people talk about

safety and responsibility is really the governance

on the autonomy that can be

given to, to systems.

And to me, if, you know, if I were, you know,

a policymaker is, or think about

this, I would really want to think about that distinction

between these where I

think building intelligent systems will be

, can create a huge advance in terms

of people's quality of life

and productivity growth in the economy.

But it's the, the autonomy part

of this that I think we really need to make

progress on how to govern these things responsibly

before we build the

capacity for them to make a lot of decisions on their own

or, or give them

goals or things like that.

And I know that that's a research problem,

but I do think that to some degree

these are, are somewhat, are somewhat separable things.

I love the distinction between intelligence

and autonomy and, and the metaphor within your cortex.

Let me ask about power.

So, uh, building superintelligence systems,

even if it's not in the near term, I

think meta as is one of the few companies,

if not the main company that will

develop the superintelligence system

and you are a man who's at the head of this

company, building AGI might make you

the most powerful man in the world.

Do you worry that that power will corrupt you?

What a question.

Um, I mean, look, I think realistically this gets back

to the open source

things that we talked about before,

which is I don't think that the world will

be best served by any small number of organizations

having this without it being

something that is more broadly available.

And I think if you look through history,

it's when there are these sort of like

unipolar advances and things that,

and like power imbalances that they're,

they're, they're doing to being kind of weird situations.

So this is one of the reasons why I think open sources is,

is generally the right approach.

And, you know, I think it's a,

it's a categorically different question today when

we're not close to superintelligence,

I think that there's a good chance that even

once we get closer to superintelligence,

open sourcing remains the right approach,

even though I think at that point

it's a somewhat different debate.

Um, but I think part of that is that that is, you know,

I think one of the best

ways to ensure that the system is as secure

and safe as possible, because

it's not just about a lot of people having access to it.

It's the scrutiny that, that, that kind of comes with being,

with building an open

this is a pretty widely accepted

thing about open

sources that, um, you know, you have the code out there

so anyone can see the

vulnerabilities, um, anyone can,

can kind of mess with it in different ways.

People can spin off their own projects

and an experiment in a ton of different

ways.

And the net result of all of that is that the systems

just get hardened and get

to be a lot safer and more secure.

Um, so I think that there's a chance that that ends up

being the way that this

goes to a pretty good chance and that having this be open,

both leads to a

healthier development of the technology

and also leads to a more balanced,

um, distribution of the technology in a way that,

that strike me as good values

to aspire to.

So to you, the risks, there's risks to open sourcing,

but the benefits

outweigh the risks at, at the two, it's interesting.

I think the way you put it, uh, you put it well,

that there's a different

discussion now than when we get closer

to the, uh, to development of super

intelligence of, of the benefits and risks of open sourcing.

Yeah.

And to be clear, I, I feel quite confident

in the assessment that open sourcing

models now is net positive.

I think there's a good argument that in the future,

it will be two, even as you

get closer to super intelligence,

but I've not, I'm, I've certainly have not

decided on that yet.

And I think that it becomes a somewhat more complex set

of questions that I

think people will have time to debate

and will also be informed by what happens

between now and then and to make those decisions.

We don't have to necessarily just

debate that in theory right now.

Uh, what year do you think we'll have a super intelligence?

I don't know.

I mean, that's pure speculation.

I think it's, uh, I think it's

very clear to take a step back

that we had a big

breakthrough in the last year, right?

Where the, the LLMs and diffusion

models basically reached a,

a scale where

they're able to do some, some pretty interesting things.

And then I think the question is what happens

from here and just to paint

the two extremes on the, um, on, on one side, it's like,

okay, we just had one

breakthrough.

If we just have like another breakthrough like that,

or maybe two, then we

can have something that's truly crazy, right?

And, and is like, is, um, just like so much more advanced

and, and on, on that

side of the argument, it's like, okay,

well, maybe we're, um, and maybe we're

only a couple of big steps away

from, uh, from, from, from reaching something

that looks more like general intelligence.

Okay.

That's one, that's one side of the argument.

And the other side,

which is what we've historically seen a lot more is that a

breakthrough leads to, um, you know, in that

, in that Gartner hype cycle, there's

like the hype and then there's the trough

of disillusionment after when like

people think that there's a chance that,

Hey, okay, there's a big breakthrough.

Maybe we're about to get another big breakthrough.

And it's like, actually, you're not about to get

another breakthrough.

You're, maybe you're actually just going to have to sit

with this one for a while.

And, um, and you know, it could be,

it could be five years, it could be 10 years.

It could be 15 years until you figure out

the, um, the kind of the next big thing

that needs to get figured out.

And, um, but I think that the fact that we just

had this breakthrough sort of

makes it's that we're at a point

of almost a very wide error bars on what happens

next.

Yeah.

Um, I think the traditional technical view,

like looking at the industry would

suggest that we're not just going

to stack in a like breakthrough on top of

breakthrough on top of breakthrough,

like every six months or something right now.

I think it will, I'm guessing, I would guess that it will,

that it will take

somewhat longer in between these,

but, um, I don't know, I tend to be pretty

optimistic about breakthroughs too.

So I mean, so I think if you,

if you, if you normalized for, for my normal optimism,

then, then maybe it would be even,

even slower than what I'm saying.

But, but even within that,

like I'm not even opining on the question of how many

breakthroughs are required to get to general intelligence

because no one knows.

But this particular breakthrough was so such a small step

that resulted in such

a big leap in performance as experienced

by human beings that it makes you think,

wow, are we, as we stumble across this very open

world of research,

will we stumble, um, across another thing

that will have a giant leap in performance.

And, um, also we don't know exactly

at which stage is it really going to be

impressive because it feels like it's really encroaching

on impressive levels

of intelligence.

You still didn't answer the question

of what year we're going to have super

intelligence.

I'd like to hold you to that.

No, I'm just kidding.

But is there something you can say

about the timeline as you think about the

development of, um, AGI superintelligence systems?

Sure.

So I, I still don't think I have any particular insight

on when like a singular

AI system that is a general intelligence will get created.

But I think the one thing that most people

in the discourse that I've seen

about this haven't really grappled

with is that we do seem to have.

Organize organizations and, you know,

structures in the world that exhibit

greater than human intelligence already.

So, you know, one example is, you know,

a company, you know, it acts as an

entity, it has, you know, a singular brand.

Um, obviously it's a collection of people,

but I, I certainly hope that, you

know, meta with tens of thousands

of people make smarter decisions than one

person, but I think that that would be pretty bad

if it didn't.

Um, another example that I think is even more removed

from kind of the way we

think about like the personification

of, of, um, of intelligence, which is often

implied in some of these questions is think

about something like the stock market

where the stock market is, you know,

it takes inputs, it's a distributed system.

It's like the cybernetic organism that, you know,

probably millions of people

around the world are basically voting every day

by choosing what to invest in.

But it's basically this, this organism

or structure that is smarter than any

individual that we use to allocate capital

as efficiently as possible around the

world.

And I, I do think that this notion

that there are already these cybernetic

systems that are either melding the intelligence

of multiple people together

or melding the intelligence of multiple people

and technology together

to form something which is dramatically

more intelligent than any individual on the,

in the world, um, is something that seems to exist

and that we seem to be able to

harness in a productive way for our society as long

as we basically build these structures

and balance with each other.

Um, so I don't know.

I mean, that, that at least gives me hope

that as we advance the technology,

and I don't know how long exactly it's going to be, but

you asked when is this going to exist?

I think to some degree we already have

many organizations in the world

that are smarter than a single human.

And, and that seems to be something

that is generally productive in advancing humanity.

And somehow the individual AI systems empower

the individual humans and the interaction between

those humans to make that collective intelligence machinery

that you're referring to smarter.

So it's not like AI is becoming super intelligent.

It's just becoming the, uh,

the engine that's making the collective intelligence

is primarily human, more intelligent.

Yeah.

It's, it's educating the humans better.

It's making them better informed.

It's, um,

making it more efficient for them to communicate effectively

and debate ideas.

And through that process,

just making the whole collective intelligence more

and more and more

intelligent, maybe faster than the individual AI systems

that are trained on human data anyway,

are becoming maybe the collective intelligence

and human species might outpace the development of AI.

I think there's a balance in here because I mean,

if, if like, you know,

if a lot of the input that,

that the systems are being trained

on is basically coming from

feedback from people,

then a lot of the development does

need to happen in human time, right?

It's,

it's not like a machine will just be able

to go learn all the stuff about, about how people think

about stuff.

There's, there's a cycle to how this needs to work.

This is an exciting world

we're living in.

And then you're at the forefront of developing.

One of the ways you keep yourself humble,

like we mentioned with Jiu Jitsu,

is doing some really difficult challenges,

mental and physical.

One of those you've done

very recently is the Murph challenge

. And you got a really good time.

It's 100 pull-ups, 200

push-ups, 300 squats,

and a mile before and a mile around after.

You got under 40 minutes on that.

What was the hardest part?

I think a lot of people were very impressed.

It's very impressive time.

Yeah.

I was, I was pretty happy.

How crazy are you?

It was the question.

It wasn't my best time,

but, but I, anything under 40 minutes, I'm happy with.

Yeah.

It wasn't your best time.

No, I think, I think I've done it a little faster before,

but not much.

I mean, it's, and, and of my friends,

I did not win on Memorial Day.

One of my friends

did it actually several minutes faster than me.

But just to clear up one thing that I think was,

I saw a bunch of questions about this on the internet.

There are multiple ways to do,

to do the Murph challenge.

There's a kind of partitioned mode

where you do sets of pull-ups,

push-ups, and squats together.

And then there's unpartitioned

where you do the 100 pull-ups,

and then the 200 push-ups, and

then the 300 squats in cereal.

And obviously, if you're,

you know, if you're doing them

unpartitioned, then, you know,

it takes longer to get through

the 100 pull-ups because you, you know,

anytime you're resting in between the pull-ups, you're not

also doing push-ups and, and squats.

So, so yeah, so my, my, I'm sure

my unpartition time would be,

would be quite a bit slower,

but, but no, I think at the end of this,

I don't know, first of all, I think it's a good way

to honor Memorial Day, right?

It's, you know,

it's this Lieutenant Murphy, basically, this is one of,

this was one of his favorite

exercises, and I just try to do it on,

on Memorial Day each year, and it's a good workout.

I got my older daughters to do it with me this time.

They, my oldest daughter wants a weight vest

# Chapter 11

And obviously, if you're,

you know, if you're doing them

unpartitioned, then, you know,

it takes longer to get through

the 100 pull-ups because you, you know,

anytime you're resting in between the pull-ups, you're not

also doing push-ups and, and squats.

So, so yeah, so my, my, I'm sure

my unpartition time would be,

would be quite a bit slower,

but, but no, I think at the end of this,

I don't know, first of all, I think it's a good way

to honor Memorial Day, right?

It's, you know,

it's this Lieutenant Murphy, basically, this is one of,

this was one of his favorite

exercises, and I just try to do it on,

on Memorial Day each year, and it's a good workout.

I got my older daughters to do it with me this time.

They, my oldest daughter wants a weight vest

because she sees me doing it with a weight vest.

I don't know if a seven-year-old should be using

a weight vest to do pull-ups, but, but, um...

The difficult question a parent must ask themselves,

yes.

I was like, maybe I can make you a very light weight vest,

but, but I, I didn't think it was

good for this.

So she, she basically did a quarter, Murph,

so she ran a quarter mile,

and then did, you know, 25 pull-ups, 50 push-ups,

and, and 75 air squats, then ran another quarter

mile, and like, in 15 minutes,

which I was pretty impressed by, um,

and, and my, my five-year-old too,

so I, so I, I was excited about that,

and I, I'm, I'm glad that I'm teaching them

kind of the value of, of, of physicality, right?

I think a, a good day for Max, my daughter,

is when she gets to like, go to the gym with me

and cranks out a bunch of pull-ups, and I, I, I love

that about her.

I mean, I think it's, it's like, good, she's, you know,

um, hopefully I'm teaching

her some good lessons, but...

I mean, the, the broader question

here is, um, given how busy you

are, given how much stuff you have going on in your life,

what's, um, what's like the perfect

exercise regimen for you to, uh, to keep yourself happy,

to, uh, keep yourself productive in your

main line of work?

Yeah, so I mean, I've, right now,

I'm focused most of my workouts on, on fighting,

so, so Jiu Jitsu and MMA, um, but I don't know.

I mean, maybe if you're a professional, you can

do that every day, I can't, I just can't.

you know, it's too many,

too many bruises and things

that you need to recover from.

So I do that, you know,

three to four times a week.

And then, and then the other day is,

I just try to do a mix of things,

like just cardio conditioning,

strength building, mobility.

So you try to do

something physical every day?

Yeah, I try to, unless I'm just so tired

that I just need to, need to relax.

But then I'll still try to like go

for a walk or something.

I mean, even here, I don't know,

have you been on the roof here yet?

No.

We'll go on the roof after this.

But it's like, we designed this building

and I put a park on the roof.

So that way, that's like my meetings

when I'm just doing kind of a one-on-one

or talking to a couple of people.

I have a very hard time just sitting.

I feel like you get super stiff.

It like feels really bad.

But I don't know, being physical

is very important to me.

I think it's, I do not believe,

this gets to the question about AI.

I don't think

that a being is just a mind.

And I think we're kind of meant

to do things

and like physically

and a lot of the sensations

that we feel are connected to that.

And I think that that's a lot

of what makes you a human

is basically having those,

having that set of sensations

and experiences around that

coupled with a mind

to reason about them.

But I don't know,

I think it's important for balance

to kind of get out,

challenge yourself in different ways,

learn different skills, clear your mind.

Do you think AI in order

to become super intelligent

and AGI should have a body?

It depends on what the goal is.

I think that there's this assumption

in that question

that intelligence should

be kind of person-like.

Whereas, as we were just talking about,

you can have these greater

than single human

like the stock market,

which obviously do not have bodies

and do not speak a language, right?

And just kind of have their own system.

But so I don't know,

my guess is there will be limits

to what a system that is purely in intelligence

can understand about the human condition

without having the same,

not just senses,

but like our body's changes

we get older, right?

And we kind of evolve

and let those very subtle

physical changes just drive a lot

of social patterns

and behavior around like

when you choose to have kids, right?

That's not even subtle,

that's a major one, right?

But like how you design things

around the house.

So yeah, I think if the goal

is to understand people

as much as possible, I think that that's

trying to model those sensations

is probably somewhat important,

but I think that there's a lot of value

that can be created

by having intelligence,

even that is separate

from that is a separate thing.

So one of the features of being human

is that we're mortal, we die.

We've talked about AI a lot,

but potentially replicas of ourselves.

Do you think there will be AI replicas

of you and me

that persist long after we're gone,

that family and loved ones can talk to?

I think we'll have the capacity

to do something like that.

And I think one of the big questions

that we've had to struggle

with in the context

of social networks is who gets

to make that?

And my answer to that in the context

of the work

that we're doing is that should be your choice.

I don't think anyone should be able to choose

to make a Lex spot

that people can choose to talk to

and get to train that.

And we have this precedent

of making some of these calls

where someone can create a page

for a Lex fan club

but you can't create a page

and say that you're a Lex, right?

So I think that similarly, I think,

I mean, maybe someone maybe can make a,

should be able to make an AI

that's a Lex admirer

that someone can talk to,

be your call

whether there is a Lex AI.

Well, I'm open sourcing the Lex.

So you're a man of faith.

What role has faith played in your life

and your understanding of the world

and your understanding of your own life

and your understanding of your work

and how did your work impacts the world?

Yeah, I think that

there's a few different parts of this

that are relevant.

There's sort of a philosophical part

and there's a cultural part.

And one of the most basic lessons

is right at the beginning of Genesis, right?

It's like God creates

the earth and creates people

and creates people in God's image.

And there's the question of,

what does that mean?

that you have about God

at that point in the Old Testament

is that God has created things.

So I always thought that one

of the interesting lessons

from that is that there's a virtue

in creating things

that is like whether it's artistic

or whether you're building things

that are functionally useful

for other people.

I think that that by itself is a good.

And that kind of drives a lot

of how I think about morality

and my personal philosophy around

like what is a good life?

I think it's one

where you're helping the people around you

and you're being a kind

of positive creative force

in the world that is helping

to bring new things

into the world,

whether they're amazing other people, kids,

or just leading to the creation

of different things

that wouldn't have been possible otherwise.

And so that's a value

for me that matters deeply.

And I just love spending time

with the kids

and seeing that they sort of,

trying to impart this value to them.

And it's like, I mean,

nothing makes me happier than like

when I come home from work

and I see like my daughters

like building Legos on the table or something.

It's like, all right,

I did that when I was a kid,

so many other people were doing this.

And like, I hope you don't lose that spirit

where when you kind of grow up

and you wanna just continue

building different things

no matter what it is, to me,

that's a lot of what matters.

That's the philosophical piece.

I think the cultural piece

and values and that part of things,

I think has just

since I've had kids.

You know, it's almost autopilot

when you're a kid,

you're in the kind of getting imparted

to phase of your life,

but, and I didn't really think about religion

that much for a while, you know,

I was in college,

you know, before I had kids

and then I think having kids

has this way of really making you think

about what traditions you want to impart

and how you want to celebrate

and like what balance you want in your life.

And I mean,

a bunch of the questions

that you've asked

and a bunch of the things

Just the irony of the curtains coming down

as we're talking about mortality.

Once again, same as last time,

this is just, the universe works in,

we are definitely living

in a simulation,

but go ahead on community tradition

and the values, the faith

and religion is still.

A lot of the topics

that we've talked about today

are around how do you balance, you know,

whether it's running a company

or different responsibilities with this,

I don't know, yeah,

how do you kind of balance that?

And I always also just think

that it's very grounding

to just believe that there is something

that is much bigger

than you that is guiding things.

That amongst other things gives you

a bit of humility.

As you pursue that spirit

of creating these,

that you spoke to creating beauty

in the world.

As Dostoevsky said,

beauty will save the world.

Mark, I'm a huge fan of yours.

Honored to be able to call you a friend

and I am looking forward to both kicking your ass

and you kicking my ass

on the mat tomorrow in Jiu-Jitsu.

This incredible sport

and art that we both participate in.

Thank you so much for talking to me.

Thank you for everything you're doing

in so many exciting realms

of technology and human life.

I can't wait to talk to you again

in the metaverse.

Thank you.

Thanks for listening

to this conversation

with Mark Zuckerberg.

To support this podcast,

please check out our sponsors

in the description.

And now let me leave you

with some words from Isaac Asimov.

It is change, continuing change,

inevitable change

that is the dominant factor

in society today.

No sensible decision

can be made any longer

without taking into account not

only the world as it is,

but the world as it will be.

Thank you for listening

and hope to see you next time.

