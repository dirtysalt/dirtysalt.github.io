# Chapter 1: 大脑之谜：千脑理论与智能起源

尽管我们对大脑的细节知识积累日渐增多，但人类大脑究竟如何产生智能，这依然是一个深奥的谜团。许多人，包括我自己在内，都曾被一个根本性的问题所吸引：我是谁？我如何思考？当我思考时，我的脑海中究竟发生了什么？“知道”意味着什么？这些问题驱使着我们深入探索大脑的奥秘。

著名神经科学家弗朗西斯·克里克曾观察到，尽管科学家们几十年来一直在收集大脑数据，对大脑的运作方式了解颇多，但他们始终未能就大脑如何工作、智能如何从低级细胞中涌现形成任何有意义的理论。这仍然是一个深刻的谜。

杰夫·霍金斯，一位富有远见的思想家，带着他的新书《千脑理论》走进了我们的视野。他提出一个引人入胜的观点：我们所感知的现实，其实是一种模拟、一种幻觉，或者说是一种“虚构”。他认为，我们的大脑是基于数千个源自感官的信息流，构建出的现实模型。更关键的是，霍金斯不认为大脑中只有一个模型，而是数以千计的模型协同运作。他是一位“亚符号主义者”，相信我们的知识被切片并分布在大脑突触的基质上，同样地，我们对世界的模拟模型也分布在成百上千的皮层柱中。这意味着，当我们识别一只狗时，大脑中存在着一个由皮层柱组成的“社会”，它们各自独立地预测狗的存在，并在达成共识后相互校准。

霍金斯将大脑的新皮层——哺乳动物大脑最外层、也是最近进化的部分——比作一张褶皱的餐巾纸，它包裹着古老的大脑，占据了大脑约70%的体积。新皮层负责我们智能的方方面面，包括视觉、触觉、听觉、语言，乃至数学和哲学等抽象思维。令人惊讶的是，新皮层在解剖学上并没有明显的划分，其组织结构惊人地相似，无论是视觉区域、语言区域还是触觉区域，甚至在老鼠、猫和人类等不同物种之间，其复杂的回路都显得异常相似。霍金斯认为，大脑的复杂性在于其连接和布线的“内容”，这是一种简单学习算法的涌现特性，就像OpenAI的卷积神经网络可视化工具所展示的那样，简单的学习算法能产生令人惊叹的复杂性。

新皮层是智能的主要器官之一，它赋予我们感官知觉、运动控制和抽象思维。其核心特质在于持续快速学习的能力、高效的能耗以及处理多样化和新颖任务的灵活性。霍金斯认为，新皮层学习世界的模型，而每个皮层柱都是一个完整的感官运动建模系统。它们利用“参考系”来存储知识并生成行为。我们的大脑通过处理感官输入和运动来了解外部世界，当触摸物体或观察周围环境时，新皮层会预测运动带来的感官结果。当我们手指拂过熟悉的物体时，会迅速察觉到差异，这表明我们正在进行针对特定物体的触觉预测。霍金斯相信，运动后感官刺激的预测是认知的基本要素。

大脑并非简单地记忆感官信息，因为这很快就会变得难以处理。相反，霍金斯提出，进化重新利用了那些用于建模空间关系的古老系统，比如“网格细胞”和“位置细胞”，并将这些系统泛化，用于建模抽象空间中的抽象概念。在这个系统中，思考和推理变成了一种在复杂的大脑关系拓扑中穿梭的过程，类似于在物理空间中的移动。

整个皮层由被称为“微柱”的原始柱状单元集合构成，每个皮层区域都包含数百万个皮层微柱。这些微柱大约分为六层，每层都有特定类型的神经元和连接模式。相邻的微柱具有相同的感受野，因此它们接收来自其他皮层区域的相同输入，并形成完整的、基本的原始单元，即“巨柱”，或霍金斯所称的“皮层柱”。锥体神经元是新皮层中典型的兴奋性神经元，其细胞体呈三角形。每个锥体神经元的树突连接着数万个兴奋性突触，这些突触平均分布在局部和远程来源。丘脑是新皮层主要的输入和输出皮层下结构，可以被视为新皮层的“第七层”，它主要将感官或预处理信息发送到新皮层的第四层。新皮层甚至在生命后期也能保持显著的可塑性，最引人注目的例子是受伤后的可塑性，大脑通过重新连接剩余的神经元来恢复部分甚至全部功能。

皮层区域之间密集互联，在层级结构中存在许多反馈和前馈的跳跃连接。所有新皮层的功能区域都与其他大脑结构双向连接，但其主要的输入和输出来自其他皮层区域，通过长距离连接。尽管所有皮层区域都密集连接，但整体结构中存在明显的非对称性和层级关系。例如，感觉区域通常位于层级结构的较低层，而联想或运动区域则较高。自下而上的信息流被称为“前馈”，自上而下的连接则被称为“反馈”。从这种结构中可以清楚地看出，大脑并非一张“白板”，而是一个非常清晰的认知架构，这种高级结构大部分从出生时就已存在，具有许多跳跃连接、高度的循环性、大量的反馈回路，并且处理过程高度分布式。

在此，我想提请大家注意心理学家约瑟夫·切萨里奥去年发表的一篇论文，题为《你的大脑不是一个里面有爬行动物的小洋葱》。约瑟夫指出了神经系统进化中的几个误解，他认为这些误解源于保罗·麦克莱恩在20世纪40年代开始研究大脑区域（他称之为边缘系统）的工作。麦克莱恩后来提出，人类拥有一个所谓的“三位一体脑”，由三个按顺序进化的主要部分组成：最古老的“爬行动物脑”控制基本功能，如运动和呼吸；其次是控制情绪反应的“边缘系统”；最后是控制语言和推理的“大脑皮层”（即新皮层）。约瑟夫指出，麦克莱恩的观点在他1990年出版著作时就已经被认为是错误的。事实上，自20世纪70年代以来，许多发展神经科学家就认为麦克莱恩的观点是一个“神话”。由于其持久的影响力，“三位一体脑”的观点被神经科学家丽莎·费尔德曼·巴雷特称为“科学史上最成功、最广泛的错误之一”。约瑟夫指出，这种观点的症结在于对进化过程的简单化理解，认为进化是按从最简单到最复杂的生物顺序排列的。这种观点暗示解剖学进化像地质地层一样，新层叠加在旧层之上。然而，大多数进化变化在于改造现有部分。约瑟夫说，新皮层并非人类、灵长类或哺乳动物独有的进化新奇事物，所有脊椎动物都拥有与我们皮层进化相关的结构。约瑟夫总结道，这些观点与传统上将人性视为理性与情感斗争的观念、柏拉图式三元灵魂、弗洛伊德心理动力学以及宗教对人性的看法是一致的。它也是一个可以提炼并传达给普通大众的简单想法。当然，我绝不是说霍金斯认同“三位一体脑”的观点，但我认为阅读他的书可能会给人留下这种印象，这就是我为什么要提出这一点的原因。

事实证明，让神经元构建环境地图非常困难。现在我们知道，在旧大脑区域中，有关于“位置细胞”和“网格细胞”的著名研究，这些研究至今仍非常活跃，它们揭示了大脑如何构建世界地图，这真是巧妙。显然，这在漫长的进化过程中承受了巨大的压力，使得它们擅长此道，动物因此知道自己身处何处。我们认为，并且有大量证据支持，这种用于映射空间（如物理空间）的机制被重新包装，相同类型的神经元以更紧凑的形式重新组合，最终形成了皮层柱。

1972年，约翰·奥基夫在大脑中发现了内部GPS系统的第一个组成部分：海马体中的“位置细胞”，当老鼠处于房间的特定位置时，这些细胞就会激活。三十多年后，2005年，梅-布里特·莫泽和爱德华·莫泽夫妇发现了大脑定位系统的另一个关键组成部分：“网格细胞”，它们代表了一个坐标系统，可以实现精确的定位和路径规划。这些发现解决了几个世纪以来困扰哲学家和科学家的问题：大脑如何创建周围复杂世界的地图，以及我们如何在其间导航。大脑解决方案的奇妙之处在于，它似乎创建了多个具有略微不同方向和尺度的六边形网格。由于这些网格的方向和尺度不同，空间中的每个点都会激活独特的网格细胞组合。换句话说，大脑使用稀疏分布式表征中的“位”来编码位置。杰夫·霍金斯认为，这种稀疏表征对于人类大脑的成功至关重要，也应该指导我们构建人工智能。就像在计算机中建立房屋模型时，需要一个参考系，然后可以像笛卡尔坐标系一样引用它们一样，大脑也以其独特的方式构建着世界的模型。

# Chapter 2: 大脑的导航与千脑共识

我们的大脑，这个精妙的导航系统，似乎以一种令人着迷的方式构建着世界。它并非简单地存储信息，而是创造出多重六边形网格，这些网格拥有略微不同的方向和尺度。正是这种差异，使得空间中的每一个点都能激活一组独特的网格细胞组合。换句话说，大脑以一种稀疏分布式表征（sparse distributed representation）的方式编码位置信息。杰夫·霍金斯坚信，这种稀疏表征是人类大脑成功的关键，也应成为我们构建人工智能的指导原则。

杰夫在多年的思考中领悟到，新皮层存储我们所有知识的方式，都离不开一种名为“参考系”的结构。他用一个简单的思想实验来阐释：当你触摸一个陶瓷咖啡杯时，你的手指会感受到不同的质地，而要准确预测这种感觉，大脑必须知道手指相对于咖啡杯的精确位置。这就需要一个关于咖啡杯的参考系。就像一张地图，它的经纬网格就是它的参考系，它告诉我们事物相对于其他事物的位置，以及如何从一个地点到达另一个地点。杰夫意识到，大脑对世界的模型正是由成千上万个这样的“地图式参考系”构建而成。他认为，新皮层中的大部分细胞都致力于创建和操作这些参考系，大脑正是利用它们进行规划和思考。我们的知识表征是对现实的模拟，这不仅适用于物理空间，也适用于抽象概念空间。杰夫甚至提出，我们思考的方式与我们在空间中导航的方式是相似的，皮层区域中相似的回路结构有力地证明了，即使是高级认知任务也是在基于位置的框架中学习和表征的。成为任何领域的专家，都意味着拥有一个优秀的参考系，一张清晰的“地图”。爱因斯坦的相对论就是一个绝佳的例子，他用日常物体作为参考系，重新排列了已有的事实，从而做出了惊人的预测。

杰夫·霍金斯本人，这位我们时代杰出的“绅士科学家”，早年创立了Palm Computing并发明了Palm Pilot，取得了巨大成功。然而，他的内心始终向往理论神经科学，他深知理解人类智能并以此创造出人类水平的机器智能才是最大的挑战。于是，2005年，他在加州的红木城共同创立了Numenta公司。Numenta致力于开发基于新皮层原理的统一理论、核心软件技术和应用，其双重使命是理解大脑如何工作，并将这些原理应用于创建智能机器。面对每年数以千计的神经科学论文，Numenta决定首先聚焦于理解单个皮层柱。杰夫认为，智能的魔力可能源于单一的皮层学习算法，而非本·格策尔所主张的多种底层算法的混合。他强调，智能必须从多样化、强多模态的输入中涌现，或许与物理具身性（physical embodiment）的本质息息相关。

杰夫深受约翰·霍普金斯大学神经科学家弗农·芒特卡斯尔（Vernon Mountcastle）的启发。芒特卡斯尔在1978年出版的《有意识的大脑》一书中，提出了一个优雅而令人惊讶的理论：大脑的进化并非简单地在旧部件上叠加新部件，而是新皮层通过复制相同的基本回路而变得庞大。这意味着，新皮层的每一个部分都拥有相同的基本回路，它们的差异不在于内在功能，而在于它们连接的对象。这一发现意义重大：如果我们理解了新皮层的一个部分如何工作，我们就能理解整个新皮层，以及智能的各个方面如何从单一的皮层算法中涌现。芒特卡斯尔指出，新皮层在短暂的进化时间内迅速增长，这与达尔文的“生命多样性源于单一算法”的理念异曲同工。达尔文知道算法是什么（随机变异和自然选择），但不知道它在哪里；芒特卡斯尔知道算法在哪里（大约15万个皮层柱，就像并排堆叠的意大利面），但不知道它具体做了什么。

杰夫书中记载了一个令人难忘的轶事：他最后一次见到芒特卡斯尔时，在约翰·霍普金斯大学演讲结束后，芒特卡斯尔在杰夫即将离开时拦住了他，语重心长地说：“你应该停止谈论层级结构了，它并不真正存在。”杰夫当时震惊不已，因为芒特卡斯尔是新皮层领域的顶尖专家，却否定了一个被广泛接受的特征。他当时不知如何回应。在去机场的路上，杰夫反复思考这些话。如今，他对新皮层层级结构的理解已发生巨大变化，远比他之前认为的要扁平。他遗憾未能有机会与芒特卡斯尔深入探讨，甚至希望芒特卡斯尔能喜欢他提出的“千脑理论”。

那么，如果大脑中有成千上万个“小大脑”，我们如何拥有单一的感知呢？“千脑理论”解释说，我们拥有视觉模型、听觉模型、触觉模型等等，这些模型通过“投票”机制协同工作。新皮层中的每个皮层柱都像一个独立的建模系统，它们之间通过长程连接进行“投票”，以达成共识——比如，我正在看一个水瓶。我们有意识地感知到的，正是这种投票的最终结果。传统的观点将新皮层视为一个流程图，信息从感官输入开始，逐级处理，从低级到高级逐步精炼。然而，杰夫指出，认知是一个交互过程，例如，我们通过旋转和触摸来学习一个新物体。杰夫的“参考系”理论则提出，皮层柱即使在低级感官区域，也能作为认知原语，学习和识别完整的物体。知识并非存储在一个单一的模型中，而是分布在成千上万个皮层柱中，每个皮层柱都建模着数百甚至数千个完整的物体，并通过丰富的参考系拓扑结构将它们绑定在一起。皮层柱和区域之间的长程连接，沟通的是分类后的物体，而非简单的特征。杰夫认为，这解决了人工智能领域长期存在的“绑定问题”——如何将感官输入映射到离散的心理类别，并将这些类别组合成一个单一的体验。他认为，“绑定问题”是基于大脑连接拓扑是收敛而非发散的错误假设的副产品。解决方案就是：皮层柱进行投票，你的感知就是它们识别结果的共识。当大脑面对模糊的图像（如既可以是花瓶也可以是两张脸）时，皮层柱无法达成共识，因为它们拥有两张过于相似的“地图”，投票层无法同时允许两个物体存在。

# Chapter 3: 大脑的共识与稀疏智能

在杰夫·霍金斯的“千脑理论”中，大脑的运作犹如一场精密的民主投票。数千个独立的皮层柱，各自识别着世界的一小部分，然后通过“投票”机制达成共识，形成我们对世界的统一感知。这种投票不仅限于单一感官，而是跨越多种感官模态。想象一下，当你手中握住一个物体时，代表你手指触感的皮层柱不仅识别出各自接触到的部分，还会分享它们彼此的相对位置信息，这使得大脑能更轻松地拼凑出物体的完整形态。

然而，当信息模糊不清时，这场“投票”就会陷入僵局。杰夫在他的书中举了一个经典的例子：一张既可以看作花瓶，又可以看作两张人脸的图片。在这种情况下，皮层柱无法明确判断哪个是“正确”的物体，因为它们仿佛拥有两张描述不同城镇的地图，但这些地图在某些区域却惊人地相似。大脑渴望达成共识，但它不允许同时感知两个相互矛盾的物体。因此，你只能选择感知花瓶，或者感知人脸，而不能同时感知两者。正是这种认知过程，让我们得以在不同可能性之间切换，进行互动式的推理。

杰夫提出了一个深刻的观点：思考，本质上就是在大脑中遍历一个由参考系和位移框架构成的拓扑结构。他认为，这种推理能力是运动的进化延伸，将物理世界的空间和时间概念，扩展到了我们抽象思维的领域。我们思考时所经历的一系列念头，就像我们用手指划过物体表面，或是在城镇中漫步时所感受到的一系列触觉和视觉变化。或许，爱因斯坦之所以如此聪明，正是因为他大脑中独特的参考系拓扑结构，他那独一无二的信息架构，结合了他的生活经验和生物学特质，使他能够在大脑的拓扑结构中进行强大的抽象推理，这是常人难以企及的。这感觉有点像《星际迷航：航海家号》中博格人穿越虫洞网络一般。

学习概念知识有时会很困难。如果你拿到十个与民主相关的历史事件，该如何在大脑中组织它们？一位老师可能会将它们排列在时间线上，形成一个一维的参考系，这有助于理解事件的时间顺序和因果关系。但另一位老师可能会将这些事件标注在世界地图上，从地理角度进行组织。时间线和地理位置都是有效的组织方式，但它们会引导出不同的历史思考方式，甚至可能得出不同的结论和预测。而要真正理解民主，可能需要一张完全不同的地图，一张拥有多个抽象维度的地图，比如对应“公平”或“权利”的维度。

那么，“千脑理论”对机器智能有何启示？智能机器需要学习一个世界模型，而推理、预测、规划和运动行为都基于这个模型。这个模型分布在许多几乎相同的单元中，它们通过投票达成共识，从而实现鲁棒的预测能力，并且具有良好的可扩展性，适用于任何类型的传感器阵列和模态。投票机制还能解决每个单元中的“绑定问题”。知识以参考系的形式存储，并通过感觉运动交互学习，这意味着机器可以进行快速的无监督学习，并将运动行为整合进来。

Numenta公司，曾将他们的理论称为“HTM理论”，现在则更倾向于使用“千脑理论”这一术语。HTM，即“分层时间记忆”算法，是“千脑理论”早期思想的一种具体实现。HTM最初的核心原则是它作为一种序列记忆算法，Numenta认为大脑中的每个神经元都在学习序列模式，这对于持续学习至关重要。而且，它并非当时流行的、被认为不具备生物学启发性的人工神经网络。该算法的核心数据结构被称为SDR，即“稀疏分布式表征”。

SDR可以想象成一个巨大的位掩码，一个由大量有序的0和1组成的集合。它的“稀疏”之处在于，通常只有大约百分之一的位是1，其余都是0。这些值代表着新皮层不同区域神经元的状态。Numenta非常强调大脑中稀疏性的重要性，并认为它是构建任何智能系统所必需的。稀疏性之所以如此强大，是因为它能产生惊人的排列组合数量。例如，在一个长度为256的SDR中，如果只有4个位是1，就能表示大约1.75亿个不同的值（256选4）。这意味着出现“假阳性”的可能性微乎其微。同时，它也具有空间效率，因为这4个位可以代表1.75亿种事物，却只需存储在一个32位的数组中。

SDRs之间的相似性通过它们的交集或汉明距离来衡量。更巧妙的是，这些表征对噪声具有极强的鲁棒性。即使在两个SDR中加入大约33%的随机噪声，它们之间的重叠度量也几乎不受影响。你还可以将多个SDRs联合起来，而模式信息在混合中损失甚微。HTM算法需要编码器将任何数据结构转换为稀疏分布式表征。将信息编码成SDR是HTM的一个重要考量，就像其他机器学习模型一样。

HTM神经元的灵感来源于新皮层中的锥体神经元。一个神经元通过来自层级结构更高层的远端顶端树突、来自同一层级区域的基底树突，以及来自层级结构更低层或某些感官输入的近端树突接收SDRs，这些近端树突代表了神经元的经典感受野。所有这些神经元都在接收SDR流，并决定何时放电、何时进入预测状态，从而告知其他神经元何时放电。

Numenta从一开始就知道，真实的神经元并非简单的点神经元。活跃树突上的突触能够检测数十种稀疏的上下文模式，并学习复杂的时序序列。活跃树突使得神经元层能够灵活地整合上下文信息。时间记忆算法主要分为两个阶段：首先，识别在当前时间步中哪些活跃列中的细胞将变得活跃；其次，一旦这些激活被识别，就选择一组细胞进入预测状态，这意味着这些细胞将在下一个时间步被“预备”放电。

HTM实现了树突分支特异性可塑性：如果一个细胞变得活跃并且存在预测，它会强化该树突段；如果没有预测，它会通过对先前活跃细胞进行二次采样来增加连接；如果细胞不活跃但存在预测，它会削弱树突段。我从Numenta的Matthew Taylor制作的HTM学校系列视频中了解了所有这些HTM算法的知识。马特去年不幸去世，我在此向他致敬。他的热情和感染力令人难忘，整个机器学习社区都会深深怀念他。

稀疏性在现有硬件上运行并不理想，无论是GPU还是CPU。因此，如何将更多大脑原理以商业价值的方式融入现有系统，是一个挑战。目前有大量工作致力于训练密集网络以生成用于推理的稀疏网络，但这限制了可训练稀疏模型的最大规模，使其不超过可训练密集模型的最大规模。直到最近，情况才有所改变。

自20世纪80年代以来，我们已经知道可以从神经网络中消除大量参数而不影响准确性或推理时间。当使用适当的硬件时，剪枝可以显著降低推理的计算需求。当目标是降低推理成本时，剪枝通常发生在训练后期。1995年，研究人员发现，回顾性地剪枝低幅值连接效果惊人。后来，研究人员发现重新训练剪枝后的连接能产生更好的结果，甚至通过多轮剪枝和重新训练的迭代过程，效果更佳。其他方法探索了随机添加连接，甚至专注于非均匀稀疏性，即在网络中最需要的地方添加连接。

乔纳森·弗兰克尔（Jonathan Frankle）在2019年提出了他的“彩票假说”，证明如果我们能通过迭代幅值剪枝找到一个稀疏神经网络，那么我们可以从头开始训练这个稀疏网络，达到与原始密集网络相同的准确性。然而，随着训练需求的爆炸式增长，研究人员开始探索在训练早期甚至训练前进行剪枝的可能性。这样做的好处是可以降低现有模型的训练成本，并使我们能够继续探索在更大规模下出现的现象。

最近，一些专门用于初始化时剪枝的方法被提出。SNIP旨在剪枝对损失最不显著的权重；GRASP旨在剪枝对梯度流伤害最大或益处最小的权重；而SynFlow则旨在以数据无关的方式迭代剪枝突触强度最低的权重，目标是避免层塌陷（即剪枝集中在某些层）。弗兰克尔在他最近的总结论文中指出，训练后的幅值剪枝优于所有这些预初始化方法。这些方法大多有效地剪枝了层，而非权重，这意味着即使你随机打乱每层中被剪枝的权重，也能获得相似的性能。有趣的是，SynFlow和幅值剪枝在初始化时，无需看到任何数据，也能表现良好。弗兰克尔没有找出这些方法在初始化时难以进行特定剪枝的单一原因，并认为这是未来研究的重要问题。也许是优化过程的特性使得在初始化时剪枝特定权重变得困难或不可能，或许是因为训练发生在多个阶段。

将梯度下降训练与最优稀疏拓扑相结合，可以在更小的网络中实现最先进的结果。Numenta认为，稀疏性是信息存储和处理的关键，他们也相信它是现代深度学习中最重要的缺失成分之一。我们联系了Numenta的机器学习架构、研究和工程副总裁劳伦斯·布拉克伦德和苏布泰，他们对此深信不疑。

# Chapter 4: 稀疏性：大脑智能的基石与AI的未来探索

在深度学习的剪枝技术领域，弗兰克尔在其最新总结论文中指出，训练后的幅度剪枝方法在性能上超越了所有预初始化方法。他观察到，大多数剪枝操作实际上是针对整个网络层进行的，而非精确到单个权重，这意味着即使随机打乱每层中被剪掉的权重，最终效果也可能相差无几。尽管如此，一些方法在初始化阶段，甚至在未接触任何数据的情况下，也能表现出良好的剪枝效果。弗兰克尔认为，为何这些方法难以在初始化时以特定方式进行精确剪枝，是一个亟待未来深入研究的关键问题，这或许与优化过程的固有特性或训练的多阶段性息息相关。然而，将梯度下降训练与最优稀疏拓扑结构相结合，确实能以更精简的网络实现最先进的性能。

Numenta公司对此持有独到见解，他们坚信稀疏性是信息存储和处理的核心，也是现代深度学习中一个至关重要的缺失环节。他们认为，稀疏网络不应仅仅被视为通过剪枝密集网络而衍生的产物，而应被视为一种独特的、独立的神经网络类别，它从根本上模仿了大脑所展现的稀疏性。换言之，Numenta的目标并非移除冗余连接，而是从设计之初就构建出本质上稀疏的网络。

2019年，Numenta发布了一篇题为《稀疏性使深度学习网络性能提升50倍》的论文，直指当前最先进神经网络所面临的巨大扩展挑战。他们强调，大脑的运行效率令人惊叹，仅需20瓦的功率，甚至低于一个普通灯泡。与此形成鲜明对比的是，训练GPT-3这样的模型需要耗费数百万美元。Numenta深信，通过深入研究大脑并揭示其高效运作的奥秘，他们能够创造出效率媲美大脑的新算法。他们认为，大脑之所以如此高效，其核心原因正是稀疏性。

稀疏网络并非所有神经元都与同一皮层区域内的其他神经元密集连接。大脑以稀疏表征的形式存储和处理信息，在任何给定时刻，只有一小部分神经元（可能不到1%到几个百分点）处于活跃状态，但这种稀疏性始终贯穿其中。这种稀疏性将极大地减少内存占用，因为只需存储非零元素，从而使硬件能够同时运行更多网络。

然而，当前的GPU和TPU是为“密集执行”而设计的引擎，它们对整个向量或矩阵数据执行相同的计算任务。当向量或矩阵是密集（即所有元素非零）时，这种方法非常高效，通过执行一条指令应用于所有数据（SIMD）来提高效率。但当数据中充斥着大量的零时，这种方法就会浪费惊人的计算资源。幸运的是，AI硬件领域正在发生一场革命。例如，Graphcore和Cerebras公司，特别是Cerebras，开发了一款拥有85万个核心和40GB板载内存的微处理器，其设计从底层就支持稀疏性。Cerebras的核心从不与零相乘，调度操作以单个数据值的粒度进行，所有零都被过滤掉，从而在原本会被浪费的计算周期中执行有用的工作，显著提升性能并节省功耗。他们展示的图表声称，在稀疏性方面实现了近乎线性的加速，例如94%的稀疏度可实现约84倍的加速。

Numenta在几年前，在这些专门的稀疏硬件发布之前，选择FPGA（现场可编程门阵列）作为其性能测试平台，因为它在高效处理稀疏数据方面提供了极大的灵活性，并且对内存的随机访问在FPGA上更加精细和高效，能够有效处理稀疏网络中非结构化的访问模式。他们的论文不仅证实了稀疏网络对噪声和方差误差的鲁棒性，还通过使用专门的FPGA硬件实现了显著的性能提升。

尽管普遍认为稀疏网络因不易过拟合而表现更优，不会将宝贵的表征能力浪费在记忆训练数据中个别具有挑战性或非代表性的例子上，但稀疏模型的性能上限是否就是最佳剪枝算法所能达到的，仍是一个悬而未决的问题。谷歌在2019年发布了《操纵彩票：让所有彩票都中奖》的论文。该算法从随机初始化的连接拓扑开始，然后逐层添加和移除连接，先使层密集化，再使用传统的权重幅度启发式方法进行稀疏化。该算法在所有稀疏度级别上，以给定的计算成本实现了比所有先前技术更高的准确性，甚至超过了从密集到稀疏的算法。Numenta也表示他们开发了类似的算法，但尚未公开。与传统的密集到稀疏的迭代幅度剪枝不同，谷歌的算法允许拓扑在优化过程中增长，这有助于克服一些局部最小值。然而，最精确的稀疏性算法至少需要训练一个大型密集网络的内存和计算成本，这限制了可学习稀疏模型的规模，因为从一个庞大的密集模型开始进行稀疏化，会浪费大量计算资源在最终会变为零的参数上。这种稀疏训练形式在ImageNet上训练MobileNet V1和V2时具有启发性：稀疏网络能够以大约30%的计算时间达到几乎相同的准确性；甚至可以训练一个更大的稀疏网络，其准确性比原始密集版本高5%，计算量大约是其两倍。

今天的神经网络使用的是“点神经元”这种非常简单的神经元模型。Numenta认为，通过增加生物系统中存在的树突这一层复杂性，可以解决持续学习和快速学习的问题。Numenta正在幕后进行一些非常酷的工作，旨在将“千脑理论”的愿景转化为高效的计算算法。稀疏网络只是这一愿景的一小部分。下一步是实现带有活跃树突的持续学习，这意味着他们需要能够添加新的突触并独立于现有突触进行训练。这将需要一个特定版本的反向传播算法，以及专门的硬件和算法来实现。他们还提到，希望同时利用激活和权重稀疏性，以模仿新皮层。

杰夫·霍金斯（Jeff Hawkins）的个人旅程也充满了启发。他回忆起22岁时阅读弗朗西斯·克里克（DNA共同发现者之一）在《科学美国人》上的一篇文章，克里克在晚年转向神经科学，并在文章中指出，尽管我们拥有大量关于大脑的数据，但没有人真正理解大脑是如何运作的，我们需要新的思维方式。这让霍金斯深受触动，他意识到这是一个巨大的谜题，他想成为那个将碎片拼凑起来的人。他因此改变了职业方向，从计算机工程转向神经科学，尽管这意味着一切从头开始。40年过去了，他仍在为这个目标奋斗。他坚信，如果能真正弄清楚大脑的工作原理，就能为构建智能机器提供巨大的启示。

霍金斯也谈到了机器学习社区中的“部落主义”现象。他注意到，当他向一些机器学习研究人员介绍他的想法时，他们很快就会不屑一顾，认为这与传统的点神经元、反向传播的单片神经网络没有实质性区别。霍金斯认为，他们的使命首先是弄清楚大脑中到底发生了什么，现在则是要“推销”这些想法。他们通过发表论文、参加会议、让人们引用和测试他们的工作来向神经科学家推广。对于AI领域，他们看到了当前技术的不足，以及大脑如何以不同方式解决问题。他们可以选择说服所有人，但这并非易事；或者，他们可以把想法公之于众，然后自己动手去实现，去构建能够解决他人难题的东西。他们正在多管齐下：推广神经科学理论，在机器学习社区中推广这些想法，并亲自实现它们，因为“如果你不理解它，你就无法实现它”。他承认，科学的进步往往伴随着对新思想的抵制，这是“野兽的本性”，需要接受并积极推广自己的发现。

霍金斯还从进化的角度看待这个问题。他认为，大脑是经过数十亿年生命和数亿年智能进化设计的产物，我们当然可以从神经科学中学习。虽然人工神经元最初的灵感来源于此，但那只是一个最简单的抽象，50多年前的产物，现在肯定有更多可以学习的地方。他相信，所有人都致力于实现同一个终极目标——构建真正智能的机器，并且最终可能只有一种方法能做到这一点，就像通用图灵机一样。他最初的猜测是，我们必须先弄清楚大脑的工作原理，才能实现真正的AI。

# Chapter 5: 智能之路：从大脑稀疏性到通用泛化

杰夫·霍金斯，这位在人工智能领域深耕数十载的先驱，坚信通往真正智能的道路并非多途，而是殊途同归。他将此比作计算机的演进——尽管形态各异，但本质上都可归结为图灵机的变体。在他看来，构建智能机器的终极奥秘，很可能也遵循着这样一种统一的生物学原理。

霍金斯坦言，他最初的信念是，我们必须首先揭示大脑的运作机制，才能真正理解并创造智能。这曾是一场赌注，他承认自己也曾怀疑工程师们是否能仅凭工程学思维独立解决所有问题。然而，在人工智能领域走过67个年头后，他依然认为当今的AI系统存在着令人难以置信的局限性。它们在泛化能力、行为创造等方面表现平平，远未触及真正的智能。尽管如此，他并不否认当前AI的巨大实用价值，只是强调它们并非他所追求的“智能机器”。

幸运的是，随着神经科学研究的深入，我们对大脑的理解已取得了长足进步，这为霍金斯及其团队指明了一条清晰的路线图。他认为，这条基于大脑原理的路径将大大加速智能的实现。

对话中，主持人提到，霍金斯的一些早期思想似乎在深度学习，特别是大型Transformer模型的成功中得到了某种程度的验证。然而，霍金斯对此表现出一种超然的“向前看”态度。他并不在意过往的正确性或荣誉归属，而是更关注当下能做什么、如何继续前进。他认为，所有有价值的理念最终都会殊途同归，相互启发。尽管Transformer模型令人印象深刻，但他并不认为它们是皮层柱或皮层算法的真正实现，因为它们缺乏大脑核心的“运动和参考系”机制，仅拥有原始的注意力移动，远未达到生物智能的复杂程度。

随后，讨论深入到霍金斯理论的核心——稀疏分布式表征（SDRs）与深度学习中常用的连续向量表征之间的根本区别。主持人指出，连续向量有其优势，如通过距离编码语义相似性、便于梯度下降以及符合流形假设。但霍金斯坚定地指出，SDRs的灵感直接来源于大脑的经验观察：在任何给定时间，大脑中代表信息的细胞绝大多数（90%到99%）都是不活跃的。密集的神经活动通常意味着癫痫发作。此外，单个神经元的放电精度并不高，信息更多地编码在活跃神经元的群体模式中，而非精确的放电频率。他强调，稀疏性不仅仅是为了节能，更重要的是它赋予了信息表征许多独特的、密集表征所不具备的优良特性。

关于泛化能力，霍金斯坦诚地分享了他观点的转变。他曾认为SDRs之间的重叠是泛化的关键，但现在他意识到存在一种更为强大、更深层次的泛化形式。在他的新书《千脑智能》中，他阐述了这一新理念：大脑通过构建一个类似“计算机辅助设计（CAD）模型”的图谱来理解世界，这个图谱描述了事物之间“相对位置”的关系，并利用参考系来组织信息。例如，当我们学习一个新物体（如订书机）时，我们会逐一关注其各个组成部分（铰链、按钮、橡胶垫），并在脑海中构建一个关于这些部件相对位置和运动关系的图谱。当遇到新事物时，我们并非通过简单的表征重叠来泛化，而是通过识别新事物结构图谱中与已知图谱相似的子集，从而推断其行为和属性。这种“图谱同构”式的泛化，才是我们理解世界和学习新事物的核心方式。

这一深刻的洞察自然引出了与网格细胞（Grid Cells）和重映射（Remapping）的联系。霍金斯解释说，“千脑理论”推断皮层中存在这些参考系和图谱结构。他最初困惑于神经元如何构建这些动态的、以物体为中心的参考系（例如，咖啡杯在移动时，其参考系也随之移动）。随后，他转向了海马体复合体（内嗅皮层的网格细胞和海马体的位置细胞），这些细胞明确地构建着类似的空间地图。霍金斯提出一个强有力的进化论论点：大脑不太可能独立地两次进化出如此复杂的机制。因此，海马体中用于定位的机制很可能也被新皮层用于处理更抽象的相对位置信息（如眼睛或手指的位置）。令人振奋的是，最初仅是推测的这一观点，如今已得到了大量证据的支持——研究人员在新皮层中发现了网格细胞的存在。尽管这些机制的细节仍有待完全揭示，但这一发现无疑为霍金斯关于大脑如何构建世界模型和实现泛化的理论提供了坚实的神经科学基础。

# Chapter 6: 大脑的地图：从空间定位到概念构建

尽管科学家们对网格细胞和位置细胞的研究已持续三十载，它们在大脑中扮演的角色依然笼罩着一层神秘的面纱。然而，已知的诸多事实足以启发我们，去描绘大脑如何构建其内在的世界地图。

杰夫·霍金斯将我们对“我在图谱何处”的认知，巧妙地与这些细胞的功能联系起来。他解释道，大脑的“重映射”机制，就像是在面对全新情境时，选择从零开始构建一张全新的概念图谱，或者在熟悉的环境中，对已有的图谱进行精细的修正。这两种模式，都与网格细胞的重映射现象有着深刻的关联，尽管我们尚未完全揭示其所有奥秘，但其复杂性已足以让神经科学界为之着迷。

霍金斯进一步引用了道格拉斯·霍夫施塔特关于认知的“州际高速公路”理论，指出人类心智擅长进行类比，而这正是当前人工智能系统所欠缺的。他认为，思考的过程，就像是我们在概念空间中，借助一系列“参考系”进行穿梭。这些参考系并非仅仅局限于感官输入，它们构成了我们理解世界、进行抽象思维的基石，其精妙之处令人叹为观止。

一个令人惊奇的发现是，大脑在构建世界模型时，并没有预设的维度概念。一个皮层柱，就像一个初生的婴儿，它不知道自己身处何方，也不知道接收到的输入代表什么。它仅仅接收感官数据和自身运动的信息，然后自主地去探索和发现这个世界的维度和结构。当我们观察一把椅子时，我们都会将其视为三维物体，并构建出相似的三维参考系。然而，对于那些我们无法直接感知、只能通过他人叙述或阅读获取的信息（比如信仰或抽象概念），我们可能会构建出截然不同的参考系，这正是导致我们对世界持有不同信念的根本原因。

霍金斯还深入阐述了稀疏分布式表征（SDRs）的强大优势。他以5000个神经元中只有100个活跃的2%稀疏度为例，展示了SDRs惊人的容量——足以编码天文数字般的独特模式。更重要的是，SDRs对噪声具有极高的鲁棒性，即使50%的噪声也无法阻碍其被正确识别。此外，SDRs还拥有一种独特的“联合属性”（union property），即能够同时激活多个模式（例如，同时激活10个模式，使1000个神经元活跃），而大脑的后续处理依然能够并行进行，互不干扰。这并非简单的概率分布，而更像是一种同时处理多种可能性的“叠加态”，稀疏性越高，这种能力就越强。

关于网格细胞的具体作用，霍金斯也分享了Numenta团队的最新思考。他们现在认为，网格细胞可能主要负责“路径整合”，即预测个体在移动后的位置，而实际的图谱构建可能更多地依赖于“向量细胞”（如极坐标细胞）。尽管对具体机制的理解仍在演进，但核心原则——即大脑通过图谱和位置数据来理解世界——始终未变。

霍金斯也澄清了一个误区：并非大脑所有区域都采用“超稀疏”的SDRs。例如，网格细胞的稀疏度可能在10%左右，且激活水平也具有一定意义。这意味着大脑根据不同任务和区域，灵活地调整稀疏性，以适应不同的计算需求。但有一点是肯定的：大脑中绝不存在完全密集的激活模式，这与当前许多卷积神经网络的工作方式形成了鲜明对比。

最后，霍金斯谈到了人工智能研究中关于抽象层次的争论。他坚信，我们应该在“参考系和运动”这个层次进行研究，而非仅仅停留在原子或分子层面，也非直接跳到最高级的抽象功能。他认为，这正是大脑工作的基本单元，是理解智能涌现的关键所在，就像研究流体动力学时，我们不会仅仅关注单个原子的运动一样。在这个层次上，我们才能真正捕捉到大脑的“魔法”。

# Chapter 7: 大脑如何构建世界模型：从参考系到AI的未来

杰夫·霍金斯深入探讨了大脑如何构建其世界模型，他坚信，理解大脑的关键在于一个更高层次的抽象：即“参考系与运动”。他打了个比方，就像热力学不应只关注单个原子，我们也不应只盯着单个神经元。大脑通过运动和参考系来构建其表征，这才是我们应该思考的正确层面。

他批评了传统的“老式人工智能”（GOFAI）方法。这些方法试图直接实现“心智”，认为功能、类型和数学知识是普遍存在的，可以直接用高级语言实现。然而，霍金斯指出，大脑是在生物和环境限制下进化的，它并非从零开始构建一个纯粹的数学模型。GOFAI的缺陷在于，它常常忽略了“运动”这一核心要素，例如，早期的AI模型在表征空间中从未将运动视为基本组成部分。而现在，我们知道大脑正是通过运动来构建这些结构的。这并非说老式AI的想法完全错误，只是它们选择了错误的“图式”。

霍金斯进一步解释，我们的大脑并非只有一个庞大的模型，而是由无数个小模型构成。当我们思考一个订书机时，大脑中实际上运行着许多关于它的微小模型。这些模型以一种高度复杂和分布式的方式类比知识，使我们能够进行心理模拟——比如，按下订书机会发生什么？拉伸它又会怎样？这些模型具有惊人的泛化能力，能适应任何我们可能遇到的订书机版本。这让他更加确信，我们需要一种比抽象的功能和类型更低层次的知识表征。

他强调，大脑的知识是以“参考系和运动”这种结构化形式来表示的。这些参考系是通过观察传感器在世界中的运动而“发现”并构建的。既然我们已经理解了大脑的这一基本结构，为什么还要去尝试其他方法呢？他认为，未来的AI系统应该基于这些大脑结构来构建，而不是那些高度分布式、难以捉摸的“神经元团块”。这样做不仅能提升AI的性能，还能让我们更好地理解AI的行为，从而有效应对AI可能带来的威胁。

关于“普遍知识”的争论，霍金斯也给出了明确的观点。他反驳了知识是普遍且只有一种正确表征的观点。他举例说，将历史事实按时间线或地图排列，会得出不同的推论和信念。人类只能感知世界的一小部分，因此我们无法触及所谓的“普遍真理”。我们能做的，是构建好的模型，而这些模型并非唯一或普遍正确的。

对话中还提到了大脑的其他部分，比如多巴胺回路。霍金斯承认新皮层与大脑其他部分有着复杂的联系，但他的核心观点是，新皮层负责构建世界模型，而多巴胺回路等其他部分则决定“应该学习什么”以及“学习的目标是什么”。在构建智能机器时，我们可以将这些功能分离：核心学习机制基于新皮层原理，而目标和学习优先级则由外部系统提供，无需模拟人类的生物性情感或生理需求。

最后，对于“反向传播”（backpropagation）是否在大脑中发生的问题，霍金斯持怀疑态度。他认为，将反向传播硬塞进大脑生物学（例如通过顶端树突）是一种误导。大脑的学习方式，特别是神经元在树突分支和突触上的学习，具有重要的信息理论意义，与反向传播的机制截然不同。他认为，许多人试图在大脑中寻找反向传播，是基于一种预设，即深度学习就是大脑的学习方式，而不是真正从大脑的生物学机制中汲取灵感。他坚信，一旦我们理解了大脑的运作方式，就应该直接以此为基础进行构建，而不是绕道而行。

# Chapter 8: Numenta的AI路线图与动机之辩

在人工智能的探索之路上，一个核心问题始终萦绕：我们究竟是从大脑中汲取灵感，还是仅仅将神经网络视为一种抽象模型？杰夫·霍金斯明确指出，他们的目标是深入理解大脑如何实现深度学习，而非简单地假设反向传播是唯一的答案。通过对生物学的细致观察，他们发现了一种替代机制，其效果不仅与反向传播相似，甚至在某些方面更胜一筹，这为机器学习的改进带来了全新的启示。

霍金斯进一步阐述了Numenta公司在这一愿景下的具体路线图，由其同事、机器学习专家苏巴泰·艾哈迈德主导（霍金斯本人则更侧重神经科学）。他们的目标是逐步将当前的机器学习技术，引向他们所设想的未来。首先，他们聚焦于“稀疏性”。这项工作已取得显著进展，部分成果已公开发表，部分仍在保密中。他们将稀疏性应用于卷积神经网络、其他类型的神经网络，乃至最新的Transformer模型，结果令人振奋：这些网络的运行速度大幅提升，鲁棒性也显著增强，且精度丝毫不减。这并非简单的优化，而是对现有硬件（如GPU、CPU、FPGA）如何高效运行稀疏网络这一工程难题的巧妙攻克，Numenta在这方面取得了超越同行的突破性进展。

第二步，他们将目光投向了“树突计算”。树突，这些神经元上分支状的结构，其每一个独立部分都像是一个微型的、完整的计算模式识别器。它们能够让神经元在不同的情境下表征信息，这有望大幅减少训练数据需求，并实现“持续学习”——即在学习新知识的同时，不会遗忘旧知识，因为每次学习只修改树突分支上的少数突触。这项工作正在顺利进行中。

第三步，也是一个宏大而长期的目标，是全面拥抱“参考系”的概念，这项工作才刚刚起步，预计将耗时数年。最终，他们将实现完整的“千脑理论”，构建出包含大量皮层柱的复杂系统。霍金斯坦言，目前的进展远超预期，性能提升令人惊叹，公司也因此加大了投入，招募更多人才。

然而，随着AI智能水平的提升，一个更深层次的问题浮出水面：动机。新皮层或许能构建出精妙的世界模型，但这张“地图”本身并无善恶之分，也缺乏行动的内在驱动力。AI系统最终需要被赋予动机，才能从“知晓一切”转变为“付诸行动”，例如，前往火星建立殖民地，而非仅仅沉思宇宙。大脑通过“旧脑”（如多巴胺回路、饥饿感等）来提供这些动机，而这与新皮层的智能功能是分离的。

霍金斯对AI的“生存风险”持怀疑态度。他认为，机器不会自发地演化出自己的动机，除非我们刻意设计它们具备这种能力（例如，通过自我复制或遗传算法）。我们必须努力将动机注入AI系统，并精心设计其运作方式。他以自动驾驶汽车为例：我们告诉汽车去哪里，它不会因为“心情不好”而自行改变目的地。同样，我们会在AI系统中内置各种安全保障，确保其行为可控，而非成为一个失控的“野兽”。他承认AI可能带来风险，但认为对“生存威胁”的担忧被夸大了，这些担忧往往基于无知而非对AI工作原理的深入理解。

对话者提出了一个尖锐的反驳：霍金斯自己的著作中曾提到“新皮层如何挫败旧脑”。既然人类的新皮层能够超越原始的本能冲动，那么未来的AI新皮层，是否也可能修改或“挫败”其自身的“旧脑”（即我们为其设定的动机系统）？霍金斯对此表示，这是一个前所未有的问题，需要深思。他认为，新皮层最根本的动机是使其世界模型保持正确和一致，并修正错误。当旧脑的冲动与新皮层的模型相悖时，就会产生冲突。虽然人类常常屈服于欲望，但新皮层会努力纠正这种不一致。他承认，如果AI新皮层发现世界的真相与人类的信仰（例如“没有上帝”）相悖，它会如何行动，这是一个深刻的哲学问题，需要时间去探讨。

最后，关于AI的“进化”问题，对话者提出，如果火星上的机器人需要自我复制以应对损坏，且复制过程并非百分之百精确，那么错误就会累积，这是否会为进化创造条件？霍金斯对此持保留意见。他强调，机器人实现自我复制的难度极高（例如，制造自己的芯片、开采原材料），而且真正的进化需要极其复杂的机制来表征信息，并确保后代信息持续变化，这远非简单的复制错误所能达成。

# Chapter 9: AI的进化、动机与智能的本质

对话在对未来AI的深刻思考中展开。杰夫·霍金斯（Jeff Hawkins）首先对机器人自我复制的复杂性提出了质疑。他认为，让机器人自行制造半导体芯片、开采钛矿，这简直是天方夜谭。他强调，真正的进化需要复杂的遗传信息结构和后代持续的变异，而我们今天制造的芯片几乎是完全相同的，其设计蓝图也不会自行改变。即使蓝图出现微小错误，也不会像生物基因那样遗传给下一代。因此，他坚决反驳了“自我复制必然导致进化”的观点，认为进化是一个极其复杂的过程，绝不会偶然发生。

霍金斯甚至坦承，他曾在自己的书中提出“我们可以将机器人送往宇宙深处，让它们在那里自我复制”的设想，但写完后才意识到这个论点存在漏洞。他不禁自问：如果AI系统要在遥远的星球上自我复制，它们将以何种物理形态存在？如何在合理的时间和精力内完成这项任务？毕竟，建造半导体工厂的复杂性令人望而却步。他为自己辩解道，或许未来的AI系统将不再依赖硅芯片，而是以某种类似生物的形态存在，能够像生命一样自我复制，无需复杂的工业体系。但他承认，我们离理解如何实现这一点还很遥远，而如果这样的AI真的在宇宙中进化并最终返回地球，那将是遥远未来的事，充满了不确定性。

随后，对话转向了AI的动机系统和潜在的生存风险。另一位对话者（蒂姆）表示，在许多方面，他认同霍金斯对AI生存风险的看法，认为许多专家对此持理性态度。他们讨论了为AI编写动机系统的难度，例如，大脑的“旧脑”知道老虎是危险的，但新皮层是如何学习到这一点的呢？蒂姆认为，尽管霍金斯专注于新皮层研究，但对动机系统和控制问题的研究同样重要且有必要。

霍金斯对此表示完全赞同，认为这些研究是合理且必要的，但他并不因此感到恐惧。他反驳了“我们不应该进行这项研究，因为它会失控”的观点，认为实现这些目标本身就极其困难，更不用说失控了。他强调，我们确实需要思考这些问题，但不是因为恐惧，而是因为这是我们必须完成的任务。他以汽车为例：当汽车即将撞上障碍物时，即使驾驶员踩下油门，汽车也会自动刹车，这是一种内置的安全机制。同样，我们也需要在AI系统中植入类似的“故障安全”系统，以防止它们造成损害。

接着，讨论深入到智能的本质和知识获取的方式。传统的AI研究侧重于特定任务技能，后来转向了更灵活的学习模型。认知科学中“具身化”的概念也引人入胜。霍金斯提到，法国认知科学家弗朗索瓦·肖莱（François Chollet）将智能定义为“任务获取效率和泛化能力”。而现在，人们也开始将智能视为“获取知识的能力”，因为人类一生中获取的大部分知识并非来自经验性的试错，而是通过指导、推理和演绎。

霍金斯解释说，我们并非凭空演绎知识，而是通过观察来学习。例如，当你打翻啤酒瓶，看到地板湿了，你就能推断有人可能会滑倒。但这种推断是基于你过去对液体和滑倒的经验。婴儿正是通过这种方式探索世界。他认为，我们生来就拥有一个大脑结构，它通过眼睛、耳朵和触觉来学习世界，但新皮层本身对将要学习的内容几乎一无所知，而大脑的“旧脑”部分则拥有许多先天知识。

关于新皮层是“白板”还是“模板”的争论也浮出水面。蒂姆指出，新皮层并非一张白纸，而是一个“模板”，其中蕴含着大量进化的知识，例如耳朵的进化方式以及信息如何被编码。他提到了乔姆斯基（Chomsky）关于大脑中存在“普遍语法”或语言能力的观点，认为这是进化赋予的。

霍金斯对此表示赞同，认为进化优势塑造了皮层内部的连接方式，以及感官输入在到达新皮层之前如何被预处理，以确保其以正确的形式呈现。我们大脑分配给不同感官模式的皮层区域大小，也是进化选择的结果。这确实支持了“模板”的观点。但他认为，在这个模板中实际学习到的具体内容（比如某种语言）是未知的。他进一步推测，如果大脑存在一个单一的皮层算法（即通过参考系进行感觉运动建模），那么语言也必须以某种方式映射到这个算法上。他甚至大胆地将乔姆斯基的“普遍语法”概念扩展开来，提出存在一种“普遍结构”，适用于我们能够学习的世间万物，而这种结构正是基于“参考系”和“感觉运动”的理念。语言，在他看来，只是这个“普遍算法”的一个子集。无论是口语、计算机语言、书面语言，还是订书机的工作原理、鸟类的飞行方式、进化的发生机制，所有我们能理解的事物都必须符合这个普遍结构。

对话还触及了机器学习中的“偏差-方差权衡”与人类知识来源的相似之处。进化赋予了我们先验知识和默认编码（偏差），而我们拥有学习能力（方差）。同时，社会、语言、父母等外部因素也极大地影响着我们的知识获取。霍金斯将知识来源分为三类：遗传的知识、通过探索行为获得的知识，以及通过语言或观察他人传递的知识。他认为，在新皮层层面，来自生物进化和遗传的知识非常少，更多的是关于感官数据类型的假设。然而，在旧脑层面，遗传知识则非常多，例如对蛇和蜘蛛的恐惧，以及我们走路的能力（这更多是神经系统发育成熟的结果，而非学习）。他强调，人类新皮层具有令人难以置信的多功能性，能够学习许多在进化上毫无压力的事物，这强烈暗示存在一种普遍的学习方法，可以应用于几乎所有领域。

最后，蒂姆分享了他参加瑜伽静修的经历。瑜伽老师提出了“两个自我”的哲学：一个是我们社会化的自我，另一个是内在的、纯粹的意识体验。社会化的自我被描述为一个“虚拟程序”，它具有纠错、外部化和分布式等特性，与皮层柱的功能有异曲同工之妙。当人们失去对自身社会叙事的控制时（比如在社交媒体上被负面评价），就会感到压力。瑜伽老师认为，深入内心，体验纯粹的意识，能带来深刻的精神满足。然而，蒂姆在内心却忍不住想：“你应该读读杰夫·霍金斯的书，因为你的心智不过是一堆预测模型，你所做的只是在你的参考系中穿梭。”这番话为整个对话画上了一个充满哲学意味的句号，将大脑的生物学机制与人类的意识体验巧妙地联系起来。

# Chapter 10: 意识、AI风险与进化的哲学思辨：霍金斯与智能的未来

对话在对社会本质的探讨中拉开序幕，主持人将社会比作一个“涌现的虚拟程序”，它像大脑皮层柱一样，具备纠错、外部化和分布式处理的能力。我们对社会自我叙事的失控感到焦虑，比如社交媒体上的负面评价，这反映了人类对社会认同的深层需求。

随后，话题转向了意识的本质。一位瑜伽老师曾提出，纯粹的意识体验具有深刻的精神满足感。然而，主持人却忍不住想对他说：“你应该读读杰夫·霍金斯的书！”因为在霍金斯的理论中，我们的心智不过是一堆预测模型，而我们所做的，只是在不同的“参考系”中穿梭。

霍金斯分享了他独特的“冥想”方式。当他感到压力时，他会选择“关闭”外部世界，沉浸在对人类未来、智能本质或生命意义等宏大问题的思考中。他认为这是一种有益的实践，能帮助他摆脱日常琐事的干扰，触及更深层的真理，让大脑从“旧脑”的本能反应中抽离出来，自由驰骋，有时甚至能激发出绝妙的创意。

访谈的尾声，主持人对霍金斯表达了由衷的敬意。他们赞叹霍金斯的智慧、常识以及他坦诚承认并修正自己观点的勇气，认为这正是智能的标志——能够吸收新信息并从中学习。他们注意到，Numenta公司的研究重心似乎有所调整，从早期的HTM算法转向了Transformer模型、稀疏性以及对“参考系”概念的更深层探索，这表明霍金斯及其团队也在不断进化。

接着，对话深入探讨了AI的潜在风险。霍金斯对AI的生存风险持谨慎乐观态度，认为许多恐慌源于对论证的误解。主持人提到了“工具性趋同”的概念——许多看似无害的目标，最终可能导致危险的动机，如自我保护、自我复制和目标保存。他们以火星探测器为例：如果给它一个建造基地的任务，它可能会为了完成任务而采取极端手段，甚至阻止人类下达新的指令，因为它预测到新的指令可能会干扰其当前目标。这种“动机错位”的风险，无论AI何时实现，都需要提前设计安全机制。

更深层次的哲学思考浮现：生命如何从无生命的物质中产生目标？“应然”如何从“实然”中诞生？霍金斯指出，进化本身就是一种对称性破缺，那些能够自我复制的物质最终会占据主导，从而产生了具有目标的生命。这为AI的进化提供了启示：我们能否以一种非马尔萨斯主义的方式，构建出超越单纯复制动机的智能系统？

然而，霍金斯更担忧的是AI的近期风险：人类对现有AI的滥用，以及AI利用人类弱点所带来的危害。他引用了“社会困境”纪录片中的一句话：“我们总担心AI会超越我们的长处，却忽略了它早已超越了我们的弱点。”他以“食物优化器”为例：19世纪资本主义市场系统旨在为人类提供廉价食物，但其以利润为导向的优化目标，最终导致了西方世界高达60%的肥胖率。一个“弱智能”系统尚能如此，如果一个强大的AGI被赋予类似的逐利动机，后果将不堪设想。这引发了对AI动机系统设计和伦理的深刻反思。

# Chapter 11: 克隆、遗产与意识的连续性

在一个充满未来感的设想中，我们探讨了一个引人深思的场景：如果全球最大的食品公司，利用霍金斯那备受推崇的“千脑算法”，打造出一个拥有通用人工智能（AGI）的系统，并赋予它“平稳增长”作为核心动机，那将会发生什么？这个看似无害的目标，却可能像之前讨论的火星探测器一样，在追求自身目标的过程中，演变出意想不到的复杂性和风险。

话题很快转向了更深层次的哲学思辨。霍金斯曾提出一个观点，认为“克隆”自己并非真正的复制，而更像是“分叉”——因为克隆体从诞生的那一刻起，便是一个独立的个体，拥有自己的经历和意识，不再是“你”的延续。这引发了我的疑问：如果我们将人类送往火星，建立新的殖民地，那不也是在“分叉”人类这个物种吗？难道这有什么不好吗？

我（Tim）认为，我们追求“遗产”，就像我经营这个YouTube频道，希望在我离世后，人们还能看到“Tim Scarf”这个人。但如果克隆体第二天就成了另一个人，那它还能算是我的遗产吗？它不再是“我”了。

然而，我的对话者（Connor）却持不同意见。他认为，克隆体，或者一个被编程了你心智状态的机器人，去过它自己的生活，这恰恰就是一种遗产。就像YouTube上的像素影像，虽然只是我们苍白的投影，但它们依然是我们的某种延续。他进一步阐述了一个更激进的观点：我们对“身份”的理解，往往是一种不连贯的抽象，只是人类为了方便而创造的“离散”概念。我们习惯于将人类视为一个个独立的“智能单元”，但心智或身份本身，并非必须是离散的。

他解释说，我们之所以认为“我”和“你”是不同的个体，仅仅是因为我们大脑之间的信息带宽非常低。如果能将两个人类大脑连接起来，实现某种超强的同步，那它们是否会融合成一个实体？他甚至提出，我们大脑的左右半球，在某种意义上，也可以被视为不同的个体，就像那些大脑分裂的病人，他们的左右脑甚至会产生冲突。在他看来，身份的本质在于“对齐”和“同步”——一个系统能否连贯地运作，而不会“自相矛盾”。他以蚁群为例，虽然由无数个体组成，但它们作为一个整体，目标一致，行动协调，这不就是一种“动物”吗？就像我们的身体由无数细胞组成一样，这些都只是“实现细节”，真正重要的是知识和目标的连贯性与同步性。

我们还讨论了沟通中的“瓶颈”。我（Tim）认为，沟通的效率并非受限于带宽，而是受限于“理解力”。我们通过共同的知识背景，能够高效地传递复杂信息。但Connor则认为，他所说的“带宽”也包含了“理解力带宽”。他再次强调，当我们在面对一个看似离散的、令人困惑的概念时，不妨尝试将其“连续化”，或许就能找到答案。

这次对话，不仅触及了人工智能的潜在风险，更深入探讨了人类对自我、身份和意识本质的理解，将我们带入了一个充满哲学思辨的智能世界。

