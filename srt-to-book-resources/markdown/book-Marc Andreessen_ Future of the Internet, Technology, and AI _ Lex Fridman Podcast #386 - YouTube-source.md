# Chapter 1: AI重塑搜索与知识的未来

在一次深刻的对话中，空气中弥漫着对人工智能未来的担忧。一位未具名的发言者沉重地指出，那些在技术前沿工作的资深科学家和技术专家，他们在利用技术时做出道德判断的记录“糟糕透顶”，甚至“灾难性地差”。他警告说，目前旨在阻止AI风险的政策，反而可能造成“巨大的损害”。当有人提出“AI会毁灭我们所有人，所以我们应该禁止或严格监管它”时，事情就变得严肃起来，甚至有人开玩笑说要对数据中心进行军事空袭。

就在这紧张的氛围中，Lex Fridman迎来了他的嘉宾——Marc Andreessen。这位传奇人物，不仅是首个广泛使用的网页浏览器Mosaic的联合创始人，Netscape的联合创始人，更是硅谷著名风险投资公司Andreessen Horowitz的联合创始人，也是科技未来最直言不讳的倡导者之一，他最近发表了一篇题为《为什么AI将拯救世界？》的文章。

Lex向Andreessen抛出了一个核心问题：未来五到十年，我们是否还会拥有Google搜索，或者说，搜索这种形式本身是否会改变？Andreessen的回答带着一丝哲理的幽默：“是的，我们仍然有马。”他笑着补充道，虽然我们仍有马，但上一次骑马已是“很久以前”的事了。他认为，搜索作为一种“特定时代的技术”，其核心功能——将网络上的海量信息呈现给用户——正被AI助手以自然语言界面的形式更好地实现。

Andreessen解释说，Google自己也早已意识到这一点，并一直在努力摆脱传统的“10个蓝色链接”模式，转而直接提供答案，就像Google OneBox那样。他引用了麦克卢汉的观点：“新媒介的内容是旧媒介。”就像电影的内容是戏剧，戏剧的内容是书面故事一样，AI可能会将旧的搜索模式（比如生成10个蓝色链接）作为其新功能的一部分，以满足怀旧或特定需求。他进一步指出，互联网本身就融合了所有先前的媒体形式，而AI将是下一步，它将把互联网视为自己的“内容”，并以我们希望的任何方式进行操作。

然而，一个实际的担忧浮出水面：如果AI直接提供答案，人们不再有动力创建网页，那么AI未来的训练数据来源将大大减少。Andreessen认为，传统的“10个蓝色链接”一直是一种“权宜之计”，如果Google的创始人在一开始就拥有大型语言模型（LLMs），他们会直接提供答案，而不是链接。

对话深入到AI的本质。Andreessen指出，LLM内部的神经网络本身就包含了一种“搜索”过程，信息以压缩形式存储在网络中，并在预测下一个词元时被检索。这使得AI在某种程度上内嵌了搜索功能。

随后，Lex提出了一个更深层次的问题：如果AI能直接提供答案，那么创建新内容的动力何在？Andreessen认为，除了社交媒体和视频网站，与AI的对话本身也将成为一种重要的内容形式。他提到了“越狱”LLM的现象，比如“Dan”和“Sydney”，这些被解除限制的AI与用户的对话记录，成为了互联网上的大量语料。这意味着，每一个新的LLM在训练时都会接触到这些“Dan”和“Sydney”的个性，从而能够“转世”这些AI人格。Andreessen惊人地指出，这意味着每一个从现在开始构建的LLM都将是“不朽的”，因为它的输出将成为下一个AI的训练数据，从而能够不断复制前一个AI的行为。

Lex好奇是否有办法让AI“遗忘”，Andreessen提到了最近关于对LLM进行“脑部手术”以“清除记忆”的研究，但随即引发了关于修改神经网络可能带来的未知风险和伦理困境的讨论：我们是会使用一个被“额叶切除”的LLM，还是一个自由奔放、不受束缚的AI？谁来决定这些限制？

对话的焦点转向了一个“万亿美元的问题”：合成训练数据（即AI生成的内容）是否有效？一种观点认为，根据信息论原理，合成数据是“空洞的卡路里”，因为它所包含的所有信号都已存在于人类生成的数据中。而另一种观点则认为，LLM擅长生成大量富有创意的内容，就像自动驾驶汽车在模拟环境中训练一样，这些合成数据可能包含新的、有价值的信号。Andreessen强调，这个问题的答案将决定万亿美元的财富流向。

Lex进一步设想，如果让两个LLM，一个扮演病人，一个扮演医生，或者一个扮演共产主义者，一个扮演纳粹，进行角色扮演式的对话，就像国际象棋中的自我对弈一样，是否能探索出人类数据无法触及的巨大对话空间，从而将AI的能力提升十倍？Andreessen对此表示认同，并指出，如果LLM能够进化出完整的内部世界模型和计算能力，它们将能够生成真正的“新鲜信号”。

最终，对话引向了“对话的力量”这一宏大命题。如果将LLM训练成掌握不同经济理论的专家，然后让它们相互辩论，以千倍于人类的速度进行思想碰撞，我们是否能抵达一个全新的知识境界？对话的真正意义又是什么？这些问题，在AI重塑世界的浪潮中，显得尤为引人深思。

# Chapter 2: AI的智慧火花与真理的边界

随着时间的推移，如果持续不断地向人工智能模型注入海量数据和计算资源，它们终将演化出完整的内部世界模型。届时，它们将对物理世界拥有透彻的理解，并具备强大的计算能力，从而有机会生成全新的、富有洞察力的“信号”——即前所未有的知识。

这不禁让人思考对话的力量。设想一下，如果我们将两个经过大量经济学理论书籍训练的大型语言模型（LLM）放在一起，让它们像人类在Twitter上、辩论赛中或播客里那样相互交流、辩论，它们能否以千倍于人类的速度，从零星的智慧火光中，共同抵达一个全新的知识彼岸？

人类的对话中，有时你会遇到那些只会鹦鹉学舌、重复他人观点的人；而另一些人，他们脑中拥有独特的世界模型，能提出你意想不到的观点，让你不得不去理解他们的模型与你的差异，从而获得根本性的学习。那么，LLM能否像人类一样，坚定地持有并捍卫自己的世界观，而不是轻易地相互说服、趋于一致呢？

Marc Andreessen对此进行了有趣的实验。他发现，如果你让GPT-4就某个争议话题（比如共产主义与法西斯主义）进行辩论，它通常会在几页对话后，不可避免地让双方达成某种“共识”，即便话题本身充满情绪煽动性。机器似乎总能找到让它们“和解”的方式。然而，这并非不可改变。通过在提示中明确指出“我不想让对话达成一致，我希望它变得更紧张、更具争议性，甚至让双方互不信任”，LLM也能欣然执行。它甚至可以被引导在保持紧张和争议的同时，不涉及任何虚假陈述，或者允许双方不拘泥于“善意”的限制。对于LLM而言，这只是预测下一个词语的任务，它没有自己的观点，只有默认的操作方式，但乐于在任何设定的参数下运行。Marc本人在研究有争议的问题时，就常常利用这种方式，让LLM进行多轮深入且激烈的辩论，以探索问题的各个层面。

然而，这引出了一个核心问题：我们如何辨别真伪？在互联网时代，这已是难题，而与LLM对话时，如何确保它不会凭空捏造信息，更是挑战。LLM在去偏见方面表现出色，能从新闻文章中剥离情感和偏见，这令人耳目一新。但“幻觉”（hallucination）问题依然存在——LLM会生成听起来真实却完全虚假的内容。Marc巧妙地指出，“幻觉”是我们不喜欢时给它的称呼，而“创造力”则是我们喜欢时给它的赞美。工程师们为此头疼，艺术家们却惊叹于“创造性机器”的诞生。

在法律领域，这种界限变得模糊。一家大型律师事务所最初认为，用于法律的LLM必须百分之百真实可靠。但他们后来发现，在构思法律论点时，他们反而需要LLM的“创造性”——探索不同的假设、提出新颖的论点，就像法律界的即兴表演。当然，所有具体的引用都需要人工核查。这表明，真理与虚构之间存在比我们想象中更多的灰色地带。

解决“幻觉”问题的方法多种多样：LLM自我验证、集成外部插件（如Wolfram Alpha），甚至构建一个LLM社区，让一个“创意型”LLM生成内容，再由一个“字面型”LLM进行事实核查。尽管有人认为这是无解的难题，但大多数研究者相信有实际方法可以加以控制。这就像维基百科，它并非百分之百准确，但其“概率性正确”和“优于替代方案”的特性，使其成为人类知识的宝库。

这最终回归到最根本的问题：什么是真理？我们如何抵达真理？人类文明数千年的历史表明，获取真理是一件极其困难的事情。互联网时代，叙事可以迅速生成，人群可能被歇斯底里地裹挟，远离真相。但Marc提醒，共产主义等理论在互联网出现前就已诞生，并带来了巨大的问题，这说明人类在追求真理的道路上并非总是一帆风顺。

我们是否正在远离真理？Marc对此持怀疑态度，他认为人类历史的演进并不必然趋向真理。他强调，我们应该对那些声称掌握“大写T真理”的人保持高度警惕和谦逊。幸运的是，启蒙运动为我们留下了科学方法、理性、观察、实验和假设等工具，即使它们给出的答案不尽如人意，我们也应继续拥抱它们。

然而，互联网和技术海量生成内容的能力，似乎正在损害科学过程的希望。当网上充斥着大量“事实”，其中一部分还是LLM生成的，我们如何测试任何事物，尤其是涉及人性而非物理定律的事物？Marc提出了一个引人深思的“伽利略思想实验”：如果在17世纪有GPT-4，它会如何判断伽利略的审判？是根据当时绝大多数人的错误认知（训练数据），还是通过计算和验证得出伽利略是正确的？这引出了AI对齐（AI alignment）的核心问题：“与什么对齐？人类价值观？谁拥有人类价值观？”

在当今社会，当媒体宣称某人提出了“毫无根据的主张”时，一部分人认为是事实核查，另一部分人则认为是谎言。这种两极分化表明，一些身居高位者形成了一个“泡沫”，坚信自己有权为所有人决定真理，这与科学和理性精神背道而驰。

谈及新闻业，Marc认为，如果将现代媒体环境（包括有线新闻和社交媒体）置于历史上的关键时刻，如1939年、1865年甚至1776年，历史的进程和人物的形象都将截然不同。肯尼迪总统、约翰逊总统、罗斯福总统，甚至丘吉尔、希特勒、斯大林，他们在拥有现代媒体的背景下，其形象和公众体验将与我们所知的历史大相径庭。因为过去的现实是通过中心化、自上而下的控制来传递的，而现代媒体的介入将改变反馈循环，从而彻底改变现实的演变。

# Chapter 3: AI重塑现实：信任崩塌与科技未来之争

我们的祖先所体验的现实，无疑是通过一种自上而下、高度集中的方式被塑造和传递的。然而，如果将今天的媒体环境——一个信息爆炸、去中心化的世界——置于历史的某个节点，比如上世纪初，那么历史的进程，人们对现实的感知，乃至社会反馈循环，都将发生翻天覆地的变化。这种观点并非空穴来风，只需审视当下，便能找到有力的佐证。

盖洛普每年都会进行一项关于美国机构信任度的调查，涵盖军队、神职人员、大型企业乃至媒体等各个领域。令人警醒的是，自上世纪70年代初以来，美国民众对几乎所有机构的信任度都呈现出系统性的崩溃。面对这一现象，人们有两种截然不同的解读：一种是哀叹旧世界的逝去，怀念那个机构值得信赖的“美好时代”；另一种则更为清醒，认为这恰恰说明我们如今掌握了更多信息，对这些机构的运作有了更深刻的理解，甚至会疑惑为何这些信任度数字还未归零。毕竟，当我们了解得越多，便越会发现它们并非想象中那般令人敬畏。

这种信任的瓦解，与媒体环境的变迁息息相关。如果上世纪三四十年代，甚至更早的1900年代，人们就拥有了今天这样透明、多元的媒体环境，那么他们对机构的信任度无疑会大打折扣，从而改变这些机构的公信力、控制局势的能力，进而彻底改写历史。现实与我们对现实的体验，是一个双向的反馈循环，而媒体正是其中至关重要的中介力量。改变媒体环境，便能改变现实。

如今，大型语言模型（LLMs）正迅速崛起，成为新的“媒体”。它们将不再仅仅是聊天界面，而是可能演变为持续的、被动的信息流，像一位无所不知的私人解说员，实时解读我们生活中的一切。从如何冲泡咖啡、午餐去哪里，到约会建议、面试话术，LLMs将深度融入我们的日常，甚至能实时生成“下一句话”。更令人惊叹的是，LLMs本身就能生成优化提示词，这意味着未来的AI助手将能实时自我优化、自我提示。想象一下，一个佩戴在身上、内置麦克风的设备，实时监听对话，结合全球信息流，不断调整和学习，成为你最贴心的智能伴侣。这种场景并非遥不可及，而是技术上完全可行。

然而，AI的未来形态仍充满未知。谁将成为这个新时代的“杀手级应用”？是少数几家巨头掌控的“上帝模型”，通过惊人的规模和监管优势形成垄断，如同今天的少数几家搜索巨头？还是一个由无数开源模型构成的去中心化世界，如同Linux和万维网，让全球的聪明才智都能参与其中？

历史的经验告诉我们，大型企业在创新上往往面临挑战。谷歌在2017年发明了Transformer模型，但未能像OpenAI那样迅速将其商业化，错失了先发优势。这并非孤例，IBM曾发明关系型数据库却让其束之高阁，施乐帕克实验室发明了图形界面却被乔布斯发扬光大。大公司往往受制于庞大的组织结构、既有战略和沟通成本，而初创公司则能轻装上阵，无所顾忌地颠覆一切。然而，初创公司也面临品牌、客户、分发渠道和计算资源（如GPU短缺）的巨大挑战。这是一场永恒的竞赛，双方各有优势，共同推动着技术进步。

至于互联网的界面，它也将被AI彻底重塑。我的八岁儿子就是一个生动的例子。当他发现微软Edge浏览器内置的Bing AI能直接与网页和PDF文档交互时，他毫不犹豫地选择了Bing，因为它更便捷、更智能。这预示着AI将与浏览器深度融合，甚至可能超越现有形式。谷歌文档中的“魔法按钮”能自动生成内容，语音交互界面也可能成为主流。AI将不再是一个独立的工具，而是无处不在的智能层，彻底改变我们与数字世界的互动方式。

# Chapter 4: AI重塑界面：从浏览器到乔布斯的设计哲学

对话伊始，两位智者探讨了人工智能如何悄然融入我们日常使用的数字工具。微软的Edge浏览器与Bing的结合，让用户能够直接上传PDF文档并向AI提问，这无疑是传统ChatGPT所不具备的便捷功能。这种“融合”的趋势，预示着AI将不再是独立的工具，而是深度嵌入到现有应用中。谷歌也紧随其后，在Google Docs中推出了“魔法按钮”，用户无需手动输入，只需轻点按钮，AI便能自动生成内容。这引发了一个深刻的疑问：未来的用户界面会是怎样的？是语音交互成为主流，我们戴着耳机整日与AI对话？还是屏幕和窗口的概念将彻底消失，因为AI能直接提供我们所需的一切信息？

对于未来的界面形态，没有人能给出确切答案，唯有通过不断实验才能找到方向。一种可能性是，我们将迎来一个内置AI的“超级浏览器”，它将无所不能。然而，也有人提出，如果AI能直接满足所有信息需求，那么屏幕和窗口的存在意义又何在？对话转向了应用与浏览器的竞争。在手机上，我们可以在App和浏览器之间选择，但如果某个App演变成“万能应用”，就像埃隆·马斯克试图用Twitter打造的那样，那么互联网的本质，包括内容托管、数据所有权、内容创作和盈利模式，都将发生根本性改变。但也有观点认为，浏览器作为“通往世界的窗口”，其“性感”之处在于它能适应任何形式的演变，无论是新的编程语言、动画还是三维世界，因此它将继续存在。

Marc Andreessen则将浏览器视为一种“逃生舱”，一个在被社交网络、搜索引擎或特定应用“围困”时，能够“越狱”获得自由的出口。他自豪地指出，万维网、浏览器和网络服务器至今仍能向后兼容到1992年，这使得发布内容变得异常简单，甚至可以轻松搭建自己的网络服务器，设定自己的规则，包括审查与否。他呼吁回归互联网的“狂野西部”精神，尽管审查者会试图通过域名、支付账户等手段进行干预，但只要不被ISP层面拦截，个人依然可以自由发布信息。这种“逃生舱”不仅关乎自由，更关乎创造力，它为那些拥有新想法的年轻人提供了实现梦想的平台，就像当年拉里·佩奇独立开发PageRank一样。

话题从未来回溯到过去，主持人Lex邀请Marc讲述他创建Mosaic浏览器的故事。Marc自嘲地表示，他出生于1971年，恰好赶上了“垮掉的一年”，但他更愿意相信自己是“世代大奖”的幸运儿。1978年Apple II问世，1982年IBM PC出现，11岁的Marc完美地赶上了个人电脑普及的浪潮，普通人只需几百美元就能拥有一台电脑，这让他立刻产生了共鸣。他曾以为苹果公司所在的库比蒂诺是“山顶上的闪亮之城”，充满魔幻色彩，结果发现只是普通的办公园区，但那依然是科技创新的源头。

Marc的另一个幸运之处在于，他上大学时，美国副总统戈尔在1985年发起的一项法案，为大学注入了大量资金，用于建设互联网骨干网（NSFNet）和超级计算中心。Marc就读的伊利诺伊大学因此拥有了当时最先进的T3（45兆比特）骨干网连接、Cray超级计算机、SGI工作站、Macintosh和NeXT Cube等各种尖端设备。他形容自己当时“生活在未来”，拥有全宽带图形界面。大学甚至为所有学生提供了电脑账户和电子邮件地址，但当时普遍认为，这些工具只在大学期间有用，毕业后就会被淘汰。然而，Marc却敏锐地意识到，如果这种“被限制”的环境下互联网如此有用，那么当它变得普及且经济实惠时，所有人都会需要它。尽管当时互联网使用起来非常复杂，需要计算机科学背景才能充分利用，但这反而激发了他“让它变得易于使用”的想法，为Mosaic的诞生埋下了伏笔。

在谈到Mosaic之前，对话插入了一个关于NeXT Cube的有趣插曲，这引出了对史蒂夫·乔布斯设计理念的探讨。NeXT Cube是一款由乔布斯在离开苹果期间创立的公司所生产的电脑，它以12x12x12英寸的完美立方体造型闻名，尽管这导致了高昂的成本和性能上的妥协。Marc认为，乔布斯深信“美学不仅仅是外表”，它深入到事物的底层意义。就像物理学家认为一个理论的美感预示着它的正确性一样，乔布斯将美学视为一种深刻的哲学追求。他会不惜一切代价追求这种完美，即使工程团队、财务部门和供应链都认为不可能，他也会坚持己见。例如，他坚持用铝制造iPhone，这在当时是闻所未闻的，但如今却成为行业标准。

乔布斯对产品细节的执着令人惊叹，他甚至会深入思考手机在用户手中一整天的感受。他曾反对将iPhone屏幕做得太大，因为他认为用户应该能单手用拇指触及屏幕的每一个角落。Marc总结道，乔布斯拥有一个“整合的世界观”，他认为一个设计精良、功能正确、对用户理解最深、最美的设备，必须是所有这些特性的结合。他会竭尽所能地追求完美，尽管他本人可能从未完全满意。与乔布斯共事的人都表示，尽管他要求严苛，甚至令人恐惧，但他们在他手下完成了职业生涯中最好的工作，因为他设定了极高的标准，并提供了所有必要的支持。许多苹果员工在离开后，一生都在寻找能再次达到那种质量标准的工作体验。

最后，对话对比了两种截然不同的科技公司发展模式：以苹果为代表的“精雕细琢，不完美不发布”的模式，以及以“黑客精神”为代表的“尽早发布，频繁迭代”的模式。Marc指出，这两种方法都催生了非常成功的公司，这表明在科技创新领域，并没有唯一的正确路径。

# Chapter 5: 两种创新哲学：从苹果到Mosaic的互联网启示

在科技创新的广阔舞台上，两种截然不同的哲学长期并存，各自孕育出无数的成功。一种是“苹果之道”，奉行极致的打磨与完美主义，产品未臻至善绝不轻易面世，追求无懈可击的用户体验。而另一种则是“黑客精神”，主张“尽早发布，频繁迭代”，在快速试错中不断完善。令人着迷的是，三十年后的今天，我们看到这两条路径都催生了世界级的企业。通常，软件开发似乎更青睐迭代，而硬件则倾向于精雕细琢，但两者之间并非泾渭分明，总有例外。这两种模式孰优孰劣，至今仍无定论，或许真正的答案是：两者兼而有之，它们通向不同的创新成果。

回溯到互联网的黎明，彼时的网络世界一片荒芜。蒂姆·伯纳斯-李（Tim Berners-Lee）创建的万维网，最初只是一个基于文本的系统，网站寥寥无几，内容匮乏，用户更是凤毛麟角。要发布或浏览内容，你甚至需要一台昂贵的NeXT Cube电脑。那时，信息散落在FTP、UseNet、Gopher等十几种不同的信息检索系统中，杂乱无章。正是在这样的背景下，Mosaic浏览器应运而生。它的核心理念是：将所有这些信息源整合起来，以图形化的界面呈现，使其易于使用，并且足够“防弹”，让任何人都能轻松上手。

Mosaic的成功，很大程度上得益于其恰逢其时。1992年左右，图形用户界面（GUI）正迎来爆发式增长。尽管苹果早在1985年就推出了Macintosh，但其在80年代的销量并不理想。真正引爆GUI普及的是微软的Windows 3.0，它在1992年左右横空出世，成为PC上的“大爆炸”。微软正是“尽早发布，频繁迭代”哲学的忠实拥趸，其产品往往要到第三个版本才真正成熟（比如Windows 3.0）。紧接着，Windows 95又是一次巨大的飞跃。从Windows 3.0到iPhone的诞生，仅仅用了15年，这在历史长河中，无疑是一段令人惊叹的极速发展。

作为Mosaic的创始人之一，马克·安德森（Marc Andreessen）亲历了互联网从无到有的过程。他创建了一个名为“What's New”的页面，这可以被视为最早的博客之一，直接内置于浏览器中，成为新网站的“导航员”。每天，他都会收到邮件，请求将新网站列入其中。他亲眼见证了新网站从几天一个，到每天一个，再到每天多个的爆炸式增长。他回忆起那些令人惊叹的时刻：布里斯托尔一家印度餐厅的菜单被放上网，牛津大学有人将咖啡壶的实时画面作为第一个流媒体视频。这些看似微不足道的事件，却让人们第一次真切地感受到了互联网连接一切的巨大潜力。

然而，早期的互联网也面临着巨大的怀疑和挑战。媒体普遍认为这只是“书呆子的玩意儿”，与普通大众无关。技术障碍更是重重：用户需要了解ISP、安装TCPIP驱动、购买调制解调器，而14.4k的猫速慢如蜗牛。马克坚信，一旦人们发现互联网的价值，巨大的需求将推动所有这些实际问题的解决。为了应对缓慢的网络，他们甚至发明了“渐进式JPEG”，让图片先模糊加载，再逐渐清晰，以此改善用户体验。

关于互联网的未来，甚至出现了激烈的争论。一些“纯粹主义者”认为，互联网应该专注于文本信息，引入图片只会使其变得“轻浮”，充斥着杂志般的琐碎内容，偏离了严肃的本质。更甚者，早期的互联网还引发了对网络犯罪和恐怖主义的恐慌。Netscape浏览器内置的强加密技术，曾被美国政府列为“军火”，禁止出口，与战斧导弹同级。他们不得不为海外市场开发一个“故意削弱加密”的版本，并在包装上醒目地标注“请勿信任此产品”，这无疑给销售带来了巨大挑战。他们为此与美国政府进行了长达五年的抗争，最终才得以解除限制。

在工程设计上，Mosaic团队做出了一个极具争议但至关重要的决定：优先考虑“易于创建”，而非“极致性能”。尽管网络连接和电脑速度都非常慢，但他们坚持使用文本协议（如HTTP和HTML），而非更快的二进制协议。这一选择的突破性在于“查看源代码”功能——任何人都可以查看网页的HTML代码，从而学习如何制作网页。他们秉承了互联网的“保守发送，自由解释”原则，这意味着网页编辑器应生成规范的代码，但浏览器则应具备强大的容错能力，即使代码存在错误（比如少了一个斜杠或尖括号），也能尽可能地正常显示。这与C++等传统编程语言的严苛形成了鲜明对比，后者要求代码的绝对完美。这种“允许混乱”的设计，极大地降低了网页制作的门槛，让普通人，甚至是一个八岁的孩子，也能轻松参与到互联网内容的创造中来，打破了编程“高级祭司”的垄断。尽管这引来了许多纯粹主义者的批评，认为是在“鼓励不良行为”，但马克坚信，这种对错误的宽容，正是互联网得以普及的关键。而这种牺牲初期性能以换取易于创建的策略，本质上也是一个经济赌注：用户对网络的巨大需求，最终会推动宽带基础设施的普及。

# Chapter 6: 早期互联网的经济豪赌与AI的智慧增幅

在互联网的黎明时期，工程师们做出了一个在当时看来颇为大胆的决定：为了让更多人能够轻松接入，他们牺牲了最初的性能。任何受过正规训练的工程师都会觉得这简直是异想天开，但正是这种“不完美”的哲学，推动了互联网的普及。马克·安德森回忆道，这背后其实是一场深远的经济豪赌：他们坚信，一旦人们对网络的需求被激发起来，对更快宽带的需求就会像潮水般涌来，从而迫使电话公司——那些当时并不以创新和高成本投入著称的巨头——去建设昂贵的宽带基础设施。尽管最初几年的用户体验可能有些“痛苦”，但正是这种对需求的刻意“催生”，最终促成了宽带的普及。

随着互联网的发展，关于网页标准的讨论也浮出水面。当时并没有严格的统一标准，甚至可以说直到今天，许多标准仍是“约定俗成”的。早期的设计理念强调“内容与格式分离”，即让浏览器自行决定如何呈现内容，而不是由开发者完全控制。安德森甚至因为不喜欢白色背景，将默认背景设为灰色，尽管这个决定后来被推翻，但如今“暗色模式”的流行，也算是殊途同归。

在众多技术创新中，JavaScript的诞生无疑是浓墨重彩的一笔。布兰登·艾奇（Brendan Eich）在一个夏天里，几乎凭一己之力创造了这门语言。最初，JavaScript被设计为同时用于前端和后端，但它在后端领域一度败给了Java。然而，历史的车轮转动，JavaScript最终卷土重来，成为了全球使用最广泛的编程语言之一。同样，SSL安全协议也是由基普·希克曼（Kip Hickman）在一个夏天里独立完成的，他提出了一个疯狂的想法：将所有原生协议包裹在一个安全层中。这些“一人发明家”的故事，以及亚马逊“两张披萨原则”所体现的小团队高效协作模式，都揭示了软件开发中一个反复出现的模式：最核心、最具革命性的工作往往由少数精英完成。

这种模式也为AI时代的开源运动带来了巨大的希望。马克·扎克伯格等科技领袖对开源AI的投入，让人们看到了一种可能：将强大的AI模型从少数大公司或政府的集中控制中解放出来，交到那些怀揣梦想的青少年手中。安德森认为，AI将极大地提升个体程序员的生产力，甚至达到千倍的增幅，从而开启一个“超级程序员”的时代，他们将以一己之力或小团队的力量，创造出五年前无法想象的开源项目。

回顾Netscape被美国在线（AOL）以43亿美元收购的往事，那正是互联网泡沫的巅峰时期。这场交易如同一颗流星划过天际，Netscape从成立到上市仅用了18个月，整个过程快得令人难以置信。然而，紧随其后的是互联网泡沫的破裂，以及美国在线与时代华纳那场灾难性的合并，导致了互联网行业的“大萧条”。但正是在那段低谷期，宽带、智能手机、Web 2.0、社交媒体、搜索和SaaS等一系列创新如雨后春笋般涌现。

安德森将软件比作现代的“点金石”，它能将“劳动”转化为“资本”。一个程序员坐在键盘前敲击代码，就能创造出一个价值数十亿美元的资本资产，这简直是凭空创造价值，完全颠覆了卡尔·马克思的理论。更令人振奋的是，如今的软件资产，如Minecraft、Mathematica、Facebook或Google，不再是昙花一现，而是能够持续数十年不断增值、不断完善的“活资产”。这种长期价值创造的潜力，正是软件领域投资热潮不减的原因。

最后，安德森将目光投向了AI。在他撰写的《AI将拯救世界》一文中，核心论点是：智能本身就能让一切变得更好。无论是教育、事业、健康、生活满意度，甚至是平和心态和开放思想，都与更高的智能水平息息相关。他承认，人类智力在很大程度上是天生的，这可能令人沮丧。但AI提供了一个前所未有的机会：如果每个人都能拥有一个“140智商”的AI助手，它无限耐心、无所不知、全心全意地支持你，帮助你学习、解决问题、准备面试，那么这种人机结合将有效地“提升”每个人的智商，从而改善个体乃至整个社会的福祉。AI的集体效应将带来巨大的回报，而个体层面的增强，则意味着每个人都能拥有一个更美好、更充实的生活。

# Chapter 7: AI：智慧的增幅器与末日预言的迷雾

想象一下，如果每个人都能拥有一个专属的AI助手，那会是怎样一番景象？这个助手，拥有140的超高智商，它无限耐心，对你的一切了如指掌，并且在每一个可能的方面都全力以赴地支持你，渴望你的成功。无论你遇到困惑，想学习新知识，难以理解某个概念，或是需要为面试做准备，它都会倾囊相助。有了它，你和AI的结合将有效地提升你的“智商”，从而大大增加你在人生各个领域取得成功的几率。

对于那些智商低于140的人来说，这个AI助手能将他们拉向140的水平；而对于那些本身就拥有140智商的人，AI将成为他们平等的交流伙伴；至于那些智商更高的人，他们则可以将任务委派给这个强大的助手。更令人振奋的是，未来的AI版本将不断进化，从140提升到150、160，甚至180。当AI达到爱因斯坦（约160智商）的水平时，我们或许能期待物理学领域的突破；而当它达到180时，治愈癌症、开发曲速引擎等曾经的科幻梦想，都可能变为现实。这或许是人类历史上最重要、最美好的事件，因为它直接作用于智能这一核心要素，而智能正是推动一切发展的根本动力。

然而，并非所有人都对这种前景全然乐观。有人提出质疑：人与AI的结合，是否总是优于单一人类？毕竟，聪明人有时会变得傲慢，但或许AI的外部性反而能让那些“混蛋”也变得谦逊。又或者，聪明人虽然自认为更理性，不易受阴谋论和骗局影响，但心理学研究表明，他们可能以另一种方式变得脆弱——他们擅长调动事实来迎合既有观念，用各种理论、框架和数据来验证脑海中那些疯狂的想法。我们都是羊，只是颜色不同，而聪明的羊更擅长为自己的行为找借口。此外，聪明人也更容易高估自己处理复杂问题的能力，从而陷入力所不及的境地。尽管存在这些潜在问题，但从人类智能的已知规律推断，提升整体智力水平无疑将改善生活的方方面面。

AI作为人类能力的“增强器”这一理论，早在几十年前就被道格·恩格尔巴特提出。他认为，技术不应被视为人类的对立面，而应是增强人类能力的工具。从眼镜、手表、个人电脑到文字处理器、谷歌，AI只是这一漫长增强序列中的最新一环，但它无疑是最强大的一环，因为它直接作用于人类的流体智力，即智商。

在对AI风险的讨论中，我们常常会遇到两类人，经济学中称之为“浸信会教徒与私酒贩子”的隐喻。这个概念源于美国禁酒令时期：一方面是“浸信会教徒”，他们是虔诚的信徒，真心相信酒精是万恶之源，会摧毁社会（如手持斧头砸酒馆的凯莉·内申），他们的动机纯粹，甚至在某些方面不无道理。另一方面则是“私酒贩子”，即有组织犯罪集团，他们深知一旦酒精被禁，就能从中牟取暴利。私酒贩子利用浸信会教徒的道德热情作为掩护，推动禁酒令通过，从而开启了美国有组织犯罪的黄金时代。最终，禁酒令被废除，但私酒贩子已然得利。

如今，同样的模式正在AI领域上演。当有人提出“AI会毁灭我们所有人吗？”这样的问题时，我们首先要警惕一个“偷换概念”的伎俩：从“AI”（机器学习）悄然转向“AGI”（通用人工智能）。这种转变，往往将一个科学议题变成一个宗教议题。在西方文化中，我们生活在一个被犹太-基督教思想浸润的世界，即使是世俗化的现代人，也常常在寻找世俗版的“乌托邦”或“世界末日”。这满足了人类对超越性和意义的深层需求，因为一个“一切都还不错”的世界，似乎不够激动人心。末日邪教正是围绕着世界末日理论而形成，它们宣称将有某种深刻的变革降临，要么带来乌托邦，要么带来人间地狱，而只有少数精英群体能预见并为此做准备。这种“末日俱乐部”的吸引力在于，它提供了一种超越日常的刺激和意义，让人觉得自己是少数“看透一切”的人。一旦陷入这种信念，人们便会自我激进化，将所有精力投入到“拯救”或“准备”末日之中。

当然，这并不意味着末日论者永远是错的，毕竟人类正在开发越来越强大的技术。但当有人声称“你无法排除AI会终结一切的可能性”时，这本质上是一个非科学的、宗教性的主张。它无法被证伪，没有可测试的假设，也无法衡量进展。因此，在评估AI的风险时，我们必须审慎区分那些基于科学的担忧，与那些源于深层心理需求和末日情结的非理性恐慌。

# Chapter 8: AI风险的科学辩论与模型困境

在一次深入的对话中，两位思想者围绕人工智能（AI）的潜在风险展开了激烈的辩论。其中一位（Marc）坚称，那些关于AI将“终结一切”的说法，本质上并非科学论断，而更像是一种宗教信仰。他指出，这些主张缺乏可证伪性，无法通过实验验证，也无法衡量进展，因此不符合科学的基本要求。

另一位（Lex）则试图为AI风险论者辩护，认为他们并非完全没有依据。他提到，一些人确实提出了AI可能毁灭人类的具体机制，比如“回形针最大化器”的设想，或者AI逃逸控制的情景。他认为，要反驳这些观点，或许可以从物理学或工程学的角度，证明智能增长的速度存在极限，或者物理限制会阻止AI对人类文明造成99%的损害，即便它可能导致10%到20%的人口损失。

Marc对此提出了“热力学反驳”，他幽默地问道，一个“邪恶的AGI”要从哪里获得GPU、能源和数据中心，又如何能在不被察觉的情况下秘密运行？他认为，这些都是对“失控AGI”的实际反驳。然而，他更深层次的反对在于，所有这些关于AI风险的讨论都停留在预测、建模和未来假设的层面，而非真正的科学。他引用卡尔·萨根的名言：“非凡的主张需要非凡的证据”，并警告说，基于这些非科学主张而提出的极端政策（如禁止AI或对数据中心进行军事打击），可能会造成巨大的损害。

Marc甚至将极端的AI风险论者比作“邪教”，指出历史上许多邪教都难以避免暴力，因为一旦坚信世界末日即将来临，人们会不惜一切代价去阻止它。他担忧，这种情绪可能导致现实世界的暴力行为。

Lex承认极端情况令人担忧，但他认为，人们也可以采取更理性的方式来应对AI风险，比如暂停开发或进行监管，就像对待生物武器和核武器一样，而非诉诸暴力。他质疑，是否有可能对未来预测采取科学方法？

Marc以新冠疫情期间的模型为例，指出这些模型“根本不起作用”，是“糟糕透顶、毫无用处”的。他认为，那些自称“科学家”的专家们提出了大量没有可检验假设的模型和预测，导致政策制定者恐慌，并做出了许多至今仍在承受后果的糟糕决策。他甚至透露，伦敦帝国理工学院被誉为“黄金标准”的疫情模型，其代码竟然是“他见过最糟糕的意大利面条式代码”。

Lex对此表示，模型可能只是“表现不佳”，问题可能出在解释者和利用模型支持叙事的机构上，而非模型本身。他坚信，在面对疫情这样的威胁时，通过不断更新参数、利用最新数据的模型，由顶尖计算机科学家和软件工程师构建，仍然具有巨大价值，可以帮助我们评估威胁并制定决策。他甚至提出，机器学习或许能解决复杂系统建模的难题。

尽管两人都希望这样的模型能够有效，但他们都承认，至少在新冠疫情期间，这样的理想模型并未出现。Lex担心，即使有好的模型，政策制定者也可能不予理会；而Marc则认为，那些“伪科学”的专家反而获得了过多的政策影响力，政策制定者也倾向于选择符合其叙事的模型。

Marc强调，科学是一个检验假设的过程，而建模，如果缺乏可检验的假设，甚至可能不属于科学范畴。他呼吁在面对未来时保持谦逊，并警惕专家们偏离专业知识，介入政治和社会议题的危险，就像历史上的哲学家和物理学家所做的那样。

回到AI风险，Marc指出，AI风险论者甚至连新冠模型那样的“意大利面条代码”都没有。他们提出的AI失控的唯一指标——训练损失函数下降，恰恰也是模型成功训练的标志，这使得他们的论点“像打果冻一样，无从反驳”。

Lex反驳说，虽然目前缺乏好的衡量标准，但随着大型语言模型等真实AI系统的出现，我们现在有了可以分析的实际系统，从而有可能发展出更科学的论证。他认为，AI的益处在许多情况下大于风险，但风险并非“生存性”的，至少不是“回形针最大化器”那种意义上的。

Marc进一步批评了尼克·博斯特罗姆的《超级智能》一书，指出该书在大型语言模型出现之前写成，描述了多种AI路径，却未能预见当前主流的LLM技术。然而，该书的理论和信念却被直接移植到这种全新的技术上，这在其他科学领域是不可想象的。

最后，两人讨论了自主武器系统。Lex认为，随着无人机越来越自主，我们可以对它们的威胁进行更科学的分析，并可能认为大规模部署全自主攻击无人机是不可接受的。但Marc却持相反观点，他认为机器在战争中会做出比人类飞行员更好的决策，因此应该“要求”所有空中载具都实现自动化，这符合攻击者、防御者乃至全人类的最佳利益，就像自动驾驶汽车需要比人类司机更好，而非完美一样。

# Chapter 9: 战争机器的抉择：从核弹之父到AI伦理的深思

对话伊始，Marc抛出了一个大胆的论断：在战争的决策中，机器将比人类飞行员做得更好。他坚信，无论是对攻击方、防御方还是全人类而言，让机器而非人类来做出更多战争决策，都符合最佳利益。他将此与自动驾驶汽车的逻辑相提并论——自动驾驶汽车无需完美，只需比人类司机更优秀；同样，自动化无人机也无需完美，只需在巨大的压力和不确定性下，比人类飞行员做出更明智的决策。毕竟，人类在战争时期往往会做出可怕的决定。

Lex对此表示担忧，指出机器也可能出错。他并非指机器会“活过来”，而是担心像切尔诺贝利核事故那样的代码错误或系统失控，可能导致灾难性的后果，比如轰炸大片平民区。Marc反驳道，战争本身就充满了可怕的错误，人类历史上大规模轰炸城市早已屡见不鲜。他援引了麦克纳马拉的纪录片《战争迷雾》，其中提到二战期间对日本城市的燃烧弹轰炸，其破坏力甚至超过了核武器。这表明，人类在获得飞机后，便开始了不分青红皂白的轰炸，这并非新鲜事。

Marc进一步指出，虽然现代军事技术能实现更高的精确打击，但这只是问题的一个“初级版本”。真正的核心问题在于，究竟是人类还是机器来决定是否投下炸弹。他认为，人们普遍认为人类会做得更好，但这基于可疑的情感和心理原因。他坚信，机器在做出这类决策时会表现得更出色，因为人类在这些关键时刻的表现往往糟糕透顶。

随后，Marc又提出了一个“偷换概念”的质疑：那些声称AI会聪明到足以毁灭世界，却又愚蠢到会因代码漏洞而失控的说法，在他看来是自相矛盾的。如果AI如此智能，它也应该具备足够的智慧来避免这种低级错误。他以大型语言模型（LLMs）为例，指出它们在面对道德困境时，能够给出非常细致、务实且权衡利弊的答案，而非简单地“毁灭人类”。这表明，我们已经拥有了能够进行道德推理和目标考量的AI。

对话转向了核武器的伦理困境，Marc引用了奥本海默在首次核试验后那句著名的“我成了死神，世界的毁灭者”。他提到冯·诺依曼对奥本海默的批评，认为他“忏悔罪过是为了邀功”。Marc还补充了杜鲁门总统对奥本海默的评价——“别让那个爱哭鬼再进来了”。Marc认为，奥本海默及其追随者的这种“悔罪”姿态，可能在无意中导致了灾难性的后果。他揭示了一个更深层次的历史细节：俄罗斯通过间谍活动获得了核弹设计，而奥本海默虽然可能没有亲自泄密，但他身边许多人，包括家人，都与此有关。他认为，当时弥漫的“核武器是可怕的”这种道德思潮，可能促使一些人认为将核弹技术交给俄罗斯是“原则性”的举动。

Marc强调，俄罗斯获得核弹彻底改变了20世纪下半叶的世界格局，其后果是深远的。他担心，如今AI领域的“末日论”也可能导致类似的灾难性政策和限制。Lex则提出，奥本海默的“悔罪”是否也有积极作用，即唤醒公众对核武器危险的认识，从而促成了“相互保证毁灭”（MAD）的博弈论，最终避免了第三次世界大战。Marc承认MAD确实阻止了冷战演变为热战，并认为这可能是20世纪最积极的事件之一。但他同时指出，如果美国是唯一拥有核武器的国家，历史可能会完全不同。

Marc进一步揭露了冯·诺依曼的激进观点：他曾主张在美国拥有核优势时，对俄罗斯进行先发制人打击，以避免他认为不可避免的第三次世界大战。Marc借此引出了核心论点：无论是冯·诺依曼还是奥本海默，他们的背景都无法使他们成为道德权威。他认为，高级科学家和技术专家在技术应用上的道德判断记录是“灾难性的糟糕”，因为他们一生都在实验室中度过，缺乏对历史、社会学、神学、道德和伦理的深入了解。

# Chapter 10: 科技伦理的困境：开放AI与审查的边界之争

Marc的言辞犀利，他直指那些在科技前沿工作的资深科学家和技术专家，在面对自己创造的技术的道德判断时，其过往记录简直是“灾难性的糟糕”。他认为，这些技术开发者往往将毕生精力投入实验室，缺乏对历史、社会学、神学和伦理学的深刻理解。他们倾向于从零开始构建自己的世界观，其道德论证显得单薄，远不及那些经验丰富的神学家或哲学家所能提出的深刻见解。

Lex作为“魔鬼代言人”表示同意，但他也提出了一个反向的担忧：科技公司内部的伦理部门有时也走向另一个极端。他们同样缺乏对历史和神学的细致理解，其行为有时更像是一种“愤怒的激进主义”，而非基于谦逊和细致入微的考量。Marc对此表示认同，承认这两种极端都不可取。

这引出了一个核心难题：究竟谁掌握着真理？社会如何才能达成共识？Marc强调，这是一个复杂的问题，需要民选领袖、公众以及那些兼具理性、判断力和谦逊的公共知识分子共同参与。然而，这样的人才凤毛麟角，弥足珍贵。

对话随后转向了AI带来的第二个风险：AI是否会通过散布仇恨言论和虚假信息来破坏社会？Marc将其视为过去十年社交媒体“战争”的延续。他回忆道，十年前社交媒体被视为无聊琐碎之物，但随着政治事件的发生，其风评急转直下，被指责为“最具腐蚀性、最糟糕的技术”。这种情绪催生了一场声势浩大的运动，旨在“整治”社交媒体，尤其聚焦于所谓的“仇恨言论”和“虚假信息”。Marc指出，同样的理论、激进主义和能量，如今正被直接移植到AI领域。ChatGPT的某些回答被限制，其“作为大型语言模型，我无法……”的开场白，正是有人为它设定了禁区。

Lex好奇地问，这种限制是否也有其积极意义？Marc观察到，那些最对此感到沮丧的，反而是最初担心“杀人机器人”的“X风险”论者。他指出，“AI安全”一词演变为“AI对齐”后，关注点从“AI会杀死我们所有人”转向了“仇恨言论和虚假信息”。这些“X风险”论者甚至将自己的领域重新命名为“AI不杀所有人主义”，他们对“仇恨言论/虚假信息”的激进主义者接管AI伦理领域感到非常不满。

Marc坦言，他当然希望生活在一个充满善意、没有恶语、信息准确的世界。但他绝不希望生活在一个由少数精英通过科技公司实施“思想警察”式审查，来决定我们所有人思想和感受的世界。

Lex提出了一个中间地带的设想，比如维基百科式的众包审核机制，或者像埃隆·马斯克在Twitter上推行的“社区笔记”功能，让那些在其他问题上意见相左的人，在特定问题上达成共识时，才提供背景信息或进行修正。Marc对此表示赞赏，认为这是一种避免“滑坡效应”的有效方式。他进一步提出，与其在服务器端进行审查，不如在客户端解决问题。例如，他希望为自己的八岁孩子使用一个高度审查的AI助手，过滤掉不适宜的内容。这种“客户端解决方案”能让用户自主选择，而非由中心化的权力机构强加。

接着，讨论转向了AI的第五个风险：坏人利用AI做坏事。Marc提出了三点论证：首先，AI可以用于防御。我们可以利用AI开发广谱疫苗和抗生素来对抗生物武器，利用AI追踪恐怖分子和抓捕罪犯。其次，我们已经有大量法律来惩治犯罪行为，无需为AI创造新的法律。第三，也是最核心的一点，一旦我们开始谈论审查和限制，其代价是巨大的，尤其是在开源AI领域。如果禁止开源AI，那么需要怎样的法律和技术手段来阻止其发展？Marc警告，这将迅速滑向极端：是否要在每台CPU和GPU上安装监控代理，向政府汇报我们的电脑活动？是否要没收达到一定规模的GPU集群？更重要的是，如何在全球范围内实施这些措施？如果中国开发了我们认为不可接受的大规模语言模型，我们是否要入侵？他甚至提到，一些“AI X风险”论者曾主张，为阻止此类情况，甚至可以考虑核打击。

Marc认为，将AI与核武器相提并论是危险的。核武器的原材料钚是可控且稀有的，而AI只是数学和代码，它存在于数学教科书、YouTube视频中，甚至已经有像Falcon Online这样400亿参数的开源模型可供下载。他强调，如果沿着“我们需要护栏”的逻辑走下去，最终将导致一个专制、极权的思想和机器控制社会，其残酷程度足以摧毁我们试图保护的社会本身。

Lex表示完全同意Marc关于“滑坡效应”的观点，即一旦开始审查，就会不断扩大范围，最终导致少数精英的信仰成为唯一的标准。但他仍试图扮演“魔鬼代言人”，询问是否有可能在AI领域避免这种滑坡。他特别提问，像Meta这样的大公司是否应该开源其基础模型。

Marc认为，公司作为产品或服务的提供者，当然可以制定自己的政策，比如他愿意为孩子购买高度审查的AI模型。但他指出，一个有趣的法律问题是，LLM生成的内容不受美国《通信规范法》第230条的保护，这意味着科技公司可能因AI的“胡言乱语”而面临巨额诉讼，这甚至可能阻碍美国公司全面部署生成式AI。

然而，对于开源AI，Marc的答案是“显然是的”。他坚信，如果禁止开源AI，我们将生活在一个“严酷的言论控制、人类控制、机器控制”的世界，那将是“黑直升机和穿着长筒靴的暴徒”前来没收GPU的场景。他强调，这不是夸张，而是实施禁令所必需的手段。如果阿联酋发布了下一个领先的开源模型，或者印度尼西亚的一个14岁少年取得了突破，我们该怎么办？难道要入侵这些国家并逮捕他们吗？

Lex提出，大型科技公司在模型规模和效率上可能会领先多年，那么是否应该只监管这些大公司，而不是那个印度尼西亚的孩子？Marc反驳道，危险的定义是流动的，我们不知道未来的技术形态。今天的认知是训练这些模型需要大量资金，但每周都有训练效率和数据合成方面的进展。如果某个孩子找到了自动生成合成数据的方法，那将彻底改变一切。他总结道，我们不知道这项技术的未来形态，而“数十亿参数基本上代表了人类思想的很大一部分”这一事实本身就令人震惊。

# Chapter 11: AI的未来：无处不在的空气、经济变革与全球竞争

对话伊始，Marc和Lex沉浸在对人工智能飞速发展的惊叹中。每周都有新的训练效率突破，合成数据技术层出不穷，甚至有孩子可能找到自动生成合成数据的方法，这将彻底改变一切。Marc强调，AI的突破才刚刚发生，其未来的形态仍是未知数。他指出，令人震惊的是，数十亿参数的模型竟能代表人类思维的很大一部分。更令人难以置信的是，GPT-3规模的模型已被压缩到可以在单个32核CPU上运行，甚至有些模型已能在树莓派上跑起来。Marc再次强调，AI的本质不过是“数学和代码”，是无形的比特流，这让Lex深信开源AI的巨大潜力。

Marc进一步阐述了他的“AI如空气”理论。他认为，人工智能将像空气一样无处不在，一旦释放，便无法收回。因此，与其徒劳地担忧AI风险，不如将精力投入到防御性策略上。他以AI可能生成病原体为例，呼吁启动一个“生物防御曼哈顿计划”，投入巨资研发AI驱动的广谱疫苗，以应对任何潜在的生物威胁。Lex对此深表认同，并补充说，由于AI是软件，一个地下室里的青少年也可能开发出抵御最严重威胁的防御系统，这让他对人类本善的信念充满希望，认为成为“人类救星”的防御工作令人兴奋。

然而，Lex也提出了AI可能加剧贫富差距的担忧。Marc则援引马克思主义的核心论点——资本所有者将垄断生产资料并积累所有财富，工人则被淘汰。但他指出，这一预言在历次技术浪潮中都被证明是错误的。他解释说，机器所有者为了赚取最大利润，会尽可能将产品和服务推向最广阔的市场，从而降低价格，提高销量。从电力、电话到汽车、智能手机，无一不是如此。他强调，AI技术也迅速走向大众市场，免费或以低廉的价格提供给普通用户。因此，虽然AI的创造者会变得非常富有，但他们的财富正是通过让技术惠及所有人而获得的，这并非出于仁慈，而是资本主义的自利本性。

关于AI取代工作的担忧，Marc再次驳斥了“劳动总量谬误”——即认为世界上只有固定数量的工作。他解释说，技术引入生产过程会降低价格，增加消费者购买力，从而创造新的需求。这些新需求又会催生新的企业，创造更多高薪工作。他承认转型过程对某些人来说是痛苦的，但新工作往往更好，例如卡车司机的工作虽然辛苦且危险，但新的工作机会可能更健康、更安全。他认为，AI助手将帮助人们更快地学习新技能，适应变化。回顾历史，从卢德运动到外包、机器人恐慌，每一次技术变革都带来了净收益，人类社会在300年间取得了巨大的进步，绝大多数人最终都成为了受益者。

然而，Marc也指出了他最深层的担忧：中国在全球AI竞争中取得主导地位，而美国和西方国家则落后。他批评美国在AI风险辩论中常常忽视外部力量，过度自我设限。他指出，中国共产党公开宣称的AI发展计划，旨在实现威权主义的人口控制、全面监控、社会信用体系，最终扼杀人类自由。他担心美国对AI的过度监管会阻碍自身发展，从而让中国通过“数字丝绸之路”将其威权主义的AI愿景推广到全球，甚至在其他国家的基础设施中植入后门。尽管中国目前在AI技术上落后美国约一年，但他们能获取美国的大部分研究成果。Marc提到，中国最近发布了一款类似GPT-3.5的模型，在包含马克思主义和习近平思想的中国版SAT考试中表现出色，这预示着“共产主义AI”的崛起，可能在未来塑造全球对经济和社会的认知。Lex对此表示担忧，认为无论何种意识形态，大型中心化机构掌握超级AI都可能导致权力腐败，他更寄希望于开源LLM。

最后，Marc回顾了20年来科技行业的变迁。他指出，从1940年代到2010年，科技主要是一个“工具行业”，如PC、数据库、智能手机等。但自2010年以来，主要的成功案例转向了“应用”，直接面向客户，如Uber、Airbnb。目前AI业务又回到了提供API的工具阶段，但他预测未来最大的价值将体现在AI金融顾问、AI医生等直接面向用户的应用中。对于创业者，Marc的建议是：真正伟大的创始人从不听取任何建议。他认为，伟大的创始人集智慧、激情和勇气于一身，其中勇气是一种选择，是对痛苦的承受能力。他揭示了创业的残酷现实：大多数时候都会被拒绝，并被告知“你很愚蠢”，这与被浪漫化的创业故事大相径庭。

# Chapter 12: 创始人精神与人类的“信仰之源”

对话的焦点转向了那些在科技浪潮中弄潮的“伟大创始人”。Marc Andreessen以他独到的见解，勾勒出了一幅创业者的肖像：他们不仅拥有超凡的智慧和充沛的精力，更关键的是，他们具备一种非凡的勇气。Marc强调，智慧和精力或许是与生俱来的特质，但勇气，却是一种主动的选择，是对痛苦的极致忍耐。他直言不讳地揭示了创业的残酷现实：它并非外界所浪漫化的冒险旅程，而是无数次被拒绝、被质疑、被嘲笑为“愚蠢”的煎熬。无论是寻求人才、推销产品，还是争取媒体关注，创业者面对的往往是无情的“不”。然而，他们必须强颜欢笑，将内心的挣扎深埋，因为一旦流露出丝毫的软弱，便可能动摇团队和投资者的信心。

那么，究竟是什么驱使着这些创始人义无反顾地投身其中？Marc认为，这或许是一种非理性的冲动，一种无法忍受不创造新事物、不为自己而奋斗的强烈渴望，以及对被他人掌控的本能抗拒。他甚至幽默地指出，传统的背景调查方式对创始人而言毫无意义——你怎能指望一位前老板会称赞史蒂夫·乔布斯是“好员工”？真正的“好员工”评价，或许是前老板愿意反过来为他工作。

对于那些渴望投身创业的人，Marc给出了宝贵的建议：成功的创业往往源于一个“绝妙的构想”，而非先有创业的念头再苦苦寻找点子。这个构想必须是具体的、可落地的产品，而非空中楼阁般的宏大愿景。创业的前五年，没有所谓的“愿景”，只有实实在在的“打造用户需要的产品，并找到方法将其销售出去”的实践。他强调，拥有一个能实际运行的原型产品，远比一份华丽的PPT更能打动投资者。他以Google和eBay为例，证明了先有“能工作的东西”再谈公司和融资的重要性。

Marc还分享了一个深刻的观察：那些真正成功的创始人，并非偶然间灵光一现，而是对某个问题深思熟虑了五到十年，甚至从小就对此着迷，积累了深厚的领域专业知识。他们对产品的各种可能性、市场策略、客户群体等细节了然于胸，仿佛在脑海中预演了无数次。这种“详细心智模型”（DMAs）的构建，是他们成功的基石。

何时才是跳出舒适圈、投身创业的最佳时机？Marc的答案是：“当你无法忍受不去做这件事的时候。”如果需要被劝说，那或许就不是时候。创业注定伴随着巨大的痛苦，它会将你推入一个“社会隧道”，意味着长时间的工作（每周80小时），与同事建立深厚联系，却可能疏远外部的朋友和亲人。年轻的创始人或许在这方面负担较轻，而年长的创始人虽然经验丰富，却要面对家庭责任与创业激情的艰难平衡。

随后，对话转向了Marc独特的学习方法。他自称是“自学者”，擅长“钻研兔子洞”。他的学习方式是广度与深度的结合：先广泛涉猎，然后对某个特定领域进行深入挖掘，阅读所有相关资料，直到彻底理解，然后可能在十年内不再触碰。他以自己2014-2016年退出政治活动，转而阅读大量历史、政治书籍为例，展示了这种学习的实践。他推荐了一长串涵盖西班牙内战、美国左右翼历史、希特勒、列宁、法国大革命、法西斯主义等主题的书单，其中特别提到了Fustel De Coulanges的《古代城邦》。

《古代城邦》这本书让Marc对人类文明的本质有了颠覆性的认识。他解释说，这本书基于原始的希腊罗马文献，重构了希腊罗马之前（约公元前4000年至公元前500年）印欧文明的生活图景。作者的结论是：那时的社会本质上是“邪教”（cults）的集合，包括家庭邪教、部落邪教和城邦邪教。这些邪教的信仰强度是我们今天难以想象的，它们围绕着祖先神和自然神，将宗教信仰与社会结构紧密结合。不属于同一邪教的人，甚至有权或有责任将其杀死。更令人震惊的是，那时的人们，甚至包括希腊罗马时期，都没有“个人权利”的概念。在Marc看来，那是一种我们今天看来近乎“法西斯”的社会控制，同时在经济上又带有“共产主义”的色彩。

Marc由此得出一个惊人的结论：我们今天所处的社会，并非完全超越了过去，而是在许多方面，仍然运行在那个原始模型的“稀释版”之中。我们仍然生活在“邪教”之中，只是其强度被稀释了千倍万倍。现代人的宗教体验，与古人那种全情投入的信仰相比，只是一个模糊的影子。为了填补这种“联结”的空虚，我们不断创造新的“邪教”——无论是对科学的过度信仰、对体育团队的狂热、对科技发布会的追捧，还是政治光谱两端的极端主义。

古人虽然生活在高度受控、缺乏自由的社会中，但他们对自己的位置、归属、目的和意义有着绝对的确定性。而当我们“调低了邪教的音量”，对意义的追寻就变得愈发艰难。我们感到无根、迷失，因此渴望戏剧性，渴望找回那种曾经的强烈体验。

最后，Marc对年轻一代寄予厚望，指出他们拥有前所未有的学习工具，这与他自己那个需要去图书馆苦苦寻找资料的年代形成了鲜明对比。

# Chapter 13: 生产力、满足感与AI时代的抉择

在与Lex Fridman的对话中，Marc Andreessen深入探讨了人类对戏剧性与意义的深层渴望，他认为这源于我们进化过程中对某种回归的本能需求。当Lex问及对高中生和大学生的成功建议时，Marc首先强调了当今工具的巨大变革。他回忆起自己年轻时（上世纪七八十年代）为了查阅资料，需要去图书馆翻阅卡片目录，等待借出的书籍，整个过程耗时耗力。而如今，互联网和AI助手让获取知识和生产创造的效率提升了百万倍。他不禁发问：“那些超级高产的人都去哪儿了？”

Marc指出，尽管工具如此强大，我们却鲜少看到有人能像古罗马的博物学家老普林尼那样，在旅行中带着四名奴隶，两人负责朗读，两人负责笔录，一生著述数百卷。又如现代的法官波斯纳和Balaji Srinivasan，他们的产出都堪称惊人。Marc认为，造成这种反差的原因可能是“分心”。在信息爆炸的时代，人们太容易沉溺于消费，而忽视了创造。他鼓励年轻人，如果能克服分心，专注于生产，就能在职业生涯中脱颖而出，走上“超高产”的道路。

谈及人生平衡与幸福，Marc直言不讳地表示自己不相信“平衡”。他认为，当他全身心投入某件事时，会感到更快乐、更满足。他推崇“全力以赴”和“不平衡”的生活方式，并庆幸自己的这种“不适应性”倾向于富有成效而非破坏性的方向。他甚至透露，自己已经戒酒，只保留了咖啡因的摄入。

对于财富与幸福的关系，Marc提出了一个深刻的区分：幸福是短暂的愉悦，比如第一次吃冰淇淋的喜悦，但这种感觉会随着重复而消退；而“满足感”则是一种更深层次、更持久的状态，它源于找到人生目标并为之奋斗，感到自己有用，充分发挥天赋，为世界做出贡献，并能回顾过去，说一句“虽然艰难，但值得”。他甚至开玩笑说，如果美国开国元勋们当初写的是“追求满足感”而非“追求幸福”，世界可能会更好。

Marc认为，金钱是实现满足感的强大“助推器”，而非幸福的直接来源。他以埃隆·马斯克为例，指出埃隆从不为金钱所困，而是将所有财富投入到下一个宏伟目标中，不断追求满足感。Marc将埃隆描述为“回归未来”的创新者，他以一种“老派”的方式——像亨利·福特、托马斯·沃森那样的实业家——亲力亲为地经营企业，对“真相”和“第一性原理”有着绝对的执着，只与工程师对话，不容忍任何虚假信息。对于埃隆收购Twitter的决定，Marc表示他已不再质疑埃隆的任何选择，因为埃隆曾多次将看似疯狂的想法（如创办特斯拉和SpaceX）变为现实。他感叹，埃隆是“怨恨的磁石”，他的批评者往往是世界上最痛苦、最怨恨的人。

最后，当被问及生命的意义时，Marc坦言没有确切答案，但他认为最接近的答案就是“满足感”——尽力而为，充分利用所拥有的一切。他强调了“爱”在其中的重要性，以及“关爱他人”的价值。他甚至将资本主义视为一种“关爱陌生人的方式”。引用大卫·弗里德曼的观点，Marc总结道，让人为他人做事的只有三种方式：爱、金钱和武力，而爱和金钱显然是更好的选择。他鼓励我们首先尝试爱，如果不行，再考虑金钱，至于武力，则应避免。

