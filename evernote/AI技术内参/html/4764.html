
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>065 | 高级推荐模型之二：协同矩阵分解</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />

<style type="text/css">html {
    font-family: Georgia, "Microsoft Yahei", "WenQuanYi Micro Hei";
}

/* pre { */
/*     background-color: #eee; */
/*     box-shadow: 5px 5px 5px #888; */
/*     border: none; */
/*     padding: 5pt; */
/*     margin-bottom: 14pt; */
/*     color: black; */
/*     padding: 12pt; */
/*     font-family: Consolas; */
/*     font-size: 95%; */
/*     overflow: auto; */
/* } */

.title  { /* text-align: center; */
          margin-bottom: 1em; }
.subtitle { /* text-align: center; */
            font-size: medium;
            font-weight: bold;
            margin-top:0; }
.todo   { font-family: monospace; color: red; }
.done   { font-family: monospace; color: green; }
.priority { font-family: monospace; color: orange; }
.tag    { background-color: #eee; font-family: monospace;
          padding: 2px; font-size: 80%; font-weight: normal; }
.timestamp { color: #bebebe; }
.timestamp-kwd { color: #5f9ea0; }
.org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
.org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
.org-center { margin-left: auto; margin-right: auto; text-align: center; }
.org-ul { padding-left: 10px; }
.org-ol { padding-left: 20px; }
ul { padding-left: 10px; }
ol { padding-left: 20px; }

.underline { text-decoration: underline; }
#postamble p, #preamble p { font-size: 90%; margin: .2em; }
p.verse { margin-left: 3%; }
pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
}
pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
}
pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
}
pre.src:hover:before { display: inline;}
pre.src-sh:before    { content: 'sh'; }
pre.src-bash:before  { content: 'sh'; }
pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
pre.src-R:before     { content: 'R'; }
pre.src-perl:before  { content: 'Perl'; }
pre.src-java:before  { content: 'Java'; }
pre.src-sql:before   { content: 'SQL'; }

table { border-collapse:collapse; }
caption.t-above { caption-side: top; }
caption.t-bottom { caption-side: bottom; }
td, th { vertical-align:top;  }
th.org-right  { text-align: center;  }
th.org-left   { text-align: center;   }
th.org-center { text-align: center; }
td.org-right  { text-align: right;  }
td.org-left   { text-align: left;   }
td.org-center { text-align: center; }
dt { font-weight: bold; }
.footpara { display: inline; }
.footdef  { margin-bottom: 1em; }
.figure { padding: 1em; }
.figure p { /* text-align: center; */ }
.inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
}
#org-div-home-and-up
{ text-align: right; font-size: 70%; white-space: nowrap; }
textarea { overflow-x: auto; }
.linenr { font-size: smaller }
.code-highlighted { background-color: #ffff00; }
.org-info-js_info-navigation { border-style: none; }
#org-info-js_console-label
{ font-size: 10px; font-weight: bold; white-space: nowrap; }
.org-info-js_search-highlight
{ background-color: #ffff00; color: #000000; font-weight: bold; }

/* http://www.yinwang.org/main.css */

body {
    /* font-family:"lucida grande", "lucida sans unicode", lucida, helvetica, "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", sans-serif; */
    font-size: 18px;
    margin: 5% 5% 5% 5%;
    padding: 2% 5% 5% 5%;
    width: 80%;
    line-height: 150%;
    border: 1px solid LightGrey;
}

H1 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
}

H2 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-bottom: 60px;
    margin-bottom: 40px;
    padding: 5px;
    border-bottom: 2px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


H3 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-top: 40px;
    margin-bottom: 30px;
    border-bottom: 1px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


H4 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-top: 40px;
    margin-bottom: 30px;
    border-bottom: 1px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


li {
    margin-left: 10px;
}


blockquote {
    border-left: 4px lightgrey solid;
    padding-left: 5px;
    margin-left: 20px;
}


pre {
    font-family: Inconsolata, Consolas, "DEJA VU SANS MONO", "DROID SANS MONO", Proggy, monospace;
    font-size: 75%;
    border: solid 1px lightgrey;
    background-color: Ivory;
    padding: 5px;
    line-height: 130%;
    margin-left: 10px;
    width: 95%;
}


code {
    font-family: Inconsolata, Consolas, "DEJA VU SANS MONO", "DROID SANS MONO", Proggy, monospace;
    font-size: 90%;
}


a {
    text-decoration: none;
    # cursor: crosshair;
    border-bottom: 1px dashed Red;
    padding: 1px;
    # color: black;
}


a:hover {
	background-color: LightGrey;
}


img {
    box-shadow: 0 0 10px #555;
    border-radius: 6px;
    margin-left: auto;
    margin-right: auto;
    margin-top: 10px;
    margin-bottom: 10px;
    -webkit-box-shadow: 0 0 10px #555;
    width: 100%;
    max-width: 600px;
}

img.displayed {
    display: block;
    margin-left: auto;
    margin-right: auto;
}

#table-of-contents {
    border-bottom: 2px LightGrey solid;
}</style>

</head>

<body>

<div class="outline-2">
<h2>065 | 高级推荐模型之二：协同矩阵分解</h2>
<div class="outline-text-2">
<p>周一我们讨论了“张量分解”模型。这种模型的特点是能够把不同的上下文当作新的维度，放进一个张量中进行建模。虽然张量分解是矩阵分解在概念上的一种直觉扩展，但其在现实建模的过程中有很大难度，最大的问题就是张量分解的求解过程相对比较复杂，不同的分解方法又带来不同的建模选择。</p>
<p>今天，我们来看另外一种思路，来解决融合多种渠道信息的问题，这就是<strong><span class="orange">协同矩阵分解</span></strong>（Collective Matrix Factorization）。</p>
<h2>为什么需要协同矩阵分解</h2>
<p>在解释什么是协同矩阵分解之前，我们先来看一看为什么需要这样一种思路。我们还是需要回到矩阵分解本身。</p>
<p>矩阵分解的核心就是通过矩阵，这个二维的数据结构，来对用户和物品的交互信息进行建模。因为其二维的属性，矩阵往往只能对用户的某一种交互信息直接进行建模，这就带来很大的局限性。</p>
<p>在之前的讨论中，我们看到了一系列不同的思路来对这样的基本结构进行扩展。</p>
<p><strong>思路一</strong>，就是通过建立显式变量和隐变量之间的回归关系，从而让矩阵分解的核心结构可以获得更多信息的帮助。</p>
<p><strong>思路二</strong>，则是采用分解机这样的集大成模型，从而把所有的特性，都融入到一个统一的模型中去。</p>
<p><strong>思路三</strong>，就是我们这周已经讲到的，利用张量，把二维的信息扩展到N维进行建模。</p>
<p>这些已有的思路都各有利弊，需要针对具体的情况来分析究竟什么样的模型最有效果。</p>
<p>然而在有一些应用中，除了用户和物品这样很明显的二元关系以外，还有其他也很明显的二元关系，如何把这些二元关系有效地组织起来，就变成了一个有挑战的任务。</p>
<p>什么意思呢？比如，我们是一个社交媒体的网站，既有用户对于物品（比如帖子）的交互信息，又有用户之间的互相连接信息（谁与谁是好友等）。那么，如何来显式地表达这两类不同的二元关系呢？</p>
<!-- [[[read_end]]] -->
<p>在前面的思路里面可以看到，我们似乎需要选择一个主要的关系来作为这个模型的基础框架，然后把其他的信息作为补充。在这样两类关系中，选择哪一个作为主要关系，哪一个作为补充关系，就显得有一点困难了。</p>
<p>更进一步说，对于用户与用户之间的建模，以及用户与物品之间的建模，我们其实会有不同的模型去构造。例如，用户与物品之间的评分，往往用整数来代表评分的数值，或者是用实数来代表喜好度。而用户与用户之间的友好关系，则往往是0或者1，象征是否有连接。因此，我们可能需要不同的模型对这些不同的数值进行建模。</p>
<p>这也就让研究人员想出了协同矩阵分解的思路。</p>
<h2>协同矩阵分解的基本思路</h2>
<p>协同矩阵分解的基本思路其实非常直观，那就是<strong>有多少种二元关系，就用多少个矩阵分解去建模这些关系</strong>。</p>
<p>用我们刚才所说的社交媒体的例子。如果我们有用户与用户的关系，用户与物品的关系，那我们就组织两个矩阵分解，分别来对这两种关系进行建模。最早对这个思想进行得比较完整的表述，我在文末列出了参考文献[1]。</p>
<p>这里的一个核心就是，如果两个没有关系的矩阵，各自做矩阵分解，那么分解出来的信息，一般来说，是没有任何关联的。</p>
<p>再来看刚才的例子，如果有一个用户与用户的矩阵需要分解，然后有一个用户与物品的矩阵需要分解。那从这两个矩阵分解中，我们分别可以得到至少两组不同的<strong>用户隐变量</strong>。一组是从用户与用户的关系而来，一组是从用户与物品的关系而来。这两组用户的隐变量是不一样的。同时，因为两个矩阵没有关联，所以无法达到我们希望这两种关系互相影响的效果。</p>
<p>要想在两个矩阵分解之间建立联系，我们必须有其他的<strong>假设</strong>。这里的其他假设就是，两组不同的用户隐变量其实是一样的。也就是说，我们假设，或者认定，<strong>用户隐变量在用户与用户的关系中，以及在用户与物品的关系中，是同一组用户隐变量在起作用</strong>。</p>
<p>这样，虽然表面上还是两个矩阵分解，但其实我们限定了其中某一部分参数的取值范围。说得直白一些，我们认定从两个矩阵分解出来的两组来自同一个因素（这里是用户）的隐变量是完全一样的。用更加学术的语言来说，这就是<strong>将两组矩阵分别投影到了相同的用户空间和物品空间</strong>。</p>
<p>这样做的好处，自然就是对于多种不同的关系来说，我们使用“<strong><span class="orange">相同隐变量</span></strong>”这样的假设，可以把这些关系都串联起来，然后减少了总的变量数目，同时也让各种关系互相影响。</p>
<p>那么，这样的假设有没有潜在的问题呢？</p>
<p>一个比较大的潜在问题就是，使用同样的一组隐变量去表达所有的同类关系，这样的假设存在一定的局限性。比如上面的例子，用同样一组用户隐变量去解释用户和用户之间的关系，同时也需要去解释用户和物品之间的关系，能够找到这样一组用户隐变量其实是有一定难度的。</p>
<p>而在实际应用中，不同关系的数据量会有很大的差距。比如，用户和物品关系的数据总量可能要比用户与用户的多。所以，由于用户和物品关系的数据多，两个矩阵分解用的同一组用户隐变量，很可能会更多地解释用户和物品的部分，从而造成了学到的隐变量未必能够真正表达所有的关系。</p>
<p>对于这样的情况，自然已经有一些学者想到了对策，我们今天就不在这里展开了。</p>
<p>最后，需要提一下，在协同矩阵分解的场景中，学习各个隐变量的参数的过程，和一般的单个矩阵分解相比，没有太多本质性的变化。最简单的学习过程，依然是利用<strong>随机梯度下降法</strong>（SGD, Stochastic Gradient Descent）去学习。只不过，每一个隐变量会存在于多个矩阵分解中，这在更新变量时增加了所需的计算量。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的另一个高级模型，协同矩阵分解，用来对不同类型的二元信息进行建模。</p>
<p>一起来回顾下要点：第一，我们简要介绍了为什么需要协同矩阵分解；第二，我们详细介绍了协同矩阵分解的原理、潜在问题和解法。</p>
<p>最后，给你留一个思考题，从概念上来看，协同矩阵分解和张量分解之间有怎样的关系？是不是所有的张量分解都可以化为多个协同矩阵分解呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Ajit P. Singh and Geoffrey J. Gordon. <a href="http://www.cs.cmu.edu/~ggordon/singh-gordon-kdd-factorization.pdf">Relational learning via collective matrix factorization</a>. Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '08). ACM, New York, NY, USA, 650-658, 2008.</span></p>
<p></p>

</div>
</div>

</body>
</html>