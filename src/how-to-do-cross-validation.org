#+title: 如何做cross validation

对于cross validation认识一直不太清晰，这几天搞kaggle题目涉及到调参，就又把cross validation这个问题想了想。

scikit-learn中有一节介绍cross validation的，里面说了怎么演化到cv的

1. 一开始只是把dataset分为train和test. 在train上面做调参，在test上判断参数结果如何选择参数。这里的问题是参数在test上工作不错，但是泛化能力不行。

2. 然后把dataset分为三份train, validation和test. 在train上调参，在validation上判断参数结果选择参数，然后在test上判断这个参数泛化能力如何。这里的问题是，因为数据被分为3分，能被用于训练的数据减少了，另外我们这里的划分是固定的，test可能并不能比较好地表示未来情况。

3. 然后出现cross validation. 将dataset分为train和validation. 在train上调参，在validation上判断参数如何。看起来和1一样，但是我们会重复这个过程，来尽可能低降低偏差提高泛化能力。方法比如k-fold CV或是LOO CV等。如果我们模型使用RandomForest的话，可以直接使用OOB来做验证。

通过CV我们可以选择出比较模型(参数). 如果我们希望对多个模型来做比较(因为不同模型在选择阶段metrics和evaluation方式不同)的话，我们可以再进行一轮CV，但是使用不同参数。比如上一阶段选参数使用cv=10, random_state = 0, 那么比较这轮的话可以使用cv=10, random_state = 1.
