#+title: Columnar Storage Optimization and Caching for Data Lakes

Short Paper@2022  å› ä¸ºè°ƒç ”Data Lakeä¸‹é¢çš„Cachingæ‰€ä»¥çœ‹äº†ä¸€ä¸‹è¿™ç¯‡æ–‡è®ºï¼Œæ„Ÿè§‰å¥½åƒæ²¡å•¥ç‰¹åˆ«çš„ä¸œè¥¿ã€‚

æ€»ç»“ä¸€ä¸‹å¤§çº¦å‡ ä¸ªç‚¹ï¼Œä¹Ÿå¯èƒ½æ˜¯æˆ‘çœ‹çš„æ¯”è¾ƒç²—ï¼Œæ²¡æœ‰å¤ªGetåˆ°ä½œè€…ä»¬çš„æ·±å±‚æ„å›¾ï¼š
1. æŒ‰ç…§columnè€Œä¸æ˜¯row groupè¿›è¡Œèšåˆï¼ˆStorage Layout Optimizationï¼‰
2. é’ˆå¯¹column chunkè€Œä¸æ˜¯row groupè¿›è¡Œç¼“å­˜ï¼ˆcolumn chunkæ˜¯ä¸€ä¸ªrow groupé‡Œé¢çš„å•åˆ—ï¼‰
3. lazy cache population/evictionç­–ç•¥

#+BEGIN_QUOTE
We refer to each column of a row group as a ğ‘ğ‘œğ‘™ğ‘¢ğ‘šğ‘› ğ‘hğ‘¢ğ‘›ğ‘˜, which is independently compressed with a domain-specific compression algorithm (e.g., dictionary encod- ing, run-length encoding) to reduce space overheads and I/O costs. Given a query, as projection is pushed down to the table scan operator, it only reads needed column chunks.

However, each existing cache has its limitation. The page cache employs LRU-based policies, and the query engine cannot directly control which part of the data is cached. The hot data that is more worthy of being cached might be evicted by a query that reads a large amount of cold data. The file cache in storage systems and the distributed file caching systems cache entire files or blocks. For PAX layout that stores all the column chunks of a row group in the same file or block, they lead to very low space efficiency.
#+END_QUOTE

Storage Layout Optimizationå°†columnè€Œä¸æ˜¯row groupè¿›è¡Œèšåˆï¼Œå¤§è‡´æ€è·¯å°±æ˜¯ä¸‹é¢è¿™æ ·çš„ï¼Œå¥½å¤„å°±æ˜¯é¡ºåºæ€§å¥½ï¼Œç¼ºç‚¹å°±æ˜¯è¦åœ¨åå°æ”¹å†™æ–‡ä»¶æ ¼å¼ï¼Œè¿™ä¸ªå¯¹äºQuery Engineæ¥è¯´ä¼¼ä¹ä¸å¤ªåˆé€‚ï¼Œåšæˆå•ç‹¬æœåŠ¡å¯ä»¥è®©ç”¨æˆ·è§¦å‘ã€‚

[[../images/columnar-storage-optimization-and-caching-for-data-lakes-0.png]]

Cache Evictionä¸æ˜¯åœ¨Populationçš„æ—¶å€™å°±å®Œæˆï¼Œè€Œæ˜¯åœ¨åå°åˆ†æä¹‹åå¼‚æ­¥å®Œæˆçš„ï¼Œé€‰æ‹©åˆé€‚çš„colum chunkåˆ é™¤æ‰ã€‚

#+BEGIN_QUOTE
In Pixels, we envisage the high efficiency of lazy cache replace- ment. The cache misses in each node are collected by Prometheus (Section 2), without immediately triggering cache replacement. Whenever the workload pattern evolves, the Storage Optimizer calculates the cache efficiency of each column chunk by dividing its hit+miss count by its size. The hit count is stored before each column chunk in the cache area (Figure 4), while the miss count is collected from the cache miss messages in the cache miss MQ. The most-efficient column chunks that do not exceed the cache capacity are included in the new cache plan that is then applied across the cluster. This is based on the temporal locality of the column access.
#+END_QUOTE
