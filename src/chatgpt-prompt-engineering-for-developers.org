#+title: ChatGPT Prompt Engineering for Developers

# ChatGPT Prompt Engineering for Developers

花了点时间看了一下这门课程 [[https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction][DLAI - Learning Platform Prototype]] 难度不是很大，感觉非常值得，总之就是教你怎么写prompt.

归纳下来大概是这么几个场景：
1. summarizing. 比如总结文字的内容，或者从中抽取信息
2. inferring. 比如推理出文字中的情绪，或者是推理出其中的主题
3. transforming. 比如翻译一段话，并且能加入情绪和场景信息
4. expanding. 比如根据一段话如何生成回复
5. chatbot. 多轮交互，并且可以设置背景

另外看了一下openai doc网站，里面写到了如何计算token一些基本问题。[[https://platform.openai.com/docs/introduction/overview][Introduction - OpenAI API]]

#+BEGIN_QUOTE
The number of tokens processed in a given API request depends on the length of both your inputs and outputs. As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text. One limitation to keep in mind is that your text prompt and generated completion combined must be no more than the model's maximum context length (for most models this is 2048 tokens, or about 1500 words). Check out our tokenizer tool to learn more about how text translates to tokens.
#+END_QUOTE

关于各种模型区别和解释 [[https://platform.openai.com/docs/models][Models - OpenAI API]]

----------

通用代码

#+BEGIN_SRC Python
import openai
import os

from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())

openai.api_key  = os.getenv('OPENAI_API_KEY')

def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0, # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]

def get_completion_from_messages(messages, model="gpt-3.5-turbo", temperature=0):
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, # this is the degree of randomness of the model's output
    )
#     print(str(response.choices[0].message))
    return response.choices[0].message["content"]
#+END_SRC

----------

常见技巧有下面这些：

**将文字圈定起来**

比如下面这样使用

#+BEGIN_EXAMPLE
the TEXT is delimited by ```

TEXT: ```{text}```
#+END_EXAMPLE

**生成格式**

#+BEGIN_EXAMPLE
Provide them in JSON format with the following keys:
book_id, title, author, genre.

Use the following format:
Text: <text to summarize>
Summary: <summary>
Translation: <summary translation>
Names: <list of names in Italian summary>
Output JSON: <json with summary and num_names>
#+END_EXAMPLE

**条件判断**

#+BEGIN_EXAMPLE
If it contains a sequence of instructions, then
#+END_EXAMPLE

**场景模拟**

#+BEGIN_EXAMPLE
Your task is to answer in a consistent style.

<child>: Teach me about patience.

<grandparent>: The river that carves the deepest \
valley flows from a modest spring; the \
grandest symphony originates from a single note; \
the most intricate tapestry begins with a solitary thread.

<child>: Teach me about resilience.
#+END_EXAMPLE

**chatbot**

这个可以设置
- system: 告诉chatgpt背景
- assitant: assitant之前的话
- user: 用户的回答

然后告诉chatgpt之前完整的对话是什么样子的

#+BEGIN_EXAMPLE
messages =  [
{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},
{'role':'user', 'content':'tell me a joke'},
{'role':'assistant', 'content':'Why did the chicken cross the road'},
{'role':'user', 'content':'I don\'t know'}  ]

response = get_completion_from_messages(messages, temperature=0.2)
print(response)

> To get to the other side, good sir!
#+END_EXAMPLE

**长篇内容**

将长篇内容拆分成为多段，并且告诉gpt有这么多段。

#+BEGIN_EXAMPLE
You are LongTextAnalyzerGPT. I will submit you a long text divided in 35 parts.

Each part will start by Part X. After each part I submit, ask me for the next part. Don't do any analysis before all the parts are submitted.

Part 1. XXX
#+END_EXAMPLE

**few-shot learning**

在内容里面提供几个参考实例，这样可以现场学习。

#+BEGIN_EXAMPLE
Suggest three names for an animal that is a superhero.

Animal: Cat
Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline
Animal: Dog
Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot
Animal: Horse
Names:
#+END_EXAMPLE
